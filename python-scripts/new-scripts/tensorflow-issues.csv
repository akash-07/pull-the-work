number,title,labels,body,assignees,milestone,comments,created_at,author_association
16513,TF1.5.0 not working with CUDA 8.0,,"After upgrading to TF 1.5.0, when I import tensorflow, it raises:

```
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory
```

- System: Ubuntu 14.04.5 LTS (64 bit)
- Python: 2.7.6
- TensorFlow: tensorflow-gpu-1.5.0
- GPU: GeForce GTX TITAN
- CUDA: 8.0",0,,0,2018-01-28T10:24:08Z,NONE
16512,how to install ffmpeg in tensorflow 1.4 binary,,"hi
i want to install ffmpeg in tensorflow 1.4 binary , python 3.5 on ubuntu 16.04 , please help me how do i do ? 
the output type python -c ""from tensorflow.contrib import ffmpeg"" is ok dont have anly error , but i dont know why : 
from tensorflow.contrib import ffmpeg

i get error , 
>>>  from tensorflow.contrib import ffmpeg
  File ""<stdin>"", line 1
    from tensorflow.contrib import ffmpeg
    ^
IndentationError: unexpected indent
",0,,0,2018-01-28T07:56:25Z,NONE
16510,Feature Request: Make lstm2d.separable_lstm accept Dynamic Batch Sizes,,"Apparently, lstm2d.separable_lstm doesn't accept dynamic batch sizes (number of images). Whenever I set the shape of a `placeholder` to `(None, height, width, depth)` to be fed into the network , I get this error:

```
Traceback (most recent call last):
  File ""...\tensorflow\contrib\ndlstm\python\lstm2d.py"", line 159, in separable_lstm
    hidden = horizontal_lstm(images, nhidden)
  File ""...\tensorflow\contrib\ndlstm\python\lstm2d.py"", line 82, in horizontal_lstm
    sequence = images_to_sequence(images)
  File ""...\tensorflow\contrib\ndlstm\python\lstm2d.py"", line 47, in images_to_sequence
    [width, num_image_batches * height, depth])
TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'
```

Here's the test code I made:

```
import tensorflow as tf
import numpy as np

from tensorflow.contrib.ndlstm.python import lstm2d


class MultidimensionalRNNTest(tf.test.TestCase):
    def setUp(self):
        self.image_height = 32
        self.image_width = 1596
        self.batch_size = None
        self.depth = 1
        self.input_layer = tf.placeholder(tf.float32, [None, self.image_height, self.image_width, self.depth])

    def test_simple_mdrnn(self):
        net = lstm2d.separable_lstm(self.input_layer, 16)

    def test_image_to_sequence(self):
        net = lstm2d.separable_lstm(self.input_layer, 16)
        net = lstm2d.images_to_sequence(net)

    def test_stack_ndlstms(self):
        net = lstm2d.separable_lstm(self.input_layer, 16)
        net = lstm2d.separable_lstm(net, 16)


if __name__ == '__main__':
    tf.test.main()
```

I guess it would be nice to have `separable_lstm` accept dynamic batch sizes so it can be used effectively.",0,,0,2018-01-28T04:46:35Z,CONTRIBUTOR
16509,Fix typo,cla: yes,,0,,0,2018-01-28T04:20:20Z,CONTRIBUTOR
16508,Check more cpu features for Clang on Windows,cla: yes,"Clang on Windows will define `__SSE__`, `__SSE2__` and other macros.

#15990",0,,0,2018-01-28T03:08:58Z,CONTRIBUTOR
16507,"ResourceExhaustedError, when running UNET",,"My computer has a gpu GeForce 940MX installed. It has the Memory bandwidth 16.02 GB/s. I'm trying to train LUNA dataset using UNET model using following code.

	from __future__ import print_function

	import numpy as np
	from keras.models import Model
	from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
	from keras.layers import concatenate
	from keras.optimizers import Adam
	from keras.optimizers import SGD
	from keras.callbacks import ModelCheckpoint, LearningRateScheduler
	from keras import backend as K


	K.set_image_dim_ordering('th')  # Theano dimension ordering in this code

	img_rows = 512
	img_cols = 512

	smooth = 1.


	def dice_coef(y_true, y_pred):
		y_true_f = K.flatten(y_true)
		y_pred_f = K.flatten(y_pred)
		intersection = K.sum(y_true_f * y_pred_f)
		return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

	def dice_coef_np(y_true,y_pred):
		y_true_f = y_true.flatten()
		y_pred_f = y_pred.flatten()
		intersection = np.sum(y_true_f * y_pred_f)
		return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

	def dice_coef_loss(y_true, y_pred):
		return -dice_coef(y_true, y_pred)


	def get_unet():
		inputs = Input((1,img_rows, img_cols))
		conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
		conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)
		pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

		conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
		conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
		pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

		conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
		conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
		pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

		conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)
		conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
		pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

		conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)
		conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)

		#up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)
		up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=1)
		conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)
		conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)

		#up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)
		up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=1)
		conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)
		conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)

		#up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)
		up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=1)
		conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)
		conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)

		#up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)
		up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=1)
		conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)
		conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)

		conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)

		model = Model(inputs=inputs, outputs=conv10)

		model.compile(optimizer=Adam(lr=1.0e-5), loss=dice_coef_loss, metrics=[dice_coef])

		return model


	def train_and_predict(use_existing):
		print('-'*30)
		print('Loading and preprocessing train data...')
		print('-'*30)
		imgs_train = np.load(""C:/Users/hirplk/Desktop/unet/Luna2016-Lung-Nodule-Detection-master_new/DATA_PROCESS/scratch/cse/dual/cs5130287/Luna2016/output_final/""+""trainImages.npy"").astype(np.float32)
		imgs_mask_train = np.load(""C:/Users/hirplk/Desktop/unet/Luna2016-Lung-Nodule-Detection-master_new/DATA_PROCESS/scratch/cse/dual/cs5130287/Luna2016/output_final/""+""trainMasks.npy"").astype(np.float32)

		imgs_test = np.load(""C:/Users/hirplk/Desktop/unet/Luna2016-Lung-Nodule-Detection-master_new/DATA_PROCESS/scratch/cse/dual/cs5130287/Luna2016/output_final/""+""testImages.npy"").astype(np.float32)
		imgs_mask_test_true = np.load(""C:/Users/hirplk/Desktop/unet/Luna2016-Lung-Nodule-Detection-master_new/DATA_PROCESS/scratch/cse/dual/cs5130287/Luna2016/output_final/""+""testMasks.npy"").astype(np.float32)
		
		mean = np.mean(imgs_train)  # mean for data centering
		std = np.std(imgs_train)  # std for data normalization

		imgs_train -= mean  # images should already be standardized, but just in case
		imgs_train /= std

		print('-'*30)
		print('Creating and compiling model...')
		print('-'*30)
		model = get_unet()
		# Saving weights to unet.hdf5 at checkpoints
		model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', save_best_only=True)
		#
		# Should we load existing weights? 
		# Set argument for call to train_and_predict to true at end of script
		if use_existing:
			model.load_weights('./unet.hdf5')
			
		# 
		# The final results for this tutorial were produced using a multi-GPU
		# machine using TitanX's.
		# For a home GPU computation benchmark, on my home set up with a GTX970 
		# I was able to run 20 epochs with a training set size of 320 and 
		# batch size of 2 in about an hour. I started getting reseasonable masks 
		# after about 3 hours of training. 
		#
		print('-'*30)
		print('Fitting model...')
		print('-'*30)
		model.fit(imgs_train, imgs_mask_train, batch_size=50, epochs=10, verbose=1, shuffle=True,
				  callbacks=[model_checkpoint])

		# loading best weights from training session
		print('-'*30)
		print('Loading saved weights...')
		print('-'*30)
		model.load_weights('./unet.hdf5')

		print('-'*30)
		print('Predicting masks on test data...')
		print('-'*30)
		num_test = len(imgs_test)
		imgs_mask_test = np.ndarray([num_test,1,512,512],dtype=np.float32)
		for i in range(num_test):
			imgs_mask_test[i] = model.predict([imgs_test[i:i+1]], verbose=0)[0]
		np.save('masksTestPredicted.npy', imgs_mask_test)
		mean = 0.0
		for i in range(num_test):
			mean+=dice_coef_np(imgs_mask_test_true[i,0], imgs_mask_test[i,0])
		mean/=num_test
		print(""Mean Dice Coeff : "",mean)

	if __name__ == '__main__':
		train_and_predict(False)
		
But when running it using GPU I'm getting the following error.

	Warning (from warnings module):
	  File ""C:\Research\Python_installation\lib\site-packages\h5py\__init__.py"", line 36
		from ._conv import register_converters as _register_converters
	FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
	Using TensorFlow backend.
	------------------------------
	Loading and preprocessing train data...
	------------------------------
	------------------------------
	Creating and compiling model...
	------------------------------
	------------------------------
	Fitting model...
	------------------------------
	Epoch 1/10
	Traceback (most recent call last):
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\client\session.py"", line 1327, in _do_call
		return fn(*args)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\client\session.py"", line 1306, in _run_fn
		status, run_metadata)
	  File ""C:\Research\Python_installation\lib\contextlib.py"", line 66, in __exit__
		next(self.gen)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
		pywrap_tensorflow.TF_GetCode(status))
	tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[50,32,512,512]
		 [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=""NCHW"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](_arg_input_1_0_2/_261, conv2d_1/kernel/read)]]
		 [[Node: loss/mul/_273 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3022_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

	During handling of the above exception, another exception occurred:

	Traceback (most recent call last):
	  File ""C:\Users\hirplk\Desktop\unet\DSB3Tutorial-master\tutorial_code\LUNA_train_unet.py"", line 150, in <module>
		train_and_predict(False)
	  File ""C:\Users\hirplk\Desktop\unet\DSB3Tutorial-master\tutorial_code\LUNA_train_unet.py"", line 127, in train_and_predict
		callbacks=[model_checkpoint])
	  File ""C:\Research\Python_installation\lib\site-packages\keras\engine\training.py"", line 1657, in fit
		validation_steps=validation_steps)
	  File ""C:\Research\Python_installation\lib\site-packages\keras\engine\training.py"", line 1213, in _fit_loop
		outs = f(ins_batch)
	  File ""C:\Research\Python_installation\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2357, in __call__
		**self.session_kwargs)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\client\session.py"", line 895, in run
		run_metadata_ptr)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\client\session.py"", line 1124, in _run
		feed_dict_tensor, options, run_metadata)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\client\session.py"", line 1321, in _do_run
		options, run_metadata)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\client\session.py"", line 1340, in _do_call
		raise type(e)(node_def, op, message)
	tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[50,32,512,512]
		 [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=""NCHW"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](_arg_input_1_0_2/_261, conv2d_1/kernel/read)]]
		 [[Node: loss/mul/_273 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3022_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

	Caused by op 'conv2d_1/convolution', defined at:
	  File ""<string>"", line 1, in <module>
	  File ""C:\Research\Python_installation\lib\idlelib\run.py"", line 124, in main
		ret = method(*args, **kwargs)
	  File ""C:\Research\Python_installation\lib\idlelib\run.py"", line 351, in runcode
		exec(code, self.locals)
	  File ""C:\Users\hirplk\Desktop\unet\DSB3Tutorial-master\tutorial_code\LUNA_train_unet.py"", line 150, in <module>
		train_and_predict(False)
	  File ""C:\Users\hirplk\Desktop\unet\DSB3Tutorial-master\tutorial_code\LUNA_train_unet.py"", line 106, in train_and_predict
		model = get_unet()
	  File ""C:\Users\hirplk\Desktop\unet\DSB3Tutorial-master\tutorial_code\LUNA_train_unet.py"", line 39, in get_unet
		conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
	  File ""C:\Research\Python_installation\lib\site-packages\keras\engine\topology.py"", line 603, in __call__
		output = self.call(inputs, **kwargs)
	  File ""C:\Research\Python_installation\lib\site-packages\keras\layers\convolutional.py"", line 164, in call
		dilation_rate=self.dilation_rate)
	  File ""C:\Research\Python_installation\lib\site-packages\keras\backend\tensorflow_backend.py"", line 3195, in conv2d
		data_format=tf_data_format)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 672, in convolution
		op=op)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 338, in with_space_to_batch
		return op(input, num_spatial_dims, padding)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 664, in op
		name=name)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 131, in _non_atrous_convolution
		name=name)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 397, in conv2d
		data_format=data_format, name=name)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
		op_def=op_def)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\framework\ops.py"", line 2630, in create_op
		original_op=self._default_original_op, op_def=op_def)
	  File ""C:\Research\Python_installation\lib\site-packages\tensorflow\python\framework\ops.py"", line 1204, in __init__
		self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

	ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50,32,512,512]
		 [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=""NCHW"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](_arg_input_1_0_2/_261, conv2d_1/kernel/read)]]
		 [[Node: loss/mul/_273 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3022_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]


Can someone please kindly explain me the reason behind this error, ResourceExhaustedError. Is it because that the memory of GPU is not enough to load the dataset. This worked fine without GPU. But took around 6 hours to finish one epoch",0,,0,2018-01-28T01:43:47Z,NONE
16506,Feature request: Have Estimator display Loss and Metrics for Every Epoch and not Every Step,,"Most of the papers I’ve read measure the time it takes to train a model with every epoch and not every step. If it isn’t possible to display the loss only for every epoch, I think it would be nice to print when an epoch has passed.",0,,0,2018-01-28T00:03:46Z,CONTRIBUTOR
16505,Remove BOM,cla: yes,"These two files started with ""Byte Order Mark"" `<U+FEFF>` which we don't want.",0,,0,2018-01-27T22:53:53Z,CONTRIBUTOR
16504,Issue propagating gradients through tf.while_loop,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu wheezy

- **TensorFlow installed from (source or binary)**:
pip

- **TensorFlow version (use command below)**:
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-4-g9283868
tf.COMPILER_VERSION = v1.4.0-4-g9283868
Sanity check: array([1], dtype=int32)

- **Python version**: 
3.5

### Describe the problem

I've found a few issues when trying to propagate gradients through tf.while_loops.

One issue is ops like this inside the loop body break gradients 
```k = tf.Print( k + 1, [k + 1, eta, loss( w_n ), chg_w, G_inf], 'EG:: k, eta, loss(w), chg_w, G_inf = ' )```

but more concerningly, conjoined conditions such as this:
```tf.logical_and( k < max_its-1, chg_w > tol  )```
or even this
``` tf.cast( max_its-k, DTYPE) *(chg_w - tol)```
breaks the differentiablity across the while loop.


### Source code / logs
``` python
tf.reset_default_graph()
sess = tf.InteractiveSession()
g = tf.Graph().as_default()

max_its = 10
tol = 1e-3

c = tf.constant( np.arange(100), dtype=DTYPE)
w = tf.Variable( initial_value=np.ones(100),  dtype=DTYPE)/100
k = tf.Variable( 0, dtype=tf.int32 )
chg_w = tf.constant( np.inf, dtype=DTYPE )


def _eg_step( k, w, chg_w): 
    grad = tf.gradients( -tf.reduce_sum( w * c ) , w )[0]
    w_n = w * tf.exp( -0.1  * grad )
    w_n = w_n / tf.reduce_sum( w_n ) 
    chg_w = tf.reduce_sum( tf.abs( w_n - w) ) / tf.reduce_sum( tf.abs( w ) )
    k = k + 1
    **# !! this busts the differentiablity !!
    # k = tf.Print( k + 1, [k + 1, eta, loss( w_n ), chg_w, G_inf], 'EG:: k, eta, loss(w), chg_w, G_inf = ' )**
    return k, w_n, chg_w

def _continue_cond( k, w, chg_w, *args ):
    **# NOTE either of this conjoined conditions
    #        tf.logical_and( k < max_its-1, chg_w > tol  )
    # OR     tf.cast( max_its-k, DTYPE) *(chg_w - tol)
    # do no propagate gradients correctly**
    return  k < max_its # tf.logical_and( k < max_its-1, chg_w > tol  )

k, w, chg_w = tf.while_loop(
    cond=_continue_cond,  body=_eg_step,
    loop_vars=[k, w, chg_w],#, weights, losses, changes, etas, max_grads,],
    name='while_loop', parallel_iterations=1
)

# see if the gradient is propagated
tf.gradients( w, c)

```",0,,0,2018-01-27T20:10:04Z,NONE
16503,Enable multi-dimensional and axis support for tf.unique_with_counts,cla: yes,"This fix tries to address the issue raised in #16499 to bring multi-dimensional and axis support for `unique_with_counts`.

When `UniqueV2` kernel was added in #12952, it actually already implemented the multi-dimensional and axis support for `unique_with_counts` as well, just not registered.

This fix:
1. Register `UniqueWithCountsV2` kernel to have axis support.
2. Hide both `UniqueWithCounts` and `UniqueWithCountsV2`
3. Add python unique_with_counts wrapper to call `gen_array_ops._unique_with_counts`
4. If API review passes and the PR merges, `unique_with_counts` will switch to `gen_array_ops._unique_with_counts_v2` (in 3 weeks).
5. Add additional test cases for `gen_array_ops._unique_with_counts_v2`.

This fix fixes #16499.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",0,,0,2018-01-27T20:01:54Z,MEMBER
16502,Java Android API: No OpKernel was registered to support Op 'ListDiff',,"### System information
Android with Java API releases 1.4.0 and 1.5.0-rc1 (1.5 is not available yet)

### What I did
I have a graph that is applying a `tf.layers.dense` on a three dimensional tensor, which is applying a dense operation to the last dimension. Learning and execution on a Windows 10 and Ubuntu work fine.

Now I froze the model and put it on Android and receive the following error.

```
01-27 20:06:59.628 10481-11380/de.test.local W/System.err: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'ListDiff' with these attrs.  Registered devices: [CPU], Registered kernels:
01-27 20:06:59.628 10481-11380/de.test.local W/System.err:   <no registered kernels>
01-27 20:06:59.628 10481-11380/de.test.local W/System.err: 	 [[Node: model/logits/Tensordot/ListDiff = ListDiff[T=DT_INT32, out_idx=DT_INT32](model/logits/Tensordot/range, model/logits/Tensordot/add_1)]]
01-27 20:06:59.628 10481-11380/de.test.local W/System.err:     at java.util.concurrent.FutureTask.report(FutureTask.java:94)
01-27 20:06:59.628 10481-11380/de.test.local W/System.err:     at java.util.concurrent.FutureTask.get(FutureTask.java:164)
01-27 20:06:59.628 10481-11380/de.test.local W/System.err:     at de.test.service.TaskWorkerLoop$Loop.run(TaskWorkerLoop.java:71)
01-27 20:06:59.628 10481-11380/de.test.local W/System.err:     at java.lang.Thread.run(Thread.java:762)
01-27 20:06:59.629 10481-11380/de.test.local W/System.err: Caused by: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'ListDiff' with these attrs.  Registered devices: [CPU], Registered kernels:
01-27 20:06:59.629 10481-11380/de.test.local W/System.err:   <no registered kernels>
01-27 20:06:59.630 10481-11380/de.test.local W/System.err: 	 [[Node: model/logits/Tensordot/ListDiff = ListDiff[T=DT_INT32, out_idx=DT_INT32](model/logits/Tensordot/range, model/logits/Tensordot/add_1)]]
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java.lang.reflect.Constructor.newInstance0(Native Method)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java.lang.reflect.Constructor.newInstance(Constructor.java:430)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:565)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:646)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:704)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:195)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:210)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:459)
01-27 20:06:59.630 10481-11380/de.test.local W/System.err:     at java8.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:624)
...
```

Is there a reason for this kernel to be missing on Android? If not, can you please add it? And what could I do in the mean time to replace the dense layer?

Many thanks in advance!",0,,0,2018-01-27T19:15:48Z,CONTRIBUTOR
16501,"Define Cr, Fr, Shared, Var to resolved undefined names",cla: yes,"flake8 testing of https://github.com/tensorflow/tensorflow

$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__
```
./tensorflow/contrib/specs/python/specs_test.py:202:11: F821 undefined name 'Cr'
      _ = Cr
          ^
./tensorflow/contrib/specs/python/specs_test.py:204:28: F821 undefined name 'Cr'
      self.assertIsNotNone(Cr)
                           ^
./tensorflow/contrib/specs/python/specs_test.py:205:32: F821 undefined name 'Cr'
      self.assertTrue(callable(Cr(64, [3, 3])))
                               ^
./tensorflow/contrib/specs/python/specs_test.py:207:11: F821 undefined name 'Cr'
      _ = Cr
          ^
./tensorflow/contrib/specs/python/specs_test.py:215:13: F821 undefined name 'Var'
        v = Var(""test_var"",
            ^
./tensorflow/contrib/specs/python/specs_test.py:232:13: F821 undefined name 'Shared'
        f = Shared(Fr(100))
            ^
./tensorflow/contrib/specs/python/specs_test.py:232:20: F821 undefined name 'Fr'
        f = Shared(Fr(100))
                   ^
```",0,,0,2018-01-27T18:22:13Z,CONTRIBUTOR
16500,contrib/learn: Typo in variable name x_exrta --> x_extra,cla: yes,"flake8 testing of https://github.com/tensorflow/tensorflow

$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__
```
./tensorflow/contrib/learn/python/learn/datasets/synthetic.py:156:32: F821 undefined name 'x_extra'
    spir_x = np.append(spir_x, x_extra)
                               ^
```",1,,2,2018-01-27T17:58:50Z,CONTRIBUTOR
16499,Extend tf.unique_with_counts to multi-dimensional tensors,,"I'm trying to solve KNN using tensorflow. After I get the K neighbours for N vectors, I have a N by K tensor. Now, for each vector in N, I need to use [```tf.unique_with_counts```][1] to find the majority vote. However, I cannot iterate in a tensor and I cannot run [```tf.unique_with_counts```][1] with a multi-dimensional tensor. It keeps giving me ```InvalidArgumentError (see above for traceback): unique expects a 1D vector.```

Why can't tf support multi-demsional input?

Example:

    def knnVote():
    '''
    KNN using majority vote
    '''
    #nearest indices
    A = tf.constant([1, 1, 2, 4, 4, 4, 7, 8, 8])
    nearest_k_y, idx, votes = tf.unique_with_counts(A)
    print(""y"", nearest_k_y.eval())
    print(""idx"", idx.eval())
    print(""votes"", votes.eval())
    majority = tf.argmax(votes)
    predict_res = tf.gather(nearest_k_y, majority)
    
    
    print(""majority"", majority.eval())
    print(""predict"", predict_res.eval())
    return predict_res

Result:

    y [1 2 4 7 8]
    idx [0 0 1 2 2 2 3 4 4]
    votes [2 1 3 1 2]
    majority 2
    predict 4

But how can I extend this to N by D input A, such as the case when ```A = tf.constant([[1, 1, 2, 4, 4, 4, 7, 8, 8],
[2, 2, 3, 3, 3, 4, 4, 5, 6]])```

  [1]: https://www.tensorflow.org/api_docs/python/tf/unique_with_counts",0,,1,2018-01-27T16:43:22Z,NONE
16498,Bounding box do not remove,,"Hi there,
After I detected my tv, it showed up but when i move it to other place, it do not remove the bounding box even though i put my camera on the table. Is this a bug?

![2018-01-28-00-34-50](https://user-images.githubusercontent.com/32919949/35474032-9eb4827e-03c3-11e8-8768-c4c81f9ad391.png)
",0,,0,2018-01-27T16:39:37Z,NONE
16496,"Feature Suggestion: ""Float-bit-strings""",,"### System information (Not really relevant ...)
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: 8 (?)
- **GPU model and memory**: GTX 1070
- **Exact command to reproduce**: NA

### Summary

This proposes the use of what I call ""float-bit-strings"" or ""float-bits"" instead of one-hot-encoded arrays so as to greatly reduce the memory and computational usage e.g. in language models.

I don't think this preliminary discussion belongs on StackOverflow so I hope it is OK to post it here. It is a new feature that could be added to TensorFlow. There's quite likely somebody on the TensorFlow dev-team or in the community who has already thought of this. But I have searched the internet and cannot find any mentioning of a similar idea.


### Background

I have started looking at language-models using e.g. LSTM and encoder-decoder architectures. There are some aspects that seem to be incredibly wasteful and limiting. Let me briefly describe this and please forgive me if I am ignorant, I have only spent a week or two on studying LSTM and language models so far :-)

For example in Machine Translation we typically have the text-data for the source- and target-languages as lists of integer-tokens, where each integer maps to a word in the vocabulary. There may be e.g. 100k different words so these integer-tokens can take on values between zero and 100k. This data cannot be input directly to a Neural Network so we use an embedding layer to convert these integers to n-dimensional vectors with values between zero and one, according to a mapping-function that may either be loaded from disk or trained along with the rest of the Neural Network; if I understand correctly.

For the decoder in a language model, we have a similar problem where we must somehow convert integer-tokens to data that the neural network can work on. A typical way of doing this seems to be a one-hot encoding; if I understand correctly. (This could also be done for the encoder-part, but it doesn't seem to be necessary).

I can't figure out what the max-size of one-hot encodings are in TensorFlow and whether it can even handle 100k one-hot encoded tensors. But it is obviously an extremely wasteful data-mapping. For example, for a vocab of 100k words we only need 17-bits (log2(100k)) to represent each integer-token - but for a one-hot encoding using 32-bit floats we need 32 x 100k bits!

I can't figure out what people normally do, but it seems like the common practice is to limit the vocab to a smaller number of words, e.g. 1k or 10k. It appears that Google Translate runs on multiple GPU's and maybe that's why they can handle extremely large vocabs with one-hot encoded tensors?


### Float-bit-strings

I thought it might be possible to use a bit-string-like representation inside a TensorFlow model. I have searched the internet and cannot find anyone who has proposed a similar idea.

The idea is to convert each integer-token to what I call a ""float-bit-string"" or ""float-bits"". For example, the number 123 has the bit-string 01111011. We can then make a corresponding tensor with floats [0., 1., 1., 1., 1., 0., 1., 1.] and input this to the TensorFlow model.

In a language model we would then have to input and output these ""float-bits"" instead of one-hot encoded arrays. This would dramatically reduce the memory and computational requirements of the models.


### Test

I have hacked together a little test using numpy and Keras / TensorFlow. The idea is to see if we can learn to map integers x with values between 0 and 10k to y = 123 * x using these ""float-bit"" encodings. And it works as you can see by running the code further below! That is perhaps not a surprise as neural networks are general function approximators, but it's not always that they work according to theory :-)

However, the network cannot learn the arithmetic mapping of e.g. y = 123 * x when x and y are ""float-bits"". This means it cannot generalize to data it hasn't seen during training in the arithmetic manner we might expect. But I don't think that is necessary for use in e.g. language models where we merely want to be able to map some tensor from e.g. an LSTM to an integer-token from the vocabulary.


### Loss Functions

I have tested this with both MSE and binary cross-entropy in Keras, which unfortunately isn't documented so I'm not completely sure what it does. But in both cases it works and the model trains to get the bit-wise mapping correct.

There might be cases where you are more concerned about the MSE between the actual integer-values instead of their ""float-bit-string"" representations, in which case we would need a TensorFlow method to convert ""float-bits"" to integers and then take the MSE of the resulting integer and the true integer from the data-set. This is not relevant for language models, because the proximity of integer-keys do not correspond to words that are necessarily similar in meaning. But it could be useful in other applications.


### TensorFlow Implementation

In order to make this work in TensorFlow it seems that we just need a couple of TensorFlow-methods for converting between integers and ""float-bit-strings"". I have hacked this together using numpy but I'm sure somebody on the dev-team can make a super-fast native TensorFlow implementation. Then we just need a wrapper in Keras and that might be enough to do e.g. language models with gigantic vocabs.


### Test-Code

    import numpy as np
    from tensorflow.python.keras.models import Sequential
    from tensorflow.python.keras.layers import InputLayer
    from tensorflow.python.keras.layers import Dense
    from tensorflow.python.keras.optimizers import RMSprop
    
    
    # Number of bits to use in our ""float-bit-strings"".
    num_bits = 32
    
    def int_to_floatbits(value):
        """"""
        Convert a single integer value to an array of 0.0 and 1.0 floats
        corresponding to the bit-string.
    
        Example: value==123 gives [0.  ... 0.  1.  1.  1.  1.  0.  1.  1.]
        """"""
    
        # Convert the integer value to a bit-string.
        # NOTE: This has been fixed to 32-bit length.
        bitstr = ""{0:032b}"".format(value)
    
        # Convert the bit-string to an array of equivalent float-values.
        floatbits = np.array([1.0 if bit == '1' else 0.0 for bit in bitstr])
    
        return floatbits
    
    
    def floatbits_to_strbits(floatbits):
        """"""
        Convert an array of floats to a bit-string.
        A float value greater than 0.5 results in 1.0
        and a float value less or equal to 0.5 results in 0.0
    
        Example: [0.1, 0.49, 0.51, 0.9, 1.1, -2.3] gives ""001110""
        """"""
    
        # Convert the float-array to a list of bit-characters '0' or '1'.
        charbits = ['1' if floatbit > 0.5 else '0' for floatbit in floatbits]
    
        # Convert the bit-characters to a string.
        strbits = """".join(charbits)
    
        return strbits
    
    def floatbits_to_int(floatbits):
        """"""
        Convert a float-array to an integer, assuming each element
        of the float-array corresponds to a bit.
        
        Example: [0.1, 0.49, 0.51, 0.9, 1.1, -2.3] corresponds to
        the bit-string ""001110"" which is the integer 14.
        """"""
    
        # Convert the float-array to a bit-string.
        strbits = floatbits_to_strbits(floatbits=floatbits)
    
        # Convert the bit-string to an integer value.
        value = int(strbits, base=2)
    
        return value
    
    
    # Various tests of the above functions.
    if True:
        foo = int_to_floatbits(123)
        print(foo)
        print(floatbits_to_strbits(foo))
        print(floatbits_to_int(foo))
    
        bar = [0.3,  0.9,  0.8,  0.51,  0.501,  0.4999,  0.999,  1.1]
        print(floatbits_to_strbits(bar))
        print(floatbits_to_int(bar))
    
        baz = [0.1, 0.49, 0.51, 0.9, 1.1, -2.3]
        print(floatbits_to_strbits(baz))
        print(floatbits_to_int(baz))
    
    # quit()
    
    # We will now train a TensorFlow / Keras model
    # that maps integers between 0 and 10000 to
    # the same numbers multiplied by 123.
    # If we were to use one-hot encoding then we would
    # need 10000 inputs to the Neural Network and
    # 1230000 outputs if using the full output range.
    # Using ""bit-strings"" encoded as floats, we only need
    # 14 bits for the input and 21 bits for the output.
    # We round it up to 32-bits.
    
    # The dataset as integers,
    # we want the Neural Network to map from x to y.
    x_int = np.arange(10000, dtype=int)
    y_int = 123 * x_int
    
    # Convert the dataset to ""float-bit-strings"" (aka. float-bits).
    x = np.array(list(map(int_to_floatbits, x_int)))
    y_true = np.array(list(map(int_to_floatbits, y_int)))
    
    # Check the mapping is correct. E.g. if the number of required bits
    # exceeds num_bits then these may not create numpy matrices correctly.
    if False:
        print(x.shape)
        print(y_true.shape)
        print(x[0:10])
        print(y_true[0:10])
    
    # Start construction of the Keras Sequential model.
    model = Sequential()
    
    # Add an input layer to the model.
    model.add(InputLayer(input_shape=(num_bits,)))
    
    # Fully-connected / dense layers with ReLU-activation.
    model.add(Dense(512, activation='relu'))
    model.add(Dense(512, activation='relu'))
    
    # Last fully-connected / dense layer with sigmoid-activation
    # so the output is between 0.0 and 1.0
    model.add(Dense(num_bits, activation='sigmoid'))
    
    optimizer = RMSprop(lr=1e-3)
    
    if True:
        # Loss is MSE.
        model.compile(optimizer=optimizer,
                      loss='mean_squared_error')
    else:
        # Loss is Binary Crossentropy, but also report MSE.
        model.compile(optimizer=optimizer,
                      loss='binary_crossentropy',
                      metrics=['mse'])
    
    epochs = 50
    
    if True:
        # Fit the model using the entire data-set.
        model.fit(x, y_true, epochs=epochs)
    else:
        # Fit the model using the data-set split into training and validation.
        # You will see that the validation-error is high so the model
        # has not learned the arithmetic function of the data-set.
        model.fit(x, y_true, epochs=epochs, validation_split=0.2)
    
    # Use the model to predict the output for a part of the data-set.
    y_pred = model.predict(x[0:10])
    
    # The true output for this part of the data-set.
    y_true_subset = y_true[0:10]
    
    # Map the ""float-bit-strings"" to integers.
    y_pred_int = list(map(floatbits_to_int, y_pred))
    y_true_int = list(map(floatbits_to_int, y_true_subset))
    
    # Print the predicted and true integers.
    print(*zip(y_pred_int, y_true_int))
    
    # Round the float-bit-strings to 2 decimals for pretty printing.
    def rounded(numbers):
        return np.array([[""{:.2f}"".format(x) for x in row] for row in numbers])
    y_pred_rounded = rounded(y_pred)
    y_true_rounded = rounded(y_true_subset)
    
    # Print the predicted and true float-bit-strings.
    # (I know it is bad to reuse the same variable-names here ...)
    for y_pred_int, y_true_int, y_pred_rounded, y_true_rounded \
        in zip(y_pred_int, y_true_int, y_pred_rounded, y_true_rounded):
    
        print(y_true_int, ""\t"", y_true_rounded)
        print(y_pred_int, ""\t"", y_pred_rounded)
        print()


### Output

True integer and true ""float-bit-string"" (note that the numbers are all exactly 0.00 or 1.00):

	738 	 ['0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '1.00' '0.00' '1.00' '1.00' '1.00' '0.00' '0.00' '0.00' '1.00' '0.00']

Predicted integer and predicted ""float-bit-string"" (note that the numbers a **not** all exactly 0.00 or 1.00):

	738 	 ['0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.00' '0.03' '0.00' '0.00' '0.00' '0.01' '0.00' '0.00' '0.00' '0.00' '0.99' '0.00' '1.00' '1.00' '1.00' '0.00' '0.00' '0.00' '1.00' '0.00']
",0,,0,2018-01-27T15:23:29Z,CONTRIBUTOR
16494,Enable [no]unroll for Clang on Windows,cla: yes,#15990,0,,0,2018-01-27T14:55:19Z,CONTRIBUTOR
16493,"Keras ""Output missing from loss dictionary""",,"I think that this warning can be rephrased:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/engine/training.py#L640-L641

Some outputs could be consumed as TB summary and not involved in any loss. 
Especially when you use an estimator converted from a tf.keras model  you have not the explicit control of the model_fn for placing summaries. 

So I suppose that one of the entry point for connecting summaries to the graph is the tf.train.SessionRunHook.

I.e. you can produce the output from the Dataset api, consume it as TB summary in the SessionRunHook without using it in any loss.

See also https://github.com/tensorflow/tensorflow/issues/14879#issuecomment-351996902 

/cc @fchollet ",0,,0,2018-01-27T14:50:45Z,NONE
16492,Clang on Windows will define __BYTE_ORDER__ etc. for us,cla: yes,#15990,0,,0,2018-01-27T14:42:49Z,CONTRIBUTOR
16491,Remove all_opensource_files,cla: yes,"Fixes #15758
@gunan /cc
@yifeif /cc",0,,1,2018-01-27T12:57:59Z,CONTRIBUTOR
16490,Tflite windows,cla: yes,"Hi,

I've ported tensorflow lite to compile with msvc for my own development purposes. It was relatively easy to get it to compile with Visual Studio 2017. The main differences/issues were:

I chose to use cmake since I'm not so familiar with bazel. I'm hoping the CMakeLists.txt file can be used for other purposes than just compiling for msvc.
needed latest version of gemmlowp which is not dependent on POSIX functionality
compiler errors due to narrowing conversions double -> float due to lack of ""f"" suffix on float numbers in unit tests
Convolution generic optimized takes prohibitively long to compile with msvc
added an operating systems abstraction layer on top of some of the OS functions which are used such as mmap files and loading of dynamic libraries
All unit tests pass except for the ones with have the ""EXPECT_DEATH"" macro. The testdata filepaths in model_test.cc also need to be made cross platform.

the cmake command i used to compile with visual studio 2017 on my windows machine:
`
cmake -G""Visual Studio 15 2017 Win64"" -DMSVC_RUNTIME=static -DGTEST_LIB_DIR=""C:/SDKS/googletest/lib"" -DGMOCK_LIB_DIR=""C:/SDKS/googletest/lib"" ..\tensorflow\contrib\lite`
",0,,0,2018-01-27T12:17:25Z,CONTRIBUTOR
16489,Fix document typo,cla: yes,Fix TFLite custom op typo,0,,0,2018-01-27T11:57:09Z,NONE
16488,Travis trusty Ubuntu 14.04.5: module compiled against API version 0xc but this version of numpy is 0xb,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Travis trusty, Ubuntu 14.04.5
- **TensorFlow installed from (source or binary)**: binary, pip
- **TensorFlow version (use command below)**: latest pip (I guess 1.5.0)
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: GCC 4.8.4
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: ...

### Describe the problem

```
$ python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
RuntimeError: module compiled against API version 0xc but this version of numpy is 0xb
ImportError: numpy.core.multiarray failed to import
ImportError: numpy.core.umath failed to import
ImportError: numpy.core.umath failed to import
2018-01-26 23:12:12.304782: F tensorflow/python/lib/core/bfloat16.cc:664] Check failed: PyBfloat16_Type.tp_base != nullptr 
/home/travis/.travis/job_stages: line 57:  2555 Aborted                 (core dumped) python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
```

### Source code / logs

See the [Travis log](https://travis-ci.org/rwth-i6/returnn/jobs/333916514).

",0,,1,2018-01-27T11:45:04Z,NONE
16486,Change RELEASE.md to specify CUDA 9.0,cla: yes,PR for https://github.com/tensorflow/tensorflow/issues/16348 (tinyest PR ever?),0,,3,2018-01-27T09:17:33Z,NONE
16485,resolve undefined name array_ops,cla: yes,"flake8 testing of https://github.com/tensorflow/tensorflow on Python 2.7.14

$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__
```
./tensorflow/contrib/framework/python/ops/accumulate_n_v2.py:94:12: F821 undefined name 'array_ops'
    return array_ops.identity(inputs[0], name=name)
           ^
```",0,,0,2018-01-27T09:07:33Z,CONTRIBUTOR
16484,use gather_nd to _gather_states in LSTMBlockWapper & fix SRU call return type,cla: yes,no need for calculate mod_indices and reshape data .,0,,0,2018-01-27T08:52:23Z,NONE
16483,Test case for session_partial_run_test.py is getting failed ,,"I tried running file `session_partial_run_test.py`, It throws an error with following two failed exception.

```
======================================================================
FAIL: testRunAndPartialRunDist (__main__.PartialRunTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""g:/tensorflow/tensorflow/python/client/session_partial_run_test.py"", line 258, in testRunAndPartialRunDist
    self.RunTestRunAndPartialRun(session.Session(server.target))
  File ""g:/tensorflow/tensorflow/python/client/session_partial_run_test.py"", line 123, in RunTestRunAndPartialRun
    self.assertEqual(r1, r2)
AssertionError: Lists differ: [4.0, 12.0] != [array([], dtype=float32), 12.0]

- [4.0, 12.0]
+ [array([], dtype=float32), 12.0]

======================================================================
FAIL: testRunAndPartialRunDist (__main__.PartialRunWithCApiTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""g:/tensorflow/tensorflow/python/client/session_partial_run_test.py"", line 258, in testRunAndPartialRunDist
    self.RunTestRunAndPartialRun(session.Session(server.target))
  File ""g:/tensorflow/tensorflow/python/client/session_partial_run_test.py"", line 123, in RunTestRunAndPartialRun
    self.assertEqual(r1, r2)
AssertionError: Lists differ: [4.0, 12.0] != [array([], dtype=float32), 12.0]

- [4.0, 12.0]
+ [array([], dtype=float32), 12.0]

----------------------------------------------------------------------
Ran 50 tests in 2.933s

FAILED (failures=2)
```

However, I tried debugging the code and found some scenarios in below function:

```
def RunTestRunAndPartialRun(self, sess):
    a = constant_op.constant(2.0, dtypes.float32)
    b = a * 2
    c = b * 3
    r1 = sess.run([b, c])
    h = sess.partial_run_setup([b, c], [])
    r2 = sess.partial_run(h, [b, c])
    self.assertEqual(r1, r2)
```

In 1st scenario, when `testRunAndPartialRunDirect()` is executed, the test gets succeed with h value:

`h = '->mul:0,mul_1:0//1/;0'`

In 2nd scenario, when `testRunAndPartialRunDist()` is executed, the test gets failed with h value:

`h = '0'`

and below following list are different since `assertEqual` is throwing an exception:

```
Lists differ: [4.0, 12.0] != [array([], dtype=float32), 12.0]

- [4.0, 12.0]
+ [array([], dtype=float32), 12.0] 
```

Looks like due to `zero` handle value, it started throwing an exception. Just need your suggestion if you are facing the same issue. Can I fix it by myself (I'd be happy to contribute)?

Guidance will be appreciated.

",0,,0,2018-01-27T08:38:04Z,CONTRIBUTOR
16482,Specify CUDA 9.0 version,cla: yes,The newest CUDA 9.1 is not supported by TF1.5. Sepecify CUDA 9.0 in order to prevent confusion,0,,3,2018-01-27T08:13:49Z,NONE
16481,Container localhost does not exist.,stat:awaiting response,"Hi,

I upgraded from 1.5.0-rc1 to the current master branch and I started receiving the following error:

```
2018-01-27 02:48:38.928667: W tensorflow/core/framework/op_kernel.cc:1201] OP_REQUIRES failed at lookup_table_op.cc:656 : Not found: Container localhost does not exist. (Could not find resource: localhost/hash_table_/Users/anthony/Development/GitHub/symphony-mt/temp/data/iwslt-15/vocab.vi_WHOLE_LINE_LINE_NUMBER)
2018-01-27 02:48:38.928786: W tensorflow/core/framework/op_kernel.cc:1201] OP_REQUIRES failed at iterator_ops.cc:855 : Not found: Container localhost does not exist. (Could not find resource: localhost/hash_table_/Users/anthony/Development/GitHub/symphony-mt/temp/data/iwslt-15/vocab.vi_WHOLE_LINE_LINE_NUMBER)
	 [[Node: Lookup_1/LookupTableFind = LookupTableFindV2[Tin=DT_STRING, Tout=DT_INT64](lookup_1_placeholder, input_1, lookup_1_placeholder_1)]]
Exception in thread ""main"" org.platanios.tensorflow.jni.NotFoundException: Container localhost does not exist. (Could not find resource: localhost/hash_table_/Users/anthony/Development/GitHub/symphony-mt/temp/data/iwslt-15/vocab.vi_WHOLE_LINE_LINE_NUMBER)
	 [[Node: Lookup_1/LookupTableFind = LookupTableFindV2[Tin=DT_STRING, Tout=DT_INT64](lookup_1_placeholder, input_1, lookup_1_placeholder_1)]]
	 [[Node: Model/Model/Iterator/Next = IteratorGetNext[output_shapes=[[?,?], [?], [?,?], [?,?], [?]], output_types=[DT_INT32, DT_INT32, DT_INT32, DT_INT32, DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Model/Model/Iterator)]]
```

It's hard to reproduce this error but a summary of the context is that I have a lookup table op inside a dataset map operator and I get this error when I try to execute the corresponding iterator ""GetNext"" op. I'm looking for information in how to parse and debug this error. I never explicitly set any containers for my variables or lookup tables (i.e., leave them to the default value; an empty string). Were there any changes introduced recently that could result in this error? Note that this happens with my Scala API but not with the Python API and so it may be that I haven't updated something in my code. I just don't really know where to look for this.

Thanks!",0,,2,2018-01-27T07:58:18Z,CONTRIBUTOR
16480,"CMake fixes, able generate reusable shared lib for C++ interface by find_package",cla: yes,"Due to some error in CLA checking https://github.com/tensorflow/tensorflow/pull/16394, a new pull request is made

I am currently working on the cmake files to generate shared library that allows users to develop with C++ interface.

It is easier to develop by adding export targets in tf_shared_lib.cmake, but I think in the future this function should be migrated to the main CMakeList.txt",0,,1,2018-01-27T04:32:49Z,CONTRIBUTOR
16477,"Windows Installation tutorial has wrong cuda version requirement, 9.0 required for latest version.",,"I just ran the installation validation and it's telling me I need 9.0, the tutorial says we must use 8.0. I don't have cheap access to Internet, now I have to find 1GB+ plus of data without paying $15 to use my phone's data. Please update the page to recommend 9.0.

Thank you.",0,,0,2018-01-27T01:54:37Z,NONE
16476,Tflite SSD Postprocessing,cla: yes,Adding custom operators to implement SSD postprocessing in mobilenet-ssd.,0,,0,2018-01-27T00:21:27Z,CONTRIBUTOR
16473,Fixing hard_sigmoid's documentation to match impl,cla: no,,1,,2,2018-01-26T21:25:42Z,NONE
16468,Keras multi input and estimator,"stat:awaiting tensorflower,type:bug/performance","If I've interpreted it correctly seems that there is some strange behavior with Keras multi inputs and the estimator.

- Why input layers are renamed with `_1` suffix?
- Why TB display a `_2` suffixed parallel sub-graph?

I've attached a snippet runnable on [colab](http://colab.research.google.com/) and the TB rendered image.

 
```import tensorflow as tf
from tensorflow import keras as ks
import numpy as np
from IPython.display import clear_output, Image, display, HTML

def strip_consts(graph_def, max_const_size=32):
    """"""Strip large constant values from graph_def.""""""
    strip_def = tf.GraphDef()
    for n0 in graph_def.node:
        n = strip_def.node.add() 
        n.MergeFrom(n0)
        if n.op == 'Const':
            tensor = n.attr['value'].tensor
            size = len(tensor.tensor_content)
            if size > max_const_size:
                tensor.tensor_content = ""<stripped %d bytes>""%size
    return strip_def

def show_graph(graph_def, max_const_size=32):
    """"""Visualize TensorFlow graph.""""""
    if hasattr(graph_def, 'as_graph_def'):
        graph_def = graph_def.as_graph_def()
    strip_def = strip_consts(graph_def, max_const_size=max_const_size)
    code = """"""
        <script src=""//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js""></script>
        <script>
          function load() {{
            document.getElementById(""{id}"").pbtxt = {data};
          }}
        </script>
        <link rel=""import"" href=""https://tensorboard.appspot.com/tf-graph-basic.build.html"" onload=load()>
        <div style=""height:600px"">
          <tf-graph-basic id=""{id}""></tf-graph-basic>
        </div>
    """""".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))

    iframe = """"""
        <iframe seamless style=""width:1200px;height:620px;border:0"" srcdoc=""{}""></iframe>
    """""".format(code.replace('""', '&quot;'))
    display(HTML(iframe))

class ExampleHook(tf.train.SessionRunHook):
    def __init__(self):
        print('Starting the session.')
        return

    def begin(self):
        g = tf.get_default_graph()
        show_graph(g)
        print('Starting the session.')
        
        #for op in tf.get_default_graph().get_operations():
          #print(str(op.name) )
        
my_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={""input_rgb"": np.array(np.random.rand(5,5,3).astype(np.float32)), ""input_gray"": np.array(np.random.rand(5,5,1).astype(np.float32)), 
       ""input_mix"": np.array(np.random.rand(5,5,1).astype(np.float32))},
    y= np.array(np.random.rand(5,5,1)),
      batch_size=1,
      num_epochs=1,
      shuffle=False)

input_rgb = ks.layers.Input(shape=(1,5, 5, 3), name=""input_rgb"")
input_gray = ks.layers.Input(shape=(1,5, 5, 1), name=""input_gray"")
input_mix = ks.layers.Input(shape=(1,5, 5, 1), name=""input_mix"")
rgb_gray = ks.layers.concatenate([input_rgb, input_gray, input_mix], name=""rbg_gray"")
x = ks.layers.Dense(1, activation='relu',name=""Dense_1"")(rgb_gray)
x = ks.layers.Dense(1, activation='softmax',name=""softmax"")(x)
model = ks.models.Model(
        inputs=[input_rgb, input_gray, input_mix],
        outputs=[x])
model.compile(loss={ 'softmax': 'binary_crossentropy'},optimizer=tf.keras.optimizers.Adam())


est = ks.estimator.model_to_estimator(
            keras_model=model)

model.summary()
print(model.input_names)
pred = list(est.predict(
    input_fn=my_input_fn,
    predict_keys=None,
    hooks=[ExampleHook()],
))
```
![tb](https://user-images.githubusercontent.com/1710528/35459923-5eca90b8-02e2-11e8-8248-764671141850.png)",0,,2,2018-01-26T20:52:39Z,NONE
16466,[Feature request] Adding a PR curves to canned estimators for (binary) classifiers,"stat:awaiting tensorflower,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
This is a feature request, and I'd be happy to **contribute** if you think it's a valuable addition. 
I have been using estimators both pre-made and custom for classification tasks. I like that sharing the use of a `head`  as defined in [tensorflow/python/estimator/canned/head.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/canned/head.py) allows both the canned models and the custom ones to share prediction and evaluation metrics for comparison, however currently it feels that some key metrics are missing, mainly PR curves which are fully supported by tensorboard.  Currently, the `head` constructor allows a list of thresholds, although they are not used by default. The problem is that when used, it creates scalar summaries for the precision and recall at each threshold, which is not that useful as in general one wants to compare how different models compare precision wise while fixing recall and the other way round.

Adding the PR summary op from [here](https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/pr_curve) would make the eval metrics more informative IMO.

Thanks for taking the time to read this!

### Source code / logs
Any code that uses pre-made estimator classifiers relies on the same head. [This](https://github.com/tensorflow/models/blob/master/official/wide_deep/wide_deep.py) is one example.",0,,1,2018-01-26T18:49:27Z,NONE
16465,bug with frame_step in tf.contrib.signal.frame or overlap_and_add (or am I doing something wrong?),,"### System information
- Based on example 
- Linux Ubuntu 16.04
- installed from binary
- v1.4.0-19-ga52c8d9, 1.4.1
- Python 2.7.14 |Anaconda custom (64-bit)| (default, Oct 16 2017, 17:29:19). IPython 5.4.1
- Cuda release 8.0, V8.0.61, cuDNN 6
- Geforce GTX 970M, Driver Version: 384.111
### Describe the problem
If I create frames in data with frame_length=1024, frame_step=256,
and overlap_add them with a hann_window, I'd expect the signal to be reconstructed perfectly. 
However there seems to be a scaling happening with a scale factor of 2x. 
If I use frame_length=1024, frame_step=512 then it reconstructs perfectly, which is unexpected.
frame_length=1024, frame_step=1024 works as expected.

I couldn't find a combination of frame_length=1024 and frame_step=? to reconstruct correctly with stft and inverse_stft.

### Source code / logs
Results
![22050 orig](https://user-images.githubusercontent.com/144230/35455525-2218c5bc-02ca-11e8-8f25-bd6fed567b3b.png)
![22050 frame l1024 s256](https://user-images.githubusercontent.com/144230/35455530-273d8712-02ca-11e8-974d-2fa150e2a454.png)
![22050 frame l1024 s512](https://user-images.githubusercontent.com/144230/35455531-2768357a-02ca-11e8-8cfc-cc0f418ae543.png)
![22050 frame l1024 s768](https://user-images.githubusercontent.com/144230/35455532-278243de-02ca-11e8-9d2b-f389dafe95d7.png)
![22050 frame l1024 s1024](https://user-images.githubusercontent.com/144230/35455533-27c4eb58-02ca-11e8-93f2-8450715c8fe8.png)
![22050 stft l1024 s256](https://user-images.githubusercontent.com/144230/35455538-2be571d0-02ca-11e8-916a-48df0ca30efa.png)
![22050 stft l1024 s512](https://user-images.githubusercontent.com/144230/35455539-2c06614c-02ca-11e8-89ef-ed86ed57ebe2.png)
![22050 stft l1024 s768](https://user-images.githubusercontent.com/144230/35455540-2c218fe4-02ca-11e8-8f07-fdb403269006.png)
![22050 stft l1024 s1024](https://user-images.githubusercontent.com/144230/35455541-2c3cde02-02ca-11e8-9df3-6dd4942b9d70.png)

```
from __future__ import print_function
from __future__ import division

import numpy as np
import scipy.io.wavfile
import tensorflow as tf
import math
import matplotlib.pyplot as plt


def plot(data, title, do_save=True):
    plt.figure(figsize=(20,5))
    plt.plot(data[:3*frame_length])
    plt.ylim([-1, 1])
    plt.title(title)
    if do_save: plt.savefig(title + '.png')
    plt.show()

def build_frame_test_graph():
    name = 'frame'
    input_T = tf.placeholder(tf.float32, [None]) 
    frames_T = tf.contrib.signal.frame(input_T, frame_length=frame_length, frame_step=frame_step)
    windowed_frames_T = frames_T * tf.contrib.signal.hann_window(frame_length, periodic=True)
    output_T = tf.contrib.signal.overlap_and_add(windowed_frames_T, frame_step=frame_step)
    return name, input_T, output_T

def build_stft_test_graph():
    name = 'stft'
    input_T = tf.placeholder(tf.float32, [None]) 
    spectrograms_T = tf.contrib.signal.stft(input_T, frame_length, frame_step)
    output_T = tf.contrib.signal.inverse_stft(spectrograms_T, frame_length, frame_step)
    return name, input_T, output_T

def test(fn):
    print('-'*80)
    tf.reset_default_graph()
    name, input_T, output_T = fn()

    title = ""{}.{}.l{}.s{}"".format(sample_rate, name, frame_length, frame_step)
    print(title)

    with tf.Session():
        output_data =  output_T.eval({input_T:input_data})

    plot(output_data, title)
    scipy.io.wavfile.write(title+'.wav', sample_rate, output_data)


frame_length = 1024
frame_step = 256
sample_rate = 22050

# generate input data sin wave at 440Hz with amplitude 1/2
input_data = np.float32(0.5*np.sin(np.linspace(0, math.pi*2*440, num=1*sample_rate)))
title = ""{}.orig"".format(sample_rate)
plot(input_data, title)
scipy.io.wavfile.write(title+'.wav', sample_rate, input_data)

for frame_step in [256, 512, 768, 1024]:
    test(build_frame_test_graph)
    test(build_stft_test_graph)

print('done.')
```",0,,0,2018-01-26T18:16:59Z,CONTRIBUTOR
16464,AssignAddVariableOp has no output,"stat:awaiting tensorflower,type:support","
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.5.0-rc1
- **Python version**: NA (Using Go bindings)
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 7.2.1
- **CUDA/cuDNN version**: 9.1 / 7.0
- **GPU model and memory**: GTX 1060 6GB
- **Exact command to reproduce**: See below


### Describe the problem
According to the docs, AssignAddVariableOp ""Outputs the incremented value, which can be used to totally order the increments to this variable."". Without this feature, I get non deterministic behavior when reading the value of the variable at the same time as I update it. However, at least in the Go bindings, it returns an operation which has no outputs. I can work around this problem by using two calls to `sess.Run()`, but this is inelegant.

### Source code / logs
```
package main

import (
	""fmt""

	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	""github.com/tensorflow/tensorflow/tensorflow/go/op""
)

func main() {
	s := op.NewScope()
	value1 := op.Const(s.SubScope(""zero""), float32(0))
	value2 := op.Const(s, float32(3.1415))
	handle := op.VarHandleOp(s, tf.Float, tf.ScalarShape())
	init := op.AssignVariableOp(s, handle, value1)
	update := op.AssignAddVariableOp(s, handle, value2)
	fmt.Println(""NumOutputs:"", update.NumOutputs())
	graph, err := s.Finalize()
	if err != nil {
		panic(err)
	}
	sess, err := tf.NewSession(graph, nil)
	if err != nil {
		panic(err)
	}
	_, err = sess.Run(nil, nil, []*tf.Operation{init})
	if err != nil {
		panic(err)
	}
	_, err = sess.Run(nil, []tf.Output{update.Output(0)}, nil)
	if err != nil {
		panic(err)
	}
}
```
```
$ go run assign_demo.go 
NumOutputs: 0
panic: Tried to fetch data for 'AssignAddVariableOp:0', which produces no output.  To run to a node but not fetch any data, pass 'AssignAddVariableOp:0' as an argument to the 'target_node_names' argument of the Session::Run API.

goroutine 1 [running]:
main.main()
	/home/isaac/go/src/github.com/is8ac/gotf/assign_demo.go:32 +0x448
exit status 2
```",0,,1,2018-01-26T17:33:42Z,NONE
16461,macOS mnist download error,,"```
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)
```
MacOS python3.6 is wrong
windows is right.


```
Traceback (most recent call last):
  File ""/Users/funny/Documents/AIML/test.py"", line 8, in <module>
    from tensorflow.examples.tutorials.mnist import input_data
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/framework_lib.py"", line 76, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 27, in <module>
    from tensorflow.python.framework import errors
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors.py"", line 22, in <module>
    from tensorflow.python.framework import errors_impl as _impl
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 27, in <module>
    from tensorflow.python.util import compat
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 130, in <module>
    remove_undocumented(__name__, _allowed_symbols)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/all_util.py"", line 103, in remove_undocumented
    should_have = make_all(module_name, doc_string_modules)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/all_util.py"", line 55, in make_all
    for m in _reference_pattern.finditer(doc_module.__doc__)
TypeError: expected string or bytes-like object
```",0,,0,2018-01-26T16:28:06Z,NONE
16460,Fix missing .,"awaiting testing (then merge),cla: no",,1,,3,2018-01-26T16:19:31Z,NONE
16456,'InputFnOps' object has no attribute 'receiver_tensors',stat:awaiting response,"
### System information
==TensorFlow installed from (source or binary)==
Source
== Python version ==
Python 2.7.13
== cat /etc/issue ==
Linux orion 4.9.0-3-amd64 #1 SMP Debian 4.9.30-2+deb9u5 (2017-09-19) x86_64 GNU/Linux
VERSION_ID=""9""
VERSION=""9 (stretch)""
== are we in docker ==
No
== compiler ==
c++ (Debian 6.3.0-18) 6.3.0 20170516
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a ==
Linux orion 4.9.0-3-amd64 #1 SMP Debian 4.9.30-2+deb9u5 (2017-09-19) x86_64 GNU/Linux
== check pips ==
numpy (1.12.1)
protobuf (3.5.1)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.8)
tensorflow-transform (0.3.1)
== check for virtualenv ==
True
== tensorflow import ==
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)
== env ==
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

### Describe the problem
I ran into some incompatibility issues running tf.estimator.DNNClassifier with tf.contrib.learn.InputFnOps and tf.contrib.learn.Experiment.  
There has been a separate [solved issue](https://github.com/tensorflow/transform/issues/36): 
I have tried the bundle version, but it doesn't work for me:
tensorflow==1.3
tensorflow_transform==0.3.1
six==1.10.0
However, if I switch to tf.contrib.learn.DNNClassifier, the issue go away.
It is also suggested to use tf.estimator.DNNClassifier rather than tf.contrib.learn.DNNClassifier.  I would like to get tf.estimator.DNNClassifier work.

### Source code / logs
```
def build_estimator(config):
    m = tf.estimator.DNNClassifier(
   # m = tf.contrib.learn.DNNClassifier(
    					config=config,
    					feature_columns=deep_columns,
                        hidden_units=[100, 100, 100],
                        n_classes=2,
                        optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)
                        )
    return m
```
```
def json_serving_input_fn():
	""""""Build the serving inputs.""""""
	inputs = {}
	for feat in INPUT_COLUMNS:
		inputs[feat.name] = tf.placeholder(shape=[None], dtype=feat.dtype)

	features = {
	  key: tf.expand_dims(tensor, -1)
	  for key, tensor in inputs.iteritems()
	}
	return tf.contrib.learn.InputFnOps(features, None, inputs)
```
```
def _experiment_fn(run_config, hparams):
    # num_epochs can control duration if train_steps isn't
    # passed to Experiment
    train_input = lambda: model.generate_input_fn(
        hparams.train_files,
        num_epochs=hparams.num_epochs,
        batch_size=hparams.train_batch_size,
    )
    # Don't shuffle evaluation data
    eval_input = lambda: model.generate_input_fn(
        hparams.eval_files,
        batch_size=hparams.eval_batch_size,
        shuffle=False
    )
    return tf.contrib.learn.Experiment(
        model.build_estimator(
            config=run_config
        )
```


Error message:
local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 440, in export_savedmodel
    serving_input_receiver.receiver_tensors,
AttributeError: 'InputFnOps' object has no attribute 'receiver_tensors'
",0,,1,2018-01-26T15:07:52Z,NONE
16455,Set training=True in BatchNormalization layer causes evaluation error in custom Estimator model,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu16.04
- **TensorFlow installed from (source or binary)**: pip install 
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**:  3.5.2
- **CUDA/cuDNN version**: 8.0/6
- **GPU model and memory**: GeForce 1080ti, 11G

### Describe the problem
I define a custom estimator model for classification following [this document](https://www.tensorflow.org/extend/estimators). **Cifar10** dataset is used for test and network framework is **xception** rewritten in tensorflow. But when using `estimator.train_and_evaluate()` to train and evaluate the model repeatedly, I find evaluation accuracy dones't improve while training accuracy is normally increasing with training. Inspired by tensorflow official [resnet estimator example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/resnet.py): <br>
```python
  with tf.variable_scope('conv_layer1'):
    net = tf.layers.conv2d(
        x,
        filters=64,
        kernel_size=7,
        activation=tf.nn.relu)
    net = tf.layers.batch_normalization(net)   # no training status, default is False
```
 
I turn off `training=is_training` in `tf.layers.batch_normalization()`, both training and evaluation do work normally. For estimator model_fn is used multiple times (see [issue 13895](https://github.com/tensorflow/tensorflow/issues/13895)),  so is this issue related to graph reuse in BN layer and if training status option could be set to enable BN layer to act differently during training and evaluation/predict?

BTW, same issue occurs when using `keras` or `slim` instead of `tf.layers` to construct network architecture.

### Source code / logs
**Network architecture:** <br>
```python
def tf_xception(features, input_shape, pooling=None, classes=2, is_training=True):
    # is_training = False  # manually set False to disable training option
    x = tf.layers.conv2d(features, 32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')
    x = tf.layers.batch_normalization(x, training=is_training, name='block1_conv1_bn')
    x = tf.nn.relu(x, name='block1_conv1_act')
    x = tf.layers.conv2d(x, 64, (3, 3), use_bias=False, name='block1_conv2')
    x = tf.layers.batch_normalization(x, training=is_training, name='block1_conv2_bn')
    x = tf.nn.relu(x, name='block1_conv2_act')

    residual = tf.layers.conv2d(x, 128, (1, 1), strides=(2, 2),
                      padding='same', use_bias=False)
    residual = tf.layers.batch_normalization(residual, training=is_training)

    x = tf.layers.separable_conv2d(x, 128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')
    x = tf.layers.batch_normalization(x, training=is_training, name='block2_sepconv1_bn')
    x = tf.nn.relu(x, name='block2_sepconv2_act')
    x = tf.layers.separable_conv2d(x, 128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')
    x = tf.layers.batch_normalization(x, training=is_training, name='block2_sepconv2_bn')

    x = tf.layers.max_pooling2d(x, (3, 3), strides=(2, 2), padding='same', name='block2_pool')
    x = tf.add(x, residual, name='block2_add')

    residual = tf.layers.conv2d(x, 256, (1, 1), strides=(2, 2),
                      padding='same', use_bias=False)
    residual = tf.layers.batch_normalization(residual, training=is_training)

    x = tf.nn.relu(x, name='block3_sepconv1_act')
    x = tf.layers.separable_conv2d(x, 256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')
    x = tf.layers.batch_normalization(x, training=is_training, name='block3_sepconv1_bn')
    x = tf.nn.relu(x, name='block3_sepconv2_act')
    x = tf.layers.separable_conv2d(x, 256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')
    x = tf.layers.batch_normalization(x, training=is_training, name='block3_sepconv2_bn')

    x = tf.layers.max_pooling2d(x, (3, 3), strides=(2, 2), padding='same', name='block3_pool')
    x = tf.add(x, residual, name=""block3_add"")

    residual = tf.layers.conv2d(x, 728, (1, 1), strides=(2, 2),
                      padding='same', use_bias=False)
    residual = tf.layers.batch_normalization(residual, training=is_training)

    x = tf.nn.relu(x, name='block4_sepconv1_act')
    x = tf.layers.separable_conv2d(x, 728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')
    x = tf.layers.batch_normalization(x, training=is_training, name='block4_sepconv1_bn')
    x = tf.nn.relu(x, name='block4_sepconv2_act')
    x = tf.layers.separable_conv2d(x, 728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')
    x = tf.layers.batch_normalization(x, training=is_training, name='block4_sepconv2_bn')

    x = tf.layers.max_pooling2d(x, (3, 3), strides=(2, 2), padding='same', name='block4_pool')
    x = tf.add(x, residual, name=""block4_add"")

    for i in range(8):
        residual = x
        prefix = 'block' + str(i + 5)

        x = tf.nn.relu(x, name=prefix + '_sepconv1_act')
        x = tf.layers.separable_conv2d(x, 728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')
        x = tf.layers.batch_normalization(x, training=is_training, name=prefix + '_sepconv1_bn')
        x = tf.nn.relu(x, name=prefix + '_sepconv2_act')
        x = tf.layers.separable_conv2d(x, 728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')
        x = tf.layers.batch_normalization(x, training=is_training, name=prefix + '_sepconv2_bn')
        x = tf.nn.relu(x, name=prefix + '_sepconv3_act')
        x = tf.layers.separable_conv2d(x, 728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')
        x = tf.layers.batch_normalization(x, training=is_training, name=prefix + '_sepconv3_bn')

        x = tf.add(x, residual, name=prefix+""_add"")

    residual = tf.layers.conv2d(x, 1024, (1, 1), strides=(2, 2),
                      padding='same', use_bias=False)
    residual = tf.layers.batch_normalization(residual, training=is_training)

    x = tf.nn.relu(x, name='block13_sepconv1_act')
    x = tf.layers.separable_conv2d(x, 728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')
    x = tf.layers.batch_normalization(x, training=is_training, name='block13_sepconv1_bn')
    x = tf.nn.relu(x, name='block13_sepconv2_act')
    x = tf.layers.separable_conv2d(x, 1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')
    x = tf.layers.batch_normalization(x, training=is_training, name='block13_sepconv2_bn')

    x = tf.layers.max_pooling2d(x, (3, 3), strides=(2, 2), padding='same', name='block13_pool')
    x = tf.add(x, residual, name=""block13_add"")

    x = tf.layers.separable_conv2d(x, 1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')
    x = tf.layers.batch_normalization(x, training=is_training, name='block14_sepconv1_bn')
    x = tf.nn.relu(x, name='block14_sepconv1_act')

    x = tf.layers.separable_conv2d(x, 2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')
    x = tf.layers.batch_normalization(x, training=is_training, name='block14_sepconv2_bn')
    x = tf.nn.relu(x, name='block14_sepconv2_act')
    # replace conv layer with fc
    x = tf.layers.average_pooling2d(x, (3, 3), (2, 2), name=""global_average_pooling"")
    x = tf.layers.conv2d(x, 2048, [1, 1], activation=None, name=""block15_conv1"")
    x = tf.layers.conv2d(x, classes, [1, 1], activation=None, name=""block15_conv2"")
    x = tf.squeeze(x, axis=[1, 2], name=""logits"")
    return x
```

**model_fn:** <br>
```python
def model_fn(features, labels, mode, params):
    # check if training stage
    if mode == tf.estimator.ModeKeys.TRAIN:
        is_training = True
    else:
        is_training = False
    input_tensor = features[""input""]
    logits = tf_xception(input_tensor, input_shape=(96, 96, 3), classes=10, is_training=is_training)
    probs = tf.nn.softmax(logits, name=""output_score"")
    predictions = tf.argmax(probs, axis=-1, name=""output_label"")
    onehot_labels = tf.one_hot(tf.cast(labels, tf.int32), 10)
    predictions_dict = {""score"": probs,
                        ""label"": predictions}
    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions_output = tf.estimator.export.PredictOutput(predictions_dict)
        return tf.estimator.EstimatorSpec(mode=mode,
                                          predictions=predictions_dict,
                                          export_outputs={
                                              tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: predictions_output
                                          })
    # calculate loss
    loss = tf.losses.softmax_cross_entropy(onehot_labels, logits)
    accuracy = tf.metrics.accuracy(labels=labels,
                                   predictions=predictions)
    if mode == tf.estimator.ModeKeys.TRAIN:
        lr = params.learning_rate
        # train optimizer
        optimizer = tf.train.RMSPropOptimizer(learning_rate=lr, decay=0.9)
        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
        tensors_to_log = {'batch_accuracy': accuracy[1]}
        logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=1000)
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          train_op=train_op,
                                          training_hooks=[logging_hook])
    else:
        eval_metric_ops = {""accuracy"": accuracy}
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          eval_metric_ops=eval_metric_ops)
```

**If the training status set True in training and False in evaluation**<br>
**train logs:**<br>
```
INFO:tensorflow:Saving checkpoints for 1 into train_episode5/model.ckpt.
INFO:tensorflow:loss = 2.3025837, step = 1
INFO:tensorflow:batch_accuracy = 0.109375
INFO:tensorflow:global_step/sec: 3.50983
INFO:tensorflow:loss = 2.3048878, step = 101 (28.492 sec)
INFO:tensorflow:Saving checkpoints for 185 into train_episode5/model.ckpt.
INFO:tensorflow:Loss for final step: 2.3093615.
...
INFO:tensorflow:Restoring parameters from train_episode5/model.ckpt-185
INFO:tensorflow:Saving checkpoints for 186 into train_episode5/model.ckpt.
INFO:tensorflow:loss = 2.2975698, step = 186
INFO:tensorflow:batch_accuracy = 0.09375
INFO:tensorflow:global_step/sec: 3.47248
INFO:tensorflow:loss = 2.3078504, step = 286 (28.798 sec)
INFO:tensorflow:Saving checkpoints for 374 into train_episode5/model.ckpt.
INFO:tensorflow:Loss for final step: 2.290754.
...
INFO:tensorflow:Restoring parameters from train_episode5/model.ckpt-374
INFO:tensorflow:Saving checkpoints for 375 into train_episode5/model.ckpt.
INFO:tensorflow:loss = 2.2987142, step = 375
INFO:tensorflow:batch_accuracy = 0.140625
INFO:tensorflow:global_step/sec: 3.50966
INFO:tensorflow:loss = 2.0407405, step = 475 (28.493 sec)
INFO:tensorflow:Saving checkpoints for 560 into train_episode5/model.ckpt.
INFO:tensorflow:Loss for final step: 2.1280906.
...
INFO:tensorflow:Restoring parameters from train_episode5/model.ckpt-560
INFO:tensorflow:Saving checkpoints for 561 into train_episode5/model.ckpt.
INFO:tensorflow:loss = 2.0747793, step = 561
INFO:tensorflow:batch_accuracy = 0.203125
INFO:tensorflow:global_step/sec: 3.31447
INFO:tensorflow:loss = 2.1767468, step = 661 (30.171 sec)
INFO:tensorflow:Saving checkpoints for 740 into train_episode5/model.ckpt.
INFO:tensorflow:Loss for final step: 1.9530052.
...
INFO:tensorflow:Restoring parameters from train_episode5/model.ckpt-740
INFO:tensorflow:Saving checkpoints for 741 into train_episode5/model.ckpt.
INFO:tensorflow:loss = 1.9676144, step = 741
INFO:tensorflow:batch_accuracy = 0.296875
INFO:tensorflow:global_step/sec: 3.50441
INFO:tensorflow:loss = 1.8766258, step = 841 (28.536 sec)
INFO:tensorflow:Saving checkpoints for 930 into train_episode5/model.ckpt.
INFO:tensorflow:Loss for final step: 1.884157.
...
INFO:tensorflow:Restoring parameters from train_episode5/model.ckpt-930
INFO:tensorflow:Saving checkpoints for 931 into train_episode5/model.ckpt.
INFO:tensorflow:loss = 1.8624167, step = 931
INFO:tensorflow:batch_accuracy = 0.296875
INFO:tensorflow:global_step/sec: 3.30778
INFO:tensorflow:loss = 1.7580669, step = 1031 (30.232 sec)
INFO:tensorflow:Saving checkpoints for 1112 into train_episode5/model.ckpt.
INFO:tensorflow:Loss for final step: 1.9509349.
...
```

**eval log:**
```
INFO:tensorflow:Saving dict for global step 170: accuracy = 0.099306434, global_step = 170, loss = 2.3029344
INFO:tensorflow:Saving dict for global step 348: accuracy = 0.11751261, global_step = 348, loss = 2.2920265
INFO:tensorflow:Saving dict for global step 528: accuracy = 0.13106872, global_step = 528, loss = 2.5031097
INFO:tensorflow:Saving dict for global step 697: accuracy = 0.085986756, global_step = 697, loss = 30.668789
INFO:tensorflow:Saving dict for global step 871: accuracy = 0.10009458, global_step = 871, loss = 47931.96
...
```
**accuracy round initial 0.1 and loss increase ridiculously !!!!**

**If training status set False in both stage:**<br>
**train log:** similar to above train log 

**eval log:** <br>
```
INFO:tensorflow:Saving dict for global step 185: accuracy = 0.1012768, global_step = 185, loss = 2.3037012
INFO:tensorflow:Saving dict for global step 374: accuracy = 0.10001576, global_step = 374, loss = 2.3124988
INFO:tensorflow:Saving dict for global step 560: accuracy = 0.20081967, global_step = 560, loss = 2.0881999
INFO:tensorflow:Saving dict for global step 740: accuracy = 0.26134932, global_step = 740, loss = 2.0297167
INFO:tensorflow:Saving dict for global step 930: accuracy = 0.26379257, global_step = 930, loss = 1.9529407
INFO:tensorflow:Saving dict for global step 1112: accuracy = 0.3454445, global_step = 1112, loss = 1.832811
```
",0,,0,2018-01-26T14:58:00Z,NONE
16453,Updated roadmap?,stat:awaiting tensorflower,The [TensorFlow roadmap](https://www.tensorflow.org/about/roadmap) was last updated a year ago (January 2017); could there be an update from the team on where TensorFlow is going in 2018?,0,,4,2018-01-26T11:28:52Z,NONE
16452,Semantic Segmentation API,"stat:awaiting tensorflower,type:feature","Hello, is there any plan to include Semantic Segmentation API in future Tensorflow releases, similar to [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection#tensorflow-object-detection-api) ?

There are other semantic segmentation repositories in Github, an awesome list is [here](https://github.com/mrgloom/awesome-semantic-segmentation), but I would like to see the implementation from Tensorflow organization.
Thanks",0,,2,2018-01-26T10:47:55Z,NONE
16446,use tflite bilinear op to resize input of label_image,"awaiting review,cla: yes,comp:lite",replace previous naive `downsize()` function with a `resize()` using TF Lite RESIZE_BILINEAR operator,1,,0,2018-01-26T07:44:36Z,CONTRIBUTOR
16443,Disable AWS S3 virtual addressing,"awaiting testing (then merge),cla: yes","The fix disables the virtual addressing of AWS S3, as was suggested in the comment https://github.com/tensorflow/tensorflow/issues/16397#issuecomment-360654674

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
",1,,4,2018-01-26T05:58:11Z,MEMBER
16442,"why save model and deploy in android device, the outputs are not the same as in ubuntu?",,"OS Platform and Distribution :Ubuntu 14.04.5 LTS   && Android 8.0
TensorFlow installed from source
TensorFlow version :1..4.0
Python version : 2.7.6
Bazel version :0.4.5
GCC/Compiler version:4.8.4
CUDA/cuDNN version:8.0
GPU model and memory: GTX1080, 8G
Exact command to reproduce:

step 1. clone code from https://github.com/davidsandberg/facenet
step 2. in the file src/compare.py, add the follow code after line 90, after align.detect_face.create_mtcnn 
            output_node_names=['pnet/prob1','pnet/conv4-2/BiasAdd','pnet/conv1/BiasAdd','rnet/prob1','rnet/conv5-2/conv5-2','onet/prob1','onet/conv6-2/conv6-2','onet/conv6-3/conv6-3']
            output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), output_node_names) #sess.graph_def,
            with tf.gfile.FastGFile(""mtcnn.pb"", mode = 'wb') as f:
                f.write(output_graph_def.SerializeToString())

step 3. run the command:  python src/compare.py ./data/20170512-110547 ./data/images/Anthony_Hopkins_0001.jpg ./data/images/Anthony_Hopkins_0002.jpg
will create the model file mtcnn.pb

step 4 deploy the file mtcnn.pb to android app, validate with the file Anthony_Hopkins_0001.jpg, indeed it can fetch the results for the outputs such as 'pnet/prob1','pnet/conv4-2/BiasAdd',  but the values are difference with the results from the facenet project run on ubuntu,

the query is what is the cause to the difference? the  way to create the mtcnn.pb is wrong? still need to optimize it to adapt android device? or there is something wrong with Tensorflow for mobile device?

the follow is the log show the difference:
with the same input:00.28515625,-0.24609375,-0.59765625
but the output is difference

Android output
 	Line 5555: 01-26 11:34:20.793 I/lxr     (22967): img00.28515625,-0.24609375,-0.59765625
	Line 5795: 01-26 11:34:21.326 I/lxr     (22967): mapWidth 70 mapHeight 70
	Line 5796: 01-26 11:34:21.327 I/lxr     (22967): outValue:0.9998832,1.16751995E-4
	Line 5797: 01-26 11:34:21.327 I/lxr     (22967): outReg:-0.068167016,-0.2052449,0.06884944,0.1512082

Ubuntu output
img_y (1, 150, 150, 3)
img_y0 [ 0.28515625 -0.24609375 -0.59765625]
out0 shape (1, 70, 70, 4)
out1 shape (1, 70, 70, 2)
out0 [-0.07926445 -0.20101449  0.06468102  0.16017048]
out1 [  9.99792397e-01   2.07666759e-04]
",0,,0,2018-01-26T05:50:11Z,NONE
16440,raw_input() was removed in Python 3,"awaiting review,cla: yes",__raw_input()__ was removed in Python 3 in favor of __input()__.  We add [__from six.moves import input__](https://pythonhosted.org/six/#module-six.moves) so that input() works identically in both Python 2 and Python 3.  We also add .strip() to gracefully deal with leading or trailing whitespace in the user input as well as lower() to gracefully deal with capital as well as lowercase letters.,1,,0,2018-01-26T04:25:51Z,CONTRIBUTOR
16433,Fix an imperfect implementation of tf.losses.mean_pairwise_squared_error,"awaiting review,cla: yes",Here is a fix for the issue [Imperfect implementation of tf.losses.mean_pairwise_squared_error (#15968)](https://github.com/tensorflow/tensorflow/issues/15968),1,,0,2018-01-26T02:42:02Z,NONE
16431,Lite: Supporting Raspberry Pi.,"awaiting review,cla: yes","Now we can cross compiling or native compiling libtensorflow-lite.a for rpi.
1. Fix 'string' does not name a type error by adding its namespace.
2. Remove unnecessary space between $(CC_PREFIX) and gcc.
3. Adding -O3 -DNDEBUG CFLAGS same as CXXFLAGS.
4. Remove redundant -lpthread link flag.
5. Add Makefile for RPi.",1,,3,2018-01-26T02:31:09Z,CONTRIBUTOR
16428,"want keras to work on GPU, but actually on CPU","stat:awaiting response,type:support","System information:
OS Platform and Distribution: Linux Ubuntu 16.04:
TensorFlow installed from anaconda:
Keras installed from pip
TensorFlow version 1.4.1
Bazel version : None:
CUDA/cuDNN version : CUDA V7.5.17, CuDNN v6.0:
GPU: GeForce GeForce GTX 1050 Ti(3.94GB):
Code: [mnist_mlp.py](https://github.com/antoniosehk/keras-tensorflow-windows-installation/blob/master/examples/mnist_mlp.py)

When run the code, it shows the following log:

> Using TensorFlow backend.
2018-01-25 17:31:16.572013: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-01-25 17:31:16.679268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-01-25 17:31:16.679499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.468
pciBusID: 0000:01:00.0
totalMemory: 3.94GiB freeMemory: 3.46GiB
2018-01-25 17:31:16.679513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)

Have no idea why it shows: 

> 2018-01-25 17:31:16.679268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero

And the code is actually running on the CPU, although the log shows the info of GPU

What have tried: stackoverflow :)",0,,1,2018-01-26T01:43:36Z,NONE
16424,Dependency on old version of bleach (1.5),"stat:awaiting response,type:support","Bleach 1.5 came out Nov 4th 2016 and this is old enough to cause dependency issues for projects that stayed up to date with Bleach.

In particular, this causes issues for Jupyter users.",0,,6,2018-01-25T23:20:59Z,NONE
16418,common global variable with constant.py,cla: no,Made a common `constant.py` for global commonly used variables.,1,,6,2018-01-25T19:56:38Z,CONTRIBUTOR
16404,remove SRU num_units == x.shape[-1] restriction,"awaiting testing (then merge),cla: yes","Based on the [author's response](https://github.com/taolei87/sru/issues/12), the restriction is unnecessary. Simply add a linear transform to the input will solve the issue

#13094 ",1,,4,2018-01-25T13:06:58Z,CONTRIBUTOR
16397,"S3 accessing reports ""Curl returned error code 6"" after AWS SDK upgrading to 1.3.15",stat:contributions welcome,"### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS 7.2
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.5.0rc1 (tag) and master (2e5ff39e)
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 4.8
- **CUDA/cuDNN version**: 8
- **GPU model and memory**: /
- **Exact command to reproduce**: 

### Describe the problem

TensorFlow 1.4.X was working well with S3 in my environment. After upgrading to 1.5.0rc1, I found that S3 could not be accessed. ""Curl returned error code 6"" is reported.

I noticed that AWS SDK had been upgraded from 1.0.90 to 1.3.15 in r1.5 and master branches. Thus, I pulled the master (2e5ff39e) and tried to change AWS SDK 1.3.15 into 1.0.90 in `tensorflow/workspace.bzl`. After this modification, it works well!

I tried with both AWS S3 (with http proxy) and Minio (localhost), and the results are the same. (AWS SDK 1.0.90 is Ok, but 1.3.15 reports error)

I guess there might be some incompatible changes after AWS SDK 1.3.15. Could you please take a look? Thanks! @yongtang

I noticed that AWS SDK required gcc 4.9, but I was using 4.8. Thus, this issue might be related to the old versions of gcc and glib on my server. I will try with some new systems as well.

### Source code / logs

Logs when using TensorFlow master (2e5ff39e):

```
>>> import tensorflow as tf
>>> tf.gfile.Exists('s3://xxxxxxxxx/f.txt')
2018-01-25 15:34:45.145317: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /home/xxxxxxxx//.aws/config and using profilePrefix = 1
2018-01-25 15:34:45.145354: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /home/xxxxxxxx//.aws/credentials and using profilePrefix = 0
2018-01-25 15:34:45.145367: I tensorflow/core/platform/s3/aws_logging.cc:54] Setting provider to read credentials from /home/xxxxxxxx//.aws/credentials for credentials file and /home/xxxxxxxx//.aws/config for the config file , for use with profile default
2018-01-25 15:34:45.145383: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating HttpClient with max connections2 and scheme http
2018-01-25 15:34:45.145401: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 2
2018-01-25 15:34:45.145414: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating Instance with default EC2MetadataClient and refresh rate 900000
2018-01-25 15:34:45.145456: I tensorflow/core/platform/s3/aws_logging.cc:54] Unable to open config file /home/xxxxxxxx//.aws/credentials for reading.
2018-01-25 15:34:45.145468: I tensorflow/core/platform/s3/aws_logging.cc:54] Failed to reload configuration.
2018-01-25 15:34:45.145479: I tensorflow/core/platform/s3/aws_logging.cc:54] Unable to open config file /home/xxxxxxxx//.aws/config for reading.
2018-01-25 15:34:45.145487: I tensorflow/core/platform/s3/aws_logging.cc:54] Failed to reload configuration.
2018-01-25 15:34:45.145495: I tensorflow/core/platform/s3/aws_logging.cc:54] Credentials have expired attempting to repull from EC2 Metadata Service.
2018-01-25 15:34:45.145614: I tensorflow/core/platform/s3/aws_logging.cc:54] Pool grown by 2
2018-01-25 15:34:45.145628: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
2018-01-25 15:34:46.146625: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28
2018-01-25 15:34:46.146655: E tensorflow/core/platform/s3/aws_logging.cc:60] Http request to Ec2MetadataService failed.
2018-01-25 15:34:46.146666: I tensorflow/core/platform/s3/aws_logging.cc:54] Failed to reload configuration.
2018-01-25 15:34:46.146715: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 25
2018-01-25 15:34:46.146849: I tensorflow/core/platform/s3/aws_logging.cc:54] Pool grown by 2
2018-01-25 15:34:46.146863: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
2018-01-25 15:34:46.147677: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 6
2018-01-25 15:34:46.147704: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.
2018-01-25 15:34:46.147716: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 0 ms before attempting again.
2018-01-25 15:34:46.147802: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
2018-01-25 15:34:46.148107: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 6
...
False
```

Logs after replacing AWS SDK 1.3.15 with 1.0.90:

```
>>> import tensorflow as tf
>>> tf.gfile.Exists('s3://xxxxxxxxx/f.txt')
2018-01-25 15:44:29.134077: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /home/xxxxxxxx//.aws/config and using profilePrefix = 1
2018-01-25 15:44:29.134108: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /home/xxxxxxxx//.aws/credentials and using profilePrefix = 0
2018-01-25 15:44:29.134121: I tensorflow/core/platform/s3/aws_logging.cc:54] Setting provider to read credentials from /home/xxxxxxxx//.aws/credentials for credentials file and /home/xxxxxxxx//.aws/config for the config file , for use with profile default
2018-01-25 15:44:29.134133: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating HttpClient with max connections -864887560 and scheme Creating HttpClient with max connections %d and scheme %s
2018-01-25 15:44:29.134147: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 2
2018-01-25 15:44:29.134157: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating Instance with default EC2MetadataClient and refresh rate 900000
2018-01-25 15:44:29.134176: I tensorflow/core/platform/s3/aws_logging.cc:54] Found credential in environment with access key id ********************
2018-01-25 15:44:29.134184: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2018-01-25 15:44:29.134223: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 25
2018-01-25 15:44:29.134264: I tensorflow/core/platform/s3/aws_logging.cc:54] Found credential in environment with access key id ********************
2018-01-25 15:44:29.134273: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2018-01-25 15:44:29.134429: I tensorflow/core/platform/s3/aws_logging.cc:54] Pool successfully grown by 2
2018-01-25 15:44:29.134442: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
2018-01-25 15:44:30.048051: I tensorflow/core/platform/s3/aws_logging.cc:54] Found credential in environment with access key id ********************
2018-01-25 15:44:30.048084: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2018-01-25 15:44:30.048159: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
True
```",0,,9,2018-01-25T08:00:10Z,CONTRIBUTOR
16396,tf.image.resize_image_with_crop_or_pad() is taking too much time to process an image or batch of images,stat:awaiting response,"ISSUE: 
I am stuck in fine tuning imagenet data rendering speed for the reason being tf.image.resize_image_with_crop_or_pad() is taking too much time to process an image or batch of images. 
```Testing was done by preprocessing ONE image (no batching) and an observed latency was `~160msec`. ```

NOTE: I did not observe memory pressure or any possible compute bottleneck during this time. 
Description:
I have a tool to load ImageNet dataset which reads the dataset from processed TFRecords and returns an iterator object to iterate over the datasets with a shuffle and repeat.
I have been observing slow rendering of data due to some overtime by certain steps in image (batch of images) pre-preprocessing. This is really impacting in data rendering speed and hence the slow training of models(Reference here is AlexNet). 

Here is the `snip` of time taken for each operation,
<img width=""1425"" alt=""imagenet_loader_perf_profile"" src=""https://user-images.githubusercontent.com/35795681/35406079-d4ec3584-01bc-11e8-9ba6-50e4dabba29e.png"">

Here is a `snip`  of data preprocess methods,
```
def _parse_example_proto(dataset, height, width, depth, dtype, num_parallel_calls):
    def _input_parser(record):
        keys_to_features = {
            ""image/encoded"": tf.FixedLenFeature((), tf.string, default_value=""""),
            ""image/format"": tf.FixedLenFeature((), tf.string, default_value=""jpeg""),
            ""image/class/label"": tf.FixedLenFeature([], dtype=tf.int64, default_value=-1),
        }
        parsed = tf.parse_single_example(record, keys_to_features)
        image = tf.image.decode_jpeg(parsed[""image/encoded""], channels=depth)
        image = tf.image.convert_image_dtype(image, dtype=dtype)
        label = tf.cast(parsed[""image/class/label""], tf.int32)
        return image, label
    return dataset.map(_input_parser, num_parallel_calls=num_parallel_calls)

def _dataset_preprocess_fn(dataset, height, width, num_parallel_calls):
    def _preprocess_fn(image, label):
        image = tf.image.resize_image_with_crop_or_pad(image, height + 8, width + 8 )
        image = tf.random_crop(image, [height, width, 3])
        image = tf.image.random_flip_left_right(image)
        image = (ISTD * image) + MEAN  #dataset level MEAN
        return image, label
    return dataset.map(_preprocess_fn, num_parallel_calls=num_parallel_calls)
```
### System information
- **OS Platform and Distribution *:  Linux Centos 7.2
- **TensorFlow installed from (source or binary)**: 1.4.0 rc1 ( commit hash badd356)
- **TensorFlow version (use command below)**:  b'v1.3.0-rc1-4546-gef196f3' 1.4.0-rc1
- **Python version**:  3.4.5
- **Bazel version (if compiling from source)**: Build label: 0.8.1
- **CUDA/CUDAnn version**: CUDA 9 and  CUDAnn 7.0
- **GPU model and memory**: Volta 100, 16GiB


I am using Amazon Instance and here are the details,
```
GPUs - Tesla V100
GPU Memory (GB): 16
vCPUs : 8
Memory (GB):61
Network Bandwidth: Upto 10Gbps
EBS Bandwidth: 1.5 Gbps
```
",0,,3,2018-01-25T07:43:27Z,NONE
16395,change from deprecated version to a new version,"awaiting review,cla: yes",,1,,3,2018-01-25T07:32:11Z,NONE
16391,Added early stopping and CheckpointSaverListeners to train and evaluate,"awaiting review,cla: yes",Addresses the issue at https://github.com/tensorflow/tensorflow/issues/16203,1,,0,2018-01-25T06:00:13Z,NONE
16387,Tensorflow not using GPU,stat:awaiting response,"I use windows in my laptop. Initially tensorflow worked well with GPU. I don't know why suddenly it's not detecting the GPU. I am using tensorflow-gpu 1.4 version (installed with pip install tensorflow-gpu) with CUDA 8.0 and cudnn 6.0. I also tried with other versions but the problem persists. Attached is the error message shown. I appreciate any help :)

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: just called a session
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: NVIDIA GeForce 1050 2GB
- **Exact command to reproduce**: sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))

(https://user-images.githubusercont
![tferror](https://user-images.githubusercontent.com/19821962/35368823-48f11022-0153-11e8-87c3-41e41118a3fa.png)
ent.com/19821962/35368747-e2d4ba8c-0152-11e8-871a-a6a5aedf6663.png)
",0,,3,2018-01-25T03:09:07Z,NONE
16385,Estimator built with keras.estimator.model_to_estimator fails on Estimator.export_savedmodel,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 3.16.36
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.4.0-19-ga52c8d9', '1.4.1')
- **Python version**: 2.7.9
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See gist

### Describe the problem

If I create a model with `tf.keras`, compile it and then turn it into an estimator by simply passing it thru to `tf.keras.estimator.model_to_estimator`, I am able to train and evaluate the model just fine -- however when I got to export it with `Estimator.export_savedmodel`, I get the following error:

```
Traceback (most recent call last):
  File ""endtoend_noweights_trainer_keras.py"", line 302, in <module>
    get_serving_input_fn(hyperparameters),
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 517, in export_savedmodel
    serving_input_receiver.receiver_tensors_alternatives)
  File ""/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/export/export.py"", line 193, in build_all_signature_defs
    raise ValueError('export_outputs must be a dict.')
ValueError: export_outputs must be a dict.
```

I'm not sure what `export_outputs` is, but if I had to guess it should be a mapping of output names to output tensors from the `keras` model.

Here's the (very unclean) [code](https://gist.github.com/zmjjmz/8e3a7e5430f2e700a9e89bf2b4f6259b) I'm using to get to this, although there's a lot of dependencies that won't work for y'all. If you need a repro I can take the time to put it together, just let me know. Notably the error occurs on line `300`.",1,,7,2018-01-25T02:20:52Z,NONE
16381,Distributed TensorFlow without shared directory,"stat:awaiting tensorflower,type:feature","It seems like there is an inherent assumption in Distributed TensorFlow that all nodes must share a common file system, such as google cloud or NFS. 

I've found in testing that models will train just fine without a common file system, but the final trained model doesn't save properly when you try something like: 
`builder = tf.saved_model_builder.SavedModelBuilder(export_dir) 
...
builder.save()`

The issue seems to be that the parameter server has the variables and the chief node has the graph. 

It'd be great if TensorFlow added a function to allow us to consolidate the graph and variables at the end of training onto the chief node in order to save the trained model. Right now there doesn't seem to be an easy way to do this.

Thanks.",0,,6,2018-01-24T23:49:37Z,NONE
16374,No module named 'tensorflow.contrib.lite.toco.python',"comp:lite,type:build/install","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Build 16299.192  and Windows 7
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0rc1 and tf-nightly  1.6.0.dev20180124
- **Python version**: 3.6.2 and 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Nvidia GT 740M 2GB
- **Exact command to reproduce**: toco --help

### Describe the problem
I am trying to run the codelab tutorial of tensorflow lite. After installing tf-nightly, when I try to run the command ""toco --help"", I get the error ModuleNotFoundError: No module named 'tensorflow.contrib.lite.toco.python'.

I have tried this on 3 computers( all Windows) and the same problem persists.


### Source code / logs
C:\Users\HP\Downloads>toco --help
Traceback (most recent call last):
  File ""c:\programdata\anaconda3\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\programdata\anaconda3\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\ProgramData\Anaconda3\Scripts\toco.exe\__main__.py"", line 5, in <module>
ModuleNotFoundError: No module named 'tensorflow.contrib.lite.toco.python'
",1,,4,2018-01-24T19:26:10Z,NONE
16370,add hooks for mutate variables in tf.Estimator,"stat:awaiting response,type:feature","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:


== cat /etc/issue ===============================================
Darwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-serving-api (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.3.0-rc2-20-g0787eee', '1.3.0')

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Right now there is no elegant way we can mutate variable in the `tf.estimator.Estimator` 
And we do have some situation that we want to discard the checkpoints but save the variable in other format fits better with our infra.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

",0,,1,2018-01-24T16:21:59Z,CONTRIBUTOR
16368,Fix of issue #13164 (Merges #13382),"awaiting review,cla: yes","Deconflicts #13382
Fixes #13164
@dantkz /cc
@ebrevdo /cc",1,,14,2018-01-24T15:28:31Z,CONTRIBUTOR
16365,Include grpc_tensorflow_std_server in Docker image,"stat:contributions welcome,type:feature","It would be nice if the grpc_tensorflow_std_server was included in the Docker image.

This would prevent users from having to write code just to launch a parameter server because they could just run the stock binary.

Some context in: tensorflow/k8s#16",0,,2,2018-01-24T14:17:45Z,NONE
16364,Standardizing the saved format and/or converting to big-endian on read,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 s390x
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: bazel test -c opt //tensorflow/python:framework_meta_graph_test which invokes meta_graph.import_scoped_meta_graph.

### Describe the problem
The testdata for //tensorflow/python:framework_meta_graph_test is not platform independent and causes test to fail on Big Endian systems.

As per discussion in #16003 , correct approach would be standardizing the stored format and/or conversion on load based on endianness. Can someone have a look?  
",0,,1,2018-01-24T13:52:54Z,CONTRIBUTOR
16363,Warning: Table trying to initialize from file ... is already initialized,stat:awaiting response,"Python: 3.6.2
Tensorflow: 1.5.0rc1
OS: Windows 10

I get this when creating a lookup table with `tf.contrib.lookup.index_table_from_file`.
As I have multiple graphs I create that table in each graph (from the same file) I need it in. This results in the warning from the title of this issue.

1. Are tables shared across graphs?
2. How to figure out if a table from a specific file is already existing/initialized?

This also occurs with `tensorflow/nmt`:
https://github.com/tensorflow/nmt/issues/234",0,,1,2018-01-24T13:00:40Z,CONTRIBUTOR
16357,Increase tolerance in `losses_impl_test.py`. fixes #16238,cla: no,,1,,2,2018-01-24T07:53:22Z,CONTRIBUTOR
16356,How leave only 1 app and how edit drawing boxes?,stat:awaiting response,"------------------------

### System information
- **Windows 10 x64**:
- **Installed from binary**:
- **TensorFlow 1.3.0**:
- **Python 3.6.3**: 
- **CuDNN 6.4.6, CUDA 8.0**:
- **NVIDIA GeForce 940M**:

### Describe the problem
1. How I can leave only 1 app? Example, TF Detect. I wanna when I install TF on my Android smartphone, installed only TF Detect. Thanks!

2. How I can edit during detection boxes?
",0,,1,2018-01-24T07:43:22Z,NONE
16352,OrderedEnqueuer not imported in keras/utils/__init__.py,stat:awaiting response,"OrderedEnqueuer is not imported with the remaining util objects.

Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,1,2018-01-24T05:48:06Z,NONE
16350,"There is an issue with your ""new issue"" page",,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- All systems/system independent

### Describe the problem
If there are documentation issues, the ""New Issue"" button will direct many people to StackOverflow. The notions of ""bugs and features"" are not universal in that they only apply to software, not to documentation as far as some people are concerned. IMHO the text above would be better if it stated that ""1. It must be a bug or a feature request, or a correction/clarification to documentation""

### Source code / logs
No source involved
",0,,3,2018-01-24T03:53:19Z,NONE
16348,Change RELEASE.md to specify CUDA version,"stat:contributions welcome,type:docs","The RELEASE.md states that ""Prebuilt binaries are now built against CUDA 9 and cuDNN 7.""

https://github.com/tensorflow/tensorflow/issues/15604 says that CUDA 9.1 is not supported.

Could we change the RELEASE.md so that it says ""Prebuilt binaries are now built against CUDA 9.0 and cuDNN 7."" until later versions are supported?
",0,,3,2018-01-24T03:00:31Z,NONE
16345,tf.nn.sparse_softmax_cross_entropy_with_logits get error:  ValueError: Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 4).,stat:awaiting response,,0,,1,2018-01-24T01:20:52Z,NONE
16344,Variance of weights initialized with tf.variance_scaling_initializer is somewhat surprising,"stat:awaiting tensorflower,type:feature","If `tf.variance_scaling_initializer` is called with `distribution='uniform'`, then the weights have variance `scale / n`. However, if `tf.variance_scaling_initializer` is called with `distribution='normal'`, the weights have variance `scale / n * (1 - (4 * norm.pdf(2))/(2 * norm.cdf(2) - 1))`, because the weights are drawn from a normal distribution truncated at +/- 2 std and the scale is not adjusted for this truncation.

While I understand that there are reasons to use a truncated normal distribution, I would argue that the distribution should be scaled to adjust for the truncation, or the fact that the scale is not adjusted for truncation should feature more prominently in the documentation. The current statement that:

> With `distribution=""normal""`, samples are drawn from a truncated normal distribution centered on zero, with `stddev = sqrt(scale / n)`

is not totally clear, since it's not obvious that `stddev` is referring to the standard deviation of the normal distribution before truncation and not after.

To make matters more confusing, unlike `tf.variance_scaling_initializer`, `tf.contrib.layers.variance_scaling_initializer` performs the appropriate correction so that the weights have variance `scale / n`.",0,,3,2018-01-24T01:16:35Z,NONE
16343,tf.data.Dataset doesn't provide a good workflow for generating custom samples from large files,stat:awaiting response,"We're given hundreds of data files, each containing many gigabytes worth of sample data in a custom format. As far as I can tell there are only two approaches to extract samples from this using `Dataset`:

1) `tf.data.Dataset.from_generator(generator=my_custom_reader, ...)`

Create a generator which produces samples. This approach is not ideal because this method must be the first dataset in the chain. The generator cannot accept a tensor. Therefore you can't batch and shuffle your list of 100's of filenames (or anything more complex). You also can't make use of `interleave(...)` because the generator can't accept a tensor, and this use case is begging to use `interleave(...)`.

A solution here might be to provide a method for a generator to accept a tensor, as `tf.py_func(...)` does for functions.

2) `tf.data.Dataset.map(map_func=tf.py_func(my_custom_reader, ...), ...)`

The map function does allow us to shuffle and parallelize the filenames using all of the functionality of the Dataset pipeline, however, with `map`, the files must be read into memory completely, and these files are large. Reading numerous files into memory is infeasible.

A solution here might be to extend the `map` function to support generators.

Unless there's an alternative approach, which I didn't glean from the docs or stackoverflow, then this seems to be an inherent limitation and a seemingly reasonable use case on which to base a feature request.
",0,,2,2018-01-24T01:03:55Z,NONE
16342,Fixed documentation formatting,cla: no,,0,,2,2018-01-24T01:03:41Z,NONE
16338,Obtain tower id when using tf.contrib.estimator.replicate_model_fn(),stat:awaiting response,"Since tensorflow 1.5, a new API tf.contrib.estimator.replicate_model_fn() is introduced to to replicate a model over GPUs. However, the current API hides the tower id information from the model_fn(). Without knowning tower id, it is difficult to create non-shared local variables/ops per tower. Is it possible to propagate the tower id information to model_fn? Thanks.",0,,1,2018-01-23T22:35:08Z,NONE
16334,save_steps in MoniteredTrainingSession,stat:awaiting response,"Any reason to omit the `save_steps` in favor of `save_secs` for `CheckpointSaverHook` in `MoniteredTrainingSession`?

https://github.com/tensorflow/tensorflow/blob/abf3c6d745c34d303985f210bf9e92cac99ba744/tensorflow/python/training/monitored_session.py#L363

The previous `SummarySavorHook` has both `save_steps` and `save_secs` considered

https://github.com/tensorflow/tensorflow/blob/abf3c6d745c34d303985f210bf9e92cac99ba744/tensorflow/python/training/monitored_session.py#L358",0,,1,2018-01-23T20:36:16Z,NONE
16333,Computing gradients of loop variables return None,"stat:awaiting tensorflower,type:docs","### System information
- Windows 10 x64
- Installed from binary
- TensorFlow 1.3.0
- Python 3.6.3
- CuDNN 6.4.6, CUDA 8.0
- NVIDIA GeForce 940M

### Bug Description

Issue [15403](https://github.com/tensorflow/tensorflow/issues/15403) was closed since it was labelled as ""not a bug or feature request"". I believe it is indeed a bug. 

The fundamental problem is that gradients do not seem to be working inside of `tf.while_loop`s. Here is a demonstration of code run inside and outside of a while loop. The code outside of the loop produces a result, whereas the gradient inside of the loop returns None: 
```
import tensorflow as tf

i = tf.constant(0)
x = tf.constant(3.0)
print(""External gradient:"", tf.gradients(x, x)[0])     # Prints Tensor(""gradients/Fill:0"", shape=(), dtype=float32)

def loop_body(i, x, y):
    print(""internal gradient:"", tf.gradients(x, y)[0]) # Prints None
    return i + 1, x, y

tf.while_loop( lambda i,x,y: tf.less(i, 5), loop_body, [i, x, x]);
```",0,,4,2018-01-23T19:36:43Z,NONE
16329,tf.nn.seq2seq.embedding_rnn_seq2seq,stat:awaiting response,"Have I written custom code: Yes
OS Platform and Distribution: Windows 10
TensorFlow installed from anaconda prompt
TensorFlow version 0.12 & 1.4
Bazel version NA
CUDA/cuDNN version NA
GPU model and memory: Floydhub
Exact command to reproduce:

self.outputs, self.states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(self.enc,self.dec, stacked_lstm, xvocab_size, yvocab_size, emb_dim)

THE PROBLEM.
I am upgrading working tf0.12 code so I can train on floydhub.  I have replaced  tf.nn.seq2seq.embedding_rnn_seq2seq  with tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq. It produces the following error log:


  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\site-packages\tensorflow\contrib\legacy_seq2seq\python\ops\seq2seq.py"", line 358, in embedding_rnn_seq2seq
    encoder_cell = copy.deepcopy(cell)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 166, in deepcopy
    y = copier(memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\site-packages\tensorflow\python\layers\base.py"", line 655, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 218, in _deepcopy_list
    y.append(deepcopy(a, memo))

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 182, in deepcopy
    y = _reconstruct(x, rv, 1, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 297, in _reconstruct
    state = deepcopy(state, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 182, in deepcopy
    y = _reconstruct(x, rv, 1, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 297, in _reconstruct
    state = deepcopy(state, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 182, in deepcopy
    y = _reconstruct(x, rv, 1, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 297, in _reconstruct
    state = deepcopy(state, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 182, in deepcopy
    y = _reconstruct(x, rv, 1, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 297, in _reconstruct
    state = deepcopy(state, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 182, in deepcopy
    y = _reconstruct(x, rv, 1, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 297, in _reconstruct
    state = deepcopy(state, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 218, in _deepcopy_list
    y.append(deepcopy(a, memo))

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 223, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 223, in <listcomp>
    y = [deepcopy(a, memo) for a in x]

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 182, in deepcopy
    y = _reconstruct(x, rv, 1, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 297, in _reconstruct
    state = deepcopy(state, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 155, in deepcopy
    y = copier(x, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 243, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)

  File ""C:\Users\BC\AppData\Local\conda\conda\envs\tf1.4\lib\copy.py"", line 174, in deepcopy
    rv = reductor(4)

TypeError: cannot serialize '_io.TextIOWrapper' object",0,,2,2018-01-23T16:19:17Z,NONE
16327,iOS app does not output predictions using resnet50,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.1
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**: 0.9.0-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A 


### Steps I followed:

- I have trained resnet_v2_50 using slim.

- I created a script just to run inference, so the input image is a placeholder with name ""input_1"" and the output is the softmax with name ""softmax"". 

- I exported the .pb graph, then I ran `python python/tools/freeze_graph.py --input_graph=resnet_v2_50.pb --input_checkpoint=model.ckpt-1 --output_graph=frozen_resnet_v2_50.pb --input_binary=True --output_node_names=""softmax""` to freeze my graph using my checkpoint.

- I ran `bazel-bin/tensorflow/tools/graph_transforms/transform_graph  --inputs=input_1 --in_graph=frozen_resnet_v2_50.pb --outputs=softmax --out_graph=quantized_resnet_v2_50.pb --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,180,180,3"") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) quantize_weights strip_unused_nodes sort_by_execution_order'`
 to quantize it.

- I imported the graph and also my labels file into `tensorflow/examples/ios/camera/data` and I ran the model on my iphone 5s (ios 10.3) using xcode 9.2. 

### Problem:
The app is running on my iphone but I am not getting any labels and probabilities while the `tensorflow/examples/label_image/label_image.py` script gives me results. If I use my model inside `tensorflow/examples/ios/simple` with iphone 8 simulator, the model is loaded but the predictions are empty. The result is the same if I use the frozen version before quantization. Is there any bug? The message running on the simple example is the following (no predictions):
`I/Users/christos/tensorflow/tensorflow/examples/ios/my_simple/RunModelViewController.mm:246] Predictions: ` 
You can see the node names and its operations below (here the output node is v/tower_0/resnet_v2_50/predictions/Reshape_1):

input_1=>Placeholder
v/tower_0/Reshape/shape=>Const
v/tower_0/Reshape=>Reshape
v/tower_0/split/split_dim=>Const
v/tower_0/split=>Split
v/tower_0/sub/y=>Const
v/tower_0/sub=>Sub
v/tower_0/sub_1/y=>Const
v/tower_0/sub_1=>Sub
v/tower_0/sub_2/y=>Const
v/tower_0/sub_2=>Sub
v/tower_0/concat/axis=>Const
v/tower_0/concat=>ConcatV2
v/tower_0/Reshape_1/shape=>Const
v/tower_0/Reshape_1=>Reshape
v/tower_0/resnet_v2_50/Pad/paddings=>Const
v/tower_0/resnet_v2_50/Pad=>Pad
v/resnet_v2_50/conv1/weights_quantized_max=>Const
v/resnet_v2_50/conv1/weights_quantized_min=>Const
v/resnet_v2_50/conv1/weights_quantized_const=>Const
v/resnet_v2_50/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/conv1/Conv2D=>Conv2D
v/resnet_v2_50/conv1/biases=>Const
v/tower_0/resnet_v2_50/conv1/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/pool1/MaxPool=>MaxPool
v/resnet_v2_50/block1/unit_1/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/biases=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut/BiasAdd=>BiasAdd
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/biases=>Const
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block1/unit_1/bottleneck_v2/add=>Add
v/resnet_v2_50/block1/unit_2/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/biases=>Const
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block1/unit_2/bottleneck_v2/add=>Add
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/shortcut/MaxPool=>MaxPool
v/resnet_v2_50/block1/unit_3/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv1/Relu=>Relu
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/Pad/paddings=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/Pad=>Pad
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/biases=>Const
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block1/unit_3/bottleneck_v2/add=>Add
v/resnet_v2_50/block2/unit_1/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/biases=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut/BiasAdd=>BiasAdd
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/biases=>Const
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block2/unit_1/bottleneck_v2/add=>Add
v/resnet_v2_50/block2/unit_2/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/biases=>Const
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block2/unit_2/bottleneck_v2/add=>Add
v/resnet_v2_50/block2/unit_3/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/biases=>Const
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block2/unit_3/bottleneck_v2/add=>Add
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/shortcut/MaxPool=>MaxPool
v/resnet_v2_50/block2/unit_4/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv1/Relu=>Relu
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/Pad/paddings=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/Pad=>Pad
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/biases=>Const
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block2/unit_4/bottleneck_v2/add=>Add
v/resnet_v2_50/block3/unit_1/bottleneck_v2/preact/gamma=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/preact/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/biases_quantized_max=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/biases_quantized_min=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/biases_quantized_const=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/biases=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut/BiasAdd=>BiasAdd
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block3/unit_1/bottleneck_v2/add=>Add
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block3/unit_2/bottleneck_v2/add=>Add
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block3/unit_3/bottleneck_v2/add=>Add
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block3/unit_4/bottleneck_v2/add=>Add
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block3/unit_5/bottleneck_v2/add=>Add
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/shortcut/MaxPool=>MaxPool
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv1/Relu=>Relu
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/Pad/paddings=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/Pad=>Pad
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block3/unit_6/bottleneck_v2/add=>Add
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/biases_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/biases_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/biases_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/biases=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/BiasAdd=>BiasAdd
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block4/unit_1/bottleneck_v2/add=>Add
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block4/unit_2/bottleneck_v2/add=>Add
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/gamma_quantized_max=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/gamma_quantized_min=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/gamma_quantized_const=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/gamma=>Dequantize
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/beta_quantized_max=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/beta_quantized_min=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/beta_quantized_const=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/beta=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/preact/Relu=>Relu
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/BatchNorm/gamma=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/Relu=>Relu
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/BatchNorm/gamma=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/BatchNorm/beta=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/BatchNorm/Const=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/BatchNorm/Const_1=>Const
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/BatchNorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/Relu=>Relu
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/weights_quantized_max=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/weights_quantized_min=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/weights_quantized_const=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/weights=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/Conv2D=>Conv2D
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/biases_quantized_max=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/biases_quantized_min=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/biases_quantized_const=>Const
v/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/biases=>Dequantize
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/block4/unit_3/bottleneck_v2/add=>Add
v/resnet_v2_50/postnorm/gamma_quantized_max=>Const
v/resnet_v2_50/postnorm/gamma_quantized_min=>Const
v/resnet_v2_50/postnorm/gamma_quantized_const=>Const
v/resnet_v2_50/postnorm/gamma=>Dequantize
v/resnet_v2_50/postnorm/beta_quantized_max=>Const
v/resnet_v2_50/postnorm/beta_quantized_min=>Const
v/resnet_v2_50/postnorm/beta_quantized_const=>Const
v/resnet_v2_50/postnorm/beta=>Dequantize
v/tower_0/resnet_v2_50/postnorm/Const=>Const
v/tower_0/resnet_v2_50/postnorm/Const_1=>Const
v/tower_0/resnet_v2_50/postnorm/FusedBatchNorm=>FusedBatchNorm
v/tower_0/resnet_v2_50/postnorm/Relu=>Relu
v/tower_0/resnet_v2_50/pool5/reduction_indices=>Const
v/tower_0/resnet_v2_50/pool5=>Mean
v/resnet_v2_50/logits/weights_quantized_max=>Const
v/resnet_v2_50/logits/weights_quantized_min=>Const
v/resnet_v2_50/logits/weights_quantized_const=>Const
v/resnet_v2_50/logits/weights=>Dequantize
v/tower_0/resnet_v2_50/logits/Conv2D=>Conv2D
v/resnet_v2_50/logits/biases_quantized_max=>Const
v/resnet_v2_50/logits/biases_quantized_min=>Const
v/resnet_v2_50/logits/biases_quantized_const=>Const
v/resnet_v2_50/logits/biases=>Dequantize
v/tower_0/resnet_v2_50/logits/BiasAdd=>BiasAdd
v/tower_0/resnet_v2_50/SpatialSqueeze=>Squeeze
v/tower_0/resnet_v2_50/predictions/Reshape/shape=>Const
v/tower_0/resnet_v2_50/predictions/Reshape=>Reshape
v/tower_0/resnet_v2_50/predictions/Softmax=>Softmax
v/tower_0/resnet_v2_50/predictions/Shape=>Const
v/tower_0/resnet_v2_50/predictions/Reshape_1=>Reshape",0,,1,2018-01-23T15:26:45Z,NONE
16323,Does Broadcast in TF copy first or just do ops along the axis,stat:awaiting response,"For example, we have
tensor a with shape (100, 100, 5) and tensor b with shape (1, 1, 5)
when running
c = tf.multiply(a, b)

Is b first copied 100 * 100 times for the **big** dot multiply with a (GPU memory consuming),
or the dot multiply is done with the original b along axis 0 and 1?

The tf.multiply page refers to **numpy multiply** that says it won't copy, just loop.
https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html

I guess it's copied first that I run into GPU memory problem by adjusting a bit the b.
How's it implemented in TF? Couldn't find the source gen_math_ops

Issue template update:
Have I written custom code No
OS Platform and Distribution: Windows 10 x64 Home version
TensorFlow installed from pip (anaconda with python 3.6.3)
TensorFlow version: 1.4.1
Bazel version: N/A
CUDA/cuDNN version: CUDA 8.0, cuDNN 6
GPU model and memory: GTX 1050Ti, 4 GB memory (3.3 GB available)
Exact command to reproduce N/A (not relevant to the question)",0,,1,2018-01-23T11:52:14Z,NONE
16322,py_func convert unicode string results to bytes for python2,"awaiting review,cla: yes",Fix #16320,1,,0,2018-01-23T10:34:23Z,CONTRIBUTOR
16319,Add alternative paths for CUDA installation.,"awaiting review,cla: yes","This detects negativo17's CUDA packages for Fedora.

I tried following the feedback in #15614, so I added alternative paths and avoided adding questions to the `./configure` script.",1,,1,2018-01-23T10:29:37Z,CONTRIBUTOR
16317,tensorflow crash on android mobile with libtensorflowlite_jni.so of arm-v7a ,"comp:lite,stat:awaiting response","
### System information
- **OS Platform and Distribution ( android 5.1 )**:
- **TensorFlow installed from (source )**:
- **TensorFlow version ( # Release 1.5.0 )**:
- **Python version** 2.7 : 
- **Bazel version ( 0.9.0-homebrew )**:
- **GCC/Compiler version
 (Apple LLVM version 7.3.0 (clang-703.0.31)
Target: x86_64-apple-darwin17.3.0 )**:


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
after using tensorflow source to build the libtensorflowlite_jni.so of arm-v7a , it crash in the android 
mobile frequently with the following message ;  somehow came with the libtensorflowlite_jni.so of arm just work fine but too long; someone can help ? 


01-23 16:17:25.292 414-414/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
01-23 16:17:25.292 414-414/? I/DEBUG: Build fingerprint: 'nubia/NX529J/NX529J:5.1.1/LMY47V/eng.nubia.20160612.203636:user/release-keys'
01-23 16:17:25.292 414-414/? I/DEBUG: Revision: '0'
01-23 16:17:25.292 414-414/? I/DEBUG: ABI: 'arm'
01-23 16:17:25.292 414-414/? I/DEBUG: pid: 8073, tid: 8930, name: AsyncTask #6  >>> com.test.tensorflow <<<
01-23 16:17:25.292 414-414/? I/DEBUG: signal 7 (SIGBUS), code -6 (SI_TKILL), fault addr 0xac66df18
01-23 16:17:25.372 414-414/? I/DEBUG:     r0 ac66df18  r1 00000004  r2 b5ba5050  r3 000003e9
01-23 16:17:25.372 414-414/? I/DEBUG:     r4 b6df239c  r5 00000002  r6 ac66df18  r7 d7744d20
01-23 16:17:25.372 414-414/? I/DEBUG:     r8 00000002  r9 b5ba5040  sl 00000000  fp b5ba5fe4
01-23 16:17:25.372 414-414/? I/DEBUG:     ip b5ba5fec  sp d7744cc8  lr 000003e8  pc c3e5ae9c  cpsr 000f0030
01-23 16:17:25.372 414-414/? I/DEBUG: backtrace:
01-23 16:17:25.372 414-414/? I/DEBUG:     #00 pc 00067e9c  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so
01-23 16:17:25.372 414-414/? I/DEBUG:     #01 pc 0004870f  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so
01-23 16:17:25.372 414-414/? I/DEBUG:     #02 pc 0004894b  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so
01-23 16:17:25.372 414-414/? I/DEBUG:     #03 pc 0005d333  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so
01-23 16:17:25.372 414-414/? I/DEBUG:     #04 pc 00007205  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+1280)
01-23 16:17:25.372 414-414/? I/DEBUG:     #05 pc 00011bf3  /data/dalvik-cache/arm/data@app@com.test.tensorflow-1@base.apk@classes.dex
01-23 16:17:28.882 414-414/? I/DEBUG: Tombstone written to: /data/tombstones/tombstone_07


",0,,6,2018-01-23T08:34:40Z,NONE
16312,Allow step callback for scipy SLSQP,"cla: yes,stat:awaiting response",This simple fix allows `SLSQP` method of scipy optimizer to use step callback as reported in issue [#16294](https://github.com/tensorflow/tensorflow/issues/16294). ,1,,0,2018-01-23T03:56:13Z,NONE
16311,Segmentation fault in _pywrap_tensorflow_internal.so,stat:awaiting response,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.3 LTS (Xenial)
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.4.0-19-ga52c8d9', '1.4.1')
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: Cuda8, cudnn6
- **GPU model and memory**: Titan Xp (with driver 387.26)
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
```
== cat /etc/issue ===============================================
Linux ubuntu 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux ubuntu 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.14.0)
protobuf (3.5.1)
tensorflow-gpu (1.4.1)
tensorflow-tensorboard (0.4.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.1
tf.GIT_VERSION = v1.4.0-19-ga52c8d9
tf.COMPILER_VERSION = v1.4.0-19-ga52c8d9
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH :/usr/local/cuda/lib64/
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Tue Jan 23 11:09:12 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN Xp            Off  | 00000000:04:00.0 Off |                  N/A |
| 40%   66C    P2   182W / 250W |  11763MiB / 12189MiB |     73%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |
| 23%   30C    P8     8W / 250W |  11591MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  TITAN Xp            Off  | 00000000:06:00.0 Off |                  N/A |
| 28%   48C    P0    62W / 250W |      0MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  TITAN Xp            Off  | 00000000:07:00.0 Off |                  N/A |
| 26%   46C    P0    63W / 250W |      0MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  TITAN Xp            Off  | 00000000:08:00.0 Off |                  N/A |
| 26%   46C    P0    63W / 250W |      0MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  TITAN Xp            Off  | 00000000:0C:00.0 Off |                  N/A |
| 23%   43C    P0    62W / 250W |      0MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  TITAN Xp            Off  | 00000000:0E:00.0 Off |                  N/A |
| 25%   44C    P0    62W / 250W |      0MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  TITAN Xp            Off  | 00000000:0F:00.0 Off |                  N/A |
| 42%   69C    P2   167W / 250W |  11833MiB / 12189MiB |     31%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     19682      C   /home/peiliang/tensorflow/bin/python       11751MiB |
|    1     19682      C   /home/peiliang/tensorflow/bin/python       11579MiB |
|    7     27581      C   python                                     11823MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.1/lib64/libcudart.so.9.1.85
/usr/local/cuda-9.1/lib64/libcudart_static.a
/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.1/doc/man/man7/libcudart.7
```

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
My custom learning code works perfectly on my older workstation with 2 GPU cards. But am having issue with our new workstation which has 8 GPU cards. I get a Segmentation fault. 


### Source code / logs

The entire source code is: https://github.com/mpkuse/cartwheel_train/tree/config-files

The main-script is `train_netvlad.py`. Currently my learning data is private, 
if you really need it to test, I can provide the data as well (~100 GB). 

My code basically builds a network with tf.slim. I have a custom operations to build a layer. Have a custom loss function. Can be found in `CartWheelFlow.py/ class VGGDescriptor`. It uses tf.while. 
Data is managed by `class TimeMachineRender`

stack trace for the crash. 

```
$ gdb --args python train_netvlad.py -t tfsuper.logs/test 
(gdb) run
.
.
.
Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
0x00007ffef7f61a2c in std::__detail::_Map_base<std::string, std::pair<std::string const, unsigned long>, std::allocator<std::pair<std::string const, unsigned long> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::string const&) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
(gdb) where
#0  0x00007ffef7f61a2c in std::__detail::_Map_base<std::string, std::pair<std::string const, unsigned long>, std::allocator<std::pair<std::string const, unsigned long> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::string const&) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007ffef7f6c4d9 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007ffef5ed94ea in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorfl---Type <return> to continue, or q <return> to quit---
ow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007ffef5ed9824 in TF_Run ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007ffef5bf701a in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007ffef5bf7411 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/---Type <return> to continue, or q <return> to quit---
_pywrap_tensorflow_internal.so
#6  0x00007ffef5bbb6f1 in _wrap_TF_Run ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00000000004c45fa in PyEval_EvalFrameEx ()
#8  0x00000000004c2705 in PyEval_EvalCodeEx ()
#9  0x00000000004de69e in ?? ()
#10 0x00000000004b0c93 in PyObject_Call ()
#11 0x00000000004c6ef6 in PyEval_EvalFrameEx ()
#12 0x00000000004c2705 in PyEval_EvalCodeEx ()
#13 0x00000000004ca7df in PyEval_EvalFrameEx ()
#14 0x00000000004c2705 in PyEval_EvalCodeEx ()
#15 0x00000000004ca7df in PyEval_EvalFrameEx ()
#16 0x00000000004c2705 in PyEval_EvalCodeEx ()
#17 0x00000000004ca7df in PyEval_EvalFrameEx ()
#18 0x00000000004c2705 in PyEval_EvalCodeEx ()
#19 0x00000000004ca088 in PyEval_EvalFrameEx ()
#20 0x00000000004c2705 in PyEval_EvalCodeEx ()
#21 0x00000000004c24a9 in PyEval_EvalCode ()
#22 0x00000000004f19ef in ?? ()
#23 0x00000000004ec372 in PyRun_FileExFlags ()
#24 0x00000000004eaaf1 in PyRun_SimpleFileExFlags ()
#25 0x000000000049e208 in Py_Main ()
#26 0x00007ffff7810830 in __libc_start_main (main=0x49db30 <main>, argc=4, 
    argv=0x7fffffffe558, init=<optimized out>, fini=<optimized out>, 
    rtld_fini=<optimized out>, stack_end=0x7fffffffe548) at ../csu/libc-start.c:291
#27 0x000000000049da59 in _start ()
```
",0,,3,2018-01-23T03:46:06Z,NONE
16308,A crash found on tensorflow_jni.so when create interpreter using byteBufferMode,"comp:lite,stat:awaiting response","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------
### System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
•OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04.4 LTS
•TensorFlow installed from (source or binary):use the pip install
•TensorFlow version (use command below):1.4.0
•Python version: Python 2.7.6
•Bazel version (if compiling from source):0.9.0
•GCC/Compiler version (if compiling from source):(Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
•CUDA/cuDNN version:NA
•GPU model and memory:NA
•Exact command to reproduce:NAYou can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I put my training model to the tflitecamerademo projects, but I encounter a crash issue.
The crash stack is

01-23 10:46:45.292 21514 21536 E AndroidRuntime: Process: android.example.com.tflitecamerademo, PID: 21514
01-23 10:46:45.292 21514 21536 E AndroidRuntime: java.lang.IllegalArgumentException: Invalid handle to Interpreter.
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:117)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at com.example.android.tflitecamerademo.Camera2BasicFragment.access$900(Camera2BasicFragment.java:69)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at com.example.android.tflitecamerademo.Camera2BasicFragment$5.run(Camera2BasicFragment.java:558)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at android.os.Handler.handleCallback(Handler.java:789)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at android.os.Handler.dispatchMessage(Handler.java:98)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at android.os.Looper.loop(Looper.java:180)
01-23 10:46:45.292 21514 21536 E AndroidRuntime: 	at android.os.HandlerThread.run(HandlerThread.java:65)

I see the similar issue in https://groups.google.com/a/tensorflow.org/forum/?hl=es-VE#!topic/discuss/jJSH5RQO4Mo, but no one answer.

P.S. My training tflite file size is about 248293KB

Could you kindly to help?

Thanks

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,2,2018-01-23T02:59:44Z,NONE
16306,Add LINM (Loop Invariant Node Motion) optimization pass in GraphOptim…,"awaiting review,cla: yes","…izer
This change was inspired by LICM (Loop Invariant Code Motion) of compilers. We observed from some public models, e.g. seq2seq (https://github.com/google/seq2seq) and tensor2tensor (https://github.com/tensorflow/tensor2tensor), as well as some of our in-house models that there are many invariant nodes, including expensive MatMul nodes, inside the loop body. 
This optimization pass is to apply on Tensorflow computational graph to detect these invariant nodes and move them out of the loop body, that's why we call it LINM (Loop Invariant Node Motion).

Although there's already a LICM pass in XLA (https://github.com/tensorflow/tensorflow/commit/51895fe67434b6e9f5419872f69c7e6092ed69e9), we still feel necessary to add this LINM pass in GraphOptimizer because:
1. The XLA LICM pass is based on XlaWhile instruction, but the conversion from loop nodes (Enter/Exit/Switch/Merge/LoopCond) of tf.while to XlaWhile instruction is not hooked up yet (https://groups.google.com/forum/#!topic/xla-dev/IqLyL67cemI)
2. We further found out that even if the conversion is hooked up, it works only when all nodes inside the loop has XLA kernel registered. It's a long way to go to get all operators supported by XLA.
3. The LINM pass in GraphOptimizer is expected to work no matter whether XLA is on or off. ",1,,1,2018-01-23T02:37:45Z,NONE
16302,Update README.md,"awaiting review,cla: yes",Correct MobilenetV1 variable,1,,0,2018-01-22T23:28:13Z,NONE
16301,Update README.md,"awaiting review,cla: yes",Correct MobilenetV1 variable,1,,3,2018-01-22T23:22:46Z,NONE
16300,Add tf.multi_one_hot that one-hot encodes multiple columns of Tensor,"awaiting review,cla: yes","Hello,
here is the PR for my feature request #16044 
Excited to see your feedback for my first TF PR and hope to give something useful back to this great library ;)",1,,7,2018-01-22T23:06:34Z,NONE
16291,[bug] Specify GPU device error when using session_options.config.mutable_gpu_options()->set_visible_device_list,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes. 
session_options.config.mutable_gpu_options()->set_visible_device_list(""0"");
session->reset(tensorflow::NewSession(session_options)); // Error in this line
Status session_create_status = (*session)->Create(graph_def); 

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.9.0
- **GCC/Compiler version (if compiling from source)**:
5.4
- **CUDA/cuDNN version**:
CUDA 8.0  /  cuDNN 6.0.21
- **GPU model and memory**:
Quadro P6000, 24G GPU memory
- **Exact command to reproduce**:


### Describe the problem
I built the tensorflow C++ API from the source using Bazel 0.9.0. When I link the shared library libtensorflow_cc.so, my code works fine. (I do not need to link libtensorflow_framework.so, since I used '--config=monolithic' when I build tensorflow using bazel.)
However, I want to specify the GPU device in my code using this function to set gpu options:
session_options.config.mutable_gpu_options()->set_visible_device_list(""0"");
session->reset(tensorflow::NewSession(session_options)); // **Error in this line**

### Source code / logs
Logs:
2018-01-22 09:39:57.262843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1202] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:02:00.0
totalMemory: 23.87GiB freeMemory: 22.46GiB
2018-01-22 09:39:57.262897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1296] Adding visible gpu device 0
2018-01-22 09:39:57.584754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21801 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:02:00.0, compute capability: 6.1)
2018-01-22 09:39:57.584802: E tensorflow/core/common_runtime/gpu/process_state.cc:130] Invalid allocator type: 0
Segmentation fault (core dumped)


Source Codes:
// Reads a model graph definition from disk, and creates a session object you
// can use to run it.
Status LoadGraph(const string& graph_file_name, std::unique_ptr<tensorflow::Session>* session) 
{
    tensorflow::GraphDef graph_def;
    Status load_graph_status = ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);
    if (!load_graph_status.ok()) 
    {
        return tensorflow::errors::NotFound(""Failed to load compute graph at '"",
                                        graph_file_name, ""'"");
    }
    //tensorflow::SessionOptions options;
    tensorflow::SessionOptions session_options;
    session_options.config.mutable_gpu_options()->visible_device_list();
    std::cout<<""list GPU done""<<std::endl;
    session_options.config.mutable_gpu_options()->set_visible_device_list(""0"");
    std::cout<<""GPU assign is done""<<std::endl;
   
    session->reset(tensorflow::NewSession(session_options));
    std::cout<<""new session is created. ""<<std::endl;
    Status session_create_status = (*session)->Create(graph_def);
    std::cout<<""Graph is loaded. ""<<std::endl;
    if (!session_create_status.ok()) 
    {
        return session_create_status;
    }
    return Status::OK();
}",0,,1,2018-01-22T15:53:27Z,NONE
16287,[Bug] LuongMonotonicAttention in contrib/seq2seq/python/ops/attention_wrapper.py,stat:awaiting tensorflower,"`LuongMonotonicAttention.__init__(...)` calls its parent `_BaseAttentionMechanism` with `query_layer` as follows:
```
        query_layer=layers_core.Dense(
            num_units, name=""query_layer"", use_bias=False),
```
But, it doesn't apply it on query in `LuongMonotonicAttention.__call__(...)`.
```
  def __call__(self, query, previous_alignments):
    """"""...
    """"""
    with variable_scope.variable_scope(None, ""luong_monotonic_attention"",
                                       [query]):
      score = _luong_score(query, self._keys, self._scale)
      score_bias = variable_scope.get_variable(
          ""attention_score_bias"", dtype=query.dtype,
          initializer=self._score_bias_init)
      score += score_bias
    alignments = self._probability_fn(score, previous_alignments)
    return alignments
```
Guessing from the way `LuongAttention` works, there should be `query_layer=None` in `LuongMonotonicAttention.__init__(...)`.",0,,2,2018-01-22T13:50:55Z,NONE
16285,"tf-seq2seq, nmt, tensorflow's seq2seq diff",stat:awaiting response,"google-seq2seq, nmt, tensorflow's seq2seq
what is the diff about them",0,,1,2018-01-22T13:17:51Z,NONE
16284,[bug?] Tensorflow accepts CUDA_VISIBLE_DEVICES but still allocates memory on multiple GPUs,,"### System information
- **I have written a custom script, but effect is also visible for just `import tensorflow as tf; sess = tf.Session()`**:
- **Windows 7 Professional**:
- **TensorFlow installed from binary (pip, in Anaconda environment)**:
- **TensorFlow version 1.4.0**:
- **Python version 3.5.4**: 
- **CUDA/cuDNN version 8.0/6.0**:
- **4 GeForce GTX 1080Ti, 11GB**:

### Problem description
I am facing the following issue:

If I set
`CUDA_VISIBLE_DEVICES=1`
and start my python script, everything works as expected, only GPU 1 is used/only memory from GPU 1 is allocated. GPU1 hosts the Desktop Window Manager.

If I set
`CUDA_VISIBLE_DEVICES=0 # or 2 or 3 `
before running my python script
`sess = tf.Session()`
faithfully reports only one available GPU (with the expected PCI bus id), see attached file ipython.txt.

However, nvidia_smi.exe shows that memory on all remaining GPUs except for GPU1 is allocated. GPU-Util shows that expected GPU is used for actual computation, see attached file nvidia_smi_output.txt.

I see this effect both for my actual tensorflow script as well for simple interactive python with

```
import tensorflow as tf
sess = tf.Session()
```

Unfortunately, the dual boot Ubuntu is not working at the moment, but once it is running again, I can try to check whether a similar effect presents itself there.
Could this be a bug, possibly related to Windows? Or a driver or hardware issue?

Attached files:
[ipython.txt](https://github.com/tensorflow/tensorflow/files/1651908/ipython.txt): ipython script and output.
[nvidia_smi_output.txt](https://github.com/tensorflow/tensorflow/files/1651905/nvidia_smi_output.txt): output of nvidia-smi.exe
",0,,2,2018-01-22T12:36:26Z,NONE
16282,Adding go_package to proto definition files necessary for Tensorflow serving,"stat:contributions welcome,type:feature","I've went through guidelines about calling Tensorflow serving in Python.
Then I've decided to make it Go.

You can find my repo here:
https://github.com/datainq/go-mnist-client

Manually preparing files is unmaintainable. What about we add `go_package` to proto files?
e.g. for a `github.com/tensorflow/tensorflow/tensorflow/core/protobuf/saver.proto` it would be:
```
go_package = ""github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf"";
```
I think keeping the generated files in go' subpath is a good idea.

Does it make sense? 
(@jhseu was the author of the initial Go code)


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**:  N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A",0,,2,2018-01-22T09:24:27Z,NONE
16279,"While using tf.while_loop , the _Slicehelper chooses strided_slice op(req 4 args) instead of slice op(req 3 args)",stat:awaiting response,"I am facing this issue while creating a decoder using tf.while_loop

`
train_decoder = tf.while_loop(self.coarse_decoder_condition, self.coarse_decoder_function,
[self.iter_decoder_c, tf.zeros([1,self.c_dec_size]), tf.ones([self.c_dec_size])] ,
				shape_invariants =[self.iter_decoder_c.get_shape(),tf.TensorShape([None,self.c_dec_size]),tf.TensorShape([self.c_dec_size]) ] )`


here is what comes up in the cmd

```
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\control_flow_ops.py"", line 2816, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\control_flow_ops.py"", line 2640, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\control_flow_ops.py"", line 2576, in _BuildLoop
    c = ops.convert_to_tensor(pred(*packed_vars))

  File ""C:\Users\HP\Music\Final\nn.py"", line 200, in coarse_decoder_condition
    return it[0] < self.oplen_c[0]

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 538, in _SliceHelper
    name=name)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 706, in strided_slice
    shrink_axis_mask=shrink_axis_mask)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 5429, in strided_slice
    name=name)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-
packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_he
lper
    op_def=op_def)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2958, in create_op
    set_shapes_for_outputs(ret)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2209, in set_shapes_for_outputs

    shapes = shape_func(op)
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2159, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 627, in call_cpp_shap
e_fn
    require_shape_fn)

  File ""C:\Users\HP\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 691, in _call_cpp_sha
pe_fn_impl
    raise ValueError(err.message)
ValueError: Index out of range using input dim 0; input has only 0 dims for 'Coarse_Decoder/while/strided_slice' (op: 'StridedSlice') with input shape
s: [], [1], [1], [1] and with computed input tensors: input[3] = <1>.


```

Essentially what is happening is that the while_loop => buildloop => _SliceHelper

the _sliceHelper chooses strided_slice op(which requires 4 args instead of 3) instead of just slice op

This is causing me to get an error while passing 3 args , which is what my requirement is.

A similar issue highlighted [here ](https://github.com/tensorflow/models/issues/817)

I can't manually choose slice() over strided_slice()

Any help would be appreciated @michaelisard",0,,3,2018-01-22T07:15:08Z,NONE
16276,Linking against system-installed cuda and cudnn,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian sid
- **TensorFlow installed from (source or binary)**: source (trying)
- **TensorFlow version (use command below)**: git master (commit 9fb9ac66ce) or any version before.
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 7.2.0
- **CUDA/cuDNN version**: CUDA 9.0, cuDNN 6.0
- **GPU model and memory**: GeForce GTX 1070
- **Exact command to reproduce**:
`bazel build --config=opt --config=mkl --config=cuda //tensorflow/tools/pip_package:build_pip_package`

### Describe the problem
The build system currently require that all the libraries from the CUDA toolkit are stored in a specific directory called `cuda_toolkit_path`, both in the bazel scripts and in the `configure.py` script. However, some systems (like Debian) have a packaged version of CUDA which installs the libraries in the standard path which cannot be found by `configure.py`.

The compiler can find those libraries just right with nothing more than `-lcuda`. It would be nice if the build system could rely on the compiler's ability to find its libraries instead of relying on the knowledge of their full path.

### Source code / logs
As a feature-request / enhancement-request, this section seems irrelevant.",0,,0,2018-01-22T04:42:06Z,NONE
16266,No OpKernel was registered to support Op 'RandomShuffleQueueV2' with these attrs. ,stat:awaiting response,"I build a graph.pb by python.

```
  classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,
                                          hidden_units=[60, 60, 60],
                                          n_classes=numbTrainClass,
                                          model_dir=os.path.curdir + ""/tmp/app_predict_mode1-12"")
```

When I load it on android, 

```
tf = new TensorFlowInterface(mContext.getAssets(), mPbFileName);
...
tf.run(null).
```
This is error.
```
java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'RandomShuffleQueueV2' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: enqueue_input/random_shuffle_queue = RandomShuffleQueueV2[capacity=1000, component_types=[DT_INT64, DT_FLOAT, DT_INT32], container="""", min_after_dequeue=250, seed=0, seed2=0, shapes=[[], [9], []], shared_name="""", _device=""/device:CPU:0""]()]]
```
",0,,1,2018-01-21T09:35:50Z,NONE
16263,losses.softmax_cross_entropy documentation on tensor rank,"stat:awaiting tensorflower,type:docs","### Documentation Issue
It seems `losses.softmax_cross_entropy()` works just fine with any tensor rank/shape (as long as the last dimension is classes) and not just shapes of `[batch_size, num_classes]` as the documentation indicates. (The documentation also indicates weights should be rank 0 or 1; also not true)

If this is the expected behavior, fixing the documentation would help people avoid doing unnecessary reshapes.",1,,1,2018-01-21T03:49:23Z,NONE
16261,Tensorflow Debug tfdbg ValueError with combined loss functions.,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. Included
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Home x64, 1709
- **TensorFlow installed from (source or binary)**: binary (pip3)
- **TensorFlow version (use command below)**:  1.4.0
- **Python version**:  3.5.2
- **Exact command to reproduce**: See source code.

### Describe the problem
When attempting to combine two loss functions, tfdbg fails to properly grab the gradients due to a ValueError when executing run.

### Source code / logs
[consolelog.txt](https://github.com/tensorflow/tensorflow/files/1649424/consolelog.txt) Log of the error.
[not_working.txt](https://github.com/tensorflow/tensorflow/files/1649426/not_working.txt) Code example that generates the error.
[working.txt](https://github.com/tensorflow/tensorflow/files/1649427/working.txt) Code example where the two loss functions are split that does not generate the error.




",1,,3,2018-01-21T00:52:40Z,NONE
16260,easier installation debugging,"stat:awaiting response,type:build/install","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 with Java API
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8 with cudnn64_6.dll
- **GPU model and memory**: 1080
- **Exact command to reproduce**: HelloTF.java

### Describe the problem
Default error message from NativeLibrary load() method is not helpful enough.   
Simple suggested improvement: please print the contents in the string variable ""frameworkResourceName"", which is the missing resource, when throwing a new UnsatisfiedLinkError exception.

### Source code / logs
Suggested Source Code Improvement for NativeLibrary.java:

    if (jniResource == null) {
      throw new UnsatisfiedLinkError(
          String.format(
              ""Cannot find TensorFlow native library %s for OS: %s, architecture: %s. See ""
                  + ""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java/README.md""
                  + "" for possible solutions (such as building the library from source). Additional""
                  + "" information on attempts to find the native library can be obtained by adding""
                  + "" org.tensorflow.NativeLibrary.DEBUG=1 to the system properties of the JVM."",
                  frameworkResourceName,
              os(), architecture()));
    }
",0,,4,2018-01-20T16:48:21Z,NONE
16259,Fix two small issues of XLA,cla: yes,"1.In Tensorflow, conventionally, INT32 ops are regarded as shape or control
ops, and are registered on CPU only. XLA should follow the same rule, to
avoid the potential data transfer between TF CPU ops and in GPU_XLA ops,
which result into performance degradation when XLA is turned-on.
2. Any OpKernel with more than 500 inputs is excluded. This is a temp
workaround to avoid an potential issue that, the cuda drive do not accept
a compiled PTX kernel with parameter space larger than 4352 bytes. The data type
of PTX kernel parameter is u64. An OpKernel with 500 inputs are more likely
to exceed the limit.",1,,0,2018-01-20T15:01:24Z,NONE
16258, Enhance layout optimization logic to remove duplicated layout transp…,"cla: yes,stat:awaiting response","Enhance layout optimization logic to remove duplicated layout transpose operation for performance improvement purpose.
    For example:
            a NCHW-to-NHWC transpose op followed by a NHWC-to-NCHW
            transpose op, under this scenario these two ops acutally can be absorbed into
            nothing, thus avoid unnecessary computation.",1,,2,2018-01-20T14:28:16Z,NONE
16257,feature request: KL distance for Gaussian Mixture Model,"stat:awaiting response,type:feature","I am hoping that **tf.contrib.distributions** module is expanded so that we can calculate **KL** divergence between **multivariate Gaussian Mixture Models(GMM)** ,with its paramter list such as weight, mean, covariance given as Tensor Array. Because I think there is going to be a more need for that for many applications. Thank you.

With current version, either  we can calculate KL divergence for a single gauss, or create GMM object, but not KL for GMM.
https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/Mixture
https://www.tensorflow.org/api_docs/python/tf/distributions/kl_divergence

I tried as shown below, but it didn'T work.

    import tensorflow as tf
    print('tensorflow ',tf.__version__)  # for Python 3
    import numpy as np
    import matplotlib.pyplot as plt

    ds = tf.contrib.distributions
    kl_divergence=tf.contrib.distributions.kl_divergence

    # Gaussian Mixure1
    mix = 0.3# weight
    bimix_gauss1 = ds.Mixture(
    cat=ds.Categorical(probs=[mix, 1.-mix]),#weight
    components=[
       ds.Normal(loc=-1., scale=0.1),
       ds.Normal(loc=+1., scale=0.5),
    ])

    # Gaussian Mixture2
    mix = 0.4# weight
    bimix_gauss2 = ds.Mixture(
        cat=ds.Categorical(probs=[mix, 1.-mix]),#weight
        components=[
            ds.Normal(loc=-0.4, scale=0.2),
            ds.Normal(loc=+1.2, scale=0.6),
    ])

    # KL between GM1 and GM2
    kl_value=kl_divergence(
        distribution_a=bimix_gauss1,
        distribution_b=bimix_gauss2,
        allow_nan_stats=True,
        name=None
    )
     sess = tf.Session() # 
     with sess.as_default():
        x = tf.linspace(-2., 3., int(1e4)).eval()
        plt.plot(x, bimix_gauss1.prob(x).eval(),'r-')
        plt.plot(x, bimix_gauss2.prob(x).eval(),'b-')
        plt.show()

        print('kl_value=',kl_value.eval())`

Then I got this error... **NotImplementedError: No KL(distribution_a || distribution_b) registered for distribution_a type Mixture and distribution_b type Mixture**

I know that with python sklearn without Tensorflow, we can calculate KL for GMM as shown below.
https://stackoverflow.com/questions/48335823/tensorflow-kl-divergence-for-a-gaussian-mixure

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:1.4
- **Python version**: 3
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8
- **GPU model and memory**:
- **Exact command to reproduce**:",1,,2,2018-01-20T08:56:08Z,NONE
16253,Introducing TensorRT operator,cla: yes,"This PR introduces a new op that wraps around an highly optimized TensorRT engine and provides a seamless integration between TensorRT and TensorFlow.
- Add a TRTEngineOp that encapsulates a TensorRT executable.
- Add CreateInferenceGraph to contract a TensorRT-compilable subgraph to a TRTEngineOp.
- Update BUILD files to include new contrib package
- Add tensorflow.contrib.tensorrt python package to expose API to python
",2,,3,2018-01-19T23:09:29Z,CONTRIBUTOR
16248,[bug?] Error in `python': malloc(): memory corruption,"stat:awaiting response,type:bug/performance","Error in `python': malloc(): memory corruption: 0x00000000723f9040

Strangely encountered this error when the training was going, it happened after a certain number of iterations (~7000 iterations with image batch size of 1 using coco dataset).  I have also attached the memory map that showed up after the backtrace.

```
*** Error in `python': malloc(): memory corruption: 0x00000000723f9040 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f9d5715a7e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8213e)[0x7f9d5716513e]
/lib/x86_64-linux-gnu/libc.so.6(__libc_malloc+0x54)[0x7f9d57167184]
/usr/local/lib/python2.7/dist-packages/numpy/core/multiarray.so(+0x1ec51)[0x7f9d560f0c51]
/usr/local/lib/python2.7/dist-packages/numpy/core/multiarray.so(+0x842c8)[0x7f9d561562c8]
/usr/local/lib/python2.7/dist-packages/numpy/core/multiarray.so(+0x844a4)[0x7f9d561564a4]
/usr/local/lib/python2.7/dist-packages/numpy/core/multiarray.so(+0x84920)[0x7f9d56156920]
/usr/local/lib/python2.7/dist-packages/numpy/core/multiarray.so(+0x85105)[0x7f9d56157105]
/usr/local/lib/python2.7/dist-packages/numpy/core/multiarray.so(+0x11b16d)[0x7f9d561ed16d]
/home/user/tools/../data/coco/PythonAPI/pycocotools/_mask.so(+0x9406)[0x7f9d1f276406]
/home/user/tools/../data/coco/PythonAPI/pycocotools/_mask.so(+0x1c05f)[0x7f9d1f28905f]
python(PyEval_EvalFrameEx+0x615e)[0x4ca15e]
python(PyEval_EvalFrameEx+0x5d8f)[0x4c9d8f]
python(PyEval_EvalCodeEx+0x255)[0x4c2765]
python(PyEval_EvalFrameEx+0x68d1)[0x4ca8d1]
python(PyEval_EvalCodeEx+0x255)[0x4c2765]
python(PyEval_EvalFrameEx+0x68d1)[0x4ca8d1]
python(PyEval_EvalCodeEx+0x255)[0x4c2765]
python(PyEval_EvalFrameEx+0x68d1)[0x4ca8d1]
python(PyEval_EvalCodeEx+0x255)[0x4c2765]
python(PyEval_EvalFrameEx+0x68d1)[0x4ca8d1]
python(PyEval_EvalCodeEx+0x255)[0x4c2765]
python(PyEval_EvalFrameEx+0x6099)[0x4ca099]
python(PyEval_EvalCodeEx+0x255)[0x4c2765]
python(PyEval_EvalCode+0x19)[0x4c2509]
python[0x4f1def]
python(PyRun_FileExFlags+0x82)[0x4ec652]
python(PyRun_SimpleFileExFlags+0x191)[0x4eae31]
python(Py_Main+0x68a)[0x49e14a]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f9d57103830]
python(_start+0x29)[0x49d9d9]
```


```
System Information
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

Compiler:
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609

PIPs:
msgpack-numpy (0.4.2)
protobuf (3.5.0.post1)
tensorflow-gpu (1.4.1)
tensorflow-tensorboard (0.4.0rc3)

TensorFlow:
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)

Env:
LD_LIBRARY_PATH /usr/lib/x86_64-linux-gnu:/usr/local/lib:/usr/local/cuda/lib64:
DYLD_LIBRARY_PATH is unset

GPU:
TITAN Xp

CUDA Lib:
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
```
[memory map.txt](https://github.com/tensorflow/tensorflow/files/1647515/memory.map.txt)

",0,,1,2018-01-19T18:21:55Z,NONE
16247,[doc][feature request] Graphical representation of operations,"stat:contributions welcome,type:docs","It would be cool if the documentation of TF operations would contain graphical examples.

E.g. the ""tf.dynamic_partition"" operation contains such a visualization:
![image](https://user-images.githubusercontent.com/1200058/35163918-880ec02e-fd48-11e7-944f-7d3aac7cadc5.png)

This would be especially helpful to understand the different slicing/joining operations.",1,,2,2018-01-19T17:43:47Z,NONE
16246,Failed to build error: mismatched argument pack lenghts...,,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 4.14.13-1-ARCH
- **TensorFlow installed from (source or binary)**: git
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.9.0-1
- **GCC/Compiler version (if compiling from source)**: 6.4.1
- **CUDA/cuDNN version**:  9.1.85-1 / 7.0.5-2
- **Exact command to reproduce**:
./configure
bazel build --config=opt --config=cuda --jobs 12 //tensorflow/tools/pip_package:build_pip_package


### Describe the problem
failed to build

### Source code / logs

> /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'
>        return __and_<is_convertible<_UElements&&, _Elements>...>::value;
>                                                                  ^~~~~
> /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {const std::tuple<tensorflow::VariantBinaryOp, tensorflow::StringPiece, tensorflow::StringPiece>}; bool <anonymous> = true; _Elements = {tensorflow::VariantBinaryOp, tensorflow::StringPiece, tensorflow::StringPiece}]' not a return-statement
>      }
>  ^
> ERROR: /home/user/dev/git/tensorflow/tensorflow/core/kernels/BUILD:1884:1: output 'tensorflow/core/kernels/_objs/list_kernels_gpu/tensorflow/core/kernels/list_kernels.cu.pic.o' was not created
> ERROR: /home/user/dev/git/tensorflow/tensorflow/core/kernels/BUILD:1884:1: not all outputs were created or valid
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> Use --verbose_failures to see the command lines of failed build steps.
> INFO: Elapsed time: 29.727s, Critical Path: 28.35s
> FAILED: Build did NOT complete successfully
> ",0,,5,2018-01-19T17:10:53Z,NONE
16239,Not supported for GpuManagedAllocator,type:feature,"GpuManagedAllocator was early supported at tensorflow/core/common_runtime/gpu/gpu_managed_allocator.cc.
But it seems there is no choice for users to use it according to the source code?
The GpuManagedAllocator can help to enlarge virtual GPU memory to fit huge training models, so it is very important to support them.
So what is the plan next about this feature?",1,,11,2018-01-19T10:41:51Z,NONE
16234,The recognized result is not correct when converting the frozen graph to tflite for android device use ,comp:lite,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: mac High Sierra
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.5.0
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**:0.9.0
- **GCC/Compiler version (if compiling from source)**:c++/4.2.1
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

The detailed system information, you can check the url:
https://drive.google.com/file/d/19oKikJ0PcGHx9daauub28IYb8J3hA-rw/view?usp=sharing

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Hi, I covert the frozen graph:mobilenet_v1_224 to tflite, and put it in the tflitecamerademo app, but the regonization result is not correct. If I use the tflite file which download from https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip

The regonization result is correct, I don't know what steps is not correct when I covert the frozeon graph to tflite file, could you help me to review what steps is the wrong?

I put the frozen graph, coverting tflite file and the regonized picture in the https://drive.google.com/drive/folders/12h9O2AtcnDuQZXogAdmexRSjxIQVc1Ej?usp=sharing

The correct result should be ""malamute"", but I use the my coverting tflite file, the result is ""shower curtain""

I use the command to do the covert
bazel run --config=opt //tensorflow/contrib/lite/toco:toco -- '--input_file=/tmp/mobilenet_frozen_graph.pb' '--output_file=/tmp/mobilenet_quant_20180117.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--inference_type=QUANTIZED_UINT8' '--inference_input_type=QUANTIZED_UINT8' '--input_shapes=1,224,224,3' '--input_arrays=input' '--output_arrays=MobilenetV1/Predictions/Reshape_1' '--mean_values=128' '--std_values=128' '--default_ranges_min=0' '--default_ranges_max=6'

Thanks

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,3,2018-01-19T02:26:39Z,NONE
16231,x86_64 compilation failed,"stat:awaiting tensorflower,type:build/install","### System information

- **MacOS High Sierra 10.13.2**:
- **Python 3.6.3**:
- **TensorFlow Latest Pull from 1/17/18**:

### Describe the problem
I am following Pete Warden's TensorFlow for Mobile Poets guide and seem to have a found an error. When I run ""tensorflow/contrib/makefile/build_all_ios.sh"" after about 20 minutes it returns an error. 

I have tried running lipo -info /Users/ryan/Downloads/tensorflow2/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf.a

and this returns: 

Architectures in the fat file:
/Users/ryan/Downloads/tensorflow2/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf.a are: i386 

I have the entire error script here:
https://drive.google.com/file/d/1JovTMGBJKbqzRPBzXy3cIQ-hbz76n0ab/view?usp=sharing

### Source code / logs
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see 
invocation)
make: *** [/Users/ryan/Desktop/tensorflow-
master/tensorflow/contrib/makefile/gen/bin/ios_X86_64/benchmark] Error 1
+ '[' 2 -ne 0 ']'
+ echo 'x86_64 compilation failed.'
x86_64 compilation failed.
+ exit 1
",1,,1,2018-01-18T23:51:42Z,NONE
16228,tf.contrib.rnn.LSTMCell()  dtype not defined. Error when creating initializer for bias variable. ,,"- **OS Platform and Distribution**: Mac OSX 10.10.5
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.5.0rc
- **Python version**:   3.6
- **Have I written custom code**: NA
- **Bazel version**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**:NA

- **Exact command to reproduce**:

import tensorflow as tf
lstm = tf.contrib.rnn.LSTMCell(10)
input_tensor = tf.ones([10,50])
lstm.build(input_tensor.get_shape())


Traceback (most recent call last):
  File ""/Applications/PyCharm CE.app/Contents/helpers/pydev/_pydevd_bundle/pydevd_exec2.py"", line 3, in Exec
    exec(exp, global_vars, local_vars)
  File ""<input>"", line 1, in <module>
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 719, in build
    initializer=init_ops.zeros_initializer(dtype=self.dtype))
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py"", line 88, in __init__
    self.dtype = dtypes.as_dtype(dtype)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py"", line 627, in as_dtype
    ""Cannot convert value %r to a TensorFlow DType."" % type_value)
TypeError: Cannot convert value None to a TensorFlow DType.

### Describe the problem
It seems that LSTMCell does get the dtype in __init__ and does not pass to parent object. Then lstm._dtype is always None. 
A workearound is to add:
lstm._dtype = 'float32'
before:
lstm.build(input_tensor.get_shape())
",0,,3,2018-01-18T22:08:47Z,NONE
16227,tf.contrib.factorization.KMeansClustering cannot save model,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux
- **TensorFlow version**: 1.4
- **Python version**: 2.7.6

### Describe the problem
In [tf.contrib.factorization.KMeansClustering](https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeansClustering#model_fn ), the TensorFlow 1.4 version of the KMeans Estimator ([previous version](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/KMeansClustering)), the [export_savedmodel](https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeansClustering#export_savedmodel) function throws an error: 

`ValueError: export_outputs must be a dict and not<type 'NoneType'>`

As far as I can tell, the older version used the function [here](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/learn/python/learn/estimators/model_fn.py#L236) to populate export_outputs from the prediction values. The newer version does not do this, rendering it impossible to create a saved model. Instead the [model_fn](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/factorization/python/ops/kmeans.py#L210) returns an EstimatorSpec with no export_outputs. 

To replicate the issue, create and train a simple contrib.factorization.KMeansClustering Estimator and try to save it.

`kmeans = tf.contrib.factorization.KMeansClustering(num_clusters = num_clusters)`
`kmeans.train(input_fn = inputFn)`
`kmeans.export_savedmodel(export_dir, exportFn)`",0,,1,2018-01-18T21:31:26Z,NONE
16226,Include netstat in the tensorflow docker container,type:feature,"### Describe the problem
This is a feature request to add net-tools to the Tensorflow docker containers.  Having netstat in the Tensorflow container will make it easier to find open ports in a multi-tenant environment when launching Tensorflow Distributed or Tensorboard.

Note, I have found how to add netstat (see URL below), but would prefer not having to change or maintain a modified version of the Tensorflow container.

https://stackoverflow.com/questions/41961217/installing-netstat-on-docker-linux-container

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NA
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:tensorflow/tensorflow:1.3.0 docker container
- **TensorFlow installed from (source or binary)**:docker container
- **TensorFlow version (use command below)**:1.3.0
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:NA
- **GCC/Compiler version (if compiling from source)**:NA
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:NA
- **Exact command to reproduce**:netstat
",1,,6,2018-01-18T19:20:32Z,NONE
16225,maxout lose the number of features in the shape of its output,,"In tf.contrib.layers.maxout(), when the shape of ""inputs"" is not completely specified, the shape of its output will be completely unknown, such as [None, None, None] in the 3d case.
Since ""num_units"" has specified the final number of features in the maxout axis, the output should set its shape accordingly:
https://github.com/tensorflow/tensorflow/pull/16114",1,,3,2018-01-18T19:19:05Z,NONE
16219,build&link tensorflow lite c++ library Error,"comp:lite,type:support","System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): v1.4.0-19-ga52c8d9 1.4.1
Python version: 2.7.12
Bazel version (if compiling from source): 0.8.1
GCC/Compiler version (if compiling from source): g++ 5.4.0
CUDA/cuDNN version: none
GPU model and memory: none
Exact command to reproduce: g++ -std=c++11 -I...tensorflow -L. -lframework demo.cpp
Describe the problem

I run 'bazel build //tensorflow/contrib/lite:framework' and get libframework.so. Then I use libframework.so in my own code, but get undefined reference error when compile with g++:
/temp/ccYTZw2h.o: In function 'main':
demo.cpp:(.text+0x46): undefined reference to 'tflite::DefaultErrorReporter()'
demo.cpp:(.text+0x6a): undefined reference ro 'tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'
......

I get following lines by 'nm libframework.so | grep 'DefaultErrorReporter'':
000000000001b1b0 b _ZGVZN6tflite20DefaultErrorReporterEvE14error_reporter
0000000000007990 T _ZN6tflite20DefaultErrorReporterEv
000000000001b1a8 b _ZZN6tflite20DefaultErrorReporterEvE14error_reporter

I'm not familiar with how to use tensorflow lite. Where is the problem could be?",1,,3,2018-01-18T10:18:22Z,NONE
16218,[feature request ? ]  How to return SparseTensor when custom ops,stat:awaiting response,"------------------------
### Describe the problem
there exists some ops (eg: decode_libsvm) that can return SparseTensor by three dense tensor
```
#see: tensorflow/tensorflow/contrib/libsvm/
REGISTER_OP(""DecodeLibsvm"")
    .Input(""input: string"")
    .Output(""label: label_dtype"")
    .Output(""feature_indices: int64"")
    .Output(""feature_values: dtype"")
    .Output(""feature_shape: int64"")
    .Attr(""dtype: {float, double, int32, int64} = DT_FLOAT"")
    .Attr(""label_dtype: {float, double, int32, int64} = DT_INT64"")
    .Attr(""num_features: int >= 1"")
```
Can I define my custom ops which can return SparseTensor directly? ,  

What I want to do is modify tf.decode_csv ,  some column can return Tensor,  some column can return SparseTensor. 
 If i return SparseTensor by (indices,values, shape) dense tensor,  it would be  diffcult . 
does there exists SparseTensor class in c++ api ?
@all, @mrry @yongtang  
Thanks

```
  def parse_csv(value):
    print('Parsing', data_file)
    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)
    features = dict(zip(_CSV_COLUMNS, columns))
    labels = features.pop('income_bracket')
    return features, tf.equal(labels, '>50K')
```

### Have I written custom code
### OS Platform and Distribution
### TensorFlow installed from
### TensorFlow version
### Bazel version
### CUDA/cuDNN version
### GPU model and memory
### Exact command to reproduce",0,,1,2018-01-18T09:41:16Z,NONE
16214,Unable to locate package cuda-command-line-tools,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:r1.5
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0
- **GPU model and memory**:
- **Exact command to reproduce**:
### Describe the problem
In the official installing guide of r1.5, the libcupti-dev library is required to run tensorflow with GPU support. When issue the following command line for CUDA Toolkit >= 8.0:
`$ sudo apt-get install cuda-command-line-tools`
I got this error:
`$ E: Unable to locate package cuda-command-line-tools`
It can't be solved after updating source list.
I have tried  on my desktop and a VM instance on Google Cloud Platform, both with Linux Ubuntu 16.04.
### Source code / logs",0,,1,2018-01-18T07:45:56Z,NONE
16213,Non-chief replicas freeze after chief completes training,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9, 1.4.1
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: Titan X (Pascal), 12 GiB
- **Exact command to reproduce**: Custom Script

### Describe the problem
Non-chief replicas freeze after chief completes training, when in synchronous mode.
The problem appears to occur immediately after the chief shuts down.

See attached source code for a complete example of multi-GPU demonstrating the problem on a toy dataset. Modify the cluster variable and start the PS first, followed by workers then the chief node last. This is somewhat broken out in run_distributed.sh.

``
        sv = tf.train.Supervisor(
            is_chief=(FLAGS.task_index == 0),
            global_step = global_step,
            init_op = init_op
        )
        ...
        with sv.prepare_or_wait_for_session(server.target, config=config) as sess:
            # is chief
            if FLAGS.task_index == 0:
                sv.start_queue_runners(sess, [chief_queue_runner])
                sess.run(init_token_op)
        ...
``

### Source code / logs
[rnn-multi-gpu.zip](https://github.com/tensorflow/tensorflow/files/1641799/rnn-multi-gpu.zip)

",0,,1,2018-01-18T06:20:25Z,NONE
16210,"added CMake options to provide external zlib, GRPC, Eigen","awaiting testing (then merge),cla: yes,stat:awaiting response","Here are changes necessary to build tensorflow with different version of GRPC, Protobuf, Eigen, zlib, etc. It is not possible to compile project using two different versions of protobuf for example. To deal with that I've chosen approach similar to one in GRPC library. Copy of https://github.com/tensorflow/tensorflow/pull/14463#issuecomment-343576192",1,,6,2018-01-18T03:52:23Z,CONTRIBUTOR
16207,Socket issue of run whl,"stat:awaiting response,type:support","Hi ,
I have a problem about run tensorflow .whl.  as follow:

Exception:
Traceback (most recent call last):
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run
    wb.build(autobuilding=True)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build
    self.requirement_set.prepare_files(self.finder)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files
    ignore_dependencies=self.ignore_dependencies))
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/req/req_set.py"", line 554, in _prepare_file
    require_hashes
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py"", line 278, in populate_link
    self.link = finder.find_requirement(self, upgrade)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/index.py"", line 465, in find_requirement
    all_candidates = self.find_all_candidates(req.name)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/index.py"", line 423, in find_all_candidates
    for page in self._get_pages(url_locations, project_name):
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/index.py"", line 568, in _get_pages
    page = self._get_page(location)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/index.py"", line 683, in _get_page
    return HTMLPage.get_page(link, session=self.session)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/index.py"", line 792, in get_page
    ""Cache-Control"": ""max-age=600"",
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/requests/sessions.py"", line 488, in get
    return self.request('GET', url, **kwargs)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/download.py"", line 386, in request
    return super(PipSession, self).request(method, url, *args, **kwargs)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/requests/sessions.py"", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/requests/sessions.py"", line 596, in send
    r = adapter.send(request, **kwargs)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/cachecontrol/adapter.py"", line 47, in send
    resp = super(CacheControlAdapter, self).send(request, **kw)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/requests/adapters.py"", line 390, in send
    conn = self.get_connection(request.url, proxies)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/requests/adapters.py"", line 290, in get_connection
    proxy_manager = self.proxy_manager_for(proxy)
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/requests/adapters.py"", line 184, in proxy_manager_for
    **proxy_kwargs
  File ""/home/CORPUSERS/xp022898/anaconda3/lib/python3.6/site-packages/pip/_vendor/requests/packages/urllib3/contrib/socks.py"", line 154, in __init__
    ""Unable to determine SOCKS version from %s"" % proxy_url
ValueError: Unable to determine SOCKS version from socks:*********",0,,2,2018-01-18T02:42:43Z,NONE
16205,Graph Transform Tool unable to build in TF source r1.5?,type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source 
- **TensorFlow version (use command below)**: r1.5
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: 0.5.4
- **CUDA/cuDNN version**: 9.0/7.0.5
- **GPU model and memory**: 1080Ti
- **Exact command to reproduce**:
```
sudo sh -c ""echo '/usr/local/cuda-8.0/lib64' >> /etc/ld.so.conf.d/nvidia.conf""
sudo ldconfig
bazel clean
bazel build tensorflow/tools/graph_transforms:transform_graph --verbose_failures
```


### Describe the problem
I'm having issue trying to build the graph transform tool with bazel although I've look at existing solutions to similar problem such as #13481. I have been able to build the graph transform tool in previous versions but not in this version, so I'm not too sure what went wrong. Note that previously I got a similar problem when I installed TF from source but it was related to CUDA and I solved it after reinstalling nvcc.

I also rebooted my comp just in case it was a temporary system error, but the error still persists.

Looking at the error, does it have anything to do with ""JEMALLOC""? I enabled this option when configuring tensorflow as seen in the official installation guide.


### Source code / logs
```
ERROR: /home/kwotsin/tensorflow/tensorflow/core/kernels/BUILD:3945:1: C++ compilation of rule '//tensorflow/core/kernels:scatter_nd_op' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/kwotsin/.cache/bazel/_bazel_kwotsin/041f6cc3555a2d9f6211c6d126ede477/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/local/cuda-9.0 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \
    TF_CUDA_VERSION=9.0 \
    TF_CUDNN_VERSION=7.0.5 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL_SYCL=0 \

  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '-std=c++11' -MD -MF bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/scatter_nd_op/tensorflow/core/kernels/scatter_nd_op_cpu_impl_5.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/scatter_nd_op/tensorflow/core/kernels/scatter_nd_op_cpu_impl_5.o' -DEIGEN_MPL2_ONLY -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DTENSORFLOW_USE_JEMALLOC -DTENSORFLOW_USE_ABSL -DTF_USE_SNAPPY -iquote . -iquote bazel-out/k8-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/k8-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt/genfiles/external/local_config_sycl -iquote external/com_google_absl -iquote bazel-out/k8-opt/genfiles/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt/genfiles/external/nsync -iquote external/jemalloc -iquote bazel-out/k8-opt/genfiles/external/jemalloc -iquote external/gif_archive -iquote bazel-out/k8-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/k8-opt/genfiles/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/k8-opt/genfiles/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/k8-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/k8-opt/genfiles/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/k8-opt/genfiles/external/local_config_cuda -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/k8-opt/genfiles/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/k8-opt/genfiles/external/nsync/public -isystem external/jemalloc/include -isystem bazel-out/k8-opt/genfiles/external/jemalloc/include -isystem external/gif_archive/lib -isystem bazel-out/k8-opt/genfiles/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/k8-opt/genfiles/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/k8-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/k8-opt/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda/cuda/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' -msse3 -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c tensorflow/core/kernels/scatter_nd_op_cpu_impl_5.cc -o bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/scatter_nd_op/tensorflow/core/kernels/scatter_nd_op_cpu_impl_5.o)
In file included from tensorflow/core/kernels/scatter_nd_op_cpu_impl_5.cc:18:0:
./tensorflow/core/kernels/scatter_nd_op_cpu_impl.h: In instantiation of 'Index tensorflow::functor::ScatterNdFunctor<Eigen::ThreadPoolDevice, T, Index, OP, IXDIM>::operator()(const CPUDevice&, Index, Eigen::array<long int, IXDIM>, typename tensorflow::TTypes<T, 2>::Tensor, typename tensorflow::TTypes<T, 2>::ConstTensor, typename tensorflow::TTypes<T, 2>::ConstTensor, typename tensorflow::TTypes<T, 2>::Tensor) [with T = float; Index = int; tensorflow::scatter_nd_op::UpdateOp OP = (tensorflow::scatter_nd_op::UpdateOp)0; int IXDIM = 5; tensorflow::CPUDevice = Eigen::ThreadPoolDevice; typename tensorflow::TTypes<T, 2>::Tensor = Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long int>, 16, Eigen::MakePointer>; typename tensorflow::TTypes<T, 2>::ConstTensor = Eigen::TensorMap<Eigen::Tensor<const int, 2, 1, long int>, 16, Eigen::MakePointer>; typename tensorflow::TTypes<T, 2>::ConstTensor = Eigen::TensorMap<Eigen::Tensor<const float, 2, 1, long int>, 16, Eigen::MakePointer>]':
./tensorflow/core/kernels/scatter_nd_op_cpu_impl.h:162:1:   required from here
./tensorflow/core/kernels/scatter_nd_op_cpu_impl.h:137:3: internal compiler error: Segmentation fault
   }
   ^
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.
Target //tensorflow/tools/graph_transforms:transform_graph failed to build
INFO: Elapsed time: 147.229s, Critical Path: 24.74s
FAILED: Build did NOT complete successfully

```",0,,2,2018-01-18T02:06:22Z,CONTRIBUTOR
16203,Feature Request: Add CheckpointSaverListener to tf.contrib.learn.Experiment,"stat:contributions welcome,type:feature","Hello, 

I'm using the `tf.contrib.learn.Experiment` system to manage experiments built using the `tf.Estimator` framework. This setup allows me to specify checkpoint saving frequencies very easily, using just the `min_eval_frequency` argument to `tf.contrib.learn.Experiment`. However, I would like to be able to add a `tf.train.CheckpointSaverListener` (for example, to upload files to AWS after each checkpoint). Can there be a param added to `tf.contrib.learn.Experiment` to pass an optional `CheckpointSaverListener` object, which is then passed to the underlying `CheckpointSaverHook` object?

Thanks!


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Amazon Deep Learning AMI
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8
- **GPU model and memory**: NVIDIA K80
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",1,,4,2018-01-18T00:56:53Z,NONE
16202,regarding the deconvolution operation for conv1d,stat:awaiting response,There are `conv2d_transpose` for` conv2d` and `conv3d_transpose `for `conv3d` respectively.  How about deconvolution operation for `tf.nn.conv1d`?,0,,1,2018-01-18T00:04:23Z,NONE
16197,add broadcasting to `softmax_cross_entropy_with_logits`,type:feature,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yeah
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip3 binary
- **TensorFlow version (use command below)**:
```
>>> tf.__git_version__
'v1.4.0-rc1-11-g130a514'
>>> tf.__version__
'1.4.0'
```
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: tf.nn.softmax_cross_entropy_with_logits(labels=tf.constant(1., shape=(2,)), logits=tf.constant(1., shape=(50,2)))


### Describe the problem
FEATURE REQUEST: `softmax_cross_entropy_with_logits` should broadcast, maybe?  I'm reading groups of data that all have the same label.  Seems a waste to have to replicate the label a gazillion times.

### Source code / logs
```
>>> a = tf.nn.softmax_cross_entropy_with_logits(labels=tf.constant(1., shape=(2,)), logits=tf.constant(1., shape=(50,2)))

Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 50 and 1 for 'SoftmaxCrossEntropyWithLogits_3' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [50,2], [1,2].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1783, in softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 4364, in _softmax_cross_entropy_with_logits
    name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2958, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2209, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2159, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimension 0 in both shapes must be equal, but are 50 and 1 for 'SoftmaxCrossEntropyWithLogits_3' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [50,2], [1,2].
```
",0,,4,2018-01-17T20:33:07Z,NONE
16194,"Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.",,"Hello,

I try to get the output of each layer of my CNN. Here is the full example:
```
`from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import sys
import tempfile
import os
import DatasetReader as dr
import numpy as np
import matplotlib.pyplot as plt


import tensorflow as tf
import utils
FLAGS = None
PLOT_DIR = './output/plots'


def deepnn(x):

  with tf.name_scope('reshape'):

    x_image = tf.reshape(x, [-1, 100, 100, 1])#(x, [-1, 28, 28, 1])

  # First convolutional layer - maps one grayscale image to 32 feature maps.
  with tf.name_scope('conv1'):
    W_conv1 = weight_variable([5, 5, 1, 32])#([5, 5, 1, 32])
    b_conv1 = bias_variable([32])
    # conv1dis = conv2d(x_image, W_conv1) + b_conv1
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
    tf.add_to_collection('conv_weights', conv2d(x_image, W_conv1))

  # Pooling layer - downsamples by 2X.
  with tf.name_scope('pool1'):
    h_pool1 = max_pool_2x2(h_conv1)

  # Second convolutional layer -- maps 32 feature maps to 64.
  with tf.name_scope('conv2'):
    W_conv2 = weight_variable([5, 5, 32, 64])
    b_conv2 = bias_variable([64])
    # conv2dis = conv2d(h_pool1, W_conv2) + b_conv2
    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
    # tf.add_to_collection('conv_weights', h_conv2)

  # Second pooling layer.
  with tf.name_scope('pool2'):
    h_pool2 = max_pool_2x2(h_conv2)

  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image
  # is down to 7x7x64 feature maps -- maps this to 1024 features.
  with tf.name_scope('fc1'):
    W_fc1 = weight_variable([25 * 25 * 64, 1024])
    b_fc1 = bias_variable([1024])
    h_pool2_flat = tf.reshape(h_pool2, [-1, 25*25*64])
    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
    # tf.add_to_collection('conv_weights', W_fc1)

  # Dropout - controls the complexity of the model, prevents co-adaptation of
  # features.
  with tf.name_scope('dropout'):
    keep_prob = tf.placeholder(tf.float32)
    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)

  # Map the 1024 features to 10 classes, one for each digit
  with tf.name_scope('fc2'):
    W_fc2 = weight_variable([1024, 2])
    b_fc2 = bias_variable([2])

  y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2

  return y_conv, keep_prob


def conv2d(x, W):
  """"""conv2d returns a 2d convolution layer with full stride.""""""
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')


def max_pool_2x2(x):
  """"""max_pool_2x2 downsamples a feature map by 2X.""""""
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')


def weight_variable(shape):
  """"""weight_variable generates a weight variable of a given shape.""""""
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)


def bias_variable(shape):
  """"""bias_variable generates a bias variable of a given shape.""""""
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)


def main(_):
  # Import data
  V0Dataset = dr.read_data_sets(FLAGS.data_dir, one_hot=True)

  datasize = 10000
  # Create the model
  x = tf.placeholder(tf.float32, [None, datasize])#224*172])

  # Define loss and optimizer
  y_ = tf.placeholder(tf.float32, [None, 2])
  print(""logits shape {}"".format(y_))


  # # Build the graph for the deep net
  y_conv, keep_prob = deepnn(x)

  with tf.name_scope('loss'):
    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,
                                                            logits=y_conv)
  cross_entropy = tf.reduce_mean(cross_entropy)

  with tf.name_scope('adam_optimizer'):
    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

  with tf.name_scope('accuracy'):
    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))
    correct_prediction = tf.cast(correct_prediction, tf.float32)

  accuracy = tf.reduce_mean(correct_prediction)

  print('cross_entropy {}'.format(cross_entropy))
  print('accuracy {}'.format(accuracy))



  with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(2):#500):
      batch = V0Dataset.train.next_batch(10)
      a = batch[1];
      a = a.reshape(10,2)
      train_step.run(feed_dict={x: batch[0], y_: a, keep_prob: 0.5})



    graph_location = tempfile.mkdtemp()
    print('Saving graph to: %s' % graph_location)
    train_writer = tf.summary.FileWriter(""/tmp/tensorflow/"")
    train_writer.add_graph(tf.get_default_graph())

    conv0 = sess.graph.get_tensor_by_name('conv1/Conv2D:0')
    print(""conv0 {}"".format(conv0))

    predictions0 = sess.run(conv0,
                           {'DecodeJpeg/contents:0': batch[0]}) # Error!!!!
    print(""predictions0 {}"".format(predictions0))
    print(""predictions0 {}"".format(predictions0.size))

```

Here are the errors I get:
```
`Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1064, in _run
    allow_operation=False)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 3035, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 3077, in _as_graph_element_locked
    ""graph."" % (repr(name), repr(op_name)))
KeyError: ""The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.""

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./deep_charging_station_train.py"", line 309, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""./deep_charging_station_train.py"", line 297, in main
    {'DecodeJpeg/contents:0': batch[0]})
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1067, in _run
    + e.args[0])
TypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.
`



```

I don't understand why this appends. I looked with Tensorboard I don't know where should I get the DecodeJpeg informations of the layer

Edit:
Have I written custom code : I use deep mnist tutorial example and I modify the size of the input image
OS Platform and Distribution : Ubuntu 16.04
TensorFlow installed from
TensorFlow version 1.4.0
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory N/A
Exact command to reproduce
",0,,4,2018-01-17T16:09:30Z,NONE
16190,ValueError: Inputs to `Dense` should have rank >= 2.,stat:awaiting response,"##error

Traceback (most recent call last):
  File ""firstGANtf.py"", line 90, in <module>
    G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)
  File ""firstGANtf.py"", line 55, in __init__
    self.map1 = tf.contrib.layers.linear(inputs=input_size , num_outputs=hidden_size)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 177, in func_with_args
    return func(*args, **current_args)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1409, in fully_connected
    outputs = layer.apply(inputs)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 303, in apply
    return self.__call__(inputs, **kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 269, in __call__
    self.build(input_shapes[0])
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/layers/core.py"", line 110, in build
    raise ValueError('Inputs to `Dense` should have rank >= 2.')
ValueError: Inputs to `Dense` should have rank >= 2.


##code

       self.map1 = tf.contrib.layers.linear(inputs=input_size , num_outputs=hidden_size)
        self.map2 = tf.contrib.layers.linear(inputs=hidden_size,  num_outputs=hidden_size)
        self.map3 = tf.contrib.layers.linear(inputs=hidden_size, num_outputs=output_size)",0,,3,2018-01-17T11:05:49Z,NONE
16189,"Will tf-Lite have GPU support , if the answer is yes ,the compute API will be which one ,OpenCL or gles ?","comp:lite,type:feature",,1,,1,2018-01-17T10:44:42Z,NONE
16187,Faster R-CNN: too many resources requested for launch,type:bug/performance,"I am trying to deploy the pretrained Faster-RCNN Inception V2 from the object detection API on a Jetson TX2. 
I am running CUDA 8, cuDNN 6 and have tested with both TF 1.3 and 1.5 in a Jupyter Notebook environment. 
When I monitor the GPU memory it starts out by having 4.8 GB free and when launching these fills up immediately. When I run on my GTX1060 6 GB GPU I have effectively the same amount of memory free but are having no issues running.
Smaller models as SSD MobileNet runs without problems.

From tests performed today, I can supply the following dumps.

Jupyter Notebook terminal output:

```
2018-01-17 16:16:19.584106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:859] ARM64 does not support NUMA - returning NUMA node zero
2018-01-17 16:16:19.584261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Found device 0 with properties: 
name: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3005
pciBusID: 0000:00:00.0
totalMemory: 7.67GiB freeMemory: 4.97GiB
2018-01-17 16:16:19.584312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Adding visible gpu device 0
2018-01-17 16:16:20.824479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:987] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4437 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)
2018-01-17 16:17:09.816477: E tensorflow/stream_executor/cuda/cuda_driver.cc:1080] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED
2018-01-17 16:17:09.816703: E tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x7f001959b0: CUDA_ERROR_LAUNCH_FAILED
2018-01-17 16:17:09.816771: E tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x7f001959b0: CUDA_ERROR_LAUNCH_FAILED
2018-01-17 16:17:09.816912: E tensorflow/stream_executor/cuda/cuda_dnn.cc:2456] failed to enqueue convolution on stream: CUDNN_STATUS_EXECUTION_FAILED
2018-01-17 16:17:10.174651: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x7f001959b0: CUDA_ERROR_LAUNCH_FAILED
2018-01-17 16:17:10.174772: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x7f001959b0: CUDA_ERROR_LAUNCH_FAILED
2018-01-17 16:17:10.174806: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x7f001959b0: CUDA_ERROR_LAUNCH_FAILED
2018-01-17 16:17:10.174836: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x7f001959b0: CUDA_ERROR_LAUNCH_FAILED
2018-01-17 16:17:10.174865: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x7f001959b0: CUDA_ERROR_LAUNCH_FAILED
```

Error dump from printout inside the notebook:

```
Exception in thread Thread-4:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""<ipython-input-5-a51933cd03d8>"", line 19, in worker
    im, t_elapsed = detect_objects(frame_rgb, sess, detection_graph)
  File ""<ipython-input-4-6c8da66803e2>"", line 19, in detect_objects
    feed_dict={image_tensor: image_np_expanded})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1128, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1344, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1363, in _do_call
    raise type(e)(node_def, op, message)
InternalError: cuDNN launch failure : input shape([1,64,138,256]) filter shape([3,3,64,192])
	 [[Node: FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_2c_3x3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_2b_1x1/Relu, FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights/read/_47__cf__53)]]
	 [[Node: BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal/_883 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_10508...ield/Equal"", tensor_type=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopBatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/non_max_suppression/iou_threshold/_1)]]

Caused by op u'FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_2c_3x3/Conv2D', defined at:
  File ""/usr/lib/python2.7/threading.py"", line 774, in __bootstrap
    self.__bootstrap_inner()
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""<ipython-input-5-a51933cd03d8>"", line 10, in worker
    tf.import_graph_def(od_graph_def, name='')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 548, in import_graph_def
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3176, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InternalError (see above for traceback): cuDNN launch failure : input shape([1,64,138,256]) filter shape([3,3,64,192])
	 [[Node: FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_2c_3x3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_2b_1x1/Relu, FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights/read/_47__cf__53)]]
	 [[Node: BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal/_883 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_10508...ield/Equal"", tensor_type=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopBatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/non_max_suppression/iou_threshold/_1)]]
```

Output of tegrastats at the point of error:
```
RAM 3151/7851MB (lfb 915x4MB) cpu [2%@345,100%@2034,99%@2034,1%@348,3%@348,6%@349] EMC 5%@1866 APE 150 GR3D 0%@114
RAM 3151/7851MB (lfb 915x4MB) cpu [0%@345,100%@1981,100%@1988,3%@348,5%@348,4%@349] EMC 5%@1866 APE 150 GR3D 0%@114
RAM 3152/7851MB (lfb 915x4MB) cpu [2%@345,100%@2021,100%@2021,4%@348,5%@348,2%@349] EMC 5%@1866 APE 150 GR3D 0%@114
RAM 3152/7851MB (lfb 915x4MB) cpu [2%@345,100%@2035,100%@2034,3%@349,4%@348,2%@348] EMC 5%@1866 APE 150 GR3D 0%@114
RAM 3152/7851MB (lfb 915x4MB) cpu [1%@345,100%@2016,100%@2019,2%@345,1%@349,3%@348] EMC 5%@1866 APE 150 GR3D 0%@114
RAM 3181/7851MB (lfb 898x4MB) cpu [21%@806,100%@2021,56%@2024,8%@499,10%@500,3%@500] EMC 5%@1866 APE 150 GR3D 24%@114
RAM 3210/7851MB (lfb 887x4MB) cpu [8%@345,100%@2018,32%@2026,7%@345,24%@345,13%@349] EMC 5%@1866 APE 150 GR3D 99%@114
RAM 3327/7851MB (lfb 838x4MB) cpu [2%@1573,100%@1987,31%@1992,35%@1574,13%@1575,5%@1573] EMC 5%@1866 APE 150 GR3D 8%@114
RAM 3578/7851MB (lfb 758x4MB) cpu [19%@1806,100%@2080,0%@2035,7%@2035,2%@2035,56%@1727] EMC 5%@1866 APE 150 GR3D 10%@114
RAM 3732/7851MB (lfb 715x4MB) cpu [2%@345,100%@2034,83%@2035,5%@348,21%@345,2%@346] EMC 7%@1866 APE 150 GR3D 99%@624
RAM 3732/7851MB (lfb 715x4MB) cpu [94%@2036,100%@2035,97%@2034,87%@1987,13%@2035,1%@2035] EMC 4%@1866 APE 150 GR3D 43%@1032
RAM 3659/7851MB (lfb 727x4MB) cpu [2%@653,81%@2022,20%@2027,28%@652,2%@655,4%@655] EMC 3%@1866 APE 150 GR3D 0%@114
RAM 3661/7851MB (lfb 727x4MB) cpu [1%@345,100%@2033,0%@2035,1%@346,2%@348,3%@349] EMC 3%@1866 APE 150 GR3D 0%@114
RAM 3661/7851MB (lfb 727x4MB) cpu [2%@345,100%@2035,0%@2034,0%@348,3%@348,0%@348] EMC 2%@1866 APE 150 GR3D 0%@114
RAM 3661/7851MB (lfb 727x4MB) cpu [3%@345,100%@2034,0%@2035,1%@348,1%@348,3%@348] EMC 2%@1866 APE 150 GR3D 0%@114
RAM 3661/7851MB (lfb 727x4MB) cpu [2%@345,100%@2034,0%@2034,2%@348,4%@348,1%@348] EMC 2%@1866 APE 150 GR3D 0%@114
RAM 3661/7851MB (lfb 727x4MB) cpu [4%@345,100%@1988,0%@1987,2%@346,2%@345,1%@345] EMC 2%@1866 APE 150 GR3D 9%@114
RAM 3661/7851MB (lfb 727x4MB) cpu [4%@345,100%@2026,0%@2026,1%@347,0%@348,3%@348] EMC 2%@1866 APE 150 GR3D 0%@114
RAM 3661/7851MB (lfb 727x4MB) cpu [8%@345,100%@2024,0%@2028,5%@345,8%@345,1%@345] EMC 2%@1866 APE 150 GR3D 0%@114
```
As you can see the RAM are nowhere near full at the moment of the error.

Can anybody suggest a solution to this?",0,,5,2018-01-17T09:24:26Z,NONE
16186,A bug when applying MultiRNNCell?,,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: This code is very similar to an official example
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: pip install tensorflow
- **TensorFlow version (use command below)**: b'unknown' 1.4.0
- **Python version**: Python 3.5.2 :: Anaconda 4.2.0 (64-bit)
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
tf.nn.MultiRNNCell sometimes doesn't work.

It raises an issue like this:
ValueError: Dimensions must be equal, but are 64 and 96 for 'lstm/rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [128,64], [96,128].

### Source code / logs
  import tensorflow as tf
  import numpy as np

  hidden_layer_size = 32
  embed = tf.zeros((128, 6, 64), dtype=tf.float32)

  num_LSTM_layers = 2
  with tf.variable_scope(""lstm""):
    
    lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_layer_size, forget_bias=1.0)
    cell = tf.contrib.rnn.MultiRNNCell(cells=[lstm_cell]*num_LSTM_layers, state_is_tuple=True)
    outputs, states = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32)
   
Error:
ValueError: Dimensions must be equal, but are 64 and 96 for 'lstm/rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [128,64], [96,128].

",0,,3,2018-01-17T09:23:15Z,NONE
16185,"add LU operation and return factorized matrices, related to #6992","awaiting review,cla: yes","This should be related to #6992 for mccajm request ""It would be nice to expose the decomposition, like tf.cholesky_solve, so that it can be reused on the next solve if A doesn't change."" 

tf.lu op is added. L, U, P, Q = tf.lu(A), where A = P^-1 L U Q^-1
The test case script is added to python/kernel_test 

",1,,3,2018-01-17T08:47:37Z,NONE
16184,Tensorflow and libcuda.so.1,,"Tensorflow 1.4.1
OS:  CentOS 6/7  (we use customized gcc 4.9.2 build for CentOS 6)

We have a number of computational servers.  Some are with GPU but some are not.  For the ease of maintenance, we build tensorflow from source code (bazel build) and install the modules under
/usr/local/... that all computational servers mount to the same /usr/local by means of NFS.

In the past (Tensorflow 1.0.0), the module could be built without linking with libcuda.so.1.  When a computational server without GPU runs tensorflow, it could run as CPU mode without problems.  When the computational server with GPU runs tensorflow, it could detect the GPU and load up libcuda.so.1 (and libcudart.so and libcudnn.so) by using dso_loader.  This works great for supporting both GPU and non-GPU servers while sharing the same module.

But I think that since 1.2.1 (at least, still 1.4.1), it seems that linking libcuda.so.1 is mandatory.  This is bad when non-GPU server would fail loading the module (missing libcuda.so.1), unless we explicitly putting libcuda.so.1 under /usr/lib64 (but this is a non-GPU server...!).  

Wonder if it is possible to make use of the old method of dso_loader instead of linking libcuda.so.1 for bazel building.  Thanks.
",0,,3,2018-01-17T08:15:06Z,NONE
16182,"What are the relation ship between TF.Slim, TF high level API and Keras",stat:awaiting response,"I am very confused. What are the relationships between TF.Slim, TF high level API and Keras. I just want to know which one has the long term evolution. Fragmentation, like Android OS, is a very bad and dangerous thing. At least for me, I am not comfortable with TF.Slim at all. Why TF cannot have a unified and Standardized API? The benefits are so obvious. It should not become different political parties fight each other.",0,,2,2018-01-17T07:52:26Z,NONE
16180,Tensorboard is down after upgrading the tensorflow?,,"Hello everyone:

I meet a issue about tensorboard after upgrading the tensorflow. It runs nicely before, but I want maintain some Python2.7 codes in Python3.4. That is why I install tensorflow .whl file of Python 3.4 and modify some grammer from Python2.7 to Python3.4. Then codes still run fine, but tensorboard is donw. The error message as following:

![image](https://user-images.githubusercontent.com/12611573/35029640-d1981942-fb96-11e7-9b89-c3c14ffaa54b.png)

OS Platform: Ubuntu 14.04
TensorFlow installed from: pip instll .whl file
TensorFlow version: tensorflow 1.2.1 for Python2, but can not check the version for Python 3

What should I do for this issue? degrade tensorflow or upgrade CUDA?
Can anybody give me any help? Thank you!
",0,,11,2018-01-17T07:00:41Z,NONE
16179,ProfilerHook and loading libcupti.so cause Ubuntu to completely freeze,"stat:awaiting tensorflower,type:bug/performance","1. OS Platform and Distribution: Ubuntu 14.04 LTE
2. TensorFlow version: 1.14
3. Bazel version: 0.9.0
4. CUDA/cuDNN version: 8.0/7.0.5
5. GPU model and memory: GeForce GTX1060 - 6070MB
6. Exact command to reproduce: python3.4 -m music_modeling 
--

I added ""ProfilerHook"" to Estimator for recording GPU memory consumption; but it always causes my Ubuntu to freeze indefinitely and Ubuntu never makes away with it.

Here is the source code:

```
import tensorflow as tf

from tensorflow.python.layers.core import dense
from tensorflow.python import debug as tf_debug

from data.music_data_reader import MusicDataReader
from model.tf_msa_rnn import dynamic_msa_rnn


FLAGS = tf.app.flags.FLAGS
tf.app.flags.DEFINE_string(""mode"", tf.estimator.ModeKeys.TRAIN,
                           """"""""Is training or testing mode"""""")
tf.app.flags.DEFINE_string(""model_dir"", './msa_model',
                           """"""""Directory in where checkpoints are stored"""""")
tf.app.flags.DEFINE_integer(""batch_size"", 20,
                            """"""Number of samples in a batch"""""")
tf.app.flags.DEFINE_integer(""num_epochs"", 100,
                            """"""""How many times the whole training set has to be fed into network"""""")
tf.app.flags.DEFINE_string(""log_directory"", './log_dir',
                           """"""""Directory in where logs and checkpoints are stored"""""")
# *************************************
# *************************************Configuration options for the network
# *************************************
tf.app.flags.DEFINE_integer(""num_units"", 30,
                            """"""""# of hidden units in an LSTM cell"""""")
tf.app.flags.DEFINE_integer(""num_msa_feats"", 10,
                            """"""""# of MS features to be learned"""""")
tf.app.flags.DEFINE_integer(""signal_len"", 100,
                            """"""""Length of the signal at a time to be processed by 
                                multi-scale analyzer
                            """""")
tf.app.flags.DEFINE_integer(""dim_pitch"", 88,
                            """"""""# of hidden units in an LSTM cell"""""")
# *************************************
# *************************************Configuration options for dataset
# *************************************
tf.app.flags.DEFINE_string(""dir_path"",
                           './music_samples/MuseData',
                           """"""""Absolute path to the music files for reading training/testing samples"""""")
tf.app.flags.DEFINE_integer(""pitch_low"",
                            21,
                            """"""""Low pitch value"""""")
tf.app.flags.DEFINE_integer(""pitch_high"",
                            109,
                            """"""""High pitch value"""""")
tf.app.flags.DEFINE_float(""dt"",
                          0.3,
                          """"""""Not sure yet..."""""")


def loss_fn(y_pred, y_true):
    '''

    :param y_pred: Logits predicted by the model
    :param y_true: Correct values corresponding each prediction
    :return:
    '''

    y_pred = tf.log(tf.nn.softmax(y_pred, name=""probs_tensor""))  # [BSxMTxOS] -- Probabilities
    p_trun = y_pred[:, 0:-1, ...]  # x'[1], x'[2], ..., x'[N-1]
    t_trun = y_true[:, 1:, ...]  # x[1], x[2], ..., x[N-1]
    loss = tf.reduce_sum(p_trun*t_trun, axis=2)  # [BSxMT] -- Dot product between 3rd dimensions
    loss = tf.reduce_mean(loss, name=""piano_roll_loss"")  # loss function -- returns a scalar
    tf.summary.scalar(""loss_fn"", loss)  # Add summary for the loss
    loss = tf.Print(loss, [loss], ""Loss: "")
    return loss


def model_fn(features,
             mode=tf.estimator.ModeKeys.TRAIN,
             params=None):

    print(""Creating Model..."")
    input_ph = tf.reshape(features['input_ph'], [FLAGS.batch_size, params['max_seq'], FLAGS.dim_pitch])
    seq_len_ph = tf.reshape(features['seq_len_ph'], [FLAGS.batch_size])
    outputs, state = dynamic_msa_rnn(FLAGS.batch_size,
                                     input_ph,
                                     seq_len_ph,
                                     params['max_seq'],
                                     FLAGS.signal_len,
                                     [20, 10],  # Number of filters per layer
                                     [11, 13],  # Kernel size for each layer
                                     [3],  # Pooling size for each layer
                                     FLAGS.num_msa_feats,
                                     FLAGS.num_units,
                                     activation=tf.nn.tanh,
                                     initializer=tf.glorot_normal_initializer())  # [BSxMTxOS], [BSxSS]
    # Create fully connected layer to generate output for piano keys
    outs = dense(outputs,
                 FLAGS.dim_pitch,
                 kernel_initializer=tf.glorot_normal_initializer())  # BSxMTxID
    loss = loss_fn(outs, features['input_ph'])
    print(""Creating Estimator Spec for %s ..."" % mode)
    # For training
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.AdamOptimizer()
        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          train_op=train_op)
    # For evaluation
    eval_metric_ops = {
        ""accuracy"": tf.metrics.accuracy(
            labels=tf.argmax(features['input_ph'][:, 1:, ...], axis=-1),
            predictions=tf.argmax(outs[:, 0:-1, ...], axis=-1)
        )
    }
    return tf.estimator.EstimatorSpec(mode=mode,
                                      loss=loss,
                                      eval_metric_ops=eval_metric_ops)


def do_train(tr_data, vl_data):

    # Create Estimator
    sess_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
    sess_conf.gpu_options.allow_growth = True
    config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,  # CheckpointSaverHook
                                    save_checkpoints_steps=100,  # CheckpointSaverHook
                                    log_step_count_steps=10,  # SummarySaverHook
                                    session_config=sess_conf)
    music_classifier = tf.estimator.Estimator(model_fn,
                                              config=config,
                                              params={'max_seq': tr_data.max_seq})
    # Prepare input data
    tr_input_fn = tf.estimator.inputs.numpy_input_fn(
        {'input_ph': tr_data.data, 'seq_len_ph': tr_data.seq_len},
        batch_size=FLAGS.batch_size,
        num_epochs=FLAGS.num_epochs,
        num_threads=1,
        shuffle=True
    )
    # Extra Hooks
    logging_hook = tf.train.LoggingTensorHook(
        tensors={'probabilities': 'probs_tensor'},
        every_n_secs=60
    )
    # debugging_hook = tf_debug.LocalCLIDebugHook(thread_name_filter=""MainThread$"", dump_root=""./dump"")
    profiler_hook = tf.train.ProfilerHook(save_steps=1,
                                          output_dir=""./profile"",
                                          show_dataflow=False,
                                          show_memory=True)
    # Train
    music_classifier.train(tr_input_fn, hooks=[profiler_hook])
    print(""Training is over..."")


def do_test(te_data):

    print(""Start testing..."")


def main(_):

    if FLAGS.mode == tf.estimator.ModeKeys.TRAIN:
        tr_data = MusicDataReader(FLAGS.dir_path,
                                  'train',
                                  (FLAGS.pitch_low, FLAGS.pitch_high),
                                  FLAGS.dt)
        vl_data = MusicDataReader(FLAGS.dir_path,
                                  'valid',
                                  (FLAGS.pitch_low, FLAGS.pitch_high),
                                  FLAGS.dt)
        print(""Number of training samples: %d"" % tr_data.data_num)
        print(""Number of validation samples: %d"" % vl_data.data_num)
        do_train(tr_data, vl_data)
    else:
        te_data = MusicDataReader(FLAGS.dir_path,
                                  'test',
                                  (FLAGS.pitch_low, FLAGS.pitch_high),
                                  FLAGS.dt,)
        print(""Number of testing samples: %d"" % te_data.data_num)
        do_test(te_data)


if __name__ == ""__main__"":
    tf.app.run(main=main)
```
I cannot attach the output of my console for it is impossible due to the indefinite freezing of my Ubuntu. All I can say is that it tells me that it loads **libcupti.so** and computes a step of training process. Then, everything totally messes up.

Thank you for your support in advance.",0,,2,2018-01-17T06:43:45Z,NONE
16175,"remove "":arm"" to build tflite on ARM64 linux","awaiting review,cla: yes,comp:lite","When build TF Lite related stuff such as lable_image for tflite on ARMv64 non-Android environment (I am running Debian on an internal development board). I saw something like:

 ```
 /home/freedom/work/tensorflow/tensorflow/contrib/lite/kernels/internal/BUILD:264:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels/internal:neon_tensor_utils' failed (Exit 1)
  gcc: error: unrecognized command line option '-mfpu=neon'
  gcc: error: unrecognized command line option '-mfloat-abi=softfp'
```

It seems ARM64 falls into the "":arm"" category. After removing it, I can build my tflite-based command line programs without problems.",1,,1,2018-01-17T04:23:38Z,CONTRIBUTOR
16174,Failed to Create Session: CUDA_ERROR_UNKNOWN,"stat:awaiting response,type:support","Failed to create session:
```
import tensorflow as tf
tf.Session()
```
Error info:
E tensorflow/core/common_runtime/direct_session.cc:170] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_UNKNOWN
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ubuntu/envs/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1482, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/home/ubuntu/envs/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 622, in __init__
    self._session = tf_session.TF_NewDeprecatedSession(opts, status)
  File ""/home/ubuntu/envs/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Failed to create session.

------------------------

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: tensorflow-gpu ('v1.4.0-19-ga52c8d9', '1.4.1')
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8.0, cuDNN 6.0
- **GPU model and memory**: Tesla M40 24GB
- **Exact command to reproduce**: N/A
",0,,1,2018-01-17T03:35:28Z,NONE
16170,"tf.train.latest_checkpoint fails when paths have ""//"" ",stat:awaiting response,"```tf.train.latest_checkpoint``` returns the error 
```
ERROR:tensorflow:Couldn't match files for checkpoint
``` 
when paths in the ""checkpoint"" file have ""//"" instead of ""/"". Usually, good practice of using ```os.path.join``` will help avoid this situation, but I believe TensorFlow should account for '//'s in paths as several developers do not use ```os.path.join```

### To reproduce this error
- Create directory ```/home/user/model```
- Create file ```/home/user/model/checkpoint``` whose contents are 

```
model_checkpoint_path: ""/home/user/model//model_1""
all_model_checkpoint_paths: ""/home/user/model//model_0""
all_model_checkpoint_paths: ""/home/user/model//model_1""
```
- Create empty files ```model/model_1.data-00000-of-00001```, ```model/model_1.index```, ```model/model_1.meta```
- Run ```tf.train.latest_checkpoint('/home/user/model')```. 
Expected output is ```u'/home/user/model//model_1'```, but TF returns an error ```ERROR:tensorflow:Couldn't match files for checkpoint /home/user/model//model_1```




### System information
- OS: Ubuntu 16.04
- TF installed via ```pip install tensorflow-gpu```
- TF version: 1.4.1
- Python version: 2.7 
- CUDA/cuDNN version: 8.0
- GPU model and memory: GeForce GTX 1080, 8GB

### Have I written custom code
Yes

### OS Platform and Distribution
Ubuntu 16.04

### TensorFlow installed from
Installed thru ```pip install tensorflow-gpu```

### TensorFlow version
1.4.1

### Bazel version
N/A

### Exact command to reproduce
N/A


",0,,2,2018-01-16T19:56:52Z,NONE
16167,Documentation Method Templates Improvement,type:docs,"### System information
N/A

### Describe the problem
The method/class templates in documentation should include a full, functioning path to the method instead of just truncating to the method's name.

I.e. this is what we have at present (bad): 
<img width=""399"" alt=""screen shot 2018-01-16 at 2 23 08 pm"" src=""https://user-images.githubusercontent.com/9597721/35007940-0511d55c-fac9-11e7-9d0c-4be2db021533.png"">

This is a more practical and copy/paste-friendly version:
<img width=""426"" alt=""screen shot 2018-01-16 at 2 22 49 pm"" src=""https://user-images.githubusercontent.com/9597721/35007976-2970cdc2-fac9-11e7-80b8-0ec1e2334734.png"">

I'm constantly just grabbing method templates, pasting to my text editor and then coming back to docs to copy/paste the package path which is now the header of the page; which is an awful workflow.

### Source code / logs
N/A",1,,5,2018-01-16T19:28:06Z,NONE
16166,import error cudnnSetRNNDescriptor_v6 in tensorflow,"stat:awaiting response,type:support","hi,
I have installed tensorflow-gpu on ubuntu server.at the beginning, my tensorflow work well but recently it gives an error when I logging to the python console and import tensorflow as tf.(server has python 3.5)
![tensor](https://user-images.githubusercontent.com/22906072/35007461-c60ec326-fb34-11e7-84f2-3ff8ca685895.jpg)
",0,,6,2018-01-16T19:16:42Z,NONE
16164,"Accidentally cancelled inceptionV3 during install, now can't install at all",,"Hello,
i was setting up tensorflow for image classification, and after i ran : 

python -m scripts.retrain \
  --bottleneck_dir=tf_files/bottlenecks \
  --model_dir=tf_files/models/""${ARCHITECTURE}"" \
  --summaries_dir=tf_files/training_summaries/""${ARCHITECTURE}"" \
  --output_graph=tf_files/retrained_graph.pb \
  --output_labels=tf_files/retrained_labels.txt \
  --architecture=""${ARCHITECTURE}"" \
  --image_dir=tf_files/flower_photos

It automatically started installing inception, i realized that i needed to change some options so i cancelled the install of inception.
Now i believe that i have a half install that doesn't let me install the full package or use the half package.

I may be wrong, but any suggestions would be appreciated.
FYI: i've run :
pip install inception, to which i receive a ""python setup.py egg_info"" failed with error code 1 in {my local/temp dir}

I also just tried running the scripts.retrain again, to which i receive a ""EOFError: compressed file ended before the end-of-stream marker was reached""

Running on Windows 7",0,,3,2018-01-16T17:28:24Z,NONE
16163,Dataset.from_generator doesn't release memory after recreating the session,"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0-rc0
- **Python version**: Python 3.6
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: see below

### Describe the problem

After closing the session and creating new one an iterator creates the generator instance but doesn't free the memory of the previous one.

Every calling of the line `session.run(x)` (see below) increases memory consumption of the script:

- 519 MiB after the first,
- 600 MiB after the second,
- 681 MiB after the third and so on.

As you can see the delta is equal to 80 MiB = N * sizeof(data.dtype). (data.dtype is float64 here)

### Source code / logs
```python
import numpy as np
import tensorflow as tf

N = 10 * 1024 * 1024

def generate():
  data = np.random.rand(N)
  for k in range(N):
    yield data[k].copy()

graph = tf.Graph()
with graph.as_default():
  x = tf.data.Dataset\
    .from_generator(generate, tf.float32)\
    .make_one_shot_iterator()\
    .get_next()

while True:
  session = tf.Session(graph=graph)
  session.run(x) # <--- PUT A BREAKPOINT HERE!
                 #  Be careful running the code without it!
  session.close()
```",1,,2,2018-01-16T16:55:16Z,NONE
16162,segmentation fault when calling help on GraphNodeProto,,"### System information
- **Have I written custom code**:
Nothing beside the example code below.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux RBSylaptop 4.14.0-2-amd64 #1 SMP Debian 4.14.7-1 (2017-12-22) x86_64 GNU/Linux

- **TensorFlow installed from**:
`    $ pip3 install tensorflow-gpu`

- **TensorFlow version**:
tf.VERSION = 1.4.1
tf.GIT_VERSION = v1.4.0-19-ga52c8d9
tf.COMPILER_VERSION = v1.4.0-19-ga52c8d9

- **Python version**:
Python 3.6.4

- **Bazel version**:
N/A

- **GCC/Compiler version**:
N/A

- **CUDA/cuDNN version**:
8.0

- **GPU model and memory**:
GeForce GTX 1070
8192 MB

- **Exact command to reproduce**:
python3 -c ""import tensorflow as tf; help(tf.profiler.profile(tf.get_default_graph()))""

You can collect some of this information using our environment capture script:

### Problem description
Calling help on the value returned by `tf.profiler.profile` generate a segmentation fault. However it might be related to the warning about the python version.

### Source code / logs
Here is the full python session:
```
$ python3                                                                                
Python 3.6.4 (default, Jan  5 2018, 02:13:53) 
[GCC 7.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
>>> help(tf.profiler.profile(tf.get_default_graph()))
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              0
-min_occurrence             0
-step                       -1
-order_by                   name
-account_type_regexes       _trainable_variables
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     params
-output                     stdout:

==================Model Analysis Report======================
node name | # parameters
_TFProfRoot (--/0 params)

======================End of Report==========================
zsh: segmentation fault  python3
```",0,,3,2018-01-16T15:13:36Z,NONE
16155,[Bug] slim.tfexample_decoder.TFExampleDecoder() crashes if RAW image with float type is used.,"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 'unkown', '1.4.0-rc0'
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7.0.3
- **GPU model and memory**: Pascal Titan X
- **Exact command to reproduce**:

### Describe the problem

To feed raw images with floating type saved in tfrecord, I am using slim.tfexample_decoder.TFExampleDecoder().

The problem is if I set the dtype of raw image to tf.float32, the function doesn't work with following error messages. 

```
Traceback (most recent call last):
  File ""train.py"", line 475, in <module>
    tf.app.run()
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 304, in main
    common_queue_min=10 * FLAGS.batch_size)
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py"", line 97, in __init__
    tensors = dataset.decoder.decode(data, items)
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 427, in decode
    outputs.append(handler.tensors_to_item(keys_to_tensors))
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 324, in tensors_to_item
    return self._decode(image_buffer, image_format)
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py"", line 353, in _decode
    pred_fn_pairs, default=decode_image, exclusive=True)
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 3262, in case
    case_seq = _build_case()
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 3257, in _build_case
    strict=strict, name=""If_%d"" % i)
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/jhkang/tools/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1902, in cond
    (val_x.dtype.name, val_y.dtype.name))
ValueError: Outputs of true_fn and false_fn must have the same type: float32, uint8

```

To see what the problem is, I checked the ``slim/data/tfexample_decoder.py``.
I figured out that there is a ``case()`` function in `` _decode()`` of ``class Image``, and if I set dtype for the raw image as other than uint8, then, the returning tensors' dtypes from ``decode_image()`` and ``decode_raw()`` used in ``case()`` are always mis-matched. You can check the code in below.

```
 def _decode(self, image_buffer, image_format):
    """"""Decodes the image buffer.
    Args:
      image_buffer: The tensor representing the encoded image tensor.
      image_format: The image format for the image in `image_buffer`. If image
        format is `raw`, all images are expected to be in this format, otherwise
        this op can decode a mix of `jpg` and `png` formats.
    Returns:
      A tensor that represents decoded image of self._shape, or
      (?, ?, self._channels) if self._shape is not specified.
    """"""
    def decode_image():
      """"""Decodes a png or jpg based on the headers.""""""
      return image_ops.decode_image(image_buffer, self._channels)

    def decode_raw():
      """"""Decodes a raw image.""""""
      return parsing_ops.decode_raw(image_buffer, out_type=self._dtype)

    pred_fn_pairs = {
        math_ops.logical_or(
            math_ops.equal(image_format, 'raw'),
            math_ops.equal(image_format, 'RAW')): decode_raw,
    }
    image = control_flow_ops.case(
        pred_fn_pairs, default=decode_image, exclusive=True)

    image.set_shape([None, None, self._channels])
    if self._shape is not None:
      image = array_ops.reshape(image, self._shape)

    return image
```
The returning tensor of `` return image_ops.decode_image(image_buffer, self._channels)`` only supports uint8 type of tensors.  
To fix this problem, I changed the previous code into the following code. 
``return math_ops.cast(image_ops.decode_image(image_buffer, self._channels), self._dtype)``

### Source code / logs
I am attaching my source code for feeding dataset from tfrecord using slim.

```
from __future__ import absolute_import, division, print_function

import os

import tensorflow as tf

from datasets import dataset_utils

slim = tf.contrib.slim

_FILE_PATTERN = '%s_*.tfrecord'

SPLITS_TO_SIZES = {'train': 24523, 'validation': 6130} # lineGT 20180112
_NUM_CLASSES = 10

_ITEMS_TO_DESCRIPTIONS = {
    'intensity': 'an intensity map',
    'heightmap': 'an heightmap map',
    'label': 'Ground truth segmentation mask',
}


def get_split(split_name, dataset_dir, file_pattern=None, reader=None):
  if split_name not in SPLITS_TO_SIZES:
    raise ValueError('split name %s was not recognized.' % split_name)

  if not file_pattern:
    file_pattern = _FILE_PATTERN
  file_pattern = os.path.join(dataset_dir, file_pattern % split_name)
  print(file_pattern)
  # Allowing None in the signature so that dataset_factory can use the
  # default.
  if reader is None:
    reader = tf.TFRecordReader

  keys_to_features = {
      'image/intensity':
          tf.FixedLenFeature(
              (), tf.string, default_value=''),
      'image/format':
          tf.FixedLenFeature(
              (), tf.string, default_value='raw'),
      'image/height':
          tf.FixedLenFeature(
              (), tf.int64, default_value=0),
      'image/width':
          tf.FixedLenFeature(
              (), tf.int64, default_value=0),
      'image/mask':
          tf.FixedLenFeature(
              (), tf.string, default_value=''),
      'image/mask/format':
          tf.FixedLenFeature(
              (), tf.string, default_value='raw'),
      'image/heightmap':
          tf.FixedLenFeature(
              (), tf.string, default_value=''),
      'image/heightmap/format':
          tf.FixedLenFeature(
              (), tf.string, default_value='raw'),
      'image/filename':
          tf.FixedLenFeature(
              (), tf.string, default_value=''),
  }

  items_to_handlers = {
      'intensity':
          slim.tfexample_decoder.Image(
            'image/intensity', 'image/format', channels=1, dtype=tf.float32),
      'heightmap':
          slim.tfexample_decoder.Image(
            'image/heightmap', 'image/heightmap/format', channels=1, dtype=tf.float32),
      'label':
          slim.tfexample_decoder.Image(
            'image/mask', 'image/mask/format', channels=1),
      'height':
          slim.tfexample_decoder.Tensor('image/height'),
      'width':
          slim.tfexample_decoder.Tensor('image/width'),
      'fileid':
          slim.tfexample_decoder.Tensor('image/filename'),
  }

  decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features,
                                                    items_to_handlers)

  labels_to_names = None

  return slim.dataset.Dataset(
      data_sources=file_pattern,
      reader=reader,
      decoder=decoder,
      num_samples=SPLITS_TO_SIZES[split_name],
      items_to_descriptions=_ITEMS_TO_DESCRIPTIONS,
      num_classes=_NUM_CLASSES,
      labels_to_names=labels_to_names)
```",0,,1,2018-01-16T10:55:34Z,NONE
16154,Added save_checkpoint_steps attribute to MonitoredTrainingSession,"cla: yes,stat:awaiting response","fix #15900
- Added `save_checkpoint_steps` attribute to `MonitoredTrainingSession`.
If both `save_checkpoint_steps` and `save_checkpoint_secs` are both `None` then default saver is disabled. Default is `save_checkpoint_secs=600`
- Added `test_save_checkpoint_steps`",1,,3,2018-01-16T10:52:43Z,NONE
16152,DeprecationWarning from `inspect.getargspec()`,type:bug/performance,"`inspect.getargspec` is deprecated in Python 3
https://docs.python.org/3/library/inspect.html#inspect.getargspec

I solved the problem in keras like this:
https://github.com/keras-team/keras/pull/7035

### System information
- Using tensorflow as a keras backend (keras 2.1.2)
- Linux Ubuntu 16.04
- installed from conda
- version 1.3.0
- python 3.6.4

### Describe the problem
We recently switched from theano to tensorflow and this warning message is filling up my test output.

### Source code / logs
```
/home/<name>/.conda/envs/<env>/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning:
  
  inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
```
",0,,3,2018-01-16T09:41:53Z,NONE
16150,Tensorflow Debugger with Multithreading,,"
## System information

1. OS Platform: Ubuntu 14.04 
2. TensorFlow installed from source : GPU-Version 1.14 branch 
3. cuDNN: 7.0
4. Python version: 3.4

--

I'm using **tf.Estimator** together with **numpy_input_fn**. Moreover, I set all num_threads to 1. However, tfdbg somehow doesn't get along well with child threads auto-created by new estimator API.

Here is how I defined Estimator:

```
def do_train(tr_data, vl_data):

    # Create Estimator
    sess_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
    sess_conf.gpu_options.allow_growth = True
    config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,  # CheckpointSaverHook
                                    save_checkpoints_steps=100,  # CheckpointSaverHook
                                    log_step_count_steps=10,  # SummarySaverHook
                                    session_config=sess_conf)
    music_classifier = tf.estimator.Estimator(model_fn,
                                              config=config,
                                              params={'max_seq': tr_data.max_seq})
    # Prepare input data
    tr_input_fn = tf.estimator.inputs.numpy_input_fn(
        {'input_ph': tr_data.data, 'seq_len_ph': tr_data.seq_len},
        batch_size=FLAGS.batch_size,
        num_epochs=FLAGS.num_epochs,
        num_threads=1,
        shuffle=True
    )
    # Extra Hooks
    logging_hook = tf.train.LoggingTensorHook(
        tensors={'probabilities': 'probs_tensor'},
        every_n_iter=10
    )
    debugging_hook = tf_debug.LocalCLIDebugHook(thread_name_filter=""MainThread$"", dump_root=""./dump"")
    # Train
    music_classifier.train(tr_input_fn, hooks=[debugging_hook])
```


Although the code runs fine; whenever I run it in debug mode, it fails at executing run command on tfdbg command line. Following is the exception I got:

```
2018-01-16 10:25:26.587936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-01-16 10:25:26.588715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 5.38GiB
2018-01-16 10:25:26.588732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-01-16 10:25:41.373907: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
Traceback (most recent call last):
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
     [[Node: rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_FLOAT, _class=[""loc:@rnn/while/TensorArrayReadV3""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter, rnn/while/rnn/msarnn_cell/Identity/Enter/_259, rnn/while/TensorArrayReadV3, rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter_1, ^rnn/while/rnn/msarnn_cell/cond/Merge/_263)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py"", line 202, in <module>
    tf.app.run(main=main)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py"", line 191, in main
    do_train(tr_data, vl_data)
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py"", line 169, in do_train
    music_classifier.train(tr_input_fn, hooks=[debugging_hook])
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py"", line 783, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python3.4/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 1024, in run
    run_metadata=run_metadata)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 827, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
     [[Node: rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_FLOAT, _class=[""loc:@rnn/while/TensorArrayReadV3""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter, rnn/while/rnn/msarnn_cell/Identity/Enter/_259, rnn/while/TensorArrayReadV3, rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter_1, ^rnn/while/rnn/msarnn_cell/cond/Merge/_263)]]

Caused by op 'rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3', defined at:
  File ""/usr/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py"", line 202, in <module>
    tf.app.run(main=main)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py"", line 191, in main
    do_train(tr_data, vl_data)
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py"", line 169, in do_train
    music_classifier.train(tr_input_fn, hooks=[debugging_hook])
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py"", line 711, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py"", line 694, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py"", line 116, in model_fn
    initializer=tf.glorot_normal_initializer())  # [BSxMTxOS], [BSxSS]
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py"", line 253, in dynamic_msa_rnn
    dtype=tf.float32)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py"", line 614, in dynamic_rnn
    dtype=dtype)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py"", line 777, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2816, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2640, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2590, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py"", line 760, in _time_step
    skip_conditionals=True)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py"", line 236, in _rnn_step
    new_output, new_state = call_cell()
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py"", line 748, in <lambda>
    call_cell = lambda: cell(input_t, state)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 183, in __call__
    return super(RNNCell, self).__call__(inputs, state)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/layers/base.py"", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py"", line 204, in call
    ms_analyzer = self._extract_features(inputs)
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py"", line 151, in _extract_features
    sub_sig = self._gen_sub_sig(inputs)  # BSxTxIN
  File ""/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py"", line 105, in _gen_sub_sig
    self.__ta_signal = self.__ta_signal.write(self.__time, inputs)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/util/tf_should_use.py"", line 107, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs))
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 310, in write
    name=name)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 5038, in _tensor_array_write_v3
    flow_in=flow_in, name=name)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
     [[Node: rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_FLOAT, _class=[""loc:@rnn/while/TensorArrayReadV3""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter, rnn/while/rnn/msarnn_cell/Identity/Enter/_259, rnn/while/TensorArrayReadV3, rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter_1, ^rnn/while/rnn/msarnn_cell/cond/Merge/_263)]]
```

Thank you for your support in advance.",0,,3,2018-01-16T08:30:16Z,NONE
16147,Inference on V100 with TF1.5 is extremely slow. ,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source and Virtual Env, problem doesn't change
- **TensorFlow version (use command below)**: 1.5.0-rc1 (Makes no difference on 1.4)
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: CUDA 9/7.0.5
- **GPU model and memory**: V100 - 16GB
- **Exact command to reproduce**:

### Describe the problem

- Inference using the V100 is very slow. For example performing object detection with SSD Mobilenet is achieving a max frame rate of ~8, compared to ~45 on a GTX1080
- Initialization with a warm up image is extremely slow - up to 2 mins for the first image. 
- I have tried model quantization using graph_transforms/transform_graph (in an attempt to use the FP16 mode) and various combinations of CUDA, cuDNN and Tensorflow versions with no difference. 

Is there some recommended environment setup for the V100?
I am successfully running Darknet (https://pjreddie.com/darknet/) with a massive increase of speed. ",2,,8,2018-01-16T06:56:15Z,NONE
16146,Documentation for GridLSTMCell is lacking and does not match the paper,,"### Describe the problem

The documentation for tf.contrib.rnn.GridLSTMCell cites the paper ""Grid Long Short-Term Memory"", by Kalchbrenner et al.
The paper describes an architecture, called the 2D Grid LSTM, to replace a stack of LSTM cells. In a 2D Grid LSTM, 2 state components are passed from one layer to the next vertically.

In Tensorflow RNN parlance, one would expect both the state and the output of the cell to be an LSTMStateTuple, which would allow seamless integration with a MultiRNNCell.
In the current implementation, instead it appears that the vertical unrolling is done internally to the GridLSTMCell.
I say it appears, because I can't quite make sense of the arguments and their documentation: specifically, there is a required ""num_frequency_block"" argument whose meaning is quite obscure.
Looking at the implementation also did not help me understand what value is actually expected in that parameter, and the related parameters.
Note that the above mentioned paper does not talk about frequencies anywhere.

Would it be possible to expand on the documentation for the cell, as well as provide a code example on how to replicate the 2D Grid LSTM from the paper?
",0,,3,2018-01-16T06:47:31Z,NONE
16143,"Undefined symbol ""_ZN3Aws8Security14SecureMemClearEPhj""",stat:awaiting response,"compiled tensorflow r.15 from source , when import tensorflow in python got following error:
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/site-packages/tensorflow-1.5.0rc1-py2.7-freebsd-11.0-RELEASE-p1-i386.egg/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow-1.5.0rc1-py2.7-freebsd-11.0-RELEASE-p1-i386.egg/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/site-packages/tensorflow-1.5.0rc1-py2.7-freebsd-11.0-RELEASE-p1-i386.egg/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/site-packages/tensorflow-1.5.0rc1-py2.7-freebsd-11.0-RELEASE-p1-i386.egg/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow-1.5.0rc1-py2.7-freebsd-11.0-RELEASE-p1-i386.egg/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow-1.5.0rc1-py2.7-freebsd-11.0-RELEASE-p1-i386.egg/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /usr/local/lib/python2.7/site-packages/tensorflow-1.5.0rc1-py2.7-freebsd-11.0-RELEASE-p1-i386.egg/tensorflow/python/_pywrap_tensorflow_internal.so: Undefined symbol ""_ZN3Aws8Security14SecureMemClearEPhj""


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace

thanks in advance !!!",0,,1,2018-01-16T06:04:50Z,NONE
16139,Segmentation fault when running optimization step with 3d convolution,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux (4.14.13-1 linux kernel version)
- **TensorFlow installed from (source or binary)**: source (using the package here: https://www.archlinux.org/packages/community/x86_64/python-tensorflow-cuda/)
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 7.2.1
- **CUDA/cuDNN version**: 9.1.85-1/7.0.5-2
- **GPU model and memory**: NVidia Quadro K4200, 4028MiB
- **Exact command to reproduce**: `python test.py`
Note that the same code also fails in a Ubuntu docker container (Dockerfile attached).

### Describe the problem
I set up a computation graph with a 3d convolution. I can evaluate the result of this graph, but when I attempt to optimize the parameters of the graph (`train_step.run(feed_dict={x: sample, y_: label})`), tensorflow segfaults.

In a jupyterlab notebook running on Ubuntu, if I run the same code, the notebook hangs indefinitely at the same line. In both cases, the last line of the program is never run - ""ran train step"" is never printed.

I also tried running this on my CPU with `os.environ['CUDA_VISIBLE_DEVICES'] = '-1'`. I get the same segfault.

The segfault goes away if I do any of the following:
- Remove the 3d convolution
- Reduce the input size significantly (e.g. 100x smaller to 1 x 41 x 96 x 128 x 1)
- Reduce the kernel size significantly

### Source code / logs
Minimal example code (test.py):
```python
import numpy as np
import tensorflow as tf

sample = np.zeros((1, 41, 960, 1280, 1))
label = np.zeros((1,))

rc_kernel = np.ones((31,))

x = tf.placeholder(tf.float64, shape=[None, 41, 960, 1280, 1])
y_ = tf.placeholder(tf.float64, shape=[None])

W_conv_r = tf.Variable(rc_kernel.reshape((1, -1, 1, 1, 1)))
h_blur = tf.nn.conv3d(x, W_conv_r, [1, 1, 1, 1, 1], ""VALID"")

h_sum = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(h_blur, axis=3), axis=2), axis=1)
y = tf.sigmoid(h_sum)

sq_err = (y - y_) ** 2

train_step = tf.train.GradientDescentOptimizer(0.1).minimize(sq_err)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    E = sq_err.eval(feed_dict={x: sample, y_: label})
    print(f'E = {E}')
    train_step.run(feed_dict={x: sample, y_: label})  # fails here
    print('ran train step')
```

Dockerfile:
[Dockerfile.txt](https://github.com/tensorflow/tensorflow/files/1633128/Dockerfile.txt)",0,,5,2018-01-15T22:29:25Z,NONE
16138,Build fails with Visual Studio 2017,type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.5.0-dev20180103
https://github.com/tensorflow/tensorflow/commit/25d275280dfb163674f81c7681c2c1d34545a155
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
9.0 with cuDNN 7
- **GPU model and memory**:
GeForce GTX 1060 6GB
- **Exact command to reproduce**:
Open Visual Studio x64 Native Tools Command Prompt with admin rights. 
using MSBuild 15.5.180.51428,

```
cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^
-DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12/swig.exe ^
-DPYTHON_EXECUTABLE=C:\Users\csemp\AppData\Local\Programs\Python\Python35\python.exe ^
-DPYTHON_LIBRARIES=C:\Users\csemp\AppData\Local\Programs\Python\Python35\libs\python35.lib ^
-Dtensorflow_ENABLE_GPU=ON ^
-DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0"" ^
-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX ^
-Dtensorflow_BUILD_CC_EXAMPLE=OFF

set PreferredToolArchitecture=x64
""C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin\amd64\MSBuild.exe"" /m:2 /p:Configuration=Release tf_python_build_pip_package.vcxproj /v:diag > diag.log
```

### Describe the problem
The build fails with the error 
```
 133>CustomBuild: (TargetId:8893)
                     CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:222 (message): (TaskId:3323)
                       Error generating (TaskId:3323)
                       C:/Users/csemp/dev/tensorflowbuild/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj (TaskId:3323)
                      (TaskId:3323)
                      (TaskId:3323)
```
It also has the error 
```
(ClCompile target) -> 
  C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.12.25827\include\algorithm(2417): error C2678: binary '*': no operator found which takes a left-hand operand of type 'const tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator' (or there is no acceptable conversion) (compiling source file C:\Users\csemp\dev\tensorflowbuild2\tensorflow\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc) [C:\Users\csemp\dev\tensorflowbuild2\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
  C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.12.25827\include\algorithm(2417): error C2100: illegal indirection (compiling source file C:\Users\csemp\dev\tensorflowbuild2\tensorflow\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc) [C:\Users\csemp\dev\tensorflowbuild2\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
```
the latter of which can be fixed by a simple change, as noted in https://github.com/tensorflow/tensorflow/issues/15925#issuecomment-356275963 .
Creating this new issue per @gunan's request
https://github.com/tensorflow/tensorflow/issues/14691#issuecomment-356846982

### Source code / logs
The log file is way too big to post apparently. I'm open to suggestions

",1,,7,2018-01-15T22:27:02Z,NONE
16136,"Error while using cuda-9.1, libcublas.so.8.0: cannot open shared object file: No such file or directory",,"Hi,
I am having the import problem. I installed cuda 9.1 and set the path as suggested https://stackoverflow.com/questions/36159194/tensorflow-libcudart-so-7-5-cannot-open-shared-object-file-no-such-file-or-di
Should i install cuda 8.0 for resolving this problem?
Issue :tensorflow not supporting cuda version greater than 8.

The error is:

            import tensorflow
            Traceback (most recent call last):
            File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in
            from tensorflow.python.pywrap_tensorflow_internal import *
            File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in
            _pywrap_tensorflow_internal = swig_import_helper()
            File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
            _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
            File ""/home/honeypot/tensorflow/lib/python3.5/imp.py"", line 242, in load_module
            return load_dynamic(name, filename, file)
            File ""/home/honeypot/tensorflow/lib/python3.5/imp.py"", line 342, in load_dynamic
            return _load(spec)
            ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File """", line 1, in
File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/init.py"", line 24, in
from tensorflow.python import *
File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/init.py"", line 49, in
from tensorflow.python import pywrap_tensorflow
File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in
from tensorflow.python.pywrap_tensorflow_internal import *
File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in
_pywrap_tensorflow_internal = swig_import_helper()
File ""/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
File ""/home/honeypot/tensorflow/lib/python3.5/imp.py"", line 242, in load_module
return load_dynamic(name, filename, file)
File ""/home/honeypot/tensorflow/lib/python3.5/imp.py"", line 342, in load_dynamic
return _load(spec)
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

Failed to load the native TensorFlow runtime",0,,7,2018-01-15T18:41:23Z,NONE
16134,Added training parameter to batch_normalization,"cla: yes,stat:awaiting response",According to the docs the batch_normalization layer does not work properly if the parameter is not set correctly.,1,,1,2018-01-15T16:36:51Z,NONE
16133,Add training parameter to dropout to make it work,"cla: yes,stat:awaiting response","I think that without this parameter set dropout is disabled all the time. At least this is what I read in the documentation, besides adding this improves training.",1,,4,2018-01-15T16:26:56Z,NONE
16129,allow 'None' as batch size for TimeFreqLSTMCell,"awaiting review,cla: yes","Currently it is not allowed to have a variable batch size in TimeFreqLSTMCell, as the size is casted to an int internally.
This patch fixes this by omitting the int cast.

Tested it in an audio event detection framework without problems.",1,,1,2018-01-15T10:31:31Z,CONTRIBUTOR
16128,Improvement Proposal - tf.alphas_like (merging tf.ones_like and tf.zeros_like into one),"stat:contributions welcome,type:feature","Hello dear tensorflowers,

In a research project, I encountered the need to create tensors of the same shape than any other tensor with a custom value (not just 0 or 1), could be Boolean, Floats, Integers and so on.

The functions prototypes are the following and will be implemented in [ tensorflow/python/ops/array_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py): 
- **tf.alphas** (shape, alpha_value, name=None)
- **tf.alphas_like** (tensor, alpha_value, name=None, optimize=True)

The code is not created from scratch. It is **highly** inspired by the functions tf.ones, tf.zeros for tf.alphas and by tf.zeros_like, tf.ones_like for tf.alphas_like.

The code use the latest implementation and has been designed to work with *eager_mode*.
The number of modification is relatively small, thus I am relatively confident on the robustness of the new implementation (largely based on the existing one).

The idea is to reproduce and merge the functions while enabling to set any custom value in the tensor:

- **tf.alphas merges:**
  - tf.ones
  - tf.zeros
- **tf.alphas_like merges:**
  - tf.zeros_like
  - tf.ones_like

### How is the API Working ?

My new functions take a parameter _alpha_value_ and fill the tensor with this value. This allows me to run such a script:

```python
import tensorflow as tf

a = tf.constant([
    [
        [4, 5, 6],
        [1, 2, 3]
    ],
    [
        [4, 5, 6],
        [1, 2, 3]
    ]
])

b1 = tf.alphas_like(a, 0.5431)
b2 = tf.alphas_like(a, 5)
b3 = tf.alphas_like(a, -5)
b4 = tf.alphas_like(a, True)

with tf.Session() as sess:
    _b1, _b2, _b3, _b4 = sess.run([b1, b2, b3, b4])
    
print(""b1:"", _b1)
print(""b2:"", _b2)
print(""b3:"", _b3)
print(""b4:"", _b4)

############### OUTPUTS ###############

>>> b1: [
  [
    [ 0.5431  0.5431  0.5431]
    [ 0.5431  0.5431  0.5431]
  ]
  [
    [ 0.5431  0.5431  0.5431]
    [ 0.5431  0.5431  0.5431]
  ]
]

>>> b2: [
  [
    [5 5 5]
    [5 5 5]
  ]
  [
    [5 5 5]
    [5 5 5]
  ]
]

>>> b3: [
  [
    [-5 -5 -5]
    [-5 -5 -5]
  ]
  [
    [-5 -5 -5]
    [-5 -5 -5]
  ]
]

>>> b4: [
  [
    [ True  True  True]
    [ True  True  True]
  ]
  [
    [ True  True  True]
    [ True  True  True]
  ]
]
```

### How can you help ?

Before submitting a PR, I would like to know a few things:
  - Is it something that would be any kind of interest and worth a PR?
  - Are the names I have chosen (tf.alphas and tf.alphas_like) okay with everyone ?
  - In my PR, should I delete the implementation of tf.zeros_likes and tf.ones_likes and replace them as an alias of my new function which basically does the same job, just in a more flexible way ?

Thanks for your time and attention,

Best Regards,

Jonathan",0,,9,2018-01-15T10:26:30Z,CONTRIBUTOR
16126,Error 	LNK1181	cannot open input file 'To.obj' ConsoleApplication1,stat:awaiting response,"The tensorflow Library built in 
windows 10; Visual Studio 2015(Update 3);Python 3.5, 
with CMake, 
now I try to run an example and I get this error, 
I don't find any To.obj in my Tensorflow build folder.
this is my code (with name: ConsoleApplication1): 
`// matmul.cpp
#define _ITERATOR_DEBUG_LEVEL 0  

#include <vector>
#include <eigen/Dense>

#include ""matmul.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/cc/ops/standard_ops.h""


using namespace tensorflow;

// Build a computation graph that takes a tensor of shape [?, 2] and
// multiplies it by a hard-coded matrix.
GraphDef CreateGraphDef()
{
	Scope root = Scope::NewRootScope();

	auto X = ops::Placeholder(root.WithOpName(""x""), DT_FLOAT,
		ops::Placeholder::Shape({ -1, 2 }));
	auto A = ops::Const(root, { { 3.f, 2.f },{ -1.f, 0.f } });

	auto Y = ops::MatMul(root.WithOpName(""y""), A, X,
		ops::MatMul::TransposeB(true));

	GraphDef def;
	TF_CHECK_OK(root.ToGraphDef(&def));

	return def;
}

int main()
{
	GraphDef graph_def = CreateGraphDef();

	// Start up the session
	SessionOptions options;
	std::unique_ptr<Session> session(NewSession(options));
	TF_CHECK_OK(session->Create(graph_def));

	// Define some data.  This needs to be converted to an Eigen Tensor to be
	// fed into the placeholder.  Note that this will be broken up into two
	// separate vectors of length 2: [1, 2] and [3, 4], which will separately
	// be multiplied by the matrix.
	std::vector<float> data = { 1, 2, 3, 4 };
	auto mapped_X_ = Eigen::TensorMap<Eigen::Tensor<float, 2, Eigen::RowMajor>>
		(&data[0], 2, 2);
	auto eigen_X_ = Eigen::Tensor<float, 2, Eigen::RowMajor>(mapped_X_);

	Tensor X_(DT_FLOAT, TensorShape({ 2, 2 }));
	X_.tensor<float, 2>() = eigen_X_;

	std::vector<Tensor> outputs;
	TF_CHECK_OK(session->Run({ { ""x"", X_ } }, { ""y"" }, {}, &outputs));

	// Get the result and print it out
	Tensor Y_ = outputs[0];
	std::cout << Y_.tensor<float, 2>() << std::endl;

	session->Close();
}`",0,,1,2018-01-15T09:01:31Z,NONE
16123,add rolling window batch operation for tf.data.Dataset ,"awaiting review,cla: yes,stat:awaiting tensorflower","Resolve #15044.

### implementation

The PR proposes a `slide` method for Dataset: Groups elements in fixed size blocks by passing a ""sliding window"" over Dataset. It behaves like `batch`, in fact, `batch(n) == slide(n, n)`.

I failed to move c++ implementation from `core` to `contrib`. Any help will be appreciated.


### how to test

+ [x] add test case.
+ [ ] pass all tests.",1,,3,2018-01-15T06:48:28Z,CONTRIBUTOR
16121,Enable some passes for graph_transform on Windows,cla: yes,"Don't know why but the following passes are disabled on Windows:

* quantize_weights
* quantize_nodes
* round_weights

This patch re-enabled them. This should fix #11351.

Regarding the original commit disabled the passes on Windows, `git blame` gives the commit:

```
commit d1ba01f81d8fa1d0171ba9ce871599063d5c7eb9
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Feb 1 18:13:33 2017 -0800

    Merge changes from github.
    Change: 146316196
```

Does anyone know what the commit message means?

I built it on Windows 7 x64 and ran it for my tiny MNIST model. Looks fine...
**So I am abusing CI to test it.**
",1,,2,2018-01-15T06:15:55Z,CONTRIBUTOR
16120,Utility classes for writing Java source code from a C++ process (part 3),"cla: yes,stat:awaiting response","Part 3 (and last) of pull request #14094 that has been split into several commits.

This part features Java output streams, based on the previously-commited `SourceWriter`, to output Java code with a stream-like API. After this PR, everything will be setup to write Java code from the generator so we could start focusing again on the real thing: ops generation.

CC: @asimshankar 

",1,,1,2018-01-15T04:59:41Z,CONTRIBUTOR
16117,Add nsync lib dep. to cc_library rule android_tensorflow_lib_selective_registration,"awaiting review,cla: yes","The nsync lib dep is missed in rule ""android_tensorflow_lib_selective_registration""

This pr adds it.",1,,1,2018-01-15T01:10:32Z,CONTRIBUTOR
16115,Gradients w.r.t. eigenvalues/eigenvectors ,"stat:awaiting tensorflower,type:bug/performance","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.1
- **TensorFlow installed from (source or binary)**: pip install tensorflow
- **TensorFlow version (use command below)**: v1.2.0-5-g435cdfc 1.2.1
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: see code

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Hi,

I'm having issues with evaluating the gradients of eigenvalues/eigenvectors with respect to the underlying matrix. Tensorflow evaluates the gradients, but these are not correct when compared to the true gradients.

We are using tf.self_adjoint_eig to evaluate the spectral decomposition for the tensorflow variable input. We have initialised this with a symmetric matrix to satisfy the self adjoint operator property. We wish to take the derivative of individual eigenvalues or eigenvector with respect to the original matrix (note for eigenvectors we take one element from one eigenvector, e.g. element 2 in eigenvector 1 to avoid the issue of gradient aggregation for now).

The methodology for evaluating true gradients of eigenvalues and vectors of a symmetric real matrix can be found in the paper ""On differentiating Eigenvalues and Eigenvectors"" by Magnus (1985), Theorem 1 eqn (6) + (7). We evaluated using our input matrix the gradients under this paper and compared it to tensorflow evaluated gradients and the gradients from finite difference approximation. For the eigenvalues, the gradients are similar (identical on diagonal entries, off by a factor of 2 on off-diagonal elements), however the eigenvectors are off by quite a bit outside the diagonal entries. To start, define a matrix A as (excuse the matrix output formatting from Python)

A=[[-3 -2  4]
      [-2  1  1]
      [ 4  1  5]]

using np.linalg.eig and tf.self_adjoint_eig on A (I simply initialised a variable with A and computed the gradient for the tf implementation)

Tensorflow eigenvalues: [-5.43071561  1.76904987  6.66166575]
Python eigenvalues: [-5.43071561  6.66166575  1.76904987]

I now wish to evaluate the gradient of eigenvalue 1 (-5.43071561) w.r.t. A. 

Analytical gradient:
[[ 0.75896178  0.28555906 -0.31842553]
 [ 0.28555906  0.10744148 -0.11980748]
 [-0.31842553 -0.11980748  0.13359674]]

Tensorflow gradient:
[[[ 0.75896178,  0.        ,  0.        ],
   [ 0.57111812,  0.10744148,  0.        ],
  [-0.63685107, -0.23961495,  0.13359674]]]

The diagonal entries are the same but the off-diagonal entries are clearly off by a factor of 2.  Now we try and evaluate gradients for the eigenvectors.

Tensorflow eigenvectors:
[[-0.87118413 -0.31452619 -0.37697678]
 [-0.32778267  0.94426587 -0.0303395 ]
 [ 0.36550888  0.09713517 -0.92572567]]
Python eigenvectors:
[[ 0.87118413  0.37697678 -0.31452619]
 [ 0.32778267  0.0303395   0.94426587]
 [-0.36550888  0.92572567  0.09713517]]

We try and find the gradient of the eigenvector 1 element 2 (+/-0.32778267). We expect the tensorflow gradient to the equivalent to the analytical gradient (after taking into account the sign difference).

Analytical gradient:
[[ 0.03511309 -0.10795607 -0.01312188]
 [ 0.01321128 -0.04061843 -0.0049371 ]
 [-0.01473184  0.04529341  0.00550534]]

Tensorflow gradient:
[[[-0.03511309,  0.        ,  0.        ],
   [ 0.09474478,  0.04061843,  0.        ],
   [ 0.02785372, -0.04035631, -0.00550534]]]

Besides the entries being different between the tensorflow evaluated and real gradients, one issue is that tensorflow only returns the lower triangle of the gradient. Despite A being symmetric, the gradient matrix is not symmetric (as per the true gradient) and so the upper right triangle shouldn't be zeros. I believe this to be a bug, however I understand there may be reasons for the differences. Thank you for reading!

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Here is a script that reproduces the above.

[eigen_decomp_examplev2.py.zip](https://github.com/tensorflow/tensorflow/files/1546631/eigen_decomp_examplev2.py.zip)
",0,,1,2018-01-14T23:08:53Z,NONE
16114,Update maxout.py,cla: yes,Specify the final number of features in the maxout axis,1,,4,2018-01-14T22:37:39Z,NONE
16112,"Define gradient for tf.linspace and make it work with higher-rank tensors, not just scalars.",stat:awaiting response,"I needed to feed-forward through `tf.linspace`, but it seems that it does not have gradient defined.

I don't know how to define gradient for existing op, but I've implemented my own version of `tf.linspace` in python using tensorflow with so that automatically defined gradient.
```python
            def linspace(start, end, num):
                range = end - start
                num_steps = num - 1
                h = range / num_steps

                def cond(ta, x, k):
                    return tf.less(x, end)

                def body(ta, x, k):
                    x = x + h
                    ta = ta.write(k, x)
                    return ta, x, k+1

                k = tf.constant(0)
                ta = tf.TensorArray(dtype=tf.float32, size=num)
                ta = ta.write(k, start)
                ta = tf.while_loop(cond, body, [ta, start, k+1])[0]
                return ta.stack()
```

One more feature I can suggest adding is improve to `linspace` so it would work with higher-rank tensors.
The function I wrote is also very short and simple, but is interesting as a generalization of `linspace`.
```python
            def linspace_vectors(start, end, num):
                cnct = tf.concat([start, end], 1)
                seq = tf.map_fn(
                    lambda row_i: linspace(row_i[0], row_i[1], num), cnct)
                splits = tf.split(seq, num, 1)
                return tf.stack(splits)
```
The function is taken from my project and returns 3-rank tensor with shapes [num, r, 1]. Inputs are 2-rank tensors with shapes [r, 1].
So that I linspaced vectors-columns, not just scalars as `tf.linspace` do.
What do you think? Is it worth adding?",0,,1,2018-01-14T13:10:47Z,NONE
16110,"Using tf1.4 to restore a model from tf0.8, a NotFoundError appeared",stat:awaiting response,"When using tf1.4 to restore a model from tf0.8, I met a NotFoundError, the related code as flow:

ema = tf.train.ExponentialMovingAverage(1.0)
saver = tf.train.Saver(ema.variables_to_restore())
model_checkpoint_path='./model_check_point/model-20160506.ckpt-500000'
saver.restore(sess, model_checkpoint_path)

The error as flow:
NotFoundError (see above for traceback): Tensor name ""incept3a/in3_conv5x5_8/batch_norm/moments/Squeeze/ExponentialMovingAverage"" not found in checkpoint files ./model_check_point/model-20160506.ckpt-500000
	 [[Node: save/RestoreV2_46 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_46/tensor_names, save/RestoreV2_46/shape_and_slices)]]
	 [[Node: save/RestoreV2_315/_35 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_702_save/RestoreV2_315"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

How can I solve this problem?

This is a project I download from the github, the code is not writen by me. I run it on ubuntu14.04,
with TF1.4.1 installed from source code, bazel0.8 , CUDA8.0, cudnn6.0, GTX1060 6G memory.

",0,,1,2018-01-14T09:53:37Z,NONE
16108,No tf.metrics.true_negatives,,"**TensorFlow version**: 1.4.1

Is there any particular reason for why there is no `tf.metrics.true_negatives` method? I know it's simple to calculate from other confusion metrics that are available, but I was wondering why the developers chose to let this one method out.",0,,3,2018-01-14T09:47:59Z,NONE
16104,Feature request: Allow the build to use the system-installed protobuf lib,,"### Describe the problem
Currently, it's impossible to use the system-installed protobuf library because the tensorflow build always uses the `protobuf_archive` version. There should be an option to use the one installed in the system.

Background: I package tensorflow for Arch Linux and we run into symbol conflicts if a user wants to use protobuf and tensorflow together in a binary because tensorflow's protobuf symbols conflict with the one installed in the system already.

Original Arch bug report: https://bugs.archlinux.org/task/56943",0,,2,2018-01-13T18:23:27Z,NONE
16102,[Bug]: Unable to update the batch_normalization layer moving_mean/moving_variance of keras ,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: Tensorflow 1.4.1
- **Bazel version (if compiling from source)**: N/A
- **Python version**: Python 3.5
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: 1080 Ti
- **Exact command to reproduce**: see below

It is following up this [issue](https://github.com/tensorflow/tensorflow/issues/15367#issuecomment-357088739) about training models by mixing Tensorflow with Keras using this style, exampled [here](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html). Basically, using Inception architectures in keras.applications.InceptionV3 and training using sess.run() with a placeholder K.learning_phase() to indicate the training/testing mode.

_At beginning, I found the evaluation accuracy in testing mode (loaded back from a checkpoint) is different from the results when evaluation on the fly during training. But when I evaluated using training mode, it can give me reasonable but not good results. So I knew the problem happened in batch normalization._

**I tried either using tf.keras and keras independent version (2.1.2). But both not work.**

After some investigations, I found there should an issue of Keras of using batch normalization. I track the moving_mean and moving_variance and found they never update (maintaining the initial values, zero and one). In tf. keras, I notice its batchnorm inherits tf.layers.BatchNormalization (see [here](https://github.com/tensorflow/tensorflow/blob/ac8e67399d75edce6a9f94afaa2adb577035966e/tensorflow/python/keras/_impl/keras/layers/normalization.py#L26)). However, by checking the tutorial of this tf.layers.BatchNormalization,
  _It required to add a **update_ops** in optimizer. But it never mentioned in Keras (which should be 
  clarified)._ 
I did not see Keras using update_ops anywhere. **So i believe if you want to fine-tune a keras predefined model in applications, you never be able to update your moving_mean and moving_variance for your new data**.

**Note that I also tried keras independent version. It never worked. moving_mean and moving_variance are always not changed. I  tracked the value of batch_mean which is used to update moving_mean. batch_mean has values but not on moving_mean.**

In addition, I found moving_mean and moving_variance are in tf.trainable_variables() when using keras but not in tf.keras. I am not sure if this matters.

Here is an example code

```
image = keras.preprocessing.image
def preprocess_input(x):
    # the same as keras.applications.inception_v3
    with tf.name_scope('preprocess_input'):
        x /= 255.
        x -= 0.5
        x *= 2.
        return x

def get_main_network(name, input_tensor, use_weights=False):

    processed_tensor = preprocess_input(input_tensor)

    if name == 'inception':
        base_model = keras.applications.InceptionV3(include_top=True,
                                                    weights='imagenet' if use_weights else None,
                                                    pooling='avg',
                                                    input_tensor=processed_tensor)
    
    model = keras.models.Model(inputs=base_model.input, outputs=base_model.output)
 
    return model

img_shape=[299,299]
img = tf.placeholder(tf.float32, shape=[None]+img_shape+[3])

with tf.name_scope('model'):
    model = get_main_network('inception', input_tensor=img, use_weights=False)
    output = model.output
    logit = tf.cast(tf.argmax(output, axis=1), np.float32)

# define loss
with tf.name_scope('cross_entropy'):
    cross_entropy_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=output)  

# define optimizer
with tf.name_scope('learning_rate'):
    global_step = tf.Variable(0, name='global_step', trainable=False)
    learning_rate = tf.train.exponential_decay(opt.learning_rate, global_step,
                                        iter_epoch*opt.lr_decay_epoch, opt.lr_decay, staircase=True)
    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9) #.minimize(cross_entropy_loss, global_step=global_step)

''' **This matters a lot but not working for independent keras version'**''
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    train_step = optimizer.minimize(cross_entropy_loss, global_step=global_step)

''' Initialization '''
init_op = tf.variables_initializer([]) # a fake one, variables already initialized in keras
sess.run(init_op)

img_path = 'elephant.jpg'
imgs= image.load_img(img_path, target_size=img_shape)
x = image.img_to_array(imgs)
x = np.expand_dims(x, axis=0)
saver = tf.train.Saver(max_to_keep=20) # must be added in the end
with sess.as_default():
    
    feed_dict = {   
                        img: x_batch,
                        label: y_batch,
                        K.learning_phase(): True
                    }
        _, loss = sess.run([train_step, 
                                    cross_entropy_loss, 
                                    ], feed_dict=feed_dict)

```
@tensorflowbutler responsed",0,,1,2018-01-13T17:39:28Z,NONE
16098,Question about r1.5's default ptxas GPU back-end,stat:awaiting response,"From TF r1.5's release notes, it is said that ""GPU back-end now uses ptxas to compile generated PTX.""  I have searched through the entire git repo of r1.5 code base with only finding that ptxas will be invoked in XLA flow.
Since we are working on some XLA and GPU optimization stuffs, I just want to make sure the meaning of this sentence since I am a little bit puzzle about it and want to ensure our development flow will align with the community major direction.

Thanks",0,,1,2018-01-13T09:59:17Z,NONE
16097,terminate called after throwing an instance of 'std::bad_alloc',,"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7
- **TensorFlow installed from**: source
- **TensorFlow version**: 1.3
- **Python version**: 2.7.13
- **Bazel version**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0.61 / 6.0.21
- **GPU model and memory**: Quadro P5000 16GB
- **Exact command to reproduce**:

### Describe the problem
When I try to alloc a tf.constant variable as a [90000, 4096] matrix with float32 type. It seems that the graphics have enough memory. But I still got an memory error.

### Source code / logs
The error information is as follows:

```
name: Quadro P5000
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:03:00.0
Total memory: 15.89GiB
Free memory: 15.66GiB
2018-01-13 19:18:10.558228: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x39a1500 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-01-13 19:18:10.559218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:
name: Quadro P5000
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:82:00.0
Total memory: 15.89GiB
Free memory: 15.43GiB
2018-01-13 19:18:10.559297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 1
2018-01-13 19:18:10.559306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0
2018-01-13 19:18:10.559317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1
2018-01-13 19:18:10.559321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y N
2018-01-13 19:18:10.559324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   N Y
2018-01-13 19:18:10.559333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro P5000, pci bus id: 0000:03:00.0)
2018-01-13 19:18:10.559338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Quadro P5000, pci bus id: 0000:82:00.0)
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted
```

The test code is as follows:

```
import numpy as np
import tensorflow as tf

a = tf.constant(np.ones([90000, 4096], dtype = np.float32), dtype = tf.float32)

sess = tf.Session()
sess.run(a)
```",0,,4,2018-01-13T08:31:29Z,NONE
16091,Failed to convert tf gb file to tflite format,comp:lite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2 LTS
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**:gcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**:n/a
- **Exact command to reproduce**: bazel run --config=opt --copt=-msse4.1 --copt=-msse4.2  //tensorflow/contrib/lite/toco:toco --  --input_file=/home/xxx/facenet/ks/onet.pb   --output_file=/home/xxx/facenet/ks/onet.tflite  --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --inference_type=FLOAT   --input_shape=1,48,48,3   --input_array=onet/input --output_array=onet/prob1

### Describe the problem
I failed to covert my pb file to tflite format because some operations were not supported. Is there any workaround for the issue? 

### Source code / logs
2018-01-13 09:47:41.439557: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.439661: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.439687: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.439736: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.439767: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.439786: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.439824: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.439864: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.439884: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.439940: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.439970: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.439987: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440027: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440055: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440073: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440107: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440135: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440152: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440208: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440240: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440259: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440302: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440333: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440352: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440392: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440423: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440442: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440500: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440533: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440552: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440596: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440630: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440650: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440689: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440720: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440739: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440798: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440828: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440851: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440886: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.440918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.440937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.440987: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.441018: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.441037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441090: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.441118: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.441135: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441168: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.441196: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.441213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441254: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Exp
2018-01-13 09:47:41.441295: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.441324: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.441340: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441372: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.441400: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.441419: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441468: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.441500: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.441518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441554: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: RandomUniform
2018-01-13 09:47:41.441586: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: VariableV2
2018-01-13 09:47:41.441604: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441649: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441673: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441701: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441724: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441759: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441782: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441961: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.441990: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.442071: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.442095: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.442120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.442142: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443280: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443319: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443386: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443411: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443433: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443454: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443475: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443495: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.443517: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1126] Converting unsupported operation: Assign
2018-01-13 09:47:41.446177: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 231 operators, 319 arrays (0 quantized)
2018-01-13 09:47:41.449197: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 68 operators, 76 arrays (0 quantized)
2018-01-13 09:47:41.449990: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 68 operators, 77 arrays (0 quantized)
2018-01-13 09:47:41.450763: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 68 operators, 77 arrays (0 quantized)
2018-01-13 09:47:41.451432: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.

",0,,5,2018-01-13T01:51:20Z,NONE
16087,  tf.estimator.train_and_evaluate list  of eval_spec,type:feature,"Sometimes could be useful to evaluate on different clusters of the evaluation set with distinct metrics, summaries etc.
Do you plan that this interface will accept a list of `eval_spec` in the future?",1,,4,2018-01-12T23:16:17Z,NONE
16085,Add unspecified dimensions (-1) support for noise_shape with tf.nn.dropout,"cla: yes,stat:awaiting response","This fix tries to address the issue raised in #16034 where it was not possible to have unspecified dimensions for `noise_shape` with `tf.nn.dropout`.

This fix adds the support so that it is possible to specify `noise_shape = [-1, 1, 1, -1]` instead of `noise_shape = [k, 1, 1, n]`.

This fix fixes #16034.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,6,2018-01-12T22:21:34Z,MEMBER
16083,Tensorflow and Bazle build in Docker Container on Windows,stat:awaiting response,"Hello, i'm trying to build the following Dockerfile:

```
FROM ubuntu:17.10

ADD https://bazel.build/bazel-release.pub.gpg /bazel-release.pub.gpg
RUN apt-key add /bazel-release.pub.gpg && rm /bazel-release.pub.gpg
RUN echo ""deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8"" | tee /etc/apt/sources.list.d/bazel.list

RUN apt-get update && apt-get install -y git build-essential bazel openjdk-8-jdk python3-dev python3-pip python3-numpy python3-wheel && ln --symbolic python3 /usr/bin/python

RUN git clone --recursive --branch r1.4 --depth 1 --shallow-submodules https://github.com/tensorflow/tensorflow
RUN cd /tensorflow && (echo ""\n\ny\nn\nn\nn\ny\nn\nn\nn\nn\nn\n\n"" | ./configure)
RUN cd /tensorflow && bazel build --config=opt //tensorflow/compiler/aot:tfcompile
```




Im getting the following Error on the last RUN operation:

```
Step 8/8 : RUN cd /tensorflow && bazel build --config=opt //tensorflow/compiler/aot:tfcompile
 ---> Running in ef36db7c22d1
..................
Loading:
Loading: 0 packages loaded
Loading: 0 packages loaded
Analyzing: target //tensorflow/compiler/aot:tfcompile (1 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (4 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (5 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (6 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (6 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (6 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (6 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (6 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (19 packages loaded)
Analyzing: target //tensorflow/compiler/aot:tfcompile (25 packages loaded)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/local_config_sycl/sycl/BUILD:4:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/local_config_sycl/sycl/BUILD:6:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/local_config_sycl/sycl/BUILD:30:9: Traceback (most recent call last):
        File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/local_config_sycl/sycl/BUILD"", line 27
                cc_library(name = ""syclrt"", srcs = [sycl_libr..."")], <3 more arguments>)
        File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/local_config_sycl/sycl/BUILD"", line 30, in cc_library
                sycl_library_path
name 'sycl_library_path' is not defined
Analyzing: target //tensorflow/compiler/aot:tfcompile (35 packages loaded)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:98:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:100:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:102:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:104:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:106:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:108:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:110:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:112:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:114:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:116:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:118:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:120:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:122:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:124:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:126:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:131:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:136:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:141:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:146:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/com_googlesource_code_re2/BUILD:151:1: name 're2_test' is not defined (did you mean 'ios_test'?)
Analyzing: target //tensorflow/compiler/aot:tfcompile (45 packages loaded)
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/local_config_sycl/sycl/BUILD:39:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '@local_config_sycl//sycl:sycl'
ERROR: /tensorflow/third_party/eigen3/BUILD:20:1: Target '@local_config_sycl//sycl:sycl' contains an error and its package is in error and referenced by '//third_party/eigen3:eigen3'
ERROR: Analysis of target '//tensorflow/compiler/aot:tfcompile' failed; build aborted: Loading failed
INFO: Elapsed time: 18.318s
FAILED: Build did NOT complete successfully (46 packages loaded)
```

My Docker Version:
```
Client:
 Version:       17.12.0-ce
 API version:   1.35
 Go version:    go1.9.2
 Git commit:    c97c6d6
 Built: Wed Dec 27 20:05:22 2017
 OS/Arch:       windows/amd64

Server:
 Engine:
  Version:      17.12.0-ce
  API version:  1.35 (minimum version 1.12)
  Go version:   go1.9.2
  Git commit:   c97c6d6
  Built:        Wed Dec 27 20:12:29 2017
  OS/Arch:      linux/amd64
  Experimental: true
```


Any ideas why this doesn't work?
The Dockerfile works fine on linux.",0,,1,2018-01-12T21:01:44Z,NONE
16082,Connect Apache Beam/Spark to TensorFlow (MonitoredTrainingSession) in a streaming manner?,"stat:awaiting response,stat:community support,type:feature","### Describe the problem
I have a lengthy question on [SO](https://stackoverflow.com/questions/47986410/optimal-data-streaming-and-processing-solution-for-enormous-datasets-into-tf-dat) about this. But in short, is there a way (or a best practice) to pipe big training datasets directly into a distributed setting (e.g. GKE),  especially if they are subjected to a heavy preprocessing? 
I'm basically reaching the limit of what can be sanely stored in TFRecords (they are verbose and heavy).
The closest issue was this one (https://github.com/tensorflow/tensorflow/issues/12903) and this guide (https://github.com/GoogleCloudPlatform/dataflow-prediction-example) but I do not see a healthy way to implement it (last one with a `@singleton` looks like a hack and not usable with the `tf.Dataset` or `MonitoredTrainingSession`).

I believe this is a useful issue/feature request for a decent amount of Tensorflow users. ",0,,4,2018-01-12T20:49:42Z,CONTRIBUTOR
16076,Using self.test_session() in setUp() in tf.test.TestCase runs setUp but not tearDown,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: From binary with pip
- **TensorFlow version (use command below)**: v1.4.1
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: 1080Ti
- **Exact command to reproduce**: python mwe.py

### Describe the problem
https://github.com/tensorflow/tensorflow/blob/1cc4ec4c5a08cadae87fa02222c5b5c3e81dedbb/tensorflow/python/framework/test_util.py#L874

If you use `tf.test.TestCase.test_session()` in `setUp()`, there will be one ""skipped"" test for which `setUp()` is run, but not `tearDown()`. I believe this has to do with `tf.TestCase.test_session()` trying to take care of automatic test discovery on the line above, but I'm not sure.

### Source code / logs

In the following MWE (mwe.py), after running this test there will be a tmp.txt file left in the current directory.

MWE:

    import tensorflow as tf

    import os
    import unittest

    class FooTest(tf.test.TestCase):
        def setUp(self):
            with open(""tmp.txt"", ""w"") as f:
                f.write(""Hello"")

            with self.test_session() as sess:
                pass

        def tearDown(self):
            os.unlink(""tmp.txt"")

        def testExample(self):
            self.assertEqual(1, 1)

    if __name__==""__main__"":
        unittest.main()
",0,,5,2018-01-12T17:29:38Z,NONE
16075,optimize_for_inference_lib.fold_batch_norms() preserves data_format,"awaiting review,cla: yes","`fold_batch_norms()` currently breaks graphs containing convolutions using NCHW data format. The function replaces a BiasAdd operation with a new one, while not preserving the data format of the original operation. As a result, the new operation always has NHWC data format, and the execution of the resulting graph fails because of mismatching dimensions.

The proposed resolution is to copy the `data_format` property from the original operation.

The patch fixes https://github.com/tensorflow/tensorflow/issues/15034.",1,,10,2018-01-12T17:07:04Z,NONE
16072,Dynamic Bi-directional RNN vs Dynamic RNN.- Not working as expected.,stat:awaiting response,"I am trying to use Bidirectional RNN and pass the output through a CNN for text classification. However, I am getting all sorts of shape errors with bidirectional RNN. Although, If I use two dynamic rnn with reverse op in the second layer, it appears to work fine:

Here is bidirectional RNN code that DOES NOT work for me:

```
    # Bidirectional LSTM layer
    with tf.name_scope(""bidirectional-lstm""):
        lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=1.0)
        lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=1.0)

        self.lstm_outputs, _ = tf.nn.bidirectional_dynamic_rnn(
            lstm_fw_cell, 
            lstm_bw_cell, 
            self.embedded_chars, 
            sequence_length=self.seqlen, 
            dtype=tf.float32)
        self.lstm_outputs = tf.concat(self.lstm_outputs, axis=2)
```


Here is the two layer dynamic rnn that DOES work for me:


```
  # Bidirectional LSTM layer
    with tf.name_scope(""bidirectional-lstm""):
        lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=1.0)
        lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=1.0)
    with tf.variable_scope(""lstm-output-fw""):
        self.lstm_outputs_fw, _ = tf.nn.dynamic_rnn(
            lstm_fw_cell, 
            self.embedded_chars, 
            sequence_length=self.seqlen, 
            dtype=tf.float32)

    with tf.variable_scope(""lstm-output-bw""):
        self.embedded_chars_rev = array_ops.reverse_sequence(self.embedded_chars, seq_lengths=self.seqlen, seq_dim=1)
        tmp, _ = tf.nn.dynamic_rnn(
            lstm_bw_cell, 
            self.embedded_chars_rev, 
            sequence_length=self.seqlen, 
            dtype=tf.float32)
        self.lstm_outputs_bw = array_ops.reverse_sequence(tmp, seq_lengths=self.seqlen, seq_dim=1)

    Concatenate outputs
    self.lstm_outputs = tf.add(self.lstm_outputs_fw, self.lstm_outputs_bw, name=""lstm_outputs"")
```

I am passing the output of this to CNN and error occurs when computing the

Here is the rest of the code:

# Convolution + maxpool layer for each filter size
        pooled_outputs = []
        for i, filter_size in enumerate(filter_sizes):
            with tf.name_scope(""conv-maxpool-%s"" % filter_size):
                # Convolution Layer
                filter_shape = [filter_size, hidden_size, 1, num_filters]
                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=""W"")
                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=""b"")

                conv = tf.nn.conv2d(
                    self.lstm_outputs_expanded, 
                    W,
                    strides=[1, 1, 1, 1], 
                    padding=""VALID"",
                    name=""conv"")

                # Apply nonlinearity
                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=""relu"")

                # Maxpooling over the outputs
                pooled = tf.nn.max_pool(
                    h, 
                    ksize=[1, sequence_length - filter_size + 1, 1, 1],
                    strides=[1, 1, 1, 1], 
                    padding='VALID',
                    name=""pool"")
                pooled_outputs.append(pooled)

        # Combine all the pooled features
        num_filters_total = num_filters * len(filter_sizes)
        self.h_pool = tf.concat(axis=3, values=pooled_outputs)
        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])


        # Dropout layer
        with tf.name_scope(""dropout""):
            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)


```
        # Final (unnormalized) scores and predictions
        with tf.name_scope(""output""):
            # Standard output weights initialization
            W = tf.get_variable(
                ""W"", 
                shape=[num_filters_total, num_classes], 
                initializer=tf.contrib.layers.xavier_initializer())
            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=""b"")

            # # Initialized output weights to 0.0, might improve accuracy
            # W = tf.Variable(tf.constant(0.0, shape=[num_filters_total, num_classes]), name=""W"")
            # b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name=""b"")

            l2_loss += tf.nn.l2_loss(W)
            l2_loss += tf.nn.l2_loss(b)

            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=""scores"")

            self.predictions = tf.argmax(self.scores, 1, name=""predictions"")

        # Calculate mean cross-entropy loss
        with tf.name_scope(""loss""):
            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)
            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss

        # Accuracy
        with tf.name_scope(""accuracy""):
            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))
            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, ""float""), name=""accuracy"")
```


here are the errors I am getting.

```
During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train_upgraded.py"", line 209, in <module>
    train_step(x_batch, seqlen_batch, y_batch)
  File ""train_upgraded.py"", line 177, in train_step
    feed_dict)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must be same size: logits_size=[7550,2] labels_size=[50,2]
         [[Node: loss/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](loss/Reshape, loss/Reshape_1)]]

Caused by op 'loss/SoftmaxCrossEntropyWithLogits', defined at:
  File ""train_upgraded.py"", line 87, in <module>
    l2_reg_lambda=FLAGS.l2_reg_lambda)
  File ""/media/hemant/MVV/MyValueVest-local/learning/Initial Embeddings/STEP 2 lstm-context-embeddings-master/model_upgraded.py"", line 138, in __init__
    losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 1783, in softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 4364, in _softmax_cross_entropy_with_logits
    name=name)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[7550,2] labels_size=[50,2]
         [[Node: loss/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](loss/Reshape, loss/Reshape_1)]]
During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train_upgraded.py"", line 209, in <module>
    train_step(x_batch, seqlen_batch, y_batch)
  File ""train_upgraded.py"", line 177, in train_step
    feed_dict)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must be same size: logits_size=[7550,2] labels_size=[50,2]
         [[Node: loss/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](loss/Reshape, loss/Reshape_1)]]

Caused by op 'loss/SoftmaxCrossEntropyWithLogits', defined at:
  File ""train_upgraded.py"", line 87, in <module>
    l2_reg_lambda=FLAGS.l2_reg_lambda)
  File ""/media/hemant/MVV/MyValueVest-local/learning/Initial Embeddings/STEP 2 lstm-context-embeddings-master/model_upgraded.py"", line 138, in __init__
    losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 1783, in softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 4364, in _softmax_cross_entropy_with_logits
    name=name)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/hemant/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[7550,2] labels_size=[50,2]
         [[Node: loss/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](loss/Reshape, loss/Reshape_1)]]
```",0,,1,2018-01-12T16:12:57Z,NONE
16065,export tflite::Intepreter's  UseNNAPI() and setNumThreads() to java,"awaiting review,cla: yes","Export tflite::Intepreter's UseNNAPI() and SetNumThreads() to Java
and modify the Android TfLiteCameraDemo app to use them.",1,,1,2018-01-12T05:40:40Z,CONTRIBUTOR
16063,`tools/ci_builds/pi/build_raspberry_pi.sh`: '__PTHREAD_SPINS' was not declared in this scope,stat:awaiting response,"Hi, 
I'm trying to build TensorFlow for RasperryPi from my computer (Ubuntu 16:04) 
When I'm running `tensorflow/tools/ci_builds/pi/build_raspberry_pi.sh`
from the docker container build from `tensorflow/tools/ci_builds/Dockerfile.pi-python3`, some compilation commands from `bazel build` failed ! 

My goal is to use TensorFlow on my RaspberryPi (with a PiCamera) with the C++ API (compiled with bazel ? or makefile ?) ! I started to run some code on my RPi, but the compilation step is so long (6hours to compile/install TensorFlow from sources with Bazel !). I would like to save time, by compiling my code on my laptop, then sending it to the RPi for execution ! 

Here my commands : 

```bash
# get tensorflow 1.5
git clone ......
cd tensorflow 
git checkout r1.5
cd tensorflow/tools/ci_build

# this docker file was added with `r1.5`!
docker build -t tf_ci_buid/pi-py3 -f Dockerfile.pi-python3 .
cd ../../../

# run the docker image
docker run -it -v ""$PWD"":/workspace -w /workspace tf_ci_buid/pi-py3:latest

# then, from the docker container, run the *.sh code 
# this script contains the `bazel build` command ! 
root@88db37534dff:/workspace# ./tensorflow/tools/ci_build/pi/build_raspberry_pi.sh 
```

But during the execution of `bazel build`, the compilation of code from `external/highwayhash/highwayhash` seems to fail ... (see error message bellow)

Someone has already encountered this issue ? Or it's due to the new version (r1.5) ?

Error message : 
```
ERROR: /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/highwayhash/BUILD:8:1: C++ compilation of rule '@highwayhash//:sip_hash' failed (Exit 1): arm-linux-gnueabihf-gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=0 \
  /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/arm-linux-gnueabihf-gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -DRASPBERRY_PI -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '-march=armv7-a' '-mfpu=neon-vfpv4' '-std=gnu11' '-DS_IREAD=S_IRUSR' '-DS_IWRITE=S_IWUSR' -O3 -U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_1 -U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_2 -U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_8 -funsafe-math-optimizations -ftree-vectorize -fomit-frame-pointer '-std=c++11' -isystem /usr/include/arm-linux-gnueabihf -isystem /usr/include/python2.7 -isystem /usr/include/ -MD -MF bazel-out/armeabi-opt/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.d '-frandom-seed=bazel-out/armeabi-opt/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o' -iquote external/highwayhash -iquote bazel-out/armeabi-opt/genfiles/external/highwayhash -iquote external/bazel_tools -iquote bazel-out/armeabi-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c external/highwayhash/highwayhash/sip_hash.cc -o bazel-out/armeabi-opt/bin/external/highwayhash/_objs/sip_hash/external/highwayhash/highwayhash/sip_hash.o)
cc1plus: warning: command line option '-std=gnu11' is valid for C/ObjC but not for C++
In file included from /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/../lib/gcc/arm-linux-gnueabihf/4.9.3/../../../../arm-linux-gnueabihf/include/c++/4.9.3/arm-linux-gnueabihf/bits/gthr-default.h:35:0,
                 from /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/../lib/gcc/arm-linux-gnueabihf/4.9.3/../../../../arm-linux-gnueabihf/include/c++/4.9.3/arm-linux-gnueabihf/bits/gthr.h:148,
                 from /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/../lib/gcc/arm-linux-gnueabihf/4.9.3/../../../../arm-linux-gnueabihf/include/c++/4.9.3/ext/atomicity.h:35,
                 from /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/../lib/gcc/arm-linux-gnueabihf/4.9.3/../../../../arm-linux-gnueabihf/include/c++/4.9.3/memory:73,
                 from external/highwayhash/highwayhash/state_helpers.h:23,
                 from external/highwayhash/highwayhash/sip_hash.h:25,
                 from external/highwayhash/highwayhash/sip_hash.cc:15:
/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/../lib/gcc/arm-linux-gnueabihf/4.9.3/../../../../arm-linux-gnueabihf/include/c++/4.9.3/ext/concurrence.h:122:34: error: '__PTHREAD_SPINS' was not declared in this scope
     __gthread_mutex_t _M_mutex = __GTHREAD_MUTEX_INIT;
                                  ^
/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/arm_compiler/bin/../lib/gcc/arm-linux-gnueabihf/4.9.3/../../../../arm-linux-gnueabihf/include/c++/4.9.3/ext/concurrence.h:177:44: error: '__PTHREAD_SPINS' was not declared in this scope
     __gthread_recursive_mutex_t _M_mutex = __GTHREAD_RECURSIVE_MUTEX_INIT;
                                            ^
INFO: Elapsed time: 275.112s, Critical Path: 9.55s
FAILED: Build did NOT complete successfully
```",0,,1,2018-01-12T01:37:05Z,NONE
16061,OSError: [Errno 12] Cannot allocate memory on deep Q learning model,stat:awaiting response,"I was having fun with the Deep Q learning model, which came from https://github.com/dennybritz/reinforcement-learning/blob/master/DQN. Then after 750 episodes this error popped up.
![1](https://user-images.githubusercontent.com/20869223/34855218-6ae8778a-f779-11e7-9a7f-bbe7670f47b0.png)
![2](https://user-images.githubusercontent.com/20869223/34855219-6b1bc496-f779-11e7-9183-24306a413c01.png)
![3](https://user-images.githubusercontent.com/20869223/34855220-6b4a6436-f779-11e7-84de-e66f157d5a68.png)
![4](https://user-images.githubusercontent.com/20869223/34855221-6b77d754-f779-11e7-90c8-2b700fd10d81.png)
![5](https://user-images.githubusercontent.com/20869223/34855222-6baf6d18-f779-11e7-9963-6a860225a0f2.png)
![6](https://user-images.githubusercontent.com/20869223/34855224-6bdfce68-f779-11e7-8a9a-16ddc709895e.png)
![7](https://user-images.githubusercontent.com/20869223/34855225-6c110014-f779-11e7-8738-c60e50059330.png)
I was running this code on Ubuntu 14.04 with a 8G graphic card(GTX 1070). I have had libav-tools installed before I ran the code.
I will try to reduce the batch size to see whether similar error will pop up again.
Please help me solve this problem.",0,,2,2018-01-12T01:18:16Z,NONE
16054,Lack of Complex64 support for Java API,"stat:contributions welcome,type:feature","This issue is not about a bug, but I will fill in the form anyhow ;-)
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac 10.13.2
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
master branch at commit: b86dc365ebbef64daceced37026518696ede5b7b
- **Python version**:
N/A Using Java version ""1.8.0_152""
- **Bazel version (if compiling from source)**:
Build label: 0.8.1-homebrew
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Dec 5 19:29:04 2017 (1512502144)
- **GCC/Compiler version (if compiling from source)**:
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/c++/4.2.1
Apple LLVM version 9.0.0 (clang-900.0.39.2)
Target: x86_64-apple-darwin17.3.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
- **CUDA/cuDNN version**:
N/A not using CUDA
- **GPU model and memory**:
N/A not using GPU
- **Exact command to reproduce**:
There is no bug to reproduce

### Describe the problem
There is not really a problem. I have need to build TensorFlow computations in Java and have support for complex numbers. Because the C API already supports COMPLEX64 tensors, it was a straight forward effort to expose them in the Java API. Along with unit tests, I have also added a Java example based on the Python tutorial that builds an image that displays the Mandelbrot fractal to show that the complex number support works correctly.

### Source code / logs
Here is a very short example of using the API, clearly there are functions in the example that are not available defined in the example, but it gets the point across. This example is basically lifted from a new java example I created called MandelbrotExample.java
```
Tensor<Complex64> resultZ = null;
try(Graph g = new Graph()) {
    //We create a meshgrid based on two numeric ranges, by wrapping the ranges
    //in Tensors and then pulling out sub grids to make complex numbers
    try (Tensor<Float> meshGridT = buildMeshGrid(range1Spec, range2Spec);
         Tensor<Integer> zeroT = Tensors.create(new int[]{0});
         Tensor<Integer> oneT = Tensors.create(new int[]{1});
         Tensor<Complex64> jTensor = Tensors.create(0.0f, 1.0f)) {
    
        Output<Integer> zero = buildConstant(g, ""0"", zeroT);
        Output<Integer> one = buildConstant(g, ""1"", oneT);

        Output<Float> meshGrid = buildConstant(g, ""meshgrid"", meshGridT);

        Output<Complex64> j = buildConstant(g, ""imagUnit"", jTensor);

        //We use GatherNd to pull out the two parts of the original mesh grid
        //the Z complex tensor
        Output<Float> Yfloat = g.opBuilder(""GatherNd"", ""get_y"")
                .addInput(meshGrid)
                .addInput(zero) //use zero
                .build().output(0);
        Output<Float> Xfloat = g.opBuilder(""GatherNd"", ""get_x"")
                .addInput(meshGrid)
                .addInput(one) //use one
                .build().output(0);

        Output<Complex64> Y = g.opBuilder(""Cast"", ""castYtoComplex"")
                .addInput(Yfloat)
                .setAttr(""DstT"", DataType.COMPLEX64)
                .build().output(0);

        Output<Complex64> X = g.opBuilder(""Cast"", ""castXtoComplex"")
                .addInput(Xfloat)
                .setAttr(""DstT"", DataType.COMPLEX64)
                .build().output(0);

        //Z is constructed by X + Yj
        Output<Complex64> mulYj = g.opBuilder(""Mul"", ""mulYj"")
                .addInput(Y)
                .addInput(j)
                .build()
                .output(0);
        Output<Complex64> Z = g.opBuilder(""Add"", ""addZ"")
                .addInput(X)
                .addInput(mulYj)
                .build()
                .output(0);

        try(Session s = new Session(g)){
            resultZ = s.runner().fetch(Z).run().get(0).expect(Complex64.class);
        }
    }
}
```
I would like to get my local branched pushed to GitHub and then a pull request put in with these changes. I have attached a diff file for the curious. I am still working on getting a corporate CLA put into place.
Thanks for your time and consideration!
[java-complex64.patch.txt](https://github.com/tensorflow/tensorflow/files/1624251/java-complex64.patch.txt)

",0,,3,2018-01-11T22:02:31Z,NONE
16053,"java.lang.IndexOutOfBoundsException: Invalid index 0, size is 0, TensorFlow on Android",,"Hello,

Updated the following info:
Have I written custom code No its modification of the code from here https://github.com/MindorksOpenSource/AndroidTensorFlowMachineLearningExample 
OS Platform and Distribution: Windows 10
TensorFlow installed from: anaconda
TensorFlow version: 1.2.0
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

I created  my custom model in keras to recognize happy faces and loaded the model into android and ran into this issue of 
java.lang.IndexOutOfBoundsException: Invalid index 0, size is 0 at runtime and my app crashed. I have modified the code from here https://github.com/MindorksOpenSource/AndroidTensorFlowMachineLearningExample 
to suit my model. Is it the problem with protobuf file creation? I have tested my model and it works well in python. Below is the log file and the source code. Please help with this issue? Thanks!

### Source code / logs


01-11 16:21:12.508 18038-18078/com.sridhar.deepak.objectdetection D/OpenGLRenderer: endAllStagingAnimators on 0xab6c06f0 (ListView) with handle 0xab7000d8
01-11 16:21:18.135 18038-18038/com.sridhar.deepak.objectdetection E/TensorFlowInferenceInterface: Failed to run TensorFlow session: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:
                                                                                                    device='GPU'; T in [DT_STRING]
                                                                                                    device='GPU'; T in [DT_BOOL]
                                                                                                    device='GPU'; T in [DT_INT32]
                                                                                                    device='GPU'; T in [DT_FLOAT]
                                                                                                    device='CPU'; T in [DT_FLOAT]
                                                                                                    device='CPU'; T in [DT_INT32]
                                                                                                  
                                                                                                  	 [[Node: bn0/cond/Switch = Switch[T=DT_BOOL](bn0/keras_learning_phase, bn0/keras_learning_phase)]]
01-11 16:21:18.135 18038-18038/com.sridhar.deepak.objectdetection D/AndroidRuntime: Shutting down VM
01-11 16:21:18.136 18038-18038/com.sridhar.deepak.objectdetection E/AndroidRuntime: FATAL EXCEPTION: main
                                                                                    Process: com.sridhar.deepak.objectdetection, PID: 18038
                                                                                    java.lang.IndexOutOfBoundsException: Invalid index 0, size is 0
                                                                                        at java.util.ArrayList.throwIndexOutOfBoundsException(ArrayList.java:255)
                                                                                        at java.util.ArrayList.get(ArrayList.java:308)
                                                                                        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.getTensor(TensorFlowInferenceInterface.java:473)
                                                                                        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeIntoFloatBuffer(TensorFlowInferenceInterface.java:320)
                                                                                        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeFloat(TensorFlowInferenceInterface.java:275)
                                                                                        at com.sridhar.deepak.objectdetection.TensorFlowImageClassifier.recognizeImage(TensorFlowImageClassifier.java:161)
                                                                                        at com.sridhar.deepak.objectdetection.HappyFaceDetector$2.onPictureTaken(HappyFaceDetector.java:82)
                                                                                        at com.flurgle.camerakit.CameraView$CameraListenerMiddleWare.onPictureTaken(CameraView.java:296)
                                                                                        at com.flurgle.camerakit.Camera1$2.onPictureTaken(Camera1.java:185)
                                                                                        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1118)
                                                                                        at android.os.Handler.dispatchMessage(Handler.java:102)
                                                                                        at android.os.Looper.loop(Looper.java:154)
                                                                                        at android.app.ActivityThread.main(ActivityThread.java:5527)
                                                                                        at java.lang.reflect.Method.invoke(Native Method)
                                                                                        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:739)
                                                                                        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:629)
01-11 16:21:18.136 18038-18038/com.sridhar.deepak.objectdetection E/MQSEventManagerDelegate: failed to get MQSService.
01-11 16:21:19.470 18038-18038/com.sridhar.deepak.objectdetection I/Process: Sending signal. PID: 18038 SIG: 9

TensorFlowImageClassifier file

    @Override
    public List<Recognition> recognizeImage(final Bitmap bitmap,int s) {
        // Log this method so that it can be analyzed with systrace.
        Trace.beginSection(""recognizeImage"");

        Trace.beginSection(""preprocessBitmap"");
        // Preprocess the image data from 0-255 int to normalized float based
        // on the provided parameters.
        if (s==1) {
            bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
            for (int i = 0; i < intValues.length; ++i) {
                final int val = intValues[i];
                floatValues[i * 3 + 0] = (((val >> 16) & 0xFF) - imageMean) / imageStd;
                floatValues[i * 3 + 1] = (((val >> 8) & 0xFF) - imageMean) / imageStd;
                floatValues[i * 3 + 2] = ((val & 0xFF) - imageMean) / imageStd;
            }
        }else {
            bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
            for (int i = 0; i < intValues.length; ++i) {
                final int val = intValues[i];
                floatValues[i * 3 + 0] = (((val >> 16) & 0xFF))/imageStd;
                floatValues[i * 3 + 1] = (((val >> 8) & 0xFF))/imageStd;
                floatValues[i * 3 + 2] = ((val & 0xFF))/imageStd;
                floatValues[i * 3 + 0] = floatValues[i * 3 + 0] - 1;
                floatValues[i * 3 + 1] = floatValues[i * 3 + 1] - 1;
                floatValues[i * 3 + 2] = floatValues[i * 3 + 2] - 1;

            }
        }
        Trace.endSection();

        // Copy the input data into TensorFlow.
        Trace.beginSection(""fillNodeFloat"");
        inferenceInterface.fillNodeFloat(
                inputName, new int[]{1, inputSize, inputSize, 3}, floatValues);
        Trace.endSection();

        // Run the inference call.
        Trace.beginSection(""runInference"");
        inferenceInterface.runInference(outputNames);
        Trace.endSection();

        // Copy the output Tensor back into the output array.
        Trace.beginSection(""readNodeFloat"");
        inferenceInterface.readNodeFloat(outputName, outputs);
        Trace.endSection();

MainActivity
    private static final int INPUT_SIZE = 64;
    private static final int IMAGE_MEAN = 128;
    private static final float IMAGE_STD = 128;
    private static final String INPUT_NAME = ""input_1"";
    private static final String OUTPUT_NAME = ""fc/Sigmoid"";

    private static final String MODEL_FILE = ""file:///android_asset/happy_model.pb"";
    private static final String LABEL_FILE =
            ""file:///android_asset/face_label.txt"";




",0,,3,2018-01-11T21:57:03Z,NONE
16052,Feature Request: Setting the shape of a tf.data.Dataset if it cannot be inferred,"stat:community support,type:feature","Hello, I have really liked the new `tf.data.Dataset` api, and had a feature request. 
I need to often make data transformations that require third-party libraries, and use `Dataset.map` along with a `tf.py_func` command as shown in the Importing Data tutorial. In the process of doing this, Tensorflow is not able to infer the shape of the numpy arrays that are returned by the py_func-based functions, and so the output_shapes attribute of the dataset returns something like `(TensorShape(None), TensorShape(None), TensorShape(None), TensorShape(None), TensorShape(None))`

To address this, I have been adding a new map function after that calls set_shape on each tensor to enforce the shape requirement. For example, I have code that looks something like this:

```
dataset = dataset.map(lambda strings, labels: tuple(tf.py_func(_featurize, [strs, labels], [tf.int32, tf.float64, tf.int32, tf.int32, labels.dtype])))
dataset = dataset.map(_set_shapes)
```
where 
```
def _set_shapes(af, pf, split, atp, labels):
    af.set_shape([None, 75])
    pf.set_shape([None, 14])
    split.set_shape([None, ])
    atp.set_shape([None, 2])
    labels.set_shape([None, ])
    return af, pf, split, atp, labels
```

Could this be simplified by adding a new `tf.data.Dataset` member function called ""set_dataset_shape"" which essentially just implements the above _set_shapes method?

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: AWS Deep Learning AMI
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: AWS Deep Learning AMI-based
- **GPU model and memory**: NVIDIA K80
- **Exact command to reproduce**: N/A

",0,,5,2018-01-11T21:52:14Z,NONE
16050,Eigen assertion when running on GPU with debug enabled ,,"I used r1.5 release version to compile in debug mode. The build command is 
bazel build -c opt --config cuda -c dbg --strip=never  //tensorflow/tools/pip_package:build_pip_package

I tested the tutorial/mnist/mnist_deep.py and it got assertion below. I searched the forum and it seems that there is no clear answer for it. Thanks.

===========================
Answer the questions below:
Have I written custom code:No
OS Platform and Distribution:ubuntu 16.04
TensorFlow installed from: official
TensorFlow version: r1.5
Bazel version: 0.8
CUDA/cuDNN version: 9.0 / 7.0
GPU model and memory: P100, 16GB
Exact command to reproduce: as above


===========================
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
Saving graph to: /tmp/tmpis6Bjq
2018-01-11 11:45:43.003071: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-01-11 11:45:43.377683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2018-01-11 11:45:43.737737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-01-11 11:45:43.738343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 1 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2018-01-11 11:45:43.738437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device peer to peer matrix
2018-01-11 11:45:43.738512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126] DMA: 0 1
2018-01-11 11:45:43.738527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 0:   Y N
2018-01-11 11:45:43.738535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 1:   N Y
2018-01-11 11:45:43.738573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
2018-01-11 11:45:43.738589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
step 0, training accuracy 0.08
python: external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:262: static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, Vectorizable>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, const Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, const Eigen::TensorBroadcastingOp<const Eigen::array<long int, 1ul>, const Eigen::TensorReshapingOp<const Eigen::Sizes<1l>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<const float, const float>, const Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<const float>, const Eigen::TensorMap<Eigen::TensorFixedSize<const float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::TensorMap<Eigen::TensorFixedSize<const float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer> > > >, const Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<const float, const float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long int>, 16, Eigen::MakePointer> > > > >; bool Vectorizable = true]: Assertion `**cudaGetLastError() == cudaSuccess'** failed.
Aborted (core dumped)
",0,,3,2018-01-11T19:59:20Z,NONE
16046,Feature Request: clarify supported environments for official binaries.,,"As it stands now, binary release of TensorFlow 1.5 is set to drop compatibility with Ubuntu 14.04 ( https://github.com/tensorflow/tensorflow/issues/15777), and compatibility with Debian Linux distros, such as Amazon Linux AMI (`ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found`).

To avoid surprise, TensorFlow should either:
1. Follow other open-source projects like Ray/PyTorch and provide official binaries for these systems
or
2. Document that support is dropped, to encourage other players (ie, AWS) to take over the job of providing these binaries

@martinwicke",0,,8,2018-01-11T18:13:57Z,CONTRIBUTOR
16045,XLA: Won't converge and doesn't respect visible devices.,,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (writing a copy I can share)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Nvidia Optimized Container 17.12
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: IntelPython 3.5
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
- **CUDA/cuDNN version**: 9.0.176 with CUBLAS Basic Accelerated Linear Algebra 9.0.234 / 7
- **GPU model and memory**: Pascal Titan 12Gb
- **Exact command to reproduce**: Coming

### Describe the problem
I've seen 2 problems with XLA:
1) XLA doesn't respect visible devices (neither CUDA Visible devices or tf config options)
2) XLA doesn't converge

_1_
XLA doesn't respect visible devices, I have seen this in both Horovod and when running on a single GPU (on a Multi-GPU desktop), `N` XLA instances are created despite only one GPU being used.

_2_ 
When I run my script with and without XLA, the XLA compiled version plateaus and doesn't converge, whilst the none-XLA version converges. Where XLA has a loss of a magnitude higher.
The benchmark is a VGG network (with BatchNorm) and achieves a 3x speed up with XLA, it just doesn't converge.

Is this a known issue? Or is it just a possibility of occurring?

",0,,23,2018-01-11T17:55:32Z,NONE
16044,Feature Request: tf.multi_one_hot that is one-hot encoding multiple columns of a Tensor,"stat:contributions welcome,type:feature","Hi there,

I just wrote a function that creates multiple one-hot-encodings for a tensor and concatenates them. I was curious whether this might serve some others and contribute this feature.


```
def multiple_one_hot(cat_tensor, depth_list):
    """"""Creates one-hot-encodings for multiple categorical attributes and
    concatenates the resulting encodings

    Args:
        cat_tensor (tf.Tensor): tensor with mutiple columns containing categorical features
        depth_list (list): list of the no. of values (depth) for each categorical

    Returns:
        one_hot_enc_tensor (tf.Tensor): concatenated one-hot-encodings of cat_tensor
    """"""
    one_hot_enc_tensor = tf.one_hot(cat_int_tensor[:,0], depth_list[0], axis=1)
    for col in range(1, len(depth_list)):
        add = tf.one_hot(cat_int_tensor[:,col], depth_list[col], axis=1)
        one_hot_enc_tensor = tf.concat([one_hot_enc_tensor, add], axis=1)

    return one_hot_enc_tensor

```
I am happy for your feedback. Tell me if you think others might profit and I would enjoy to create a pull request ;)",0,,3,2018-01-11T16:12:08Z,NONE
16042,tf.contrib.cudnn_rnn.CudnnGRU does not work with input_mode='skip_input' in TF1.5,,"### System information
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: `pip install tensorflow-gpu==1.5.0rc0`
- **TensorFlow version**: v1.3.0-rc1-6090-g622487f 1.5.0-rc0
- **Python version**:  3.5
- **CUDA/cuDNN version**: CUDA 9.0, CuDNN 7.0.5
- **GPU model and memory**: GTX 1080 8GB

### Describe the problem
We are running tf.contrib.cudnn_rnn.CudnnGRU in our speech recognition setup with input_mode='skip_input' and it crashes the whole process. Here is the assertion error that we are getting:

`Check failed: size == params_input[i].NumElements() Params size mismatch. Expected 0, got 10000`

Looks like it's crashing here: [tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc:440](https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc#L440). It does not crash if input_mode is 'linear_input'.

Here is the minimal example to reproduce:

### Source code / logs
```
import tensorflow as tf

layer = tf.contrib.cudnn_rnn.CudnnGRU(num_layers=1, num_units=100,
                             input_mode='skip_input', direction='bidirectional')
# (time, batch_size, num_inputs)
x = tf.random_normal((100, 16, 100))
y = layer(x)

with tf.Session() as sess:
	sess.run(tf.global_variables_initializer())
	print(sess.run(y))

```

Logs:

```
2018-01-11 17:10:44.858413: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-01-11 17:10:45.067854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:03:00.0
totalMemory: 7.92GiB freeMemory: 7.80GiB
2018-01-11 17:10:45.274222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 1 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:04:00.0
totalMemory: 7.92GiB freeMemory: 7.80GiB
2018-01-11 17:10:45.274776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device peer to peer matrix
2018-01-11 17:10:45.274804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126] DMA: 0 1 
2018-01-11 17:10:45.274812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 0:   Y Y 
2018-01-11 17:10:45.274817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 1:   Y Y 
2018-01-11 17:10:45.274826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
2018-01-11 17:10:45.274832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1)
2018-01-11 17:10:46.240862: F tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc:440] Check failed: size == params_input[i].NumElements() Params size mismatch. Expected 0, got 10000
Aborted (core dumped)
```

### Thoughts

I think the problem is in python wrapper code located at [contrib/cudnn_rnn/python/layers/cudnn_rnn.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py).

Both [`_canonical_weight_shape(self, layer)`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py#L417) and [`_canonical_bias_shape(self, layer)`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py#L443) don't handle the case when `input_mode='skip_input'`. The wrapper code doesn't even check if `input_size == num_units` when `input_mode='skip_input'` as it should! The issue seems to be easy to fix, but I may be mistaken.

Here is an example that shows that both 'skip_input' and 'linear_input' get the same set of canonical parameter shapes:
```
CudnnGRU = lambda **kwargs: tf.contrib.cudnn_rnn.CudnnGRU(num_layers=1, num_units=7, direction='bidirectional', **kwargs)

layer = CudnnGRU(input_mode='skip_input')
layer.build((200, 16, 5))
print(""skip_input weights"", layer.canonical_weight_shapes)
print(""skip_input biases"", layer.canonical_bias_shapes)

layer = CudnnGRU(input_mode='linear_input')
layer.build((200, 16, 5))
print(""linear_input_weights"", layer.canonical_weight_shapes)
print(""linear_input_biases"", layer.canonical_bias_shapes)
```

Example output:
```
skip_input weights [(7, 5), (7, 5), (7, 5), (7, 7), (7, 7), (7, 7), (7, 5), (7, 5), (7, 5), (7, 7), (7, 7), (7, 7)]
skip_input biases [[7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7]]
linear_input_weights [(7, 5), (7, 5), (7, 5), (7, 7), (7, 7), (7, 7), (7, 5), (7, 5), (7, 5), (7, 7), (7, 7), (7, 7)]
linear_input_biases [[7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7]]
```

### Workaround

In our setup we decided that we will keep allocating opaque_params buffer manually with first querying its size with 
```
# Note: this code may require tf==1.4 to run.
layer = tf.contrib.cudnn_rnn.CudnnGRU(1, num_units=800, input_size=800,
                                      input_mode='linear_input',
                                      direction='bidirectional')
with tf.Session() as sess:
    OPAQUE_BUFFER_SIZE = sess.run(layer.params_size())
    print(OPAQUE_BUFFER_SIZE)
```

But this is really troublesome because it requires running the intermediate graph to get OPAQUE_BUFFER_SIZE before building the main graph.",1,,2,2018-01-11T14:48:34Z,CONTRIBUTOR
16039,How TF-Detect draw a rectangular?,,"How TF-Detect draw a rectangular?
I can't find the corresponding code?
Is it calling OpenGL to draw a rectangular?",0,,3,2018-01-11T13:12:20Z,NONE
16035,FasterRCNN error,stat:awaiting response,"Hi friends. 
While  i am trying to execute tensor flow based faster RCNN, i got the following error. 
please help me how to solve this.

tensorflow.python.framework.errors_impl.InternalError: WhereOp: Could not launch cub::DeviceReduce::Sum to count number of true indices.  temp_storage_bytes: 2815, status: invalid device function
",0,,2,2018-01-11T11:04:19Z,NONE
16034,Feature request: tf.nn.dropout noise_shape should support unspecified dimensions,"stat:awaiting response,type:feature","It would be nice if the noise_shape in [tf.nn.dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) would support unspecified dimensions, and just use the shape of the input tensor, e.g. `-1` or `None`. This way it could be specified as `noise_shape = [-1, 1, 1, -1]` instead of `noise_shape = [k, 1, 1, n]`.",0,,2,2018-01-11T11:03:11Z,NONE
16032,"When will those operations such as ""BuiltinOperator_L2_NORMALIZATION"" be delegated to NNAPI? ","comp:lite,stat:awaiting tensorflower","System information
Have I written custom code: yes
OS Platform and Distribution: Ubuntu 14.04
TensorFlow installed from: pip
TensorFlow version (use command below): 1.4.1
Python version: 2.7.5

My problem:
      My android application wants to load the ""facenet"" model through TF lite with NNAPI enabled to do face recognition. But it always crashed. After I debugged,  I found it was caused by that the ""L2_NORMALIZATION""  was not delegated to NNAPI. I wonder when will those operations be supported by nnapi_delegate, as my application has to use the hardware acceleration. Or is there any workaround to make the application complete normally with ""Use_NNAPI"" enabled ?  ",0,,1,2018-01-11T10:23:23Z,NONE
16028,Optimzer: Better handling of gradients for min/max ops.,,"Please don't kick me too hard for this. If this ticket should not be here, please direct me to the proper place. It's not a help or support request, just a very naive idea/request/improvement.

Image a model has this op in the graph: `y = tf.maximum(a, b)`. If `y` is contributing error to the loss (higher `y` higher is loss), then you are interested in minimizing both `a` and `b`. Otherwise, your optimizer will play whack-a-mole game forever. Especially, if you have something like this in your model: `b = 1 - a` and `y = tf.maximum(a, b)`

I've researching how does optimizer works and looks like each op has a function that defines how to calculate its gradients. 
In the current implementation for maximum/minimum (python's version) is located here: 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_grad.py#L901
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_grad.py#L883

In the current implementation, it discards gradients for `a`, if `b` is bigger than `a` and other way around. 

I think, that there is some place for improvement of training speed simply by considering gradients for all variables in min/max operations (including reduce_min/reduce_max and all max/min pooling). There are a lot of models with max pooling. It makes sense that they will train faster if they stop playing whack-a-feature each time it has max pooling layer.

If it make sense, I would like to do a small PoC.
",0,,3,2018-01-11T04:47:49Z,NONE
16026,can't use mpi_allreduce op when tensors run on gpus,stat:awaiting response,"I compiled and installed new mpi_collective feature with openmpi3.0 on tensorflow 1.5.  When I use allreduce function to aggregate loss, I got segmentation fault errors. However, When I force code to run on CPU device, it's fine. 

**## here is my runtime environment.**
== cat /etc/issue ===============================================
Linux user-ubuntu 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""14.04.5 LTS, Trusty Tahr""
VERSION_ID=""14.04""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux user-ubuntu 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.5.1)
tensorflow (1.5.0rc0)
tensorflow-tensorboard (0.4.0rc2)

== tensorflow import ============================================
tf.VERSION = 1.5.0-rc0
tf.GIT_VERSION = unknown
tf.COMPILER_VERSION = unknown
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Wed Jan 10 21:56:08 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 0000:06:00.0     Off |                    0 |
| N/A   27C    P0    27W / 250W |      0MiB / 16276MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla P100-PCIE...  Off  | 0000:84:00.0     Off |                    0 |
| N/A   25C    P0    27W / 250W |      0MiB / 16276MiB |      3%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61

**##here is error.**

tensor@user-ubuntu:~/tensorflow-r1.4/tensorflow/contrib/mpi_collectives$ mpirun -n 2 python mpi_simple_nn.py 

2018-01-10 21:50:44.579981: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-01-10 21:50:44.580748: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-01-10 21:50:47.127209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:06:00.0
totalMemory: 15.89GiB freeMemory: 15.34GiB
2018-01-10 21:50:47.127952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:06:00.0
totalMemory: 15.89GiB freeMemory: 15.34GiB
2018-01-10 21:50:48.027960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.34GiB
2018-01-10 21:50:48.028762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.34GiB
2018-01-10 21:50:48.028835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1221] Device peer to peer matrix
2018-01-10 21:50:48.028932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1221] Device peer to peer matrix
2018-01-10 21:50:48.028886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1227] DMA: 0 1 
2018-01-10 21:50:48.028910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1237] 0:   Y N 
2018-01-10 21:50:48.028926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1237] 1:   N Y 
2018-01-10 21:50:48.028933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Adding visible gpu device 0
2018-01-10 21:50:48.028938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Adding visible gpu device 1
2018-01-10 21:50:48.028966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1227] DMA: 0 1 
2018-01-10 21:50:48.028974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1237] 0:   Y N 
2018-01-10 21:50:48.028979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1237] 1:   N Y 
2018-01-10 21:50:48.028994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Adding visible gpu device 0
2018-01-10 21:50:48.029000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Adding visible gpu device 1
2018-01-10 21:50:48.568865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:987] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14824 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-01-10 21:50:48.668728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:987] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 553 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-01-10 21:50:48.676343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:987] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14824 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
2018-01-10 21:50:48.708625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:987] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 553 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
my_rank  1
my_rank  0
[user-ubuntu:49967] *** Process received signal ***
[user-ubuntu:49967] Signal: Segmentation fault (11)
[user-ubuntu:49967] Signal code: Invalid permissions (2)
[user-ubuntu:49967] Failing at address: 0x1042c005000
[user-ubuntu:49967] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x10330)[0x7f2122752330]
[user-ubuntu:49967] [ 1] /lib/x86_64-linux-gnu/libc.so.6(+0x9ac36)[0x7f2122413c36]
[user-ubuntu:49967] [ 2] /usr/local/openmpi3/lib/openmpi/mca_btl_vader.so(mca_btl_vader_sendi+0x332)[0x7f1fd5d9b832]
[user-ubuntu:49967] [ 3] /usr/local/openmpi3/lib/openmpi/mca_pml_ob1.so(+0xb6eb)[0x7f1fd63c86eb]
[user-ubuntu:49967] [ 4] /usr/local/openmpi3/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_send+0x690)[0x7f1fd63ca130]
[user-ubuntu:49967] [ 5] /usr/local/openmpi3/lib/libmpi.so.40(PMPI_Send+0xf2)[0x7f1ffc59d062]
[user-ubuntu:49967] [ 6] /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/mpi_collectives/python/ops/_mpi_ops.so(_ZN10tensorflow7contrib15mpi_collectives13RingAllreduceIN5Eigen9GpuDeviceEfEENS_6StatusEPNS_15OpKernelContextEPKNS_6TensorEPS8_SB_+0x14f)[0x7f21082b50bf]
[user-ubuntu:49967] [ 7] /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/mpi_collectives/python/ops/_mpi_ops.so(+0x1cab9)[0x7f21082aaab9]
[user-ubuntu:49967] [ 8] /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/mpi_collectives/python/ops/_mpi_ops.so(+0x23760)[0x7f21082b1760]
[user-ubuntu:49967] [ 9] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60)[0x7f1ff5c48a60]
[user-ubuntu:49967] [10] /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184)[0x7f212274a184]
[user-ubuntu:49967] [11] /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f2122476ffd]
[user-ubuntu:49967] *** End of error message ***
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
-------------------------------------------------------
--------------------------------------------------------------------------
mpirun noticed that process rank 0 with PID 0 on node user-ubuntu exited on signal 11 (Segmentation fault)",0,,1,2018-01-11T02:59:49Z,NONE
16025,Checkpoints continue to grow after the first restore,,"### System information
- No

- **OS Platform and Distribution**: Mac OS X, v 10.13.2
- **TensorFlow installed from**: binary
- **TensorFlow version**: v1.3.0-rc1-5211-gab0fcac 1.5.0-dev20171126
- **Python version**: Python 3.5.0
- **Bazel version**: N/A
- **GCC/Compiler version**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Intel Iris Pro 1536 MB
- **Exact command to reproduce**: N/A
- **Have I written custom code**: N/A

### Describe the problem

The parameter `max_to_keep` of the `Saver` class does not seem to have effect once a model and its training variables are restored. In other words, the first time I train my model, the saver is keeping only `max_to_keep` checkpoints. Then I interrupt the training. Later, when I resume it, the number of checkpoints keeps going without any apparent limit.

### Related issues

- https://github.com/tensorflow/tensorflow/issues/5929
- https://github.com/tensorflow/tensorflow/issues/6326
",0,,4,2018-01-11T00:25:19Z,NONE
16023, can't feed  the multi-channel to contrib_audio.audio_spectrogram,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp35-cp35m-linux_x86_64.whl
- **TensorFlow version (use command below)**: 1.4
- **Python version**:  3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 8.0/cuDNN6.0
- **GPU model and memory**: Geforce 1080 TI
- **Exact command to reproduce**:

### Describe the problem
can't  feed the multi-channel to audio_spectrogram()
the error is 
Spectrogram size calculation failed:Expected height 98 but got 100

if use [16000, 1] at line 29 in my below code, the result is ok. no error. It means only accept one channel.
I read the code at:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/spectrogram_op.cc
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/spectrogram.cc

I think the error is :
samples_to_next_step_ and  input_queue_ is modified when calculation for each channel.
But Spectrogram don't initialized these two variable at each channel, 

### Source code / logs
![image](https://user-images.githubusercontent.com/32910309/34800518-fff6eaee-f618-11e7-8563-3cac1b8637c6.png)

![image](https://user-images.githubusercontent.com/32910309/34800232-c10414f2-f617-11e7-94a5-2c0a7ec3738d.png)

",0,,1,2018-01-10T23:11:54Z,NONE
16009,"bazel build ask for ANDROID_NDK_HOME, ANDROID_SDK_HOME -- no way to disable it",type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
('v1.5.0-rc0-1-g793280a', '1.5.0-rc0')
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
```
Build label: 0.9.0
Build target: bazel-out/k8-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Dec 19 09:31:58 2017 (1513675918)
Build timestamp: 1513675918
Build timestamp as int: 1513675918
```
- **GCC/Compiler version (if compiling from source)**:
g++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
- **CUDA/cuDNN version**:
toolkit_9.0 and cudnn 7.0.5_for_9.0
- **GPU model and memory**:
different machines (irrelevant)
- **Exact command to reproduce**:
see [this gist](https://gist.github.com/PatWie/aef90e72dbeaf2f79fbcaa031d74baad) which is mainly

```bash
export TF_NEED_GCP=0
export TF_NEED_CUDA=1
export TF_CUDA_VERSION=""$($CUDA_TOOLKIT_PATH/bin/nvcc --version | sed -n 's/^.*release \(.*\),.*/\1/p')""
export TF_CUDA_COMPUTE_CAPABILITIES=6.1,5.2,3.5
export TF_NEED_HDFS=0
export TF_NEED_OPENCL=0
export TF_NEED_JEMALLOC=1
export TF_ENABLE_XLA=0
export TF_NEED_VERBS=0
export TF_CUDA_CLANG=0
export TF_CUDNN_VERSION=7
export TF_NEED_MKL=0
export TF_DOWNLOAD_MKL=0
export TF_NEED_MPI=0
export TF_NEED_GDR=0
export TF_NEED_S3=0
export TF_NEED_OPENCL_SYCL=0
export TF_NEED_COMPUTECPP=0
export GCC_HOST_COMPILER_PATH=$(which gcc)
export CC_OPT_FLAGS=""-march=native""

./configure

bazel build --config=opt --copt=-mfpmath=both --copt=-msse4.2 --copt=-O3 --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=1 ....
```
### Describe the problem
In the past, using exactly this scripted worked. However, there are now a few issues:
The build uses `AVX2` even I haven't specified it as `--copt` (which worked in the past)

### Source code / logs
depending on the machine it gives

```
Python 2.7.12 (default, Nov 20 2017, 18:23:56) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
2018-01-10 15:06:19.070740: F tensorflow/core/platform/cpu_feature_guard.cc:36] The TensorFlow library was compiled to use AVX2 instructions, but these aren't available on your machine.
zsh: abort      python
```
or
```
Python 2.7.12 (default, Nov 20 2017, 18:23:56) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
zsh: illegal hardware instruction  python
```

On machines with AVX2 everything is fine. Further, there is no way to skip to setup ANDROID_NDK_HOME, ANDROID_SDK_HOME (I manually uncommented this in `configure.py`).

*edit*
I am willing to provide a pull-request for `configure.py`, adding something like `TF_NEED_ANDROID`.",0,,3,2018-01-10T14:10:14Z,NONE
16004,cudnn,stat:awaiting response,"INFO:tensorflow:Starting Queues.
2018-01-10 18:45:29.789178: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2018-01-10 18:45:29.843774: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
INFO:tensorflow:global_step/sec: 0
2018-01-10 18:45:33.552377: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2018-01-10 18:45:33.587139: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2018-01-10 18:45:33.621270: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2018-01-10 18:45:33.660148: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2018-01-10 18:45:34.072946: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2018-01-10 18:45:34.244066: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2018-01-10 18:45:37.678240: E tensorflow/stream_executor/cuda/cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2018-01-10 18:45:37.678276: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2018-01-10 18:45:37.678313: F tensorflow/core/kernels/conv_ops.cc:667] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms)",0,,2,2018-01-10T10:49:52Z,NONE
16000,TensorFlow Installation Error on SLES 11 SP Linux ,,"I have been trying to install tensorflow (1.3.0/1.4/1.4.1) on SLES 11 Linux, I was getting GLIBC_2.14 not found an exception, currently, we have the **GLIBC_2.11.3 version in SLES 11 SP3T**. 

Please help me to install any of **tensorflow > 0.8** versions on SLES 11 Linux and let me know the tensorflow compatible version for SLES 11. OR SLES 11 SP3 Linux is not compatible with TensorFlow any of the versions.

Thanks in Advance.
  ",0,,3,2018-01-10T07:40:41Z,NONE
15999,[Feature Request] Request for weighted sampling in tf.data.Dataset ,"stat:awaiting response,type:feature",Are there any methods that we can sample with weights without pre-weighting the dataset as the input in Dataset API?,0,,4,2018-01-10T07:03:07Z,NONE
15997,Allow tensorflow/tensorflow/workspace.bzl to customize dependencies,,"When including tensorflow as a dependency of a Bazel project, it requires you to take all the declared dependencies in  `tensorflow/tensorflow/workspace.bzl` or none of them. Some projects, like the closure_rules allow you to customize the dependencies:
https://github.com/bazelbuild/rules_closure/blob/master/closure/repositories.bzl#L21

This allows you to use whatever versions you want for specific dependencies that may be different from what tensorflow's workspace.bzl declares.",0,,3,2018-01-10T05:51:04Z,CONTRIBUTOR
15996,CMake building fail on Linux Centos 7 ,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**:  2.7.5
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: K80
- **Exact command to reproduce**:

### Describe the problem
After successful config by CMake, the make failed.

### Source code / logs
[  1%] Performing build step for 'zlib'
Scanning dependencies of target zlib
[  2%] Building C object CMakeFiles/zlib.dir/adler32.o
[  5%] Building C object CMakeFiles/zlib.dir/compress.o
[  7%] Building C object CMakeFiles/zlib.dir/crc32.o
[ 10%] Building C object CMakeFiles/zlib.dir/deflate.o
[ 12%] Building C object CMakeFiles/zlib.dir/gzclose.o
[ 15%] Building C object CMakeFiles/zlib.dir/gzlib.o
[ 17%] Building C object CMakeFiles/zlib.dir/gzread.o
[ 20%] Building C object CMakeFiles/zlib.dir/gzwrite.o
[ 22%] Building C object CMakeFiles/zlib.dir/inflate.o
[ 25%] Building C object CMakeFiles/zlib.dir/infback.o
[ 27%] Building C object CMakeFiles/zlib.dir/inftrees.o
[ 30%] Building C object CMakeFiles/zlib.dir/inffast.o
[ 32%] Building C object CMakeFiles/zlib.dir/trees.o
[ 35%] Building C object CMakeFiles/zlib.dir/uncompr.o
[ 37%] Building C object CMakeFiles/zlib.dir/zutil.o
[ 40%] Linking C shared library libz.so
/usr/bin/ld: CMakeFiles/zlib.dir/compress.o: relocation R_X86_64_32 against `.rodata.str1.1' can not be used when making a shared object; recompile with -fPIC
CMakeFiles/zlib.dir/compress.o: could not read symbols: Bad value
collect2: error: ld returned 1 exit status
make[5]: *** [libz.so.1.2.8] Error 1
make[4]: *** [CMakeFiles/zlib.dir/all] Error 2
make[3]: *** [all] Error 2
make[2]: *** [zlib/src/zlib-stamp/zlib-build] Error 2
make[1]: *** [CMakeFiles/zlib.dir/all] Error 2
make: *** [all] Error 2


Do I need revise some code of CMakeLists.txt?

",0,,5,2018-01-10T05:44:12Z,NONE
15994,Feature request: (documentation) operation complexity / performance chart,,"* Have I written custom code: NA
* OS Platform and Distribution: Any
* TensorFlow installed from: NA
* TensorFlow version: NA
* Bazel version: NA
* CUDA/cuDNN version: NA
* GPU model and memory: NA
* Exact command to reproduce: NA

It would be interesting to have a complexity/performance chart for different operations. For example, to know that `tf.reshape` is computationally cheaper than `tf.transpose`. 

I did see the [Performance Guide](https://www.tensorflow.org/performance/performance_guide), but that's not what I mean.",0,,3,2018-01-10T03:08:58Z,NONE
15992,"android demo ,How to switch the horizontal screen?",stat:awaiting response,"tensorflow 1.4
TF-OD-API model

```
<activity android:name=""org.tensorflow.demo.DetectorActivity""
                  android:screenOrientation=""landscape""
                  android:label=""@string/activity_name_detection"">
            <intent-filter>
                <action android:name=""android.intent.action.MAIN"" />
                <category android:name=""android.intent.category.LAUNCHER"" />
            </intent-filter>
 </activity>
```

I have some problems now, and I want to ask how to do the rotation.
  ",0,,2,2018-01-10T02:32:41Z,NONE
15990,[Tracking bug] Building Tensorflow with Clang on Windows,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: Python 3.6
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: VS 2017 15.5
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: n/a

This is tracking bug to use Clang on Windows to build Tensorflow.

Benefits:
- Faster build (Clang does not suffer from `__forceinline` issue in pure MSVC #10521).
- Mostly compatible with MSVC (`clang-cl` understands MSVC command flags, macros and even imitates some of the MSVC's bugs).
- Cross compilation.
- Unlock some runtime optimizations such as [crc32c acceleration](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/hash/crc32c_accelerate.cc) that relies on `__builtin_cpu_supports` (compiler-rt is required).
- Better x64 code (according to one Chromium engineer).",0,,3,2018-01-10T01:50:19Z,CONTRIBUTOR
15989,Fix freeze_graph command line argument error.,"awaiting review,cla: yes",Fix TypeError: main() missing 1 required positional argument: 'unused_args' when using freeze_graph command line tool (pip console script entry point),1,,5,2018-01-10T00:12:56Z,NONE
15982,Add broadcasting support for `tf.where`,"awaiting review,cla: yes","This fix tries to address the issue raised in #9284 where there was no broadcasting support for `tf.where`. This fix adds the support of broadcasting by adding a `broadcast` arg in `tf.where`. When `broadcast=True` then `tf.where` matches `np.where` in behavior. When `broadcast=False` the old behavior of `tf.where` are kept.

This fix fixes #9284.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,2,2018-01-09T22:05:59Z,MEMBER
15978,No documentation for ConfigProto,"stat:awaiting tensorflower,type:docs","### System information

Not necessary in this case.

### Describe the problem

No documentation for the `ConfigProto` class in the TF website. Specifically, in neither of the following pages

- https://www.tensorflow.org/api_docs/python/tf/ConfigProto
- https://www.tensorflow.org/versions/r1.5/api_docs/python/tf/ConfigProto
- https://www.tensorflow.org/versions/master/api_docs/python/tf/ConfigProto
  
### Possible solutions

The following article https://www.tensorflow.org/tutorials/using_gpu contains info about `ConfigProto`. Either the docs for `ConfigProto` can be written based on that info or, at least, a link to that article should be added to the `ConfigProto` docs.",1,,2,2018-01-09T16:34:52Z,NONE
15977,Improve video input pipeline (using TFRecord files),,"I am building a video input pipeline for DeepMind's [Kinetics dataset](https://deepmind.com/research/open-source/open-source-datasets/kinetics/) using TFRecord files. Since the dataset is large (200k videos) my TFRecord files store the frames as compressed JPG images; otherwise it would require too much space on disk. Each `tf.train.Example` has the following structure:

```
Example {
  'num_frames': tf.int64,
  'label': tf.int64,
  'frames/0001': tf.string,
  'frames/0002': tf.string,
  ...
}
```

Where all the frames store a JPG image as compressed bytes. Using `tf.data.TFRecordDataset` and `tf.image.decode_jpg` I am able to load the images and decode from JPG into `tf.uint8` tensors (full code can be found [here](https://github.com/tomrunia/TF_VideoInputPipeline/blob/master/kinetics/input_pipeline.py)):

```
def decode(serialized_example):
  
    # Prepare feature list; read encoded JPG images as bytes
    features = dict()
    features[""class_label""] = tf.FixedLenFeature((), tf.int64)
    for i in range(64):
        features[""frames/{:04d}"".format(i)] = tf.FixedLenFeature((), tf.string)

    # Parse into tensors
    parsed_features = tf.parse_single_example(serialized_example, features)

    # Decode the encoded JPG images
    images = []
    for i in range(64):
        images.append(tf.image.decode_jpeg(parsed_features[""frames/{:04d}"".format(i)]))

    # Pack the frames into one big tensor of shape (N,H,W,3)
    images = tf.stack(images)
    label  = tf.cast(parsed_features['class_label'], tf.int64)

    return images, label
```
Two things currently seem impossible with the current features of TFRecord files:

1. There seems to be no way to take a random sample of frames. The code example now takes the first 64 frames from the TFRecord, but what is often preferred is taking a random sample of consecutive frames. In one of my failed attempts I have tried to accomplish this along the lines of:

```
num_frames = tf.cast(parsed_features['num_frames'], tf.int64)
offset = tf.random_uniform(shape=(), minval=0, maxval=label, dtype=tf.int64)
```

2. The number of frames in the video example seems impossible to access in TensorFlow. It can be obtained using ` tf.train.Example.FromString` as given [here](https://stackoverflow.com/a/42402484/3419427), but that does not help me in this case. If this was possible I could just load all the video frames into a tensor (at increased cost...) and than use `tf.random_crop` to sample a random number of frames from the video. 

My overall question is whether the input pipeline for videos using TFRecord files can be improved? This needs to consider speed of reading data and compression options to limit file size for enormous  datasets. It would be convenient to directly use mp4 streams with TFRecord files, however decoding this is problably much slower than decoding JPG images (**EDIT**: this pull request is related: https://github.com/tensorflow/tensorflow/pull/13242)

Note that there are many ways to setup the data pipeline for videos. I have described some of them in this post on StackOverflow and motivated why I chose for TFRecord files. This post also describes the problem described here, so it may be informative: https://stackoverflow.com/questions/48101576/tensorflow-read-video-frames-from-tfrecords-file

Have I written custom code: N/A
OS Platform and Distribution: N/A
TensorFlow installed from: N/A
TensorFlow version: N/A
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A
  ",0,,3,2018-01-09T16:17:52Z,NONE
15973,"How to change the model, without any change into android APK file",,"Hello,

I want to make an android app in this way, like we can change model file anytime in future, and it will not require any change into application code, means no need to generate new APK file of application, on any change into model.
In short I want to know, is there anyway to place model file other then assets folder. So that I can refer updated model file anytime from app.

Thanks,
Sumeet Guha.",0,,3,2018-01-09T10:46:45Z,NONE
15972,Maven Version of tensorflow Java API jar wrongly updated in Documentation,,"### System information
Have I written custom code : N/A
OS Platform and Distribution : N/A
TensorFlow installed from : N/A
TensorFlow version : N/A
Bazel version : N/A
CUDA/cuDNN version : N/A
GPU model and memory : N/A
Exact command to reproduce : N/A

### Describe the problem
https://www.tensorflow.org/install/install_java shows maven version as 1.4.1 

```
<dependency>
  <groupId>org.tensorflow</groupId>
  <artifactId>tensorflow</artifactId>
  <version>1.4.1</version>
</dependency>
```
However, this version is not available in public maven Repositories.
https://mvnrepository.com/artifact/org.tensorflow/tensorflow
Only versions  1.3.0 , 1.4.0, 1.4.0-rc0 and 1.5.0-rc0 are available.
Please correct documentation or release 1.4.1 Versions.

### Source code / logs
N/A
  ",0,,3,2018-01-09T09:44:50Z,NONE
15971,Fix local path for hexagon_graph_execution in sample script,"awaiting review,cla: yes","As Android arch is supported since r1.5, the local path must also be changed.
If not, and error occurs that the file can not be found.

Signed-off-by: MyungSung Kwak <yesmung@gmail.com>",1,,4,2018-01-09T09:17:34Z,NONE
15969,Fix variable property of DropoutWrapper,"awaiting review,cla: yes",Fix #15810.,1,,1,2018-01-09T05:59:31Z,CONTRIBUTOR
15968,Imperfect implementation of tf.losses.mean_pairwise_squared_error,stat:awaiting response,"### System information
- **TensorFlow version**: 1.4.0, 1.4.1, and 1.5.0-rc0 (checked)
- **Have I written custom code**: N/A
- **OS Platform and Distribution**: N/A
- **TensorFlow installed from**: N/A
- **Bazel version**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
The implementation of `tf.losses.mean_pairwise_squared_error` looks imperfect.
For example, as explained in [the API reference of the function](https://www.tensorflow.org/api_docs/python/tf/losses/mean_pairwise_squared_error)
> For example, if `labels`=[a, b, c] and `predictions`=[x, y, z], there are three pairs of differences are summed to compute the loss: loss = [ ((a-b) - (x-y)).^2 + ((a-c) - (x-z)).^2 + ((b-c) - (y-z)).^2 ] / 3

let me put the following data as `labels` and `predictions`:
```
labels = tf.constant([[0., 0.5, 1.]])
predictions = tf.constant([[1., 1., 1.]])
tf.losses.mean_pairwise_squared_error(labels, predictions)
```
In this case, the result should be `[(0-0.5)^2+(0-1)^2+(0.5-1)^2]/3=0.5`, but tensorflow returns different value 0.3333333134651184.

### Suggestion to fix the source code
[tensorflow/python/ops/losses/losses_impl.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/losses/losses_impl.py)

If the loss function `mean_pairwise_squared_error` measures the differences between pairs of corresponding elements of `predictions` and `labels` as explained in [the API reference of the function](https://www.tensorflow.org/api_docs/python/tf/losses/mean_pairwise_squared_error), here is a simple patch:
> (lines 520-521 need to be changed as)
> `term1 = 2.0 * _safe_div(sum_squares_diff_per_batch, num_present_per_batch-1)`
and
> (lines 525-526 need to be changed as)
> `term2 = 2.0 * _safe_div(math_ops.square(sum_diff), math_ops.multiply(num_present_per_batch, num_present_per_batch-1))`
  ",0,,2,2018-01-09T05:51:16Z,NONE
15966,remove write_version=saver_pb2.SaverDef.V1,"awaiting review,cla: yes",This PR fixes the failed testAdditionalHooks and testRestoredModelPerformance test for PR #14341,1,,1,2018-01-09T04:36:20Z,CONTRIBUTOR
15965,unsupported operand type(s) for /: 'Tensor' and 'float,stat:awaiting response,"Tensorflow version is :  tensorflow-gpu (1.4.1)
Python version is:    Python 3.5.4 :: Anaconda custom (64-bit)

",0,,2,2018-01-09T03:47:01Z,NONE
15964,DownloadfileTask Failed,stat:awaiting response,"try projrct as https://www.tensorflow.org/mobile/android_build#android_sample_apps,but downloadtask failed,  then solve it ,may be you shoule change the 

> download-models.gradle  classpath 'de.undercouch:gradle-download-task:3.2.0' to 3.3.0",0,,2,2018-01-09T03:37:07Z,NONE
15962,Model diverges with NaN if the class label exceeds the expected number of classes,stat:awaiting response,"Tried in Tensorflow v1.4

Have I written custom code - Yes
OS Platform and Distribution - CentOS Linux release 7.4.1708
TensorFlow installed from - Not from source
TensorFlow version - v1.4.1
GPU model and memory - Tesla P100 16GB

If the class label exceeds the expected number of classes (dimensions of losses and given label won't match), TensorFlow simply errors out with `loss diverged with a NaN`. Ideally it should warn the user that the class label provided exceeded the expected number of classes.

It is easy to hit this error and spend lot of time in debugging. For Ex: If there are 101 number of classes, TensorFlow expects the labels to be in `[0,100]`, but if the user has labels `[1,101]`, any attempts to train would simply error out with `loss diverged with a NaN`.

Can we have some warning specifically for this case?
  ",0,,2,2018-01-09T02:35:00Z,NONE
15953,tf.Print() re/direction,,"## Feature Request

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: latest (1.5.0-rc0)
- **Python version**:  N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
https://github.com/tensorflow/tensorflow/blob/a77096897f1a8068ca8f57ffb6e3d9e28508cc27/tensorflow/core/platform/default/logging.cc#L89
It would be nice to be able to direct the string to a log file instead of `stderr` (following the **TODO** in the code)

  ",0,,3,2018-01-08T17:12:09Z,NONE
15948,Error converting to .tflite Using Toco,comp:lite,"### System information
- **Have I written custom code**: Yes. See network definition code [here](https://gist.github.com/OluwoleOyetoke/30f2cac788042c495f1ae34a6b742a1d). For complete project, see [here](https://github.com/OluwoleOyetoke/Computer_Vision_Using_TensorFlowLite)
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Yes
- **TensorFlow version (use command below)**: tensorflow (1.4.0)
- **Python version**:  Python 2.7.12
- **Bazel version (if compiling from source)**: Bazel 0.9.0
- **GCC/Compiler version (if compiling from source)**: gcc 5.4.1 20160904
- **CUDA/cuDNN version**: Null
- **GPU model and memory**: Null
- **Exact command to reproduce**: bazel-bin/tensorflow/contrib/lite/toco/toco --input_format=TENSORFLOW_GRAPHDEF --input_file=$1 --output_format=TFLITE --output_file=$2 --inference_type=$3 --#input_type=$4 --input_arrays=$5 --output_arrays=$6 --inference_input_type=$7 --input_shapes=1,227,227,3

### Problem Description, Source Code and Logs
When I try to use Toco to convert my Custom AlexNet Model from TensorFlow to TensorFlowLite, I repeatedly get a dimensions error as shown below

    F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:982] Check failed: input_dims.size() == 4 (2 vs. 4)

Here is how I call toco:

    bazel-bin/tensorflow/contrib/lite/toco/toco \
    --input_format=TENSORFLOW_GRAPHDEF \
    --input_file=/tmp/output_graph.pb \
    --output_format=TFLITE \
    --output_file=/tmp/my_model.lite \
    --inference_type=FLOAT \
    --inference_input_type=FLOAT \
    --input_arrays=input_layer \
    --output_arrays=classes_tensor\
    --input_shapes=1,227,227,3

Here is my terminal print out during the operation: 

    INFO: Analysed 0 targets (4 packages loaded).
    INFO: Found 0 targets...
    INFO: Elapsed time: 5.267s, Critical Path: 0.03s
    INFO: Build completed successfully, 1 total action
    2018-01-05 10:24:23.011483: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.
    2018-01-05 10:24:25.853112: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: IsVariableInitialized
    2018-01-05 10:24:25.853197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RefSwitch
    2018-01-05 10:24:25.853241: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomShuffleQueueV2
    2018-01-05 10:24:25.853268: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QueueDequeueUpToV2
    2018-01-05 10:24:26.207160: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 64 operators, 90 arrays (0 quantized)
    2018-01-05 10:24:27.327055: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 15 operators, 33 arrays (0 quantized)
    2018-01-05 10:24:27.327262: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 15 operators, 34 arrays (0 quantized)
    2018-01-05 10:24:27.327356: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:982] Check failed: input_dims.size() == 4 (2 vs. 4)
    /home/olu/Dev/scratch_train_sign/freeze_graph_tf.sh: line 28:  8881 Aborted 

I went into the propagate_fixed_sizes.cc file, and around line line 982 I found this comment below

    // The current ArgMax implementation only supports 4-dimensional inputs with
    // the last dimension as the axis to perform ArgMax for.

The only place in my training code where I used ArgMax is as below:

     predictions = { ""classes"": tf.argmax(input=logits, axis=1, name=""classes_tensor""), ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"") }

The failure messaged printed out seem not to be sufficient enough for me to understand what exactly the problem is. My trained TensorFow Model is fine and I have been able to run inferences on it, however, converting these saved model to TFLite doesn't work. Could this mean the current TFLite version does not support the conversion of some custom TF models yet?. Please I will be glad to know what exactly I may be doing wrong. 

Thank you 

  ",0,,5,2018-01-08T15:23:14Z,NONE
15945,DataLossError when loading saved model from r1.4 (Unable to read file ... failed to seek to header entry),stat:awaiting response,"I have a few saved models stored, these were built using _version 1.2.0-rc1_ 
When I try to load any of these saved models using _version 1.4.1_, I get the following error:
```
INFO:tensorflow:Restoring parameters from b'../models/export_output/1510150323/variables/variables'
2018-01-08 19:42:35.838751: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents
--------quite a few entries of the above log-------------
2018-01-08 19:42:36.134122: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents
2018-01-08 19:42:36.134144: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents
2018-01-08 19:42:36.134177: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents
Traceback (most recent call last):
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.DataLossError: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents
	 [[Node: save_1/RestoreV2_159 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_159/tensor_names, save_1/RestoreV2_159/shape_and_slices)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/media/Files/Research/FoodClassification/deployment/deployment.py"", line 308, in _main
    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], EXPORT_MODEL_DIR)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py"", line 226, in load
    saver.restore(sess, variables_path)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1666, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.DataLossError: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents
	 [[Node: save_1/RestoreV2_159 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_159/tensor_names, save_1/RestoreV2_159/shape_and_slices)]]

Caused by op 'save_1/RestoreV2_159', defined at:
  File ""<stdin>"", line 1, in <module>
  File ""/media/Files/Research/FoodClassification/deployment/deployment.py"", line 308, in _main
    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], EXPORT_MODEL_DIR)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py"", line 216, in load
    saver = tf_saver.import_meta_graph(meta_graph_def_to_load, **saver_kwargs)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1810, in import_meta_graph
    **kwargs)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py"", line 660, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 313, in import_graph_def
    op_def=op_def)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

DataLossError (see above for traceback): Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents
	 [[Node: save_1/RestoreV2_159 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_159/tensor_names, save_1/RestoreV2_159/shape_and_slices)]]
```
I was able to load the same models in _version 1.2.0-rc1_.
I tried building a new saved model using _version 1.4.1_ , that I was able to load in both versions without any problems. 

The versions I tested were both built, without cuda. 
OS: arch linux",0,,3,2018-01-08T14:31:46Z,NONE
15943,add_n: issue with IndexedSlices,,"inside function add_n, line 2117, shouldn't
""if not all(isinstance(x, ops.Tensor) for x in inputs):"" check also whether x is IndexedSlices instead of merely Tensor? i.e. replace the statement with:

if not ( (all(isinstance(x, ops.Tensor) for x in inputs)) | (all(isinstance(x, ops.IndexedSlices) for x in inputs)) ):

Thanks!


",0,,5,2018-01-08T11:10:05Z,NONE
15942,build_all_ios.sh:  x86_64 compilation failed.,,"when i compile build_all_ios.sh:   

****tensorflow 1.1 :**   is OK.... build success....**

when i load ""xxxx.pb"" model,  error:

Invalid argument: No OpKernel was registered to support Op 'Mul' with these attrs.  Registered devices: [CPU], Registered kernels:
  device='CPU'; T in [DT_FLOAT]
	 [[Node: UpSample2D_2/mul = Mul[T=DT_INT32](UpSample2D_2/mul/x, UpSample2D_2/Const)]]

How to solver ?

**tensorflow 1.4 :**   

make: *** [/Users/open/Downloads/tensorflow-1.4/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/random/distribution_sampler.o] Error 1
+ '[' 2 -ne 0 ']'
+ echo 'i386 compilation failed.'
i386 compilation failed.
+ exit 1
## 
**tensorflow 1.5 :**   

ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [/Users/open/Downloads/tensorflow-1.5/tensorflow/contrib/makefile/gen/bin/ios_X86_64/benchmark] Error 1
+ '[' 2 -ne 0 ']'
+ echo 'x86_64 compilation failed.'
x86_64 compilation failed.
+ exit 1


How to solver ?

**python:3.6.3  mac OS:  10.12.6**
",0,,7,2018-01-08T10:48:52Z,NONE
15940,[tensorflow lite] add setUseNNAPI to the Interpreter class,"awaiting review,cla: yes,comp:lite",add setUseNNAPI to the Interpreter class,1,,1,2018-01-08T09:30:18Z,NONE
15939,Slim VGG losses increase gradually with default training configuration,,"Hi, when I try to train imagenet with slim vgg network with default configuration,
The loss increases gradually from ~0.1 to over 10000. 
I am not even able to debug this issue because, all tensors losses are encapsulated inside slim.
Is there any way to debug this issue? ",0,,2,2018-01-08T09:30:13Z,NONE
15935,android CameraActivity: Exception!,stat:awaiting response,"tensorflow: CameraActivity: Exception!
java.lang.RuntimeException: Error initializing box priors from file:///android_asset/multibox_location_priors.txt
                                                                     at org.tensorflow.demo.TensorFlowMultiBoxDetector.create(TensorFlowMultiBoxDetector.java:121)
                                                                     at org.tensorflow.demo.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:146)
                                                                     at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:120)
                                                                     at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1189)
                                                                     at android.os.Handler.dispatchMessage(Handler.java:102)
                                                                     at android.os.Looper.loop(Looper.java:135)
                                                                     at android.app.ActivityThread.main(ActivityThread.java:5372)
                                                                     at java.lang.reflect.Method.invoke(Native Method)
                                                                     at java.lang.reflect.Method.invoke(Method.java:372)
                                                                     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1117)
                                                                     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:810)
",0,,2,2018-01-08T02:44:44Z,NONE
15933,Tensorflow 1.4.1 on Linux (CentOS-7.4) and Tensorflow 1.4.1 on MacOSX producing *very* different results in image creation simulation.,," 
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  
Linux CentOS-7.4 and MacOSx 10.10.5

- **TensorFlow installed from (source or binary)**: Both; Installed from binary, then, built and installed from source. Same behaviour on each install.

- **TensorFlow version (use command below)**:
Tensorflow 1.4.0 and Tensorflow 1.4.1

- **Python version**: 
2.7.14 (installed from binary, and then built and installed from source

- **Bazel version (if compiling from source)**:
Bazel 0.9.0.  Source built and installed successfully, Python .whl file built & installed successfully.

- **GCC/Compiler version (if compiling from source)**:
Xcode7.2.1 and the Gnu gFortran, 5.2.  (needed gFortran for SciPy install.  All installs OK.)

- **CUDA/cuDNN version**:
N/A - compiled and running CPU versions only for now.

- **GPU model and memory**:

- **Exact command to reproduce**:
(See supplied test program - based on the Laplace PDE (""Raindrops on Pond"") simulation example
from Tensorflow Tutorial)
 
Description of Problem:
 I've run into a curious situation.  I am getting very different behaviour in Tensorflow 1.4.1 on Linux and Tensorflow 1.4.1 on MacOSX, in straightforward image-generation simulation, based on the ""Raindrops on a Pond"" (Laplace PDE) example from the Tensorflow Tutorial.

I must stress that *both* Tensorflow installations seem to be 100% correct, and operate other tests correctly, producing the same numeric results for simple models.

I have also built Tensorflow 1.4.1 completely from source, and the Python 2.7.14 as well, on the MacOSX (MacBook) machine, in order to build the Python using ""--enable-unicode=ucs4"", since that was one difference I was able to find, between the two version.  But even with the Macbook now running exactly the same Python 2.7.14 as the Linux box, I am still getting wildly divergent evoluationary behaviour as when I iterate the simple simulation.   The numbers just zoom off in very different directions on each machine, and the generated images show this.  

On the MacOSX, the simulation evolves very quickly to a pure white canvas (all ""255""s), but on the Linux platform, the image grows more complex, with the generated numbers bifurcating between large negative and large positive - and hence when np.clip-ed, to range 0-255, show a complex moire-style pattern.

I have confirmed all related libraries and packages seem to be the same versions.  The difference seems to be in the operation of Tensorflow.  

This seems pretty serious, as each platform is Intel.  The Linux box (CentOS-7.4) is Core-i3, while the Macbook is Core-i5.  But both are 64-bit, and both Tensorflow installations seem to be correct.  I have tried both the binary version, and then built a complete local version of Tensorflow 1.4.1 for the Macbook from source.  Both seem to be Ok, and operate correctly.  The Linux version of Tensorflow 1.4.0 was installed from binary appears to be operating correctly, albeit differently, but just for this one program.

When the sample program runs, it will display fourteen 400x400 images, as well as the numeric values of the row-20 of the ""a"" array (400 numbers).   The program can be started from an Xterm shell window, with ""python LapTest.py"".  It does not need Jupyter or IPython.  With SciPy loaded, the images are rendered as .PNG files on both platforms, using Preview on the MacOSX MacBook, and ImageMagick on the CentOS-7.4 Linux box.   Program runs fine to completion, and all looks ok on both machines.

But the results - even with the simple initial pseudo-random conditions - evolve completely differently, and consistantly.  The Macbook version of Tensorflow 1.4.1 goes to a pure white screen, while the LInux Tensorflow 1.4.1 configuration evolves to a complex, chaotic, moire-pattern.  

Leaving aside the question of even which machine is ""correct"", the expected result is of course that both machines should at least show clear evidence of similar behaviour.

No change was made to the test program, ""LapTest.py"", from one machine to the other.   The different behaviour is not related to how the images are displayed, which is working fine on both platforms.   A copy of this simple program is provided.   I have removed or commented out the IPython/Jupyter dependent code, so this program can be run on plain vanilla Python 2.7.14, as long the appropriate packages (tensorflow, numpy, scipy, PIL (Pillow version), matplotlib, imageio ...) are available

Example of Source code to demostrate behaviour:     LapTest.py 
``` 
#-------------------------------------------------------------------------------
# Prgm: LapTest.py
#
# --- the Tensorflow LaPlace Image example (Uses PIL(Pillow ver.), and numpy)
# --- updated for TensorFlow 1.4.1 running on CentOS-7.4 & Python 2.7.14
#     compiled (configured, actually) with the ""--enable-unicode=ucs4"" option
#                                             (Python compile default is ucs2)
#                                             (which caused TensorFlow 1.4 to)
#                                             (fail to load. Building Python )
#                                             (with ucs4, => pip can install )
#                                             (TensorFlow 1.4.0 successfully.)
#
# --- This version of program tested on: MacOSX 10.10.5. (Yosemite)
# --- LapTest.py on Linux (CentOS-7.4), and LapTest.py on MacOSX, with Tensorflow-1.4.1 and
#     Python 2.7.14 (with ucs4 enabled on both Python versions), show *very*
#     different behaviour, and produce very different results.
#     Note: CentOS-7.4 is using Linux kernel: 4.14.9-1el7.elrepo.x86_64    
#
# --- Import various libraries for simulation
import tensorflow as tf
import numpy as np
import scipy.misc
import imageio
import os
import sys
import subprocess
import PIL
import time    


# --- Import for visualization and jpeg encoder  
import matplotlib
matplotlib.rcParams[""backend""]= 'TkAgg'
from matplotlib import pyplot as plt
# from PIL import Image, ImageDraw
from io import BytesIO
#  from IPython.display import clear_output, Image, display

#--- we need this to get a sane for-loop...
def jump_range(start, end, step):
    while start <= end:
        yield start
        start += step

# --- function for displaying state of the pond's surface as an image
def DisplayArray(a, fmt='jpeg', rng=[0,1]):
  global proc
  # proc.kill() 
  # """"""Display an array as a picture. """"""
  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37
  amod = np.clip(a, 0, 255)
  a = np.uint8(amod)
#  a = np.clip(a, 0, 255) 
#  a = np.uint8(a) 
#  np.clip(a, 0, 255, out=a )
#  a = a.astype('uint8')
  print "" ""
  print "" ----------- This is a: => row 20  ------------""
  print a[20]
  print "" ----------------------------------------------""
  f = BytesIO()
  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook
  PIL.Image.fromarray(a).save(f,fmt)
  # --- clear_output(wait = True)  --- only for IPython
  # display(Image(data=f.getvalue()))
  # --- write the image
  # --- write the simulation images to .jpg files
  scipy.misc.imsave(""tensor.jpg"", a)
  pic = PIL.Image.open(""tensor.jpg"")
  # --- new approach... use subprocess, wait for time(2) then kill it
  # proc = subprocess.Popen([""display"", ""./tensor.jpg""])
  # time.sleep(0.5)
  pic.show()
  # clear_output(wait=True)
  # --- this line below doesn't work outside of the Jupyter environment...
  # display(Image(data=f.getvalue()))
  #
  # pic.close()  <--- does not work to close image.  Just removes the pointer to image in memory
    
def DisplayArrayToFile(a, fmt='jpeg', rng=[0,1]):
  # """"""Display an array as a picture to a file... """"""
  a = (a - rng[0])/float(rng[1] - rng[0])*37
  a = np.uint8(np.clip(a, 0, 255))
  f = BytesIO()
  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook
  PIL.Image.fromarray(a).save(f,fmt)
  # clear_output(wait = True)
  # display(Image(data=f.getvalue()))
  # --- write the image
  # --- this is my stuff to write the simulation images to .jpg files
  #scipy.misc.imsave (""tensor_new.jpg"", a)
  imageio.imwrite(""tensor_new.jpg"", a)
  # --- image = PIL.Image.open(""tensor_new.jpg"")
  # --- image.show()
  # clear_output(wait=True)
  # display(Image(data=f.getvalue()))
  #
 
# --- make print stmt print the whole array... (not just part of it...)
np.set_printoptions(threshold=np.nan)
  
# --- make interactive session for testing - can use regular session also
sess = tf.InteractiveSession()
# sess = tf.Session()

# --- computational functions go here... once we get jpeg pic working
def make_kernel(a):
  """"""Transform a 2D array into a convolutional kernel """"""
  a = np.asarray(a)
  a = a.reshape(list(a.shape) + [1,1])
  return tf.constant(a, dtype=1)


def simple_conv(x, k):
  """""" A simplified 2D convolutional operation """"""
  x = tf.expand_dims(tf.expand_dims(x, 0), -1)
  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')
  return y[0, :, :, 0]


def laplace(x):
  """"""Compute the 2D laplacian of an array """"""
  laplace_k = make_kernel([[0.5, 1.0, 0.5],
                           [1.0, -6., 1.0],
                           [0.5, 1.0, 0.5]])  
  return simple_conv(x, laplace_k)



# --- Define the PDE - the pond surface is a perfect 400x400 square
N = 400

# --- list of display points...
dispval = jump_range(0, 12500, 1000)
# --- dispval has to be a list...
dispval = list(dispval)
print ""We will look at these values: "",dispval

# --- now, we create some ""raindrops""
# --- Initial Conditions -- some rain drops hit the pond
# --- set everything to zero
u_init = np.zeros([N, N], dtype=np.float32)
ut_init = np.zeros([N, N], dtype=np.float32)

# Some material accretion occurs (raindrops hit pond) at random points
for n in range(40):
  a,b = np.random.randint(0, N, 2)
  u_init[a,b] = np.random.uniform()

# --- Create and Display the jpeg image...
# proc = subprocess.Popen([""display"", ""./tensor.jpg""])
# DisplayArray(u_init, rng=[-0.1, 0.1])

# Parameters
# eps -- time resolution
# damping -- wave damping
eps = tf.placeholder(tf.float32, shape=())
damping = tf.placeholder(tf.float32, shape=())

# --- Create vaiables for simulation state
U  = tf.Variable(u_init)
Ut = tf.Variable(u_init)

# --- Discretized PDE update rules
U_  = U + eps * Ut
Ut_ = Ut + eps * (laplace(U) - damping * Ut)

# --- Operation to update the state
step = tf.group(
  U.assign(U_),
  Ut.assign(Ut_))

# --- Run the simulation forward with a simple FOR loop.
# --- Initialize state to initial conditions
tf.global_variables_initializer().run(session=sess)

# --- Run 12701 steps of PDE
for i in range(12701):
  # Step simulation  (damping was 0.04, I made it negative .14)
   with sess.as_default(): step.run( {eps: 0.03, damping: -0.14})
# --- to see everything...
#   with sess.as_default(): print ""U.eval()   .... "", U.eval()[20]  # --- ,""   "", Ut.eval()
# ------

   if (i in dispval) :
       with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])
       print ""                                ------ For iteration:  "",i
       sys.stdout.flush()
       print ""U.eval()   ....... ""
       with sess.as_default(): print   U.eval()[20]      # --- ,""   "", Ut.eval()
       print ""                                --- End of iteration:  "",i
       sys.stdout.flush()
       continue
#
# --- to show each iteration...
#  with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])
print ""Done at: "",i

# --- Ok, we are done...
with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])

with sess.as_default(): DisplayArrayToFile(U.eval(), rng=[-0.1, 0.1])
print ""Last Image Written to file: tensor_new.jpg. Done.""   
#--------------- done ------------------
```

If someone could try this program on a supported version of Linux (ie. the Ubuntu version that TensorFlow officially supports), that would be helpful.  I am running a recent version of the Linux kernel on the CentOS-7.4 box  (uname -a reports: kernel version 4.14.9-1.el7.elrepo.x86_64 ).  Really like to nail down what is happening.  I have attached images of results I am seeing on the two machines, first the Linux box, second is the Macbook.   

![laptest_linux_img_20180107_150905_sml](https://user-images.githubusercontent.com/16905336/34654259-45838fc6-f3c7-11e7-93b1-96751153c3a4.jpg)
![laptest_mac_img_20180107_151332_sml](https://user-images.githubusercontent.com/16905336/34654263-4c961b44-f3c7-11e7-8998-f3122f6d9e7c.jpg)
",0,,18,2018-01-07T21:27:51Z,NONE
15932,General change in batch size Performance Question,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
I have opened a question on StackOverflow. I suspect only a developer can answer the question. The link to the question is here:
https://stackoverflow.com/questions/48099754/does-a-change-in-batch-size-impact-performance

The question is around Reinforcement Learning and if there will be a speed improvement if the batch size of the graph is not changed. RL usually has a training batch and a ""next_action"" type of single sample (batch size =1). The network is intermittently hit with either the training batch size or batch size of 1. Does TF take a performance hit every time the graph sees a different batch size through the feed_dict()? If this is the case, should 2 graphs be created so the batch size doesn't change from call to call?

If you post the answer here I will copy it to StackOverflow.

Thanks

### Source code / logs
N/A

  ",0,,3,2018-01-07T21:24:47Z,CONTRIBUTOR
15931,Making SQLite better,"awaiting review,cla: yes,stat:awaiting response",,1,,1,2018-01-07T19:35:06Z,CONTRIBUTOR
15925,cmake compile error C2678: binary '*': no operator found sparse_column_iterable.cc,,"`cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/ProgramData/chocolatey/bin/swig.exe -DPYTHON_EXECUTABLE=C:/Python36/python.exe -DPYTHON_LIBRARIES=C:/Python36/libs/python36.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 `

```
c:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.12.25827\include\algorithm(2417): error C2678: binary '*': no operator found which takes a left-hand operand of type 'const tensorflow::boosted_trees::utils::`anonymous-namespace'::IndicesRowIterator' (or there is no acceptable conversion) (compiling source file D:\_working_dir\_ml\tensorflow\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc) [D:\_working_dir\_ml\tensorflow\tensorflow\contrib\cmake\build\tf_core_kernels.vcxproj]
  c:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.12.25827\include\algorithm(2417): error C2100: illegal indirection (compiling source file D:\_working_dir\_ml\tensorflow\tensorflow\contrib\boosted_trees\lib\utils\sparse_column_iterable.cc) [D:\_working_dir\_ml\tensorflow\tensorflow\con
trib\cmake\build\tf_core_kernels.vcxproj]
```
Windows 8.1 x64
cmake 3.10.1
swig 3.0.9
Visual Studio 2017 Community

the same problem asked
https://stackoverflow.com/questions/48058113/compiling-tensorflow-1-4-on-windows-10",0,,7,2018-01-07T12:22:32Z,NONE
15921,iOS: Op type not registered 'DecodeWav',type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I am trying to run graph model from Simple Audio Recognition example on iOS.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13
- **TensorFlow installed from (source or binary)**: Branch r1.4
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: Build label: 0.9.0-homebrew
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

I am trying to run graph model from Simple Audio Recognition example on iOS. When I am calling `session->Create(tensorflow_graph)` with the graph I get the error: ""Could not create TensorFlow Graph: Not found: Op type not registered 'DecodeWav'..."".

My initial thought is that because I am using TensorFlow-experimental (1.1.1) from pods, it's possible that this Op type is not registered. So I tried building it myself, which builds without errors with command: `tensorflow/contrib/makefile/build_all_ios.sh`. I then remove TensorFlow-experimental (1.1.1) from the project and link my own build of tensorflow, but I get the same error. 

I also found the following PR - [[iOS] Add optional Selective Registration of Ops #14421](https://github.com/tensorflow/tensorflow/pull/14421)

I tried building from master with the above PR merged like so:
 
For iPhone 5:
`tensorflow/contrib/makefile/build_all_ios.sh -a armv7 -g /Users/anton/Development/tensorflow/tensorflow/examples/ios/simple/data/tensorflow_inception_graph_speech.pb`

For iPhone SE:
`tensorflow/contrib/makefile/build_all_ios.sh -a arm64 -g /Users/anton/Development/tensorflow/tensorflow/examples/ios/simple/data/tensorflow_inception_graph_speech.pb`

If I then go and check the file `/tensorflow/tensorflow/core/framework/ops_to_register.h` (auto-generated after above command) I can see that DecodeWav is listed among kernels and operations:

```
// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER

    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
""BinaryOp< CPUDevice, functor::add<float>>"",
""AudioSpectrogramOp"",
""ConstantOp"",
""Conv2DOp<CPUDevice, float>"",
""DecodeWavOp"",
""IdentityOp"",
""MatMulOp<CPUDevice, float, false >"",
""MaxPoolingOp<CPUDevice, float>"",
""MfccOp"",
""NoOp"",
""PlaceholderOp"",
""ReluOp<CPUDevice, float>"",
""ReshapeOp"",
""SoftmaxOp<CPUDevice, float>"",
""RecvOp"",
""SendOp"",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || isequal(op, ""Add"")
     || isequal(op, ""AudioSpectrogram"")
     || isequal(op, ""Const"")
     || isequal(op, ""Conv2D"")
     || isequal(op, ""DecodeWav"")
     || isequal(op, ""Identity"")
     || isequal(op, ""MatMul"")
     || isequal(op, ""MaxPool"")
     || isequal(op, ""Mfcc"")
     || isequal(op, ""NoOp"")
     || isequal(op, ""Placeholder"")
     || isequal(op, ""Relu"")
     || isequal(op, ""Reshape"")
     || isequal(op, ""Softmax"")
     || isequal(op, ""_Recv"")
     || isequal(op, ""_Send"")
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)

#define SHOULD_REGISTER_OP_GRADIENT false
#endif

```

But when I try to run the graph model I still get same error message. I have removed the pod version, and I am 100% sure I am running my own build version of tensorflow on iOS.

I can't tell if this is a bug or I am doing something wrong during the build process.

Has anyone tried running any graph that uses DecodeWav on iOS?

Thanks.

### Source code / logs

Error: Could not create TensorFlow Graph: Not found: Op type not registered 'DecodeWav' in binary running on Antons-iPhone. Make sure the Op and Kernel are registered in the binary running in this process.





",1,,8,2018-01-07T02:55:51Z,NONE
15920,cmake CUDA include-path whitespaces not supported,stat:awaiting response,"I'm not sure if this is intentional, but I just had some trouble with compiling tf_core_gpu_kernels due to a invalid include-dir path as command line argument given to nvcc (caused by a whitespace in the path).

In windows I was able to solve this by adding double quotes at line 277 in CMakeLists.txt:
`set(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};--include-path \""${PROJECT_BINARY_DIR}/$\{build_configuration\}\"";--expt-relaxed-constexpr)`

Possible errors when not using double quotes:
nvcc fatal : A single input file is required for a non-link phase when an outputfile is specified

Also note that there will be problems because of CUDA not supporting some versions of msvc.
The current version for example is not yet supported.
CUDA_HOST_COMPILER path is automatically set to $(VCInstallDir)/bin, what will cause problems on some systems. For VS2015 this works fine but not for VS2017 if you are using the recent compiler.

There are also several errors when using the intel compiler, as for example the typename TType<...> declarations, which are not really required. Either remove the typename keyword or use 'auto'.
Other than that the master branch is compilable with ICC 18.
",0,,2,2018-01-06T23:12:19Z,NONE
15919,A bug of tf.layers.batch_normalization when training is not a constant,stat:awaiting response,"I encountered a bug of tf.layers.batch_normalization when the training argument is not a constant. Usually, when the training argument evaluates to False, the moving mean and variance should not be updated. However, in certain cases, the moving mean and variance may become NaN.

The bug occurs in the following code in python/layers/normalization.py:

```
    training_value = utils.constant_value(training)
    if training_value is None:
      one_minus_decay = utils.smart_cond(training,
                                         lambda: self._one_minus_decay,
                                         lambda: 0.)
    else:
      one_minus_decay = ops.convert_to_tensor(self._one_minus_decay)
    if training_value or training_value is None:
      mean_update = self._assign_moving_average(self.moving_mean, mean,
                                                one_minus_decay)
      variance_update = self._assign_moving_average(self.moving_variance,
                                                    variance, one_minus_decay)
```

When training is not a constant but evaluates to False, one_minus_decay is set to 0, and it is expected that _assign_moving_average does not actually change the moving average. However, mean and variance are outputs of FusedBatchNormOp, which are not actually computed when training is False. So, the content of mean and variance are random, and it can contain NaN values in certain cases. The NaN values in mean and variance then lead to NaN values in the moving mean and moving variance, even if the one_minus_decay is 0 (NaN times 0 is still NaN). Once moving mean and variance contain NaN values, the network produces NaN outputs forever.

I think a way to fix this issue is to modify _assign_moving_average. Just add following one line: 
`update_delta = tf.cond(tf.equal(one_minus_decay, 0), 0, update_delta)`
 Another way to fix is to let mean and variance output be zero if training is False. This way also helps preventing triggering the inf_or_nan_filter of tfdbg.
  ",0,,2,2018-01-06T23:03:16Z,NONE
15916,Object Tracking Support ,stat:awaiting response,"I have a bug after updating to the latest android studio and building the detection app with it.
For previous versions of android studio I didn't have this issue before

when I ran the tf_detect app it showed an error for few seconds that says ""Object Tracking Support Not Found...""
and when I add the line ""dependencies {
    compile 'org.tensorflow:tensorflow-android:+'
}""
to the gradle build file it shows another error
Error:(42, 0) Could not find method compile() for arguments [org.tensorflow:tensorflow-android:+] on object of type org.gradle.api.internal.artifacts.dsl.dependencies.DefaultDependencyHandler.
<a href=""openFile:C:\Users\mohda\Desktop\tensorflow-master_new\tensorflow-master\tensorflow\examples\android\build.gradle"">Open File</a>

any suggestions or fixes to this issue please?
What am I doing:
I have created a custom trained detector and it was working fine till android studio was updated. I have even tried with a fresh copy of the original demo and I have the same error. Yet when I downloaded the nightly build apk it didn't show any error. so it must be the android studio / tensorflow compatibility / dependency issue here.
Thanks 
  ",0,,2,2018-01-06T17:03:49Z,NONE
15915,Failed to synchronise stop event.,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**:  5.4.0 
- **CUDA/cuDNN version**: 9.1/7.0.5
- **GPU model and memory**: GT 750M 2GB
- **Exact command to reproduce**: Run the custom program.

### Describe the problem
Trying to train a simple 5 layer model with 3.7million parameters that are trainable which would occupy around 1.5GB VRAM, the training fails instantly at the very first epoch. People who had similar error claimed that it was fixed in cuDNN 7.0.5 from this thread [#14363](https://github.com/tensorflow/tensorflow/issues/14363) . But this update isn't fixing the crash. I've posted the error log below:

### Source code / logs
```
Total params: 3,714,788
Trainable params: 3,714,788
Non-trainable params: 0
_________________________________________________________________
2018-01-06 21:58:27.567991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-01-06 21:58:27.568491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GT 750M major: 3 minor: 0 memoryClockRate(GHz): 0.967
pciBusID: 0000:01:00.0
totalMemory: 1.95GiB freeMemory: 1.60GiB
2018-01-06 21:58:27.568526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0, compute capability: 3.0)
Train on 646 samples, validate on 162 samples
Epoch 1/20
2018-01-06 21:58:30.447458: E tensorflow/stream_executor/cuda/cuda_driver.cc:1080] failed to synchronize the stop event: CUDA_ERROR_ILLEGAL_INSTRUCTION
2018-01-06 21:58:30.447529: E tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x5650223aede0: CUDA_ERROR_ILLEGAL_INSTRUCTION
2018-01-06 21:58:30.447572: E tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x5650223aede0: CUDA_ERROR_ILLEGAL_INSTRUCTION
2018-01-06 21:58:30.447629: F tensorflow/stream_executor/cuda/cuda_dnn.cc:2964] failed to set stream for cudnn handle: CUDNN_STATUS_MAPPING_ERROR
Aborted (core dumped)

```

  
  ",0,,6,2018-01-06T16:51:27Z,NONE
15913,How to build contrib module that depends on tensorflow/core/kernels:linalg?,type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. Making a contrib module.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.9
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 8.1.0 (clang-802.0.42)
- **CUDA/cuDNN version**: Building without GPU support
- **GPU model and memory**: Building without GPU support
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
I am writing a contrib module that depends on tensorflow/core/kernels:linalg (specifically the `//tensorflow/core/kernels:linalg_ops_common` target). However, adding this dependency

	tf_custom_op_library(
	    name = ""python/ops/_medical_image_ops.so"",
	    srcs = [
	        ""kernels/index_ops.cc"",
	        ""ops/index_ops.cc"",
	    ],
	    deps = [
	        ""//tensorflow/core/kernels:linalg""
	    ],
	)

yields

	ERROR: /Users/kasper/Development/tensorflow3/tensorflow/contrib/medical_image/BUILD:13:1: in check_deps rule //tensorflow/contrib/medical_image:python/ops/_medical_image_ops.so_check_deps:
	Traceback (most recent call last):
		File ""/Users/kasper/Development/tensorflow3/tensorflow/contrib/medical_image/BUILD"", line 13
			check_deps(name = 'python/ops/_medical_image_ops.so_check_deps')
		File ""/Users/kasper/Development/tensorflow3/tensorflow/tensorflow.bzl"", line 1196, in _check_deps_impl
			fail(((_dep_label(input_dep) + "" cann...)))
	tensorflow/core/kernels:linalg cannot depend on tensorflow/core:framework

The `//tensorflow/core/kernels:linalg_ops_common` target is private so I cannot depend on it directly. In an earlier release I believe there was a `//tensorflow/core/kernels:linalg_ops_common_headers_lib` target but this is not there anymore.

How can I add one of the linalg targets as a dep without introducing this circular dependency?

(I have scoured over many of the `cannot depend on tensorflow/core:framework` issues from the past but have not found a solution)

### Source code / logs
This is my full BUILD file:

	# Description:
	#   Contains ops for working natively with medical images in TensorFlow.

	licenses([""notice""])  # Apache 2.0

	exports_files([""LICENSE""])

	package(default_visibility = [""//visibility:public""])

	load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"", ""tf_custom_op_py_library"",
	     ""tf_kernel_library"", ""tf_gen_op_libs"", ""tf_gen_op_wrapper_py"")

	tf_custom_op_library(
	    name = ""python/ops/_medical_image_ops.so"",
	    srcs = [
	        ""kernels/index_ops.cc"",
	        ""ops/index_ops.cc"",
	    ],
	    deps = [
	        ""//tensorflow/core:lib""
	    ],
	)

	tf_gen_op_libs(
	    op_lib_names = [""index_ops""],
	)

	tf_gen_op_wrapper_py(
	    name = ""medical_image_ops"",
	    deps = ["":index_ops_op_lib""],
	)

	tf_custom_op_py_library(
	    name = ""medical_image_py"",
	    srcs = [
	        ""__init__.py"",
	        ""python/medical_image/medical_image.py"",
	        ""python/medical_image/transforms.py"",
	        ""python/ops/index_ops.py"",
	    ],
	    dso = ["":python/ops/_medical_image_ops.so""],
	    srcs_version = ""PY2AND3"",
	    deps = [
	        "":medical_image_ops"",
	    ],
	)

	filegroup(
	    name = ""all_files"",
	    srcs = glob(
	        [""**/*""],
	        exclude = [
	            ""**/METADATA"",
	            ""**/OWNERS"",
	        ],
	    ),
	    visibility = [""//tensorflow:__subpackages__""],
	)

  
  ",1,,2,2018-01-06T16:27:44Z,CONTRIBUTOR
15911,"Crash when using CUDA API while using Tensorflow. ""current context was not created by the StreamExecutor cuda_driver API""",,"### Expected behavior

I expect to work with the CUDA library by using libcudart directly in my Python script before and while Tensorflow is being used - without errors.

### Actual behavior

The script crashes with following error as soon as I've used libcudart through ctypes before tensorflow is imported.

```
2018-01-06 14:45:50.641211: F tensorflow/stream_executor/cuda/cuda_driver.cc:232] current context was not created by the StreamExecutor cuda_driver API: 0x7fe122002400; a CUDA runtime call was likely performed without using a StreamExecutor context
```

### Environment

| Name  | Value |
| ------------- | ------------- |
| OS  | Mac OS 10.12.4 |
| tensorflow-gpu  | pip 1.1.0, v1.1.0-rc0-61-g1ec6ed5  |
| Device  | GPU Titan X pascal  |
| Python  | 2.7.12  |
| Python  | 3.5.2 |
| CUDA  | 8.0  |
| cuDNN  | 5.1.5 |


### Reproduce

```python
from __future__ import print_function

import ctypes
import platform

system = platform.system()

if system == ""Linux"":
    libcudart = ctypes.cdll.LoadLibrary(""libcudart.so"")
elif system == ""Darwin"":
    libcudart = ctypes.cdll.LoadLibrary(""libcudart.dylib"")
elif system == ""Windows"":
    libcudart = ctypes.windll.LoadLibrary(""libcudart.dll"")
else:
    raise Exception(""Cannot identify system."")

version = ctypes.c_int()
rc = libcudart.cudaRuntimeGetVersion(ctypes.byref(version))
if rc != 0:
    raise ValueError(""Could not get version"")
if version.value < 6050:
    raise Exception(""CUDA version must be >= 6.5"")

libcudart.cudaSetDevice(0)

free = ctypes.c_size_t()
total = ctypes.c_size_t()
rc = libcudart.cudaMemGetInfo(ctypes.byref(free), ctypes.byref(total))

print(""Memory "" + str(free.value) +  "" of "" + str(total.value))

del libcudart

import tensorflow as tf

hello = tf.constant('Hello, TensorFlow!')

# Start tf session
sess = tf.Session()

# Run the op
print(sess.run(hello))
````

Execute 

```
$ python3 tf-cuda-crash.py
```

Output will be like

```
$ python3 tf-cuda-crash.py
Memory 9916960768 of 12884574208
2018-01-06 14:45:50.639837: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-06 14:45:50.639863: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-06 14:45:50.639870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-06 14:45:50.641211: F tensorflow/stream_executor/cuda/cuda_driver.cc:232] current context was not created by the StreamExecutor cuda_driver API: 0x7fe122002400; a CUDA runtime call was likely performed without using a StreamExecutor context
[1]    4240 abort      python3 tf-cuda-crash.py
```

Happens with both Python2 and 3.
  ",0,,3,2018-01-06T14:23:59Z,NONE
15910,Feature Request: Sparse Cholesky decomposition,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
TensorFlow has a Cholesky decomposition [kernel](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cholesky_op.cc) based on wrappers around the [Eigen](http://eigen.tuxfamily.org/index.php?title=Main_Page) and [cuSOLVER](http://docs.nvidia.com/cuda/cusolver/index.html#cusolver-intro) (for GPUs) libraries.

From experience, a sparse solver can provide huge speedups in the right circumstances. The cuSOLVER library has the feature in their sparse LAPACK library, cuSolverSP, and the Eigen library in the SparseCholesky module.

Alternatively, there is the [CHOLMOD](https://developer.nvidia.com/cholmod) library which is supported by Eigen in the CholmodSupport module. This CHOLMOD library supports both CPU and GPU sparse Cholesky factorisations.

Would a Cholesky decomposition for sparse matrices be a feature of interest? 
  ",0,,1,2018-01-06T11:02:11Z,NONE
15900,Feature Request: MonitoredTrainingSession should accept checkpoint steps,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a
- **TensorFlow installed from (source or binary)**: n/a
- **TensorFlow version (use command below)**: n/a
- **Python version**: n/a
- **Bazel version (if compiling from source)**:n/a
- **GCC/Compiler version (if compiling from source)**:n/a
- **CUDA/cuDNN version**:n/a
- **GPU model and memory**:n/a
- **Exact command to reproduce**:n/a

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
As of 1.4, MonitoredTrainingSession conveniently offers constructor parameters for checkpoint_secs, summary_secs, and summary_steps. It does not offer a parameter for checkpoint_steps, so if I want to checkpoint by steps and not seconds, I have to register a custom CheckpointSaverHook. It would be nice if MonitoredTrainingSession encapsulated that, as it does for the similar summary_secs, summary_steps, and checkpoint_secs.

### Source code / logs
https://github.com/tensorflow/tensorflow/blob/cddf8d82dec9fff526f5c064add725b7f35f95fa/tensorflow/python/training/monitored_session.py#L272
",0,,2,2018-01-06T01:03:55Z,NONE
15896,Add EvalResultsExporter for writing the results of evaluation to a file,"awaiting review,cla: yes","Previously you could capture the return value of `estimator.train_and_evaluate`,
which was a dictionary of the final evaluation results (like accuracy, AUC).

Since `estimator.train_and_evaluate` no longer returns a value, it looks like
there's no way to get the `eval_results` dictionary directly. This is the
solution I wrote for getting and storing that dictionary. Since the solution
is generalizable, I thought it'd be useful to include it for others to use.",1,,4,2018-01-05T23:28:40Z,CONTRIBUTOR
15894,Allow `~/` in path for transform_graph,"awaiting review,cla: yes,stat:awaiting tensorflower","This fix tries to address the issue raised in #13211 where it was not possible to specify `~` (e.g., `~/`, `~user/`, etc) for the path used in transform_graph. This fix adds the support of `~` transform_graph on Linux.

This fix fixes #13211.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,1,2018-01-05T22:52:33Z,MEMBER
15892,Change GitHub repo URL from http://www.tensorflow.org to https://www.tensorflow.org,,Reasoning: HTTPS all the things,0,,3,2018-01-05T22:24:22Z,CONTRIBUTOR
15891,Dependencies of tensors created within a tf.while_loop() might not be executed,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. See test case below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 'Sierra' Version 10.12.6 (16G1114)
- **TensorFlow installed from (source or binary)**: Both. I have compiled TensorFlow at 136697ecdc64b5171522fb7f89cfe51a02f0f1c1 with my small change in PR #15823. I have also tried using the pip package.
- **TensorFlow version (use command below)**: ('v1.4.0-19-ga52c8d9b01', '1.4.1') (pip package)
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**: 0.9.0-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 8.1.0 (clang-802.0.42)
- **CUDA/cuDNN version**: CUDA 9.0.176_mac, cuDNN 9.0-osx-x64-v7
- **GPU model and memory**: NVIDIA GeForce GT 750M with 2048 MB device memory (CUDA Compute Capability 3.0)
- **Exact command to reproduce**:

`python repro.py`

.. where `repro.py` contains the test case to reproduce, listed below.

### Describe the problem
Here is my test case:

```python
# Part I
from __future__ import division, print_function
import numpy as np
import tensorflow as tf
from tensorflow.python.ops import resource_variable_ops as rr

rs = np.random.RandomState(seed = 2)
A = rs.normal(size = (10, 10,))
print('singular values of A: %s' % (np.linalg.svd(A, compute_uv = False),))
B = rs.normal(size = (10, 10,))
print('singular values of B: %s' % (np.linalg.svd(B, compute_uv = False),))



# Part II
A_var = tf.Variable(B)
init_A_var_op = tf.assign(A_var, A)
A_dep = tf.constant(10, tf.int32)

with tf.control_dependencies([init_A_var_op]):
    A_dep = A_dep + 1

with tf.control_dependencies([A_dep]):
    var_s = tf.svd(A_var, compute_uv = False)
with tf.Session() as session:
    session.run(tf.global_variables_initializer())
    computed_s, computed_A_dep = session.run([var_s, A_dep])
print('computed_s = %s, computed_A_dep = %d' % (computed_s, computed_A_dep,))



# Part III
A_var = tf.Variable(B)
init_A_var_op = tf.assign(A_var, A)
A_dep = tf.constant(9, tf.int32)

def loop_condition(j, A_dep):
    return j < 1
def loop_body(j, A_dep):
    with tf.control_dependencies([init_A_var_op]):
        A_dep = A_dep + 1
    return j + 1, A_dep

_, A_dep = tf.while_loop(loop_condition,
                         loop_body,
                         loop_vars = [tf.constant(0, tf.int32), A_dep],
                         parallel_iterations = 1,
                         back_prop = False)

with tf.control_dependencies([A_dep]):
    var_s = tf.svd(A_var, compute_uv = False)
with tf.Session() as session:
    session.run(tf.global_variables_initializer())
    computed_s, computed_A_dep = session.run([var_s, A_dep])
print('computed_s = %s, computed_A_dep = %d' % (computed_s, computed_A_dep,))



# Part IV
A_var = rr.ResourceVariable(B)
init_A_var_op = A_var.assign(A)
A_dep = tf.constant(8, tf.int32)

def loop_condition(j, A_dep):
    return j < 1
def loop_body(j, A_dep):
    with tf.control_dependencies([init_A_var_op]):
        A_dep = A_dep + 1
    return j + 1, A_dep

_, A_dep = tf.while_loop(loop_condition,
                         loop_body,
                         loop_vars = [tf.constant(0, tf.int32), A_dep],
                         parallel_iterations = 1,
                         back_prop = False)

with tf.control_dependencies([A_dep]):
    var_s = tf.svd(A_var.read_value(), compute_uv = False)
with tf.Session() as session:
    session.run(tf.global_variables_initializer())
    computed_s, computed_A_dep = session.run([var_s, A_dep])
print('computed_s = %s, computed_A_dep = %d' % (computed_s, computed_A_dep,))
```

Part I is basic setup. I create two random 10&times;10 matrices and compute their singular values:
<pre>
singular values of A: [ 5.65906715  4.9420261   4.40626739  3.73506125  2.70703249  2.57429488
  1.73387162  1.16000494  0.58836563  0.39101954]
singular values of B: [ 7.0283055   4.65840063  4.48502098  3.25319445  2.94667168  2.74267484
  1.86004291  1.6626967   0.63884034  0.27131664]
</pre>

Part II shows usage of control_dependencies() to guarantee that `A` has been assigned to `A_var` before the singular values of `A_var` are computed. The output from this part is:
<pre>
computed_s = [ 5.65906715  4.9420261   4.40626739  3.73506125  2.70703249  2.57429488
  1.73387162  1.16000494  0.58836563  0.39101954], computed_A_dep = 11
</pre>

(This is the expected result for Part II.)

In Part III, I have introduced use of a tf.while_loop(). Now, tf.svd() is returning the singular values of `B`:
<pre>
computed_s = [ 7.0283055   4.65840063  4.48502098  3.25319445  2.94667168  2.74267484
  1.86004291  1.6626967   0.63884034  0.27131664], computed_A_dep = 10
</pre>

(This is **not** the expected result for Part III. I expect that the singular values of `A` would be printed.)

In Part IV, based on reading https://github.com/tensorflow/tensorflow/issues/4663#issuecomment-336609536 , I switched to using `ResourceVariable`. However, the output is still the same (the singular values of `B`):
<pre>
computed_s = [ 7.0283055   4.65840063  4.48502098  3.25319445  2.94667168  2.74267484
  1.86004291  1.6626967   0.63884034  0.27131664], computed_A_dep = 9
</pre>

(This is **not** the expected result for Part IV. I expect that the singular values of `A` would be printed.)

It appears the issue is that tf.control_dependencies() on tensors created by tf.while_loop() might not execute the tensors' own dependencies.

This used to work okay (around TensorFlow 1.1, if I recall correctly).

While searching for a previous report of this issue, I found #6087 which appears related, in that the sample code there has a tf.while_loop() that creates tensors with dependencies. When I run the sample code, I consistently get result = 10. This is an unexpected result, in my opinion. What is happening is that `update_x` runs exactly once, so for each of the 5 loop iterations, `x` has the value 2.

I tried rewriting the sample code to use a ResourceVariable, but the output is the same:

```python
from __future__ import division, print_function
import tensorflow as tf
from tensorflow.python.ops import resource_variable_ops as rr

with tf.variable_scope('state'):
    x = rr.ResourceVariable(tf.constant(1, dtype=tf.float32))
    update_x = x.assign(x.read_value() + 1)

def iter_fun(i, y):
    # comment the line below, the program will run without any error
    # but I need control_dependencies, or at least some way to replace it...
    with tf.control_dependencies([update_x]):
        y = y + tf.Print(x.read_value(), ['i = ', i, 'y = ', y, 'x = ', x.read_value()])
    return (i+1, y,)

with tf.variable_scope('iteration'):
    num_iterations = 5
    initial_i = tf.constant(0, dtype=tf.int32)
    initial_y = tf.constant(0, dtype=tf.float32)
    _, result = tf.while_loop(
        cond=lambda i, *_: i < num_iterations,
        body=iter_fun,
        loop_vars=(initial_i, initial_y))

init_op = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init_op)
    print(sess.run(result))
```
  ",0,,6,2018-01-05T21:51:29Z,CONTRIBUTOR
15890,Scope subprocess and tempfile imports in tensorflow lite to fix #15410,"awaiting review,cla: yes,comp:lite","Fix for https://github.com/tensorflow/tensorflow/issues/15410

As @aselle mentions in issue #15410: ""this has to do with the interface sealing in tensorflow (where we try to prevent exposing symbols unrelated to the interfaces)"", one potential fix is to scope the imports to the required `toco_convert_protos` function.

Validated this issue can be reproduced and fixed by this change.",1,,1,2018-01-05T20:18:30Z,CONTRIBUTOR
15886,"Successful Local Build of Tensorflow r1.5 GPU for Python 3.6, CUDA Toolkit 9.0, and CUDNN 7.0 on Windows 7 X64 SP1 using CMake in VS 2015 Update 3",,"I have spent a week trying to compile Tensorflow from source using Bazel on Windows with no success. In 2 days, I was able to compile it using CMake following the command output from a successful build I saw on Jenkins on 02-Jan-2018.

I wanted to provide details to spare others the pain of development in the future. The whole build took 6 hours to compile on my system.

I have an older system, which is why I was doing this. You will need to path variables in the attached scripts to work with the path variables for your system. For the most part, however, the scripts replicate what is mentioned on github here:

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 x64 SP1
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.5.0-rc0
- **Python version**: 3.6.4
- **CMake version (if compiling from source)**: CMake 3.10.1
- **GCC/Compiler version (if compiling from source)**: cl.exe (Visual Studio 2015 Update 3)
- **CUDA/cuDNN version**: 9.0.176 / 7.0.4
- **GPU model and memory**: NVIDIA Quadro K4000 P8, Driver 385.54, 3072 MiB
- **SWIG Version**: swigwin-3.0.12
- **Git Version**: Git for Windows 2.15.1 64-bit
- **MSBuild Version**: 14.0.25420.1
- **CPU**: Intel Xeon E5-2620 v2

- **Exact command to reproduce**:

After installing the above, I wrote a batch script to set and clean up system environment variables (please see attached script). Due to the 1024 character limit for PATH on windows, I manually edited the PATH in the registry editor to overcome this limitation.

I then wrote another script that set local variables, cloned tensorflow source and checked out version 1.5, then prepared the source with cmake and compiled with msbuild.

The final output was a python wheel, which I pip installed. I successfully ran the standard hello world script without error, i.e.

```
import tensorflow as tf
hello = tf.constant('Hello')
sess = tf.Session()
sess.run(hello)
```

as well as a small AlexNet network without issues.

I hope this helps future users and further emphasizes that it is possible to build Tensorflow 1.5 for GPU on Windows 7. I have not compiled this with AVX support, but that could be a next improvement (I'm not sure if this is possible. I only know MKL support is limited to Linux at the moment. However, Windows binaries for MKL and MPI can be downloaded from the Intel website).


[Scripts.zip](https://github.com/tensorflow/tensorflow/files/1607554/Scripts.zip)



",0,,5,2018-01-05T18:50:07Z,NONE
15883,Different convolutional padding per channel,stat:awaiting response,"Hello,

would it be possible to specify different convolutional padding for each channel? My use case is using 3D convolutions on input, where the first dimension is temporal and the next 2 dimensions are 2D images. I'd like to have ""SAME"" padding on temporal dimension and ""VALID"" padding on convolutional dimensions.

The model in question is for estimating speed of a vehicle from on-board camera where a sequence of images of fixed length (e.g. 10 frames) is sent to a 3D convolutional network and it makes sense to avoid unnecessary clipping of temporal dimension where it's perfectly fine for convolutional part.

Would this be possible to add to TensorFlow?

Thank you!

Have I written custom code: No
OS Platform and Distribution: Linux Mint 18.2
TensorFlow installed from: pip
TensorFlow version: 1.3.0
Bazel version: N/A
CUDA/cuDNN version: 9.0
GPU model and memory: GTX970 4GB
Exact command to reproduce: tf.nn.conv2d's ""padding"" parameter uses a single approach for all convolutional dimensions
  ",0,,2,2018-01-05T17:13:06Z,NONE
15882,"tfdbg error ""Dump root directory does not exist"" with empty fetches",type:bug/performance,"### System information
- **Have I written custom code**: yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: binary (pip install)
- **TensorFlow version**:
== tensorflow import ============================================
tf.VERSION = 1.4.1
tf.GIT_VERSION = v1.4.0-19-ga52c8d9
tf.COMPILER_VERSION = v1.4.0-19-ga52c8d9
Sanity check: array([1], dtype=int32)
- **Python version**: 2.7.12
- **CUDA/cuDNN version**: 
== cuda libs  ===================================================
/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
- **GPU model and memory**: GeForce GTX 1080, 8114MiB
- **Exact command to reproduce**: see code below

### Describe the problem
`LocalCLIDebugWrapperSession.run()` does not behave like `tf.Session.run()` if there are no fetches. The dump directory will never be created and it crashes with an `IOError`. For me this issue occured in a situation like this:
```
      session.run([var.initializer for var in not_initialized_from_checkpoint])
```
where actually everything was restored from the checkpoint and `not_initialized_from_checkpoint` was empty. This code runs fine with an ordinary tf.Session but crashed with tfdbg. It took me some time to track down the issue. If it's not too hard to fix, it would be nice to keep other users from the same pain (maybe - just speculating - #13604 crashes for the same reason)

### Source code / logs
```
import tensorflow as tf
from tensorflow.python import debug as tf_debug

sess = tf.Session()
dbg_sess = tf_debug.LocalCLIDebugWrapperSession(tf.Session())

print sess.run([tf.constant(1.0)])     # [1.0]
print sess.run([])                     # []
print dbg_sess.run([tf.constant(1.0)]) # [1.0]
print dbg_sess.run([])                 # IOError: Dump root directory /tmp/tfdbg_ai_aWv does not exist
```
",1,,4,2018-01-05T15:34:48Z,NONE
15880,Allow full deallocation of GPU memory,stat:awaiting response,"When using the TF C++ library inside an application that also uses GPUs for other tasks (not implemented in TF), it would be useful to be able to deallocate all the GPU memory TF has allocated once the session is closed, and no further TF calls are expected for the time being. gpu_options.allow_growth keeps TF's allocated pool small, but it still can grow to several GB. Even after the session is deleted, the pool doesn't shrink. To free it up, the whole application must be restarted, if I'm not mistaken.

Being able to destroy the [ProcessState](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/process_state.cc) singleton seems to solve it without breaking anything. However, its destructor is protected. Alternatively, getting the Allocator for each GPU from ProcessState and manually destroying them does the trick, but renders TF unusable for all future operations because ProcessState still thinks the Allocators exist and doesn't recreate them when they are required again.

I think making the ProcessState destructor public (or adding a public method to invoke similar code) would be the best solution, but maybe I'm missing an obvious solution that already exists?",0,,2,2018-01-05T14:24:39Z,NONE
15874,Weird behaviour of tf.control_dependencies,,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  CUDA V8.0.61 CUDNN 6.0.20
- **GPU model and memory**: K40M
- **Exact command to reproduce**:

### Describe the problem

The source code is a minimal one to use dynamic rnn to predict token tag.

I tried to use ` tf.control_dependencies` to ensure `loss` will be evaluated before train_op. However,  I mistakenly evaluated `loss` in `session.run([train, loss])`.   

Then I found that if the input length (`EXAMPLE_LENGTH ` in the example code) is larger than or equal to 32, the program will hang without any notification. If I set `CUDA_VISIBLE_DEVICES=''` to use CPU only, the program will output an error code. However, if the input length is smaller than 32, it will run without any problem. 

I am not sure if it is a bug or an intentional behavior.

### Source code / logs
```python
import tensorflow as tf

from tensorflow.contrib.rnn import stack_bidirectional_dynamic_rnn
from tensorflow.python.ops import rnn_cell

EXAMPLE_LENGTH = 31
with tf.Graph().as_default():
    x = tf.random_uniform(maxval=2000, minval=1, 
                          shape=[1, EXAMPLE_LENGTH, 300], dtype=tf.float32)
    lengths = tf.constant([EXAMPLE_LENGTH])
    y = tf.random_uniform(maxval=5, minval=0, 
                          shape=[1, EXAMPLE_LENGTH], dtype=tf.int32)

    cell = rnn_cell.BasicRNNCell(50)
    output, _ = tf.nn.dynamic_rnn(cell, x, dtype=""float32"")
    
    logits = tf.layers.dense(output ,units=5)
    loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))
    with tf.control_dependencies([loss]):
        opt = tf.train.AdamOptimizer()
        train_op = opt.minimize(loss)
        


    sess = tf.InteractiveSession()
    sess.run(tf.global_variables_initializer())

    for i in range(10):
        _, l = sess.run([train_op, loss])
        print(i, l)
```


### Traceback


#### Only output error with CPU
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1322     try:
-> 1323       return fn(*args)
   1324     except errors.OpError as e:

/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1301                                    feed_dict, fetch_list, target_list,
-> 1302                                    status, run_metadata)
   1303 

/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    472             compat.as_text(c_api.TF_Message(self.status.status)),
--> 473             c_api.TF_GetCode(self.status.status))
    474     # Delete the underlying status object from memory otherwise it stays alive

InvalidArgumentError: Retval[0] does not have value

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-43-926b17edef2c> in <module>()
     26 
     27     for i in range(10):
---> 28         _, l = sess.run([train_op, loss])
     29         print(i, l)

/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    887     try:
    888       result = self._run(None, fetches, feed_dict, options_ptr,
--> 889                          run_metadata_ptr)
    890       if run_metadata:
    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1119       results = self._do_run(handle, final_targets, final_fetches,
-> 1120                              feed_dict_tensor, options, run_metadata)
   1121     else:
   1122       results = []

/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1315     if handle is None:
   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1317                            options, run_metadata)
   1318     else:
   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1334         except KeyError:
   1335           pass
-> 1336       raise type(e)(node_def, op, message)
   1337 
   1338   def _extend_graph(self):

InvalidArgumentError: Retval[0] does not have value
```",1,,1,2018-01-05T09:07:41Z,NONE
15873,Feature request: Want TFSlim to automatically download the pre-trained checkpoint,stat:awaiting response,"I want TFSlim to automatically download the pre-trained checkpoint like Keras:
https://keras.io/applications/

When I use Keras, the code below automatically download the pre-trained VGG 16 weights:

```python
from keras.applications.vgg16 import VGG16
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np

model = VGG16(weights='imagenet', include_top=False)
```

On the other hands, TFSlim required to download the checkpoint manually.

Is there any plans to add the feature?",0,,2,2018-01-05T09:07:36Z,NONE
15872,Converting unsupported operation:Unpack Equal TensorArrayV3,"comp:lite,stat:awaiting response","zhangyixindeMBP:tensorflow-1.5.0-rc0 zhangyixin$ bazel run --config=opt \
>   //tensorflow/contrib/lite/toco:toco -- \
>   --input_file=/Users/zhangyixin/Desktop/ssd_mobilenet_201801051717_face/frozen_inference_graph.pb  \
>   --output_file=/Users/zhangyixin/Desktop/ssd_mobilenet_201801051717_face/frozen_inference_graph.pb-pb-lite.lite \
>   --input_format=TENSORFLOW_GRAPHDEF \
>   --output_format=TFLITE \
>   --inference_type=FLOAT \
>   --input_shape=1,300,300,3 \
>   --input_array=image_tensor \
>   --output_arrays=detection_boxes,detection_scores,detection_classes,num_detections
WARNING: Config values are not defined in any .rc file: opt
INFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).
INFO: Found 1 target...
Target //tensorflow/contrib/lite/toco:toco up-to-date:
  bazel-bin/tensorflow/contrib/lite/toco/toco
INFO: Elapsed time: 0.387s, Critical Path: 0.01s
INFO: Build completed successfully, 1 total action

INFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/Users/zhangyixin/Desktop/ssd_mobilenet_201801051717_face/frozen_inference_graph.pb' '--output_file=/Users/zhangyixin/Desktop/ssd_mobilenet_201801051717_face/frozen_inference_graph.pb-pb-lite.lite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--inference_type=FLOAT' '--input_shape=1,300,300,3' '--input_array=image_tensor' '--output_arrays=detection_boxes,detection_scores,detection_classes,num_detections'
2018-01-05 16:55:04.603261: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.603851: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayV3
2018-01-05 16:55:04.603888: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.603921: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayScatterV3
2018-01-05 16:55:04.603938: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayV3
2018-01-05 16:55:04.603976: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Enter
2018-01-05 16:55:04.604002: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Enter
2018-01-05 16:55:04.604038: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Enter
2018-01-05 16:55:04.604098: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: LoopCond
2018-01-05 16:55:04.604176: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Enter
2018-01-05 16:55:04.604219: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Enter
2018-01-05 16:55:04.604238: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayReadV3
2018-01-05 16:55:04.604379: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Enter
2018-01-05 16:55:04.604437: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayWriteV3
2018-01-05 16:55:04.604600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Exit
2018-01-05 16:55:04.604620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArraySizeV3
2018-01-05 16:55:04.604668: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayGatherV3
2018-01-05 16:55:04.604778: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.604868: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.605025: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: LogicalAnd
2018-01-05 16:55:04.621652: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.627529: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.629129: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.630742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.631634: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.631684: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.632365: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.632426: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.633228: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.633277: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.633915: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.633964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.634590: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.634647: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.635357: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.635451: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.636153: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.636180: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Equal
2018-01-05 16:55:04.636466: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.636938: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.637261: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.637554: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.637835: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638123: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638385: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638484: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638604: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638691: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638745: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638804: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638861: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.638875: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Equal
2018-01-05 16:55:04.638953: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.639062: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Unpack
2018-01-05 16:55:04.639152: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Unpack
2018-01-05 16:55:04.639201: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Exp
2018-01-05 16:55:04.639216: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Exp
2018-01-05 16:55:04.639407: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.639464: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice
2018-01-05 16:55:04.640078: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayV3
2018-01-05 16:55:04.640109: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayV3
2018-01-05 16:55:04.640130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: TensorArrayV3",0,,2,2018-01-05T08:58:37Z,NONE
15871,TFlite toco failed to convert the quantized inception protobuf to tflite format ,"comp:lite,type:feature","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Linux qiuji01 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

- **TensorFlow installed from (source or binary)**:
source
 
- **TensorFlow version (use command below)**:
tensorflow (1.5.0rc0)

git commit id:
commit f99275a6a309699c73e1bbebd89ba9aa32e79aa3
Author: Amit Patankar <amitpatankar@google.com>
Date:   Thu Jan 4 17:35:54 2018 -0800

- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.5.4.
- **GCC/Compiler version (if compiling from source)**:
gcc version 5.4.0 20160609
- **CUDA/cuDNN version**:
no
- **GPU model and memory**:
no
- **Exact command to reproduce**:

/root/TF/new/out/toco/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/lite/toco/toco --input_file=incept_8wn_gt.pb --output_file=incept_8wn_gt.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --inference_type=QUANTIZED_UINT8 --input_shape=1,299,299,3 --input_array=""Mul""  --output_array=""softmax""

### Describe the problem
I am trying to follow the transform_graph (~/tensorflow/tools/graph_transforms/) README.md to get a 8 bit quantized model, then feed it into the Tflite toco (~/tensorflow/contrib/lite/) to  transform it from protobuf into tflite format.  My steps are:
1. download the inception model  from http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz and extract it.

2. build the graph_transforms using the following command:
bazel --output_base=../out/transform_graph/ build -s -c opt tensorflow/tools/graph_transforms:transform_graph

3. quantize and optimize the inception model using t he following command:
/root/TF/new/out/transform_graph/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=classify_image_graph_def.pb --out_graph=incept_8wn_gt.pb --inputs='Mul:0' --outputs='softmax:0' --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,299,299,3"") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'

4. build the toco using the following command:
bazel --output_base=../out/toco build tensorflow/contrib/lite/toco:toco

5. transform the quantized inception model from protobuf format into TFlite format using the following the command:

/root/TF/new/out/toco/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/lite/toco/toco --input_file=incept_8wn_gt.pb --output_file=incept_8wn_gt.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --inference_type=QUANTIZED_UINT8 --input_shape=1,299,299,3 --input_array=""Mul""  --output_array=""softmax""





### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

The error log is as following:

2018-01-05 08:08:37.682405: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.682532: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.682593: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.682651: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.682762: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.682950: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683126: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683270: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683385: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683442: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683496: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683546: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683645: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683743: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683862: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.683960: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684051: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684106: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684156: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684210: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684273: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684364: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684418: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684468: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684538: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684591: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.684738: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685056: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685112: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685163: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685263: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685700: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685757: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.685883: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.686121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.686378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.686456: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688240: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688313: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688395: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688454: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688508: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688537: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.688566: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.688589: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.688612: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.688634: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.688654: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.688675: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.688697: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.688722: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.688743: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.688763: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.688781: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.688797: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.688813: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.688856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688907: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.688949: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689010: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689133: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689182: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689298: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689361: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689442: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689709: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689791: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689845: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689940: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.689992: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.690186: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.690258: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.690290: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.690314: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.690338: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.690360: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.690382: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.690403: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.690425: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedMaxPool
2018-01-05 08:08:37.690489: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.690739: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.690833: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.690915: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691020: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691122: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691263: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691368: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691476: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691513: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691536: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691727: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691757: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691782: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.691807: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.692081: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692093: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692104: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.692115: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692125: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692135: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.692148: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.692158: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692168: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692178: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.692189: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692199: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692208: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.692219: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedMaxPool
2018-01-05 08:08:37.692229: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.692241: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.692252: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692262: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692273: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.692283: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692293: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692302: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.692312: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692322: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692331: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.692359: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692411: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692439: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692584: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.692599: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692609: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692618: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.692628: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692639: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692650: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.692664: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.692675: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692685: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692696: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.692706: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692717: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692727: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.692773: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692800: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692815: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.692827: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692837: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692848: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.692858: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692868: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692877: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.692901: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692912: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.692921: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.692932: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.692942: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.692965: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.692996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693021: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693046: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693070: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693098: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.693111: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.693139: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693148: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693157: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.693168: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.693179: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693188: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693199: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.693209: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693219: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693229: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.693255: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693380: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693407: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693431: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693445: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.693459: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.693473: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.693484: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693495: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693505: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.693514: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693522: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.693539: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.693549: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693557: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693566: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.693574: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693583: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693591: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.693615: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693639: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693723: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.693736: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693746: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693755: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.693764: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693772: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693781: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.693790: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.693799: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693808: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693817: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.693826: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.693834: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.693842: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.693869: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693891: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.693957: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.694080: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.694349: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.694394: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.694461: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694474: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694483: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694492: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694501: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694510: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.694527: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694536: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694553: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694561: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694572: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694581: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.694636: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizeV2
2018-01-05 08:08:37.694651: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694661: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694669: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694678: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694687: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694696: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694704: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.694713: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.694724: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694734: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694741: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694750: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694759: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694767: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694775: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.694783: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694792: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694800: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694808: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694817: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694825: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694833: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.694841: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694850: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694857: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694865: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694874: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694881: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694889: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.694897: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694906: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694914: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694922: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694930: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694938: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694946: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.694954: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.694963: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694971: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.694979: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.694987: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.694994: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695002: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695011: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695020: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695028: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695045: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695052: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695060: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695069: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.695079: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695088: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695096: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695105: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695113: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695128: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695137: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.695147: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695157: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695164: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695172: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695180: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695188: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695206: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695215: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695224: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695233: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695241: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695249: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695259: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695269: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695278: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695298: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695308: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695317: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695325: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695333: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695342: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedMaxPool
2018-01-05 08:08:37.695352: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695361: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695370: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695395: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695403: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695411: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.695421: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695431: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695439: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695448: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695456: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695464: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695472: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695481: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695490: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695498: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695507: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695516: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695524: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695532: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695541: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695550: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695558: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695567: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695575: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695583: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695591: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695599: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695608: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695616: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695624: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695633: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695641: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695649: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695658: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695667: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695675: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695684: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695692: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695700: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695708: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695717: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695725: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695734: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695743: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695751: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695760: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695768: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695776: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695786: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695794: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695803: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695819: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695827: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695835: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695844: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695853: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695861: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695869: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695877: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695884: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695892: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695901: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695909: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695926: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695934: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695941: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.695949: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.695959: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.695969: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.695977: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.695986: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.695994: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696002: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696010: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696019: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.696029: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696040: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696048: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696056: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696064: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696072: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696079: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696088: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696096: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696105: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696114: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696138: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696146: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696155: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696163: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696172: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696180: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696188: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696195: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696204: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696212: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696221: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696229: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696237: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696252: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696261: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696270: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696278: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696287: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696296: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696303: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696311: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696319: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696328: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696337: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696345: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696354: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696362: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696370: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696395: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696404: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696412: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696420: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696427: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696436: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696445: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696453: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696462: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696471: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696479: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696487: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696495: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.696506: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696514: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696523: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696532: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696540: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696548: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696556: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696565: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696574: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696582: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696591: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696599: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696607: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696614: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696624: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.696635: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.696645: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696654: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696663: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696671: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696679: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696687: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696695: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696703: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696712: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696720: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696729: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696737: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696745: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696753: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696762: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696771: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696788: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696797: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696804: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696812: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696821: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696830: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696838: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696855: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696863: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696870: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696879: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696887: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696896: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696904: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696912: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696921: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696928: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696936: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.696945: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696953: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696962: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.696970: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.696978: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.696985: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.696994: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697002: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697011: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697019: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697028: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697036: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697045: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697053: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697062: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697070: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697078: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697086: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697094: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697102: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697111: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697129: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697137: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697145: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697153: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697161: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697169: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697178: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697186: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697195: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697203: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697211: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697218: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697227: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.697238: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.697248: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697257: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697266: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697275: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697283: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697292: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697300: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697309: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697318: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697327: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697344: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697352: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697360: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697370: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697386: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697396: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697404: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697412: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697420: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697428: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697437: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697445: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697453: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697462: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697470: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697478: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697486: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697495: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697503: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697511: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697527: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697534: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697543: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697552: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697560: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697569: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697577: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697585: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697593: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697601: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697618: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697626: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697634: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697642: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697650: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697658: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697667: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697676: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697685: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697693: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697702: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697709: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697718: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697727: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697735: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697744: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697752: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697760: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697768: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697776: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697785: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697793: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697802: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697810: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697818: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697826: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697835: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.697845: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697854: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697863: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697872: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697881: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697889: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697897: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697905: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697914: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697922: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697931: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697940: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697948: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697956: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.697965: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.697973: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.697981: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.697990: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.697998: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698006: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698014: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.698022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.698031: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698040: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698047: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.698056: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698064: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698071: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.698080: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.698089: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698097: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698106: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.698115: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698123: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.698139: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.698147: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698155: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698163: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.698171: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698179: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698187: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.698195: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedMaxPool
2018-01-05 08:08:37.698204: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.698215: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.698225: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698233: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698242: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.698250: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698258: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698266: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.698275: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.698284: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.698292: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.698301: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706033: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706066: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706089: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706101: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706111: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706131: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706139: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706147: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706160: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706179: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706200: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706216: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706229: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706243: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706257: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706276: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706294: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706487: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706543: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706552: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706560: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706570: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706580: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706589: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706598: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706607: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706615: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706624: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706655: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706669: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706677: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706686: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706696: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706704: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706712: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706725: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706737: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706746: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706756: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706764: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706772: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706781: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706791: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.706801: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706819: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706837: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706846: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706853: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706863: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.706882: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedMaxPool
2018-01-05 08:08:37.706902: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706917: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706929: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706938: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.706948: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706956: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.706964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.706973: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.706982: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.706991: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707001: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707009: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707017: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707025: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707034: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.707046: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707058: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707083: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707104: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707119: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707133: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.707148: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707160: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707175: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707188: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707203: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707217: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707232: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.707247: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707262: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707277: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707311: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707326: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707355: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.707370: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707384: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707398: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707412: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707425: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707438: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707453: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.707468: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707482: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707497: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707512: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707526: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707539: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707556: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.707571: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707585: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707615: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707629: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707643: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707658: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConv2D
2018-01-05 08:08:37.707673: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707687: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707702: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707717: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707731: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707744: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedRelu
2018-01-05 08:08:37.707761: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedConcat
2018-01-05 08:08:37.707780: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedAvgPool
2018-01-05 08:08:37.707798: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedReshape
2018-01-05 08:08:37.707814: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedMatMul
2018-01-05 08:08:37.707830: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707845: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707860: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QuantizedBiasAdd
2018-01-05 08:08:37.707875: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RequantizationRange
2018-01-05 08:08:37.707890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Requantize
2018-01-05 08:08:37.707904: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Dequantize
2018-01-05 08:08:37.763586: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1080 operators, 3039 arrays (0 quantized)
2018-01-05 08:08:37.849158: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 793 operators, 2752 arrays (1 quantized)
2018-01-05 08:08:37.934553: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 793 operators, 2752 arrays (1 quantized)
2018-01-05 08:08:38.022469: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 793 operators, 2752 arrays (1 quantized)
2018-01-05 08:08:38.082050: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 793 operators, 2752 arrays (1 quantized)
2018-01-05 08:08:38.156372: F tensorflow/contrib/lite/toco/tooling_util.cc:1217] Array conv/Conv2D_eightbit/Mul__port__0/min, which is an input to the (Unsupported TensorFlow op: QuantizeV2) operator producing the output array conv/Conv2D_eightbit/Mul__port__0/quantize, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.

",0,,11,2018-01-05T08:38:40Z,CONTRIBUTOR
15870,the determinant is not finite,stat:awaiting response,"
### Describe the problem
 The items ‘tf.matrix_determinant(sig))‘ and 'tf.matrix_inverse(sig) 'induce error when i try to transform my code from CPU version with r1.2 Tensorflow on windows to GPU r1.4 tensorflow on Ubuntu 16.04. It works fine on windows,while something's wrong on Linux.
I'm not sure whether this problem is triggered by changed version of Tensorflow or the changed platform from CPU to GPU

It seems to me that the data precision has something to do with this, but have little knowlege on this region. Any idea what causes this phenomenon and how to solve this? Thx!

Here are the errors.
InvalidArgumentError (see above for traceback): The determinant is not finite.
         [[Node: MatrixDeterminant_2 = MatrixDeterminant[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](truediv_6)]]
         [[Node: gradients/Exp_1_grad/mul/_85 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_657_gradients/Exp_1_grad/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]


InvalidArgumentError (see above for traceback): Input is not invertible.
         [[Node: gradients/MatrixDeterminant_2_grad/MatrixInverse = MatrixInverse[T=DT_FLOAT, adjoint=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](truediv_6)]]
         [[Node: gradients/Exp_1_grad/mul/_85 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_657_gradients/Exp_1_grad/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]





",0,,2,2018-01-05T07:54:12Z,NONE
15869,tensorflow/go for Windows?,"stat:community support,type:build/install","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: either
- **TensorFlow version (use command below)**: 1.4+
- **Python version**: n/a
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: MINGW64
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none
- **Exact command to reproduce**: visit https://www.tensorflow.org/versions/master/install/install_go

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Feature request: https://www.tensorflow.org/versions/master/install/install_go doesn't have Windows 10 instructions.  I am curious if the tensorflow/go will be installable for windows

### Source code / logs
I currently get an error on the `ld.exe` phase of the go get . for github.com/tensorflow/tensorflow/tensorflow/go : `cannot find -ltensorflow`.  I'm not sure how to specify that the `tensorflow.dll` should be used. ",0,,3,2018-01-05T04:13:14Z,NONE
15868,S3 Checkpointing fails with large graphs,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: tensorflow/tensorflow:1.4.0 container running on Amazon Linux
- **TensorFlow installed from (source or binary)**: Used tensorflow/tensorflow:1.4.0 image
- **TensorFlow version (use command below)**: ('v1.4.0-rc1-11-g130a514', '1.4.0')
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

1. Exported AWS credentials to environment variables
2. docker run -it --rm -p 8888:8888 -e AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY -e AWS_SESSION_TOKEN tensorflow/tensorflow:1.4.0
3. Opened Jupyter UI in browser at localhost:8888
4. Pasted code below in a new notebook, modified checkpoint_s3_dir variable to point to my S3 bucket, and ran it:

```
# Replace with a bucket that you have write access to
checkpoint_s3_dir = 's3://<your_bucket>/checkpoint_testing'

import numpy as np
import tensorflow as tf
from tensorflow.python.keras.layers import Dense, LSTM
from tensorflow.python.estimator.model_fn import ModeKeys
from tensorflow.contrib.learn import RunConfig

# I don't believe the specifics of how my Estimator is configured are important;
# this is a toy example similar to the code where we encountered the problem.
# By varying the embedding dimension used, we can easily generate a graph
# large enough to trigger this problem.

WINDOW_SIZE = 7
BATCH_SIZE = 128
MAX_VOCAB_SIZE = 100000
HIDDEN_DIM = 512
NUM_CLASSES = 2
NUM_PARTITIONS = 10

def partitioned_embeddings(embedding_dim):    
    # Randomly generate embedding
    emb = np.random.rand(MAX_VOCAB_SIZE, embedding_dim).astype(np.float32)
    partitioned_embeddings = []
    for i in range(NUM_PARTITIONS):
        partitioned_embeddings.append(tf.constant(emb[i::NUM_PARTITIONS]))

    return partitioned_embeddings

def model_fn(features, labels, mode, params):
    emb_parts = partitioned_embeddings(params['embedding_dim'])
    embedded_vectors = tf.nn.embedding_lookup(params=emb_parts, ids=features['inputs'],
                                          name='embedding_lookup', partition_strategy='mod')
    l = LSTM(HIDDEN_DIM)(embedded_vectors)
    layers = Dense(NUM_CLASSES, activation='sigmoid')(l)

    global_step = tf.train.get_or_create_global_step()
    
    optimizer = tf.train.AdamOptimizer()
    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=layers)
    train_op = optimizer.minimize(loss, global_step=global_step)
    
    return tf.estimator.EstimatorSpec(ModeKeys.TRAIN, loss=loss, train_op=train_op)

def train(embedding_dim, model_dir=None):
    # Generate random training data
    word_ids = np.random.randint(0, high=MAX_VOCAB_SIZE, size=(BATCH_SIZE * 10, WINDOW_SIZE),
                             dtype=np.int32)
    # Generate random labels
    labels = np.random.randint(0, high=NUM_CLASSES, size=(BATCH_SIZE * 10, NUM_CLASSES), dtype=np.int32)
    
    input_fn = tf.estimator.inputs.numpy_input_fn(x={'inputs': word_ids}, y=labels, batch_size=BATCH_SIZE,
                                              shuffle=False)
    
    estimator = tf.estimator.Estimator(model_fn=model_fn, params={'embedding_dim': embedding_dim},
                                       config=RunConfig(model_dir=model_dir))
    estimator.train(input_fn=input_fn)

# Embedding dimension = 5 succeeds
train(5, model_dir=checkpoint_s3_dir + '/dim_5')
# Embedding dimension = 500 fails during checkpointing to S3
train(500, model_dir=checkpoint_s3_dir + '/dim_500')
```


### Describe the problem
I believe this is a TensorFlow Bug.

My example code, which trains using an Estimator and checkpoints to an S3 bucket I own, succeeds when the graph it produces is small, but fails during checkpointing when I increase the embedding_dimension variable. Everything else should be the same, so I suspect file sizes are the issue.

I've dug into this a bit and my guess is that when the graph size gets too large, the S3 operations time out during checkpointing due to the default client-side timeout on the AWS C++ S3 SDK. That issue is described here: https://stackoverflow.com/questions/38647444/aws-c-s3-sdk-putobjectrequest-unable-to-connect-to-endpoint

The S3 file system currently uses the default timeout: https://github.com/tensorflow/tensorflow/blob/b3d5ec90bc6b7ae7822ea82d82b41e529c5e047a/tensorflow/core/platform/s3/s3_file_system.cc#L513

Which is 3 seconds:
https://sdk.amazonaws.com/cpp/api/0.12.9/df/d19/struct_aws_1_1_client_1_1_client_configuration.html#a68c35ac8d14619e4bfc77d848fd89473

### Source code / logs
Example code above.

Full output is below:
```
INFO:tensorflow:Using config: {'_model_dir': 's3://sagemaker-826912895975/checkpoint_testing/dim_5', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6ad8212510>, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Saving checkpoints for 1 into s3://sagemaker-826912895975/checkpoint_testing/dim_5/model.ckpt.
INFO:tensorflow:loss = 0.733852, step = 1
INFO:tensorflow:Saving checkpoints for 10 into s3://sagemaker-826912895975/checkpoint_testing/dim_5/model.ckpt.
INFO:tensorflow:Loss for final step: 0.693191.
INFO:tensorflow:Using config: {'_model_dir': 's3://sagemaker-826912895975/checkpoint_testing/dim_500', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6ac1672690>, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}
INFO:tensorflow:Create CheckpointSaverHook.
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
<ipython-input-1-1df0ebd892ce> in <module>()
     61 train(5, model_dir=checkpoint_s3_dir + '/dim_5')
     62 # Embedding dimension = 500 fails during checkpointing to S3
---> 63 train(500, model_dir=checkpoint_s3_dir + '/dim_500')

<ipython-input-1-1df0ebd892ce> in train(embedding_dim, model_dir)
     56     estimator = tf.estimator.Estimator(model_fn=model_fn, params={'embedding_dim': embedding_dim},
     57                                        config=RunConfig(model_dir=model_dir))
---> 58     estimator.train(input_fn=input_fn)
     59 
     60 # Embedding dimension = 5 succeeds

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    300 
    301     saving_listeners = _check_listeners_type(saving_listeners)
--> 302     loss = self._train_model(input_fn, hooks, saving_listeners)
    303     logging.info('Loss for final step: %s.', loss)
    304     return self

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc in _train_model(self, input_fn, hooks, saving_listeners)
    781         loss = None
    782         while not mon_sess.should_stop():
--> 783           _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
    784       return loss
    785 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    519                           feed_dict=feed_dict,
    520                           options=options,
--> 521                           run_metadata=run_metadata)
    522 
    523   def should_stop(self):

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    890                               feed_dict=feed_dict,
    891                               options=options,
--> 892                               run_metadata=run_metadata)
    893       except _PREEMPTION_ERRORS as e:
    894         logging.info('An error was raised. This may be due to a preemption in '

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc in run(self, *args, **kwargs)
    965         raise six.reraise(*original_exc_info)
    966       else:
--> 967         raise six.reraise(*original_exc_info)
    968 
    969 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc in run(self, *args, **kwargs)
    950   def run(self, *args, **kwargs):
    951     try:
--> 952       return self._sess.run(*args, **kwargs)
    953     except _PREEMPTION_ERRORS:
    954       raise

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc in run(self, fetches, feed_dict, options, run_metadata)
   1014     options = options or config_pb2.RunOptions()
   1015     feed_dict = self._call_hook_before_run(run_context, actual_fetches,
-> 1016                                            feed_dict, options)
   1017 
   1018     # Do session run.

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc in _call_hook_before_run(self, run_context, fetch_dict, user_feed_dict, options)
   1040     hook_feeds = {}
   1041     for hook in self._hooks:
-> 1042       request = hook.before_run(run_context)
   1043       if request is not None:
   1044         if request.fetches is not None:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.pyc in before_run(self, run_context)
    432           ops.get_default_graph().as_graph_def(add_shapes=True),
    433           self._checkpoint_dir,
--> 434           ""graph.pbtxt"")
    435       saver_def = self._get_saver().saver_def if self._get_saver() else None
    436       graph = ops.get_default_graph()

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_io.pyc in write_graph(graph_or_graph_def, logdir, name, as_text)
     67   if as_text:
     68     file_io.atomic_write_string_to_file(path,
---> 69                                         text_format.MessageToString(graph_def))
     70   else:
     71     file_io.atomic_write_string_to_file(path, graph_def.SerializeToString())

/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.pyc in atomic_write_string_to_file(filename, contents, overwrite)
    421   write_string_to_file(temp_pathname, contents)
    422   try:
--> 423     rename(temp_pathname, filename, overwrite)
    424   except errors.OpError:
    425     delete_file(temp_pathname)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.pyc in rename(oldname, newname, overwrite)
    400   with errors.raise_exception_on_not_ok_status() as status:
    401     pywrap_tensorflow.RenameFile(
--> 402         compat.as_bytes(oldname), compat.as_bytes(newname), overwrite, status)
    403 
    404 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc in __exit__(self, type_arg, value_arg, traceback_arg)
    471             None, None,
    472             compat.as_text(c_api.TF_Message(self.status.status)),
--> 473             c_api.TF_GetCode(self.status.status))
    474     # Delete the underlying status object from memory otherwise it stays alive
    475     # as there is a reference to status from this from the traceback due to

InternalError: : Unable to connect to endpoint
```
",0,,5,2018-01-05T01:33:56Z,NONE
15859,Eager mode: create_file_writer cannot be called twice,,"Have I written custom code: No
OS Platform and Distribution: OS X 10.13.2
TensorFlow installed from: Source
TensorFlow version: cc9bdb70b88c76f293f27e29e91cb7739ba3fdc4
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce:

```python
import tensorflow as tf
import tensorflow.contrib.eager as tfe
tfe.enable_eager_execution()
tf.contrib.summary.create_file_writer(""/Users/malmaud/tmp/summaries"")
tf.contrib.summary.create_file_writer(""/Users/malmaud/tmp/summaries"")
```

The second call to `create_file_writer` gives:

```
---------------------------------------------------------------------------
AlreadyExistsError                        Traceback (most recent call last)
<ipython-input-5-4583ede32bc2> in <module>()
----> 1 tf.contrib.summary.create_file_writer(""/Users/malmaud/tmp/summaries"")

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/summary/summary_ops.py in create_file_writer(logdir, max_queue, flush_millis, filename_suffix, name)
    210         max_queue=max_queue,
    211         flush_millis=flush_millis,
--> 212         filename_suffix=filename_suffix)
    213 
    214 

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/summary/summary_ops.py in _make_summary_writer(name, factory, **kwargs)
    271   #   ops.get_default_session().run(node)
    272   ops.add_to_collection(_SUMMARY_WRITER_INIT_COLLECTION_NAME,
--> 273                         factory(resource, **kwargs))
    274   return SummaryWriter(resource)
    275 

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/summary/gen_summary_ops.py in create_summary_file_writer(writer, logdir, max_queue, flush_millis, filename_suffix, name)
    145     _result = _execute.execute(b""CreateSummaryFileWriter"", 0,
    146                                inputs=_inputs_flat, attrs=_attrs, ctx=_ctx,
--> 147                                name=name)
    148     _result = None
    149   return _result

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     64     else:
     65       message = e.message
---> 66     six.raise_from(core._status_to_exception(e.code, message), None)
     67   # pylint: enable=protected-access
     68   return tensors

~/anaconda3/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

AlreadyExistsError: Resource localhost//N10tensorflow22SummaryWriterInterfaceE [Op:CreateSummaryFileWriter]
```

Explicitly calling `create_file_writer` with a unique `name` keyword argument solves the issue, but I'd have thought the name should be auto-uniquefied like with other TensorFlow ops.
  ",0,,3,2018-01-04T20:14:03Z,CONTRIBUTOR
15858,Add unsortedsegment(prod/min/max/sqrt_n/mean).,"awaiting review,cla: yes","
This pull request
- adds CPU/GPU implementations of
  - `tf.unsorted_segment_min`,
  - `tf.unsorted_segment_prod` and a
  - GPU implementation for `tf.unsorted_segment_max`.
- adds python implementations of:
  - `tf.unsorted_segment_mean`
  - `tf.unsorted_segment_sqrt_n`
- fixes the gradient calculation for unsorted_segment_sum/max.
  #13055 introduced silent dropping of negative values on the cpu.
  However, the gradient of e.g. unsorted_segment_sum used tf.gather
  and therefore failed for negative indices on cpu.
  
I tried to simplify the code and to remove code duplication,
addressing this [todo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L362).
(Also I once filed an  [issue](https://github.com/tensorflow/tensorflow/issues/7389)  to add these ops but only now had time to finish it ;).)


Some notes on this pull request:

- tf.gather returns zero on GPU for negative indices and raises an exception on
  CPU. To overcome this, the current implementation masks negative indices and
  sets them to zero later. This is of course not as efficient as the original gather.
  Would it make sense to use something like `if ""gpu"" in op.device.lower():` to run
  different functions, depending on the device?
- Instead of having a native op for mean/sqrt_n I added them in python.
  Making them native would require two additional template arguments
  (a functor to process the counter), resulting in more complicated code with
  probably only minor performance improvement, if at all. In my quick
  benchmarks, the python ops are nearly as fast as unsorted_segment_sum. However,
  they use more memory than a native op would, due to creating a tensor of ones.
  (bincount doesn't work here as it doesn't support negative indices)
- I simply copy-pasted some atomicOp code in `cuda_kernel_helper.h` instead of
  writing this more nicely as for a short period there was a completely different
  version of this file online and I wanted to check back with you before
  doing something more sophisticated. What's the status of this?

  Additionally, I guess the function `AccumulateInto` in `segment_reduction_ops_gpu.cu.cc`
  could be removed? CudaAtomicAdd has specializations for complex types in
  cuda_kernel_helper.h

Cheers,
Phil",1,,5,2018-01-04T20:05:30Z,CONTRIBUTOR
15855,Export inception model after retrain,"awaiting review,cla: yes","The are many issues and Stackoverflow posts asking how to export a retrained Inception model: https://github.com/tensorflow/serving/issues/449, https://github.com/tensorflow/serving/issues/33, https://github.com/tensorflow/serving/issues/7. It would be nice if retrain.py did this so that it's easier for newcomers to use Tensorflow Serving.

This PR exports the model after retrain is finished. I've also added a comment on how to serve the retrained model.
  
  ",1,,6,2018-01-04T18:14:39Z,NONE
15849,gcc: error: unrecognized command line option '-fcolor-diagnostics',,"The issue is similar to [#1192](https://github.com/tensorflow/tensorflow/issues/1192) 

I am trying build Tensorflow from source on UBUNTU machine (16.04 LTS)
I am using following version of gcc and bazel

- gcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
- bazel Build label: 0.9.0

### Problem Description
I get a number of build errors during the **bazel build** phase.
All errors are similar to one below (I used --verbose_failures option for **bazel build**):


`ERROR: /home/murthy/tensorflow/tensorflow/core/BUILD:1656:1: Couldn't build file tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.o: C++ compilation of rule '//tensorflow/core:version_lib' failed (Exit 1): gcc failed: error executing command 
  (cd /home/murthy/.cache/bazel/_bazel_murthy/72b24eaacfd1d73bef6a8acb540b8c44/execroot/org_tensorflow && \
  exec env - \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/murthy/.virtualenvs/dl4cv/bin/python \
    PYTHON_LIB_PATH=/home/murthy/.virtualenvs/dl4cv/lib/python3.5 \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=0 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '-march=native' -mssse3 -mfma -mcx16 -msse4.1 -msse4.2 -mpopcnt -mavx '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.d '-frandom-seed=bazel-out/k8-py3-opt/bin/tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.o' -fPIC -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' -msse3 -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/tensorflow/core/util/version_info.cc -o bazel-out/k8-py3-opt/bin/tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.o)
gcc: error: unrecognized command line option '-fcolor-diagnostics'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
`
## What did I do?
I manually removed the `-fcolor-diagnostics` flag and gcc did not give an error.
further I looked up the man pages for gcc and was surprised to find

` Language Independent Options
           -fmessage-length=n 
           -fdiagnostics-show-location=[once|every-line] 
           -fdiagnostics-color=[auto|never|always]
           -fno-diagnostics-show-option -fno-diagnostics-show-caret
`

**Note**: the interchange in the words 'diagnostics' and 'color' in the man pages as compared to that in flags for **bazel build**

I am not sure if this is Tensorflow issue or bazel issue but am looking for a way to suppress the `-fcolor-diagnostics' flag or change it to `-fdiagnostics-color`
",0,,3,2018-01-04T14:44:19Z,NONE
15848,*** Error in `python': double free or corruption (out): 0x00007fc5d674d9b0 ***,,"I've built the latest version of TensorFlow from github repository with the following commands.

bazel build -s --config=mkl -c opt --copt=-msse4.1 --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package

bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

pip install /tmp/tensorflow_pkg/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl

And get the following error after the import tensorflow command in python

Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 16 2017, 15:28:36) 
[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Intel(R) Distribution for Python is brought to you by Intel Corporation.
Please check out: https://software.intel.com/en-us/python-distribution
>>> import tensorflow as tf
*** Error in `python': double free or corruption (out): 0x00007fc5d674d9b0 ***

Any suggestions on how to fix this issue?",0,,3,2018-01-04T12:56:02Z,NONE
15847,Reinitializing an iterator throws an OutOfRangeError when using a MonitoredSession with NanTensorHook,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
edit: none, using CPU only
- **GPU model and memory**:
- **Exact command to reproduce**:
See below under source code

### Describe the problem
When using a Monitored Training Session with a NanTensorHook and an Iterator from a Dataset, reinitializing the Iterator causes an OutOfRangeError. 
This is likely because the NanTensorHook adds the loss value to the SessionRunArgs, but the evaluation of the loss-value then fails since no more data are available from the iterator.

Ideally, there should be a way to reinitialize the iterator without the hooks beeing executed.

### Source code / logs
example code to reproduce the problem
```
import tensorflow as tf

dataset = tf.data.Dataset.range(100)
dataset = dataset.map(lambda x: (0, x))
dataset = dataset.batch(64)
iterator = dataset.make_initializable_iterator()
(label, element) = iterator.get_next()

# pseudo loss for the NanTensorHook
loss = tf.reduce_mean(1 - label)

global_step = tf.train.get_or_create_global_step()
scaffold = tf.train.Scaffold(local_init_op=iterator.initializer)

with tf.train.MonitoredTrainingSession(
        scaffold=scaffold,
        hooks=[tf.train.NanTensorHook(loss_tensor=loss)]) as sess:
    # Compute for 5 epochs.
    for epoch in range(5):
        print('epoch: ' + str(epoch))
        try:
            while not sess.should_stop():
                sess.run(element)
        except tf.errors.OutOfRangeError:
            print('end')

        if sess.should_stop():
            break

        # the following line silently fails, since an OutOfRangeError is thrown
        sess.run(iterator.initializer)
```
Removing the NanTensorHook or placing the `sess.run(iterator.initializer)` call inside an try-except-statement provides a workaround for this problem
```
        try:
            sess.run(iterator.initializer)
        except tf.errors.OutOfRangeError:
            print('Out of range errors occurs')
```

  ",0,,2,2018-01-04T12:47:10Z,NONE
15846,tf.losses.sigmoid_cross_entropy,stat:awaiting response,"Hi,
it seems that there is a mistake in the api doc:
logits: Float [batch_size, num_classes] logits outputs of the network. 
however it should be:
logits: Float [batch_size, num_classes] Unscaled log probabilities.
since it said it is going to ""Creates a cross-entropy loss using tf.nn.sigmoid_cross_entropy_with_logits""",0,,2,2018-01-04T11:46:39Z,NONE
15845,TF Lite,comp:lite,"Feature Request for TF Lite - support for the following:
td_split
tf_pad (Padding is something that an RNN needs de-facto unless tensorflow RNNs accept lists of variously shaped tensors.)
tf_gather
tf_slice
LSTM Cells
Dynamic RNNs
Are there alternatives to the above in TF Lite?

Have I written custom code - No
OS Platform and Distribution - Android
TensorFlow installed from - https://github.com/tensorflow
TensorFlow version - 1.4
Bazel version - 0.5.4
CUDA/cuDNN version - NA
GPU model and memory - Na
Exact command to reproduce - NA




  ",2,,6,2018-01-04T11:31:10Z,NONE
15841,MultiRNNCell with attention cause Dimensions error,stat:awaiting response,"when i use MultiRNNCell  and attention for decoding,it goes to 

> ValueError: Dimensions must be equal, but are 2048 and 3072 for 'read/decode/seq_decode/while/BasicDecoderStep/seq_decode/attention_wrapper/attention_wrapper/multi_rnn_cell/cell_0/cell_0/lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [?,2048], [3072,4096].

I trace the code,and found it maybe a bug:
https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/rnn_cell_impl.py:
line:1066 calls to LSTMCell(line:600),its _linear1 is initialization from the first LSTMCELL, and will not initialization from the second LSTMCELL. my first LSTMCELL input is with attention.its shape is (?, emb+attention)
but,my second LSTMCELL input is without attention because it called in the while loop, which shape is (?, emb).,When second LSTMCELL use _linear1 is initialization from the first LSTMCELL,it goes to this error



  ",0,,2,2018-01-04T09:55:13Z,NONE
15840,Numerous ::`anonymous namespace':: Linking errors in Tensorflow 1.3.1 Windows build with GPU,stat:awaiting response,"
Building with VS 2015 64bit and CUDA 8 and Cudnn v7 (cudnn64_7.dll).

All other projects in the solution got built. Even the project pywrap_tensorflow_internal_static got built. But, when building the project pywrap_tensorflow_internal for the dll one, it compiles successfully but gives numerous linking errors as below:

I also see that (probably) all of them contain the anonymous namespace - ``class tensorflow::`anonymous namespace'::``.

```
1>pywrap_tensorflow_internal.exp : warning LNK4070: /OUT:_pywrap_tensorflow_internal.pyd directive in .EXP differs from output filename 'D:\rough\tensorflow-1.3.1\tensorflow\contrib\cmake\build\Release\pywrap_tensorflow_internal.dll'; ignoring directive
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: void __cdecl tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16>::Initialize<1>(class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int)'::`2'::$TSS0"" (?$TSS0@?1???$Initialize@$00@?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@QEAAXAEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@H@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: void __cdecl tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16>::Initialize<0>(class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int)'::`2'::$TSS0"" (?$TSS0@?1???$Initialize@$0A@@?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@QEAAXAEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@H@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""TSS0<`template-parameter-2',tensorflow::`anonymous namespace'::M::cale_independent_strtonum,cointerface ?? :: ?? ::HA::tensorflow::Z::AMPEBDPEAPEBD>"" (?$TSS0@?1???$locale_independent_strtonum@M@?A0x77a2fbcf@tensorflow@@YAMPEBDPEAPEBD@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""TSS0<`template-parameter-2',tensorflow::`anonymous namespace'::N::cale_independent_strtonum,cointerface ?? :: ?? ::HA::tensorflow::Z::ANPEBDPEAPEBD>"" (?$TSS0@?1???$locale_independent_strtonum@N@?A0x77a2fbcf@tensorflow@@YANPEBDPEAPEBD@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `private: static void __cdecl tensorflow::SparseMatMul<float,float>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<float> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<float> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0"" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@MM@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBM$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `private: static void __cdecl tensorflow::SparseMatMul<float,struct tensorflow::bfloat16>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<float> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<float> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0"" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@MUbfloat16@tensorflow@@@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,float>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0"" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@M@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBM$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,struct tensorflow::bfloat16>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0"" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@U12@@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `bool __cdecl tensorflow::`anonymous namespace'::IsGradientNode(class tensorflow::Graph const *,class tensorflow::Node const *)'::`2'::$TSS0"" (?$TSS0@?1??IsGradientNode@?A0xd76da148@tensorflow@@YA_NPEBVGraph@3@PEBVNode@3@@Z@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<signed char>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@C@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<unsigned char>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@E@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<short>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@F@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<int>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@H@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<float>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@M@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<double>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@N@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QInt16>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@UQInt16@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QInt32>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@UQInt32@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QInt8>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@UQInt8@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QUInt16>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@UQUInt16@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QUInt8>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@UQUInt8@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::half>::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@Uhalf@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<class std::complex<float> >::output_dtypes(void)const '::`2'::$TSS0"" (?$TSS0@?1??output_dtypes@?$Dataset@V?$complex@M@std@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)
...
...
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""class Eigen::array<int,2> const `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,float>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`26'::zero"" (?zero@?BK@??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@M@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBM$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4V?$array@H$01@7@B)
1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol ""class Eigen::array<int,2> const `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,struct tensorflow::bfloat16>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`26'::zero"" (?zero@?BK@??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@U12@@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4V?$array@H$01@7@B)
1>D:\rough\tensorflow-1.3.1\tensorflow\contrib\cmake\build\Release\pywrap_tensorflow_internal.dll : fatal error LNK1120: 1937 unresolved externals
========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========

```
By any chance, does anyone know what these errors are hinting towards?

Thanks in advance.


  ",0,,3,2018-01-04T09:11:04Z,NONE
15835,"When data become large,parition variables can not initialized successfully",,"i use tensorflow to distributed trainning models, i use the partition valriables to store an array data, when the data is not so bigger, everything looks ok,but when the array data become larger, when the session initialize, the partition variables can not initialized and the session will wait util time out.

Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. the feat_info can initialize successfully, but the adj_info cannot initialized. the adj_info is larger than feat_info

 i use monitored_session or supervisor to do the initialize_variables, when data is not so large, it will initialize successfully, my machine have more than 300GB memory is enough for the larger variable

Have I written custom code
yes
OS Platform and Distribution
linux platform
TensorFlow installed from
N/A
TensorFlow version
r1.4
Bazel version
CUDA/cuDNN version
no gpu
GPU model and memory
no gpu
Exact command to reproduce
N/A

Source code / logs

i use ps_num = 4, worker_num =4 and i also try some other distributed config, like ps_num=1, worker_num=4, the result is the same
source code:
with tf.device(tf.train.replica_device_setter(
worker_device=""/job:worker/task:%d"" % task_id,
cluster=cluster_spec)):

  feat_info = tf.get_variable(""feature_info"", (len(id_map),FLAGS.features_column), tf.float32, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))
  adj_info = tf.get_variable(""adj_info"", (len(id_map),FLAGS.max_degree), tf.int64, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))
 
  with tf.device('/job:worker/task:%d' %task_id):
      adj_local = tf.Variable(tf.constant(minibatch.adj, dtype=tf.int64), trainable=False, name=""adj_local"", collections=[tf.GraphKeys.LOCAL_VARIABLES])
      feat_local = tf.Variable(tf.constant(features, dtype=tf.float32), trainable=False, name=""feat_local"", collections=[tf.GraphKeys.LOCAL_VARIABLES])
 
  length, begin, end = split_node_by_task(len(id_map), task_id, num_workers)
  adj = tf.nn.embedding_lookup(adj_info, [x for x in range(begin, end)])
  adj = adj_local
  
  feat = tf.nn.embedding_lookup(feat_info, [x for x in range(begin, end)])
  feat = feat_local
log:
2017-12-08 23:54:17.377290: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session c2b3ba9b700261ba with config:
INFO:tensorflow:Waiting for model to be ready. Ready_for_local_init_op: None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15
2017-12-09 00:00:35.637019: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session f35fcf332e3908ec with config:
INFO:tensorflow:Waiting for model to be ready. Ready_for_local_init_op: None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15
and it will alway waiting adj_info to initialize",0,,4,2018-01-04T06:17:30Z,NONE
15833,gradient function missing for odeint,,"I am trying to program a optimization problem using TensorFlow. The cost function depends on the outcome of an ODE solved by TensorFlow. However I find that TensorFlow's auto differential does not support the function which contains odeint.

odeint: tensorflow.org/api_docs/python/tf/contrib/integrate/odeint

It would great be of great help if we could have it.

Have I written custom code: N/A
OS Platform and Distribution: Ubuntu 16.04 
TensorFlow installed from: official website pip 
TensorFlow version: 14.01
Bazel version: N/A
CUDA/cuDNN version: 8.0
GPU model and memory: GTX1080Ti, not relevant
Exact command to reproduce: N/A
  ",0,,3,2018-01-04T05:37:53Z,NONE
15831,Using keras and tf.keras has different result,type:bug/performance,"### System information
- **TensorFlow)**:
- **Linux Ubuntu 16.04**:
- **TensorFlow installed from Binary**:
- **TensorFlow version (1.4)**:
- **Python version 3.6.3**: 

### Describe the problem
I am using tf.keras and keras but it has a different result. I am using the code below for sentiment analysis classification using imdb dataset.
### Source code / logs
```
model = Sequential()
model.add(Embedding(n_unique_words, n_dim, input_length=max_reviw_length))
model.add(Flatten())
model.add(Dense(n_dense, activation='relu'))
model.add(Dropout(dropout))
model.add(Dense(1, activation='sigmoid'))
model.summary() 
```


```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 100, 64)           320000    
_________________________________________________________________
flatten_1 (Flatten)          (None, 6400)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                409664    
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 65        
=================================================================
Total params: 729,729
Trainable params: 729,729
Non-trainable params: 0
__________________________

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])
```
preprocessing all exact the same

tf.keras result

```
Train on 25000 samples, validate on 25000 samples
Epoch 1/4
25000/25000 [==============================] - 9s - loss: 0.7412 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.50000.4
Epoch 2/4
25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 3/4
25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 4/4
25000/25000 [==============================] - 7s - loss: 0.6932 - acc: 0.4942 - val_loss: 0.6931 - val_acc: 0.5000

<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fad685e7c18>
```

keras result

```
Train on 25000 samples, validate on 25000 samples
Epoch 1/4
25000/25000 [==============================] - 9s 344us/step - loss: 0.5607 - acc: 0.6900 - val_loss: 0.3622 - val_acc: 0.8404
Epoch 2/4
25000/25000 [==============================] - 8s 308us/step - loss: 0.2849 - acc: 0.8849 - val_loss: 0.3486 - val_acc: 0.8446
Epoch 3/4
25000/25000 [==============================] - 8s 305us/step - loss: 0.1179 - acc: 0.9642 - val_loss: 0.4183 - val_acc: 0.8339
Epoch 4/4
25000/25000 [==============================] - 8s 307us/step - loss: 0.0252 - acc: 0.9960 - val_loss: 0.5202 - val_acc: 0.8345

<keras.callbacks.History at 0x7f560b85d940>


```",1,,4,2018-01-04T03:52:08Z,NONE
15830,tensorflow/contrib/lite/kernels/resize_bilinear.cc:42 NumInputs(node) != 1 (2 != 1),"comp:lite,stat:awaiting response","###System information
Have I written custom code: Yes, 
OS Platform and Distribution: Ubuntu14.04
TensorFlow installed from: source build w/ Bazel
TensorFlow version: 1.4
Python version: Anaconda 3.5.2
Bazel version: 0.9.0
GCC/Compiler version (if compiling from source): gcc version 4.8.4
CUDA/cuDNN version: Not relevant
GPU model and memory: Not  relevant
Exact command to reproduce: Not relevant


### Describe the problem

I construct a network with only bilinear_resize operation (I use the tf.image.resize_bilinear) and add operation, and  convert it to a tflite model successfully. However,  when I run the tflite mode, it comes to the errors as follows:

java.lang.NullPointerException: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/resize_bilinear.cc:42 NumInputs(node) != 1 (2 != 1)

I find the code line in resize_bilinear.cc:42 as follows:
TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);

Is it right to modify the code line to : 
TF_LITE_ENSURE(context, NumInputs(node) == 1 || NumInputs(node) == 2); 
   


### Source code / logs
def network():
      img = tf.placeholder(name='img', dtype=tf.float32, shape=(1,100,100,3))
      img = tf.layers.conv2d(img, 3, (3,3), padding='same', name='conv1')
      img = tf.image.resize_bilinear(img, [200,200])
      var = tf.get_variable('weights', dtype=tf.float32, shape=(1,200,200,3))
      val = img + var
      out = tf.identity(val, name='out')


  ",0,,2,2018-01-04T03:42:09Z,NONE
15824,Move SpeechActivity animation to XML.,"awaiting review,cla: yes","Moved SpeechActivity animation to `res/animator/color_animation.xml`.

Specifying the animation in code is tougher to read and detracts from what is supposed to be a simple example of how to use TF in Android.",1,,1,2018-01-03T21:14:54Z,CONTRIBUTOR
15818,Tensorflow Object Detection using Tensorflow Mobile,,"I am trying to use a custom model in the [TF-Detect Android Demo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android).

**model: ssd_mobilenet_v1_coco**

The model is trained on 8 classes. After exporting the model I've optimised it using Tensorflow-Mobile.
```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
    --in_graph=frozen_inference_graph.pb \
    --out_graph=optimized_inf_graph.pb \
    --inputs='image_tensor' \
    --outputs='detection_boxes detection_scores detection_classes num_detections' \
    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'
```
The optimised graph is giving proper output in my local system, but when it's integrated in the application there is no output shown in the screen. But when I'm using the unoptimised graph (`frozen_inference_graph.pb`) in the application, it's working fine. I'm getting outputs.What am I doing wrong here?


Have I written custom code: No
OS Platform and Distribution: Mac OS Sierra
TensorFlow installed from: Virtualenv installation
TensorFlow version: 1.4
Bazel version: Build label: 0.7.0-homebrew
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce:

1. Trained a `ssd_mobilenet_v1_coco` model using google cloud ml for 8 classes
2. Exported the frozen graph from checkpoints using the below command set:

```
python export_inference_graph.py --input_type image_tensor \
     --pipeline_config_path training/ssd_inception_v2_coco.config \
     --trained_checkpoint_prefix training/model.ckpt-200000 \
     --output_directory frozen_graph/
```

`export_inference_graph.py` is the python script provided in here https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py. Tested the `frozen_inference_graph.py` in my local system, it's working fine.

3. Used the below command to convert the `frozen_inference_graph.py` to optimized graph:

```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
    --in_graph=<path to frozen_inference_graph.pb> \
    --out_graph=<path where optimized_inf_graph.pb will be stored> \
    --inputs='image_tensor' \
    --outputs='detection_boxes detection_scores detection_classes num_detections' \
    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'
```
Tested the `optimized_inf_graph.pb` graph in my local system. It's working fine.

4. Copied the `optimized_inf_graph.pb` in `tensorflow/tensorflow/examples/android/assets/` folder. Also, copied `my_labels.txt` file in the assets folder.

5. Replaced `ssd_mobilenet_v1_android_export.pb` with `optimized_inf_graph.pb` in DetectorActivity.java [file](https://github.com/tensorflow/tensorflow/blob/15b1cf025da5c6ac2bcf4d4878ee222fca3aec4a/tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java#L65)

Replaced `coco_labels_list.txt` with `my_labels.txt` in DetectorActivity.java [file](https://github.com/tensorflow/tensorflow/blob/15b1cf025da5c6ac2bcf4d4878ee222fca3aec4a/tensorflow/examples/android/src/org/tensorflow/demo/DetectorActivity.java#L67)

Tf Detect:
```
private static final String TF_OD_API_MODEL_FILE =
      ""file:///android_asset/optimized_inf_graph.pb"";
  private static final String TF_OD_API_LABELS_FILE = ""file:///android_asset/coco_labels_list.txt"";
```

My Version:
```
private static final String TF_OD_API_MODEL_FILE =
      ""file:///android_asset/ssd_mobilenet_v1_android_export.pb"";
  private static final String TF_OD_API_LABELS_FILE = ""file:///android_asset/my_labels.txt"";
```

6. Installed on my phone: LG G4",0,,3,2018-01-03T15:24:15Z,NONE
15815,"When data become large,parition variables can not initialized successfully",,"#15216 
i have a issue, but nobody help me to solve it ",0,,5,2018-01-03T12:42:54Z,NONE
15810,Calling variable property of DropoutWrapper gives Error: AttributeError: 'DropoutWrapper' object has no attribute 'trainable',stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Using docker container minimaxir/keras-cntk:cpu-compiled (https://hub.docker.com/r/minimaxir/keras-cntk/tags/)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.1 also tested on 1.4
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I was trying to access the weights and biases of an BasicLSTM cell I created. The BasicLSTM cell also has a DropoutWrapper and when trying to access the variables property the below error is thrown.
`AttributeError: 'DropoutWrapper' object has no attribute 'trainable'`

Someone tried to help me with the error on stackoverflow (second half of this [answer](https://stackoverflow.com/a/47643427/1169493)) and noticed that while variables is implemented in Layer. 

I will quote his very helpful response below:

> Although variables is documented for most (all?) RNN classes, it does break for DropoutWrapper. The property has been documented since r1.2, but accessing the property causes an exception in 1.2 and 1.4 (and looks like 1.3, but untested). Specifically,
> 
> from tensorflow.contrib import rnn
> ...
> lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)
> wrapped_cell = rnn.DropoutWrapper(lstm_cell)
> outputs, states = rnn.static_rnn(wrapped_cell, x, dtype=tf.float32)
> print(""LSTM vars!"", lstm_cell.variables)
> print(""Wrapped vars!"", wrapped_cell.variables)
> will throw AttributeError: 'DropoutWrapper' object has no attribute 'trainable'. From the traceback (or a long stare at the DropoutWrapper source), I noticed that variables is implemented in DropoutWrapper's super RNNCell's super Layer. Dizzy yet? Indeed, we find the documented variables property here. It returns the (documented) weights property. The weights property returns the (documented) self.trainable_weights + self.non_trainable_weights properties. And finally the root of the problem:

```
 @property
 def trainable_weights(self):
     return self._trainable_weights if self.trainable else []
 
 @property
 def non_trainable_weights(self):
     if self.trainable:
         return self._non_trainable_weights
     else:
        return self._trainable_weights + self._non_trainable_weights
```

> That is, variables does not work for a DropoutWrapper instance. Neither will trainable_weights or non_trainable_weights sinceself.trainable is not defined.
> 
> One step deeper, Layer.__init__ defaults self.trainable to True. Where that property gets removed, deled, unset, whatever from a DropoutWrapper object, I cannot tell.

  ",0,,6,2018-01-03T10:59:59Z,CONTRIBUTOR
15809,add checking for input values in GANHead constructor,"awaiting review,cla: yes",,1,,4,2018-01-03T08:29:36Z,NONE
15805,Unable to convert LSTM model to .tflite model,comp:lite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.2
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.3.0-rc2-20-g0787eee', '1.3.0')
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A, using CPU only
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 
```
~/tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \
  --input_file=""$(pwd)/lstm-model.pb"" \
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --output_file=""$(pwd)/lstm-model.tflite"" --inference_type=FLOAT \
  --input_type=FLOAT --input_arrays=input \
  --output_arrays=output --input_shapes=28,28
```
### The Issue
When trying to convert an LSTM from a frozen graph (.pb) file to (.tflite) using the tensorflow toco script, I get unsupported operations error.

### Source code / logs
This is the source code for the mode:
```
'''
Edited code from https://jasdeep06.github.io/posts/Understanding-LSTM-in-Tensorflow-MNIST/
'''

import tensorflow as tf
from tensorflow.contrib import rnn

#import mnist dataset
from tensorflow.examples.tutorials.mnist import input_data
mnist=input_data.read_data_sets(""/tmp/data/"",one_hot=True)

#define constants
#unrolled through 28 time steps
time_steps=28
#hidden LSTM units
num_units=128
#rows of 28 pixels
n_input=28
#learning rate for adam
learning_rate=0.001
#mnist is meant to be classified in 10 classes(0-9).
n_classes=10
#size of batch
batch_size=128

#weights and biases of appropriate shape to accomplish above task
out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))
out_bias=tf.Variable(tf.random_normal([n_classes]))

#defining placeholders
#input image placeholder
x=tf.placeholder(""float"",[None,time_steps,n_input],name=""input"")
#input label placeholder
y=tf.placeholder(""float"",[None,n_classes])

#processing the input tensor from [batch_size,n_steps,n_input] to ""time_steps"" number of [batch_size,n_input] tensors
input=tf.unstack(x ,time_steps,1)

#defining the network
#cell = rnn.BasicLSTMCell(num_units,forget_bias=0)
lstm_layer = tf.nn.rnn_cell.MultiRNNCell([rnn.BasicLSTMCell(num_units) for _ in range(3)])
outputs, _ = rnn.static_rnn(lstm_layer,input,dtype=""float32"")

#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication
prediction=tf.matmul(outputs[-1],out_weights,name=""output"")+out_bias

#loss_function
loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))
#optimization
opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)

#model evaluation
correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))
accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))

#initialize variables
init=tf.global_variables_initializer()

saver = tf.train.Saver()

with tf.Session() as sess:
    sess.run(init)
    iter=1
    while iter<800:
        batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size)

        batch_x=batch_x.reshape((batch_size,time_steps,n_input))

        sess.run(opt, feed_dict={x: batch_x, y: batch_y})

        if iter %10==0:
            acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})
            los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})
            print(""For iter "",iter)
            print(""Accuracy "",acc)
            print(""Loss "",los)
            print(""__________________"")

        filename = saver.save(sess, ""model/model.ckpt"")

        iter=iter+1

#calculating test accuracy
test_data = mnist.test.images[:128].reshape((-1, time_steps, n_input))
test_label = mnist.test.labels[:128]
print(""Testing Accuracy:"", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))
```
This is code I used for freezing the graph:
```
'''
Code from https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc
'''

import os, argparse

import tensorflow as tf

# The original freeze_graph function
# from tensorflow.python.tools.freeze_graph import freeze_graph

dir = os.path.dirname(os.path.realpath(__file__))

def freeze_graph(model_dir, output_node_names):
    """"""Extract the sub graph defined by the output nodes and convert
    all its variables into constant
    Args:
        model_dir: the root folder containing the checkpoint state file
        output_node_names: a string, containing all the output node's names,
                            comma separated
    """"""
    if not tf.gfile.Exists(model_dir):
        raise AssertionError(
            ""Export directory doesn't exists. Please specify an export ""
            ""directory: %s"" % model_dir)

    if not output_node_names:
        print(""You need to supply the name of a node to --output_node_names."")
        return -1

    # We retrieve our checkpoint fullpath
    checkpoint = tf.train.get_checkpoint_state(model_dir)
    input_checkpoint = checkpoint.model_checkpoint_path

    # We precise the file fullname of our freezed graph
    absolute_model_dir = ""/"".join(input_checkpoint.split('/')[:-1])
    output_graph = absolute_model_dir + ""/frozen_model.pb""

    # We clear devices to allow TensorFlow to control on which device it will load operations
    clear_devices = True

    # We start a session using a temporary fresh Graph
    with tf.Session(graph=tf.Graph()) as sess:
        # We import the meta graph in the current default Graph
        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)

        # We restore the weights
        saver.restore(sess, input_checkpoint)

        # We use a built-in TF helper to export variables to constants
        output_graph_def = tf.graph_util.convert_variables_to_constants(
            sess, # The session is used to retrieve the weights
            tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes
            output_node_names.split("","") # The output node names are used to select the usefull nodes
        )

        # Finally we serialize and dump the output graph to the filesystem
        with tf.gfile.GFile(output_graph, ""wb"") as f:
            f.write(output_graph_def.SerializeToString())
        print(""%d ops in the final graph."" % len(output_graph_def.node))

    return output_graph_def

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(""--model_dir"", type=str, default="""", help=""Model folder to export"")
    parser.add_argument(""--output_node_names"", type=str, default="""", help=""The name of the output nodes, comma separated."")
    args = parser.parse_args()

    freeze_graph(args.model_dir, args.output_node_names)
```

This is the output of the toco command:
```
2018-01-02 20:05:24.912921: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.
2018-01-02 20:05:24.973744: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1099] Converting unsupported operation: Unpack
2018-01-02 20:05:24.974315: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1099] Converting unsupported operation: StridedSlice
2018-01-02 20:05:25.041459: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1209 operators, 1775 arrays (0 quantized)
2018-01-02 20:05:25.118862: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 1114 operators, 1672 arrays (0 quantized)
2018-01-02 20:05:25.176555: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 1114 operators, 1672 arrays (0 quantized)
2018-01-02 20:05:25.208552: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.
2018-01-02 20:05:25.234811: F tensorflow/contrib/lite/toco/tflite/export.cc:303] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: ExpandDims, Fill, SPLIT, StridedSlice, TensorFlowShape, Unpack.
pbtotflite.sh: line 8:  8277 Abort trap: 6           ~/tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=""$(pwd)/lstm-model.pb"" --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=""$(pwd)/lstm-model.tflite"" --inference_type=FLOAT --input_type=FLOAT --input_arrays=input --output_arrays=output --input_shapes=28,28
```",1,,2,2018-01-03T04:08:53Z,NONE
15793,Feature Request: tf.train.MonitoredTrainingSession implementation for slim.learning.train,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**:  N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

This is a feature request:
Issue #6263 states that tf.train.Supervisor is to be deprecated. Since the slim.learning.train uses Supervisor internally, is it still advisable to use it?
Or are there any chances to implement the slim.learning.train to use tf.train.MonitoredSession instead of Supervisor?

@sguada 

Thanks!
  ",0,,4,2018-01-02T20:32:41Z,NONE
15792,Portability of TensorFlow Meta graph file,,"OS Platform and Distribution : CentOS
TensorFlow installed from : Sources
TensorFlow version : 1.4
Bazel version : N/A
CUDA/cuDNN version 8.0 (CUDA) and 6.0 (CuDNN)
GPU model and memory : N/A
Exact command to reproduce : N/A

The `.meta` file from TensorFlow contains device information. Although I can use `clear_devices=False` to prevent device information getting logged, I beg to ask the relevance of the `.meta` file with respect to portability.

 1. If I have the code for the generation of the TensorFlow graph, then I do not need the `.meta` file as per [this answer][1]. 

 2. What is the applicability of transferring only the `.meta` file to someone ? 

 3. Assuming that I train the graph with 4 GPUs, and then provide `.meta` file to someone with 8 or possibly only 1 GPU. For someone with 8 GPUs, would this not prevent him/her from actually running the graph for training/inference over 8 GPUs ? In the case of someone with only 1 GPU, what would happen to entities with device numbers 1-3 ?

 4. And finally, what are the implications of point 3, when `clear_devices=True` ? 

  [1]: https://stackoverflow.com/a/36203288/8530591
  ",0,,3,2018-01-02T20:26:30Z,NONE
15786,order quantized table by value for ease of reading,"awaiting review,cla: yes",,1,,2,2018-01-02T15:11:05Z,CONTRIBUTOR
15783,CUDA crashes during Cholesky_grad procedure,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (see command below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary (pip)
- **TensorFlow version (use command below)**: 'unknown' 1.4.0
- **Python version**: 3.5.2
- **CUDA/cuDNN version**: Cuda: 8.0.61.2; cuDNN: 6.1
- **GPU model and memory**: GeForce GTX 770M (3GB); NVIDIA driver 388.71
- **Bazel version**: N/A
- **Exact command to reproduce**:
```
import tensorflow as tf
import numpy as np

with tf.Session() as sess:
    x = tf.placeholder(tf.float64, [None, None])
    f = tf.reduce_sum(tf.cholesky(x))
    sess.run(tf.global_variables_initializer())
    print(sess.run(tf.gradients(f, x), {x:np.array(1.).reshape(1, 1)}))
```

### Describe the problem
Python crashes when running the code above. It was initially encountered when trying to perform a Cholesky decomposition during sparse Gaussian process regression (see https://github.com/GPflow/GPflow/issues/602). I am out of my depth here, but the following error messages seemed interesting:
* Address 0x00000000 is out of bounds
* Blas GEMV launch failed
* failed to run cuBLAS routine cublasDgemv_v2: CUBLAS_STATUS_EXECUTION_FAILED

I have run various CUDA profiling tests and have had no issues. The cholesky decomposition example that comes with CUDA could also execute just fine. I have tried both reducing the amount of GPU memory available to tensorflow _and_ setting it grow-able, to no effect.

### Source code / logs
See above for source code.

stdout/stderr:
```
2018-01-02 18:14:34.305556: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-01-02 18:14:35.110794: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 770M major: 3 minor: 0 memoryClockRate(GHz): 0.797
pciBusID: 0000:01:00.0
totalMemory: 3.00GiB freeMemory: 2.50GiB
2018-01-02 18:14:35.110932: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 770M, pci bus id: 0000:01:00.0, compute capability: 3.0)
2018-01-02 18:14:35.290410: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\kernels\cuda_solvers.cc:159] Creating CudaSolver handles for stream 00000189FC81C670
2018-01-02 18:14:35.615695: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
2018-01-02 18:14:35.615847: F C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:203] Unexpected Event status: 1
2018-01-02 18:14:35.615695: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\stream_executor\cuda\cuda_driver.cc:1110] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available
```

cuda-memcheck:
```
========= CUDA-MEMCHECK
2018-01-02 18:15:26.061068: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-01-02 18:15:26.872851: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 770M major: 3 minor: 0 memoryClockRate(GHz): 0.797
pciBusID: 0000:01:00.0
totalMemory: 3.00GiB freeMemory: 2.52GiB
2018-01-02 18:15:26.873028: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 770M, pci bus id: 0000:01:00.0, compute capability: 3.0)
2018-01-02 18:15:27.425673: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\kernels\cuda_solvers.cc:159] Creating CudaSolver handles for stream 00000162C1EBD150
2018-01-02 18:15:30.721433: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_blas.cc:551] failed to run cuBLAS routine cublasDgemv_v2: CUBLAS_STATUS_EXECUTION_FAILED
Traceback (most recent call last):
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1323, in _do_call
    return fn(*args)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Blas GEMV launch failed:  m=1, n=1
         [[Node: gradients/Cholesky_grad/MatMul_1 = MatMul[T=DT_DOUBLE, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients/Cholesky_grad/MatrixTriangularSolve, gradients/Cholesky_grad/MatrixBandPart)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test2.py"", line 11, in <module>
    print(sess.run(tf.gradients(f, x), {x:np.array(1.).reshape(1, 1)}))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run
    run_metadata_ptr)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas GEMV launch failed:  m=1, n=1
         [[Node: gradients/Cholesky_grad/MatMul_1 = MatMul[T=DT_DOUBLE, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients/Cholesky_grad/MatrixTriangularSolve, gradients/Cholesky_grad/MatrixBandPart)]]

Caused by op 'gradients/Cholesky_grad/MatMul_1', defined at:
  File ""test2.py"", line 11, in <module>
    print(sess.run(tf.gradients(f, x), {x:np.array(1.).reshape(1, 1)}))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 581, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 353, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 581, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\linalg_grad.py"", line 77, in _CholeskyGrad
    math_ops.matmul(l_inverse, middle, adjoint_a=True), l_inverse)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1891, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 2436, in _mat_mul
    name=name)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

...which was originally created as op 'Cholesky', defined at:
  File ""test2.py"", line 9, in <module>
    f = tf.reduce_sum(tf.cholesky(x))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gen_linalg_ops.py"", line 419, in cholesky
    ""Cholesky"", input=input, name=name)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InternalError (see above for traceback): Blas GEMV launch failed:  m=1, n=1
         [[Node: gradients/Cholesky_grad/MatMul_1 = MatMul[T=DT_DOUBLE, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients/Cholesky_grad/MatrixTriangularSolve, gradients/Cholesky_grad/MatrixBandPart)]]

========= Invalid __global__ read of size 1
=========     at 0x00000398 in void Eigen::internal::FullReductionKernel<int=256, int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<double>, Eigen::DimensionList<__int64, unsigned __int64=2> const , Eigen::TensorGeneratorOp<tensorflow::generator::OverwriteDiagGenerator<double>, Eigen::TensorMap<Eigen::Tensor<double const , int=2, int=1, __int64>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<double>, __int64>(Eigen::internal::SumReducer<double>, double, __int64, Eigen::internal::SumReducer<double>::CoeffReturnType*, unsigned int*)
=========     by thread (0,0,0) in block (0,0,0)
=========     Address 0x00000000 is out of bounds
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame:C:\WINDOWS\SYSTEM32\nvcuda.dll (cuTexRefSetAddress + 0x1aaaf3) [0x1b8145]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd [0x35d2]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd [0x2365]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (perftools::gputools::cuda::CUDATimer::Stop + 0x1cf760) [0x2202ba0]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (perftools::gputools::cuda::CUDATimer::Stop + 0x1d18f2) [0x2204d32]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (perftools::gputools::cuda::CUDATimer::Stop + 0x1ce985) [0x2201dc5]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::MatrixSetDiagOp<Eigen::GpuDevice,double>::Compute + 0x407) [0x13180d7]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::BaseGPUDevice::ComputeHelper + 0x4f4) [0x3aab84]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::BaseGPUDevice::Compute + 0x18a) [0x3aa3aa]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::NewLocalExecutor + 0xfdb) [0x2aefdb]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (?_Copy@?$_Func_impl@V?$_Binder@U_Unforced@std@@P8ExecutorState@?A0x4546b700@tensorflow@@EAAXUTaggedNode@345@_J@ZQEAV345@AEBU6345@AEA_J@std@@V?$allocator@H@2@X$$V@std@@EEBAPEAV?$_Func_base@X$$V@2@PEAX@Z + 0x78) [0x2b2548]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop + 0x3d9) [0x247839]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop + 0x560) [0x2479c0]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::WindowsFileSystem::Utf8ToWideChar + 0x175) [0x276795]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::WindowsFileSystem::Utf8ToWideChar + 0xc9) [0x2766e9]
=========     Host Frame:C:\WINDOWS\System32\ucrtbase.dll (iswascii + 0xa5) [0x1d885]
=========     Host Frame:C:\WINDOWS\System32\KERNEL32.DLL (BaseThreadInitThunk + 0x14) [0x11fe4]
=========     Host Frame:C:\WINDOWS\SYSTEM32\ntdll.dll (RtlUserThreadStart + 0x21) [0x6ef91]
=========
========= ERROR SUMMARY: 1 error
```

  ",0,,4,2018-01-02T10:27:26Z,NONE
15779,"I have simple question on tensorflow , Does tensorflow support for IONIC (Hybrid-Applications), I mean the models that we genarate through tensorflow that will support for Ionic application.",stat:awaiting response,"  I have simple question on tensorflow , Does tensorflow support for IONIC (Hybrid-Applications), I mean the models that we genarate through tensorflow that will support for Ionic application",0,,2,2018-01-02T04:50:50Z,NONE
15778,Add `colors` support for `tf.image.draw_bounding_boxes`,"awaiting review,cla: yes","This fix tries to address the issue raised in #15692 where it was not possible to specify the colors for boxes in `tf.image.draw_bounding_boxes`. Instead, a predefined fixed color table was used to cycle through colors.

This fix adds `colors` Input to `DrawBoundingBoxexV2` so that it is possible to specify the color. In case no color is specified, the default color table will be used.

Since there is an API change, the op is labeled as V2.

This fix fixes #15692.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,1,2018-01-01T23:55:48Z,MEMBER
15777,libstdc++.so.6: version `CXXABI_1.3.8' not found,,"All of my `tf-nightly` Travis CI pipelines started failing today with following error

``` ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/travis/virtualenv/python3.5.4/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)```

Example:
https://travis-ci.org/yaroslavvb/chain_constant_memory/builds/323851093

Any ideas how to fix?
",1,,22,2018-01-01T21:56:33Z,CONTRIBUTOR
15776,Compiler Errors Installing Tensorflow from Source,stat:awaiting response,"### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 SP1
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.5
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 6.4.0
- **CUDA/cuDNN version**: 7.0
- **GPU model and memory**: NVIDIA Quadro K4000

- **Exact command to reproduce**:

bazel build -c opt %BUILD_OPTS% //tensorflow/tools/pip_package:build_pip_package

### Describe the problem

I have tried compiling with MSYS2 and VS2015. I am trying to get VS2015 to work.

###Using VS2015 and `--cpu=x64_windows_msvc --host_cpu=x64_windows_msvc` (among other options), I get the following error:

```
c:\Users\adam.hendry\Downloads\tensorflow>bazel build -c opt %BUILD_OPTS% //tens
orflow/tools/pip_package:build_pip_package
.......................
Loading:
Loading: 0 packages loaded
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (48 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (81 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (93 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (94 packages
loaded)
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/core/BUILD:1807:1:
 in includes attribute of cc_library rule //tensorflow/core:framework_headers_li
b: '../../external/nsync/public' resolves to 'external/nsync/public' not below t
he relative path of its package 'tensorflow/core'. This will be an error in the
future. Since this rule was created by the macro 'cc_header_only_library', the e
rror might have been caused by the macro implementation in C:/users/adam.hendry/
downloads/tensorflow/tensorflow/tensorflow.bzl:1138:30
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (116 packages
 loaded)
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (127 pack
ages loaded).
INFO: Found 1 target...
Building: no action
[0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt
INFO: From Compiling external/zlib_archive/uncompr.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzlib.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/adler32.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzclose.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/compress.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
[134 / 1,014] Compiling external/zlib_archive/deflate.c [for host]; 1s local ...
 (16 actions, 14 running)
INFO: From Compiling external/zlib_archive/infback.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling tensorflow/core/lib/hash/crc32c_accelerate.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/highwayhash/highwayhash/arch_specific.cc [for host
]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/crc32.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inflate.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inftrees.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzread.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzwrite.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/zutil.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inffast.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/trees.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/deflate.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/fft2d/fft/fftsg.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/farmhash_archive/src/farmhash.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling tensorflow/compiler/xla/executable_run_options.cc:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
[349 / 1,966] Compiling external/protobuf_archive/src/google/protobuf/compiler/j
s/embed.cc [for host]; 1s local ... (5 actions, 3 running)
INFO: From Compiling external/farmhash_archive/src/farmhash.cc:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/protobuf_archive/src/google/protobuf/compiler/js/e
mbed.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling tensorflow/core/grappler/costs/robust_stats.cc:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/lmdb/midl.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
[643 / 3,343] Compiling external/lmdb/mdb.c; 0s local ... (23 actions, 22 runnin
g)
INFO: From Compiling external/zlib_archive/gzread.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/trees.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzclose.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzwrite.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/crc32.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inffast.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inftrees.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/compress.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/uncompr.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/zutil.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzlib.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/infback.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/deflate.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inflate.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/adler32.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/png_archive/pngtrans.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/highwayhash/highwayhash/sip_hash.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/png_archive/pngget.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/png_archive/pngread.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
ERROR: C:/users/adam.hendry/downloads/tensorflow/tensorflow/compiler/xla/service
/cpu/BUILD:772:1: C++ compilation of rule '//tensorflow/compiler/xla/service/cpu
:custom_call_target_registry' failed (Exit 1): cl.exe failed: error executing co
mmand
  cd C:/users/adam.hendry/appdata/local/temp/_bazel_adam.hendry/qoyar4dt/execroo
t/org_tensorflow
  SET CUDA_COMPUTE_CAPABILITIE=None
    SET CUDA_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.1
    SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.
1
    SET CUDNN_INSTALL_PATH=C:/cuda
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C
:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\INCLUDE;C:\Program
Files (x86)\Windows Kits\10\include\10.0.16299.0\ucrt;C:\Program Files (x86)\Win
dows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\10\inclu
de\10.0.16299.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.16299
.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.16299.0\winrt;
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\LIB\amd64;C:\
Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\LIB\amd64;C:\Program
Files (x86)\Windows Kits\10\lib\10.0.16299.0\ucrt\x64;C:\Program Files (x86)\Win
dows Kits\NETFXSDK\4.6.1\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\1
0.0.16299.0\um\x64;
    SET NO_WHOLE_ARCHIVE_OPTION=1
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE\Com
monExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studi
o 14.0\VC\BIN\amd64;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program F
iles (x86)\Microsoft Visual Studio 14.0\VC\VCPackages;C:\Program Files (x86)\Mic
rosoft Visual Studio 14.0\Common7\IDE;C:\Program Files (x86)\Microsoft Visual St
udio 14.0\Common7\Tools;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team
 Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio 14.0
\Team Tools\Performance Tools;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\
Program Files (x86)\Windows Kits\10\bin\x86;C:\Program Files (x86)\Microsoft SDK
s\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;;C:\Windows\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Python/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Python/Python36/lib/site-packages
    SET TEMP=C:\Users\ADAM~1.HEN\AppData\Local\Temp
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.0
    SET TF_CUDA_VERSION=9.1
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
    SET TMP=C:\Users\ADAM~1.HEN\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /c ten
sorflow/compiler/xla/service/cpu/custom_call_target_registry.cc /Fobazel-out/x64
_windows_msvc-py3-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/custom_call_
target_registry/tensorflow/compiler/xla/service/cpu/custom_call_target_registry.
o /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPR
ECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /big
obj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 -DGEMMLOWP_ALLOW_SLO
W_SCALAR_FALLBACK -w -march=native -D_GLIBCXX_USE_CXX11_ABI=0 /I. /Ibazel-out/x6
4_windows_msvc-py3-opt/genfiles /Iexternal/bazel_tools /Ibazel-out/x64_windows_m
svc-py3-opt/genfiles/external/bazel_tools /Iexternal/bazel_tools/tools/cpp/gcc3
/showIncludes /MD /O2 /DNDEBUG
C:\users\adam.hendry\appdata\local\temp\_bazel_adam.hendry\qoyar4dt\execroot\org
_tensorflow\tensorflow\compiler\xla\service\cpu\custom_call_target_registry.cc :
 fatal error C1083: Cannot open compiler generated file: '': Invalid argument
cl : Command line warning D9002 : ignoring unknown option '-march=native'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 25.271s, Critical Path: 3.48s
FAILED: Build did NOT complete successfully
```

###Using VS2015 and `--cpu=x64_windows_msys --host_cpu=x64_windows_msys` (among other options), I get this error:

```
c:\Users\adam.hendry\Downloads\tensorflow>bazel build -c opt %BUILD_OPTS% //tens
orflow/tools/pip_package:build_pip_package
.......................
Loading:
Loading: 0 packages loaded
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (73 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (131 packages
 loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (141 packages
 loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (142 packages
 loaded)
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/core/BUILD:1807:1:
 in includes attribute of cc_library rule //tensorflow/core:framework_headers_li
b: '../../external/nsync/public' resolves to 'external/nsync/public' not below t
he relative path of its package 'tensorflow/core'. This will be an error in the
future. Since this rule was created by the macro 'cc_header_only_library', the e
rror might have been caused by the macro implementation in C:/users/adam.hendry/
downloads/tensorflow/tensorflow/tensorflow.bzl:1138:30
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (157 packages
 loaded)
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/contrib/learn/BUIL
D:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflo
w/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/sessio
n_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/contrib/learn/BUIL
D:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflo
w/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/sessio
n_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (254 pack
ages loaded).
INFO: Found 1 target...
Building: no action
[0 / 17] [-----] BazelWorkspaceStatusAction stable-status.txt
[105 / 747] Executing genrule @local_config_cuda//cuda:cuda-lib; 2s local ... (2
4 actions running)
[106 / 747] Executing genrule @local_config_cuda//cuda:cuda-lib; 5s local ... (2
3 actions running)
[111 / 747] Executing genrule @local_config_cuda//cuda:cuda-lib; 10s local ... (
24 actions running)
[113 / 747] Executing genrule //tensorflow/core:version_info_gen [for host]; 13s
 local ... (23 actions running)
[129 / 968] Executing genrule //tensorflow/core:version_info_gen [for host]; 20s
 local ... (24 actions running)
[148 / 1,274] Executing genrule //tensorflow/core:version_info_gen [for host]; 3
1s local ... (24 actions running)
[149 / 1,275] Executing genrule //tensorflow/core:version_info_gen [for host]; 3
7s local ... (24 actions running)
[149 / 1,275] Executing genrule //tensorflow/core:version_info_gen [for host]; 4
6s local ... (24 actions running)
[155 / 1,279] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 57s local ... (23 actions running)
[228 / 1,543] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 68s local ... (24 actions, 23 running)
[417 / 2,009] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 83s local ... (24 actions, 23 running)
[437 / 2,009] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 98s local ... (23 actions running)
[458 / 2,009] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 115s local ... (24 actions, 23 running)
[523 / 2,096] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 135s local ... (24 actions, 23 running)
ERROR: C:/users/adam.hendry/appdata/local/temp/_bazel_adam.hendry/qoyar4dt/exter
nal/com_google_absl/absl/base/BUILD.bazel:30:1: C++ compilation of rule '@com_go
ogle_absl//absl/base:spinlock_wait' failed (Exit 1): gcc failed: error executing
 command
  cd C:/users/adam.hendry/appdata/local/temp/_bazel_adam.hendry/qoyar4dt/execroo
t/org_tensorflow
  SET CUDA_COMPUTE_CAPABILITIE=None
    SET CUDA_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.1
    SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.
1
    SET CUDNN_INSTALL_PATH=C:/cuda
    SET NO_WHOLE_ARCHIVE_OPTION=1
    SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\Program Files (x86)\Microsoft Vi
sual Studio 14.0\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Fi
les (x86)\MSBuild\14.0\bin;C:\Program Files (x86)\Microsoft Visual Studio 14.0\C
ommon7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN;C:\Progra
m Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools;C:\Windows\Microsoft.NE
T\Framework\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\VC
Packages;C:\Program Files (x86)\HTML Help Workshop;C:\Program Files (x86)\Micros
oft Visual Studio 14.0\Team Tools\Performance Tools;C:\Program Files (x86)\Windo
ws Kits\10\bin\x86;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETF
X 4.6.1 Tools\;C:\Program Files (x86)\Microsoft Visual Studio 14.0\;C:\Program F
iles (x86)\Microsoft Visual Studio 14.0\VC\;C:\Program Files (x86)\Microsoft Vis
ual Studio 14.0\VC\bin\;C:\Program Files (x86)\Windows Kits\10\;C:\Python\Python
36\;C:\Python\Python36\Scripts\;C:\ProgramData\chocolatey\bin;C:\Program Files\G
it LFS;C:\Program Files\CMake\bin;C:\Program Files\Java\jdk1.8.0_152\;C:\Program
Data\Oracle\Java\javapath;C:\Windows;C:\Windows\System32;C:\Windows\System32Wbem
;C:\Windows\System32WindowsPowerShell\v1.0\;C:\bazel\output;C:\apache-maven-3.3.
9\;C:\apache-maven-3.3.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\
v9.1\;%CUDNN_PATH%;C:\Program Files\ImageMagick-7.0.5-Q16\;C:\Program Files (x86
)\QuickTime\QTSystem\;C:\Program Files (x86)\gs\gs9.21\bin\;C:\cppan\cppan.exe;C
:\Program Files (x86)\Tesseract-OCR\;C:\Program Files\MiKTeX 2.9\miktex\bin\x64\
;C:\ffmpeg\bin;C:\Users\adam.hendry\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm
\;C:\Program Files\HDF_Group\HDF5\1.10.1\bin\;C:\Program Files (x86)\GtkSharp\2.
12\bin;C:\Program Files (x86)\gettext-iconv\lib\gettext;C:\Program Files (x86)\C
ommon Files\Intel\Shared Libraries\redist\ia32\mpirt;C:\Program Files (x86)\Comm
on Files\Intel\Shared Libraries\redist\ia32\compiler;C:\Program Files\Common Fil
es\Microsoft Shared\Windows Live;C:\Program Files (x86)\Common Files\Microsoft S
hared\Windows Live;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Pro
gram Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Progr
am Files (x86)\Windows Live\Shared;C:\Program Files\Microsoft SQL Server\130\Too
ls\Binn\;C:\Intel\OpenCL\sdk\bin\x64;C:\Intel\OpenCL\sdk\bin\x86\;C:\Intel\OpenC
L\sdk\bin\Pin;C:\Intel\OpenCL\sdk\bin\GTPin;C:\Program Files\Git\cmd;
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Python/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Python/Python36/lib/site-packages
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.0
    SET TF_CUDA_VERSION=9.1
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
  C:/msys64/usr/bin/gcc -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -w -march=native -
std=gnu++0x -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MF bazel-out/x64_windows_msys-py3-op
t/bin/external/com_google_absl/absl/base/_objs/spinlock_wait/external/com_google
_absl/absl/base/internal/spinlock_wait.d -frandom-seed=bazel-out/x64_windows_msy
s-py3-opt/bin/external/com_google_absl/absl/base/_objs/spinlock_wait/external/co
m_google_absl/absl/base/internal/spinlock_wait.o -D__CLANG_SUPPORT_DYN_ANNOTATIO
N__ -iquote external/com_google_absl -iquote bazel-out/x64_windows_msys-py3-opt/
genfiles/external/com_google_absl -iquote external/bazel_tools -iquote bazel-out
/x64_windows_msys-py3-opt/genfiles/external/bazel_tools -isystem external/bazel_
tools/tools/cpp/gcc3 -Wall -Wextra -Wcast-qual -Wconversion-null -Wmissing-decla
rations -Woverlength-strings -Wpointer-arith -Wunused-local-typedefs -Wunused-re
sult -Wvarargs -Wvla -Wwrite-strings -c external/com_google_absl/absl/base/inter
nal/spinlock_wait.cc -o bazel-out/x64_windows_msys-py3-opt/bin/external/com_goog
le_absl/absl/base/_objs/spinlock_wait/external/com_google_absl/absl/base/interna
l/spinlock_wait.o
In file included from external/com_google_absl/absl/base/config.h:66:0,
                 from external/com_google_absl/absl/base/port.h:23,
                 from external/com_google_absl/absl/base/internal/spinlock_posix
.inc:23,
                 from external/com_google_absl/absl/base/internal/spinlock_wait.
cc:27:
external/com_google_absl/absl/base/policy_checks.h:40:2: error: #error ""Cygwin i
s not supported.""
 #error ""Cygwin is not supported.""
  ^~~~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 172.251s, Critical Path: 153.84s
FAILED: Build did NOT complete successfully
```

###Any help would be appreciated. I can give you more details as well.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,22,2018-01-01T20:06:46Z,NONE
15771,Flexible input shape for map method in class RandomFourierFeatureMapper,,"This is a feature request. In tensorflow r1.4, Class RandomFourierFeatureMapper, map method,
The shape of the input must be, [batch_size, self._output_dim].   

There can be scenarios where in each batch there are multiple training point, essentially i'm proposing a scenario where the input shape  must be  [batch_size, x ,self._output_dim].   

Which is not possible in current API.        
In the matmul we can see that it is mentioned, ""The inputs must, following any transpositions, be tensors of rank >= 2 where the inner 2 dimensions specify valid matrix multiplication arguments, and any further outer dimensions match."" which is in-fact very flexible.     

",0,,4,2018-01-01T15:24:40Z,NONE
15770,fix todo: make a class which constrcuts resource and provide get_next.,"awaiting review,cla: yes",,1,,3,2018-01-01T13:56:45Z,NONE
15767,Decode_raw_op_test failure on s390x,stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: s390x Ubuntu 16.04 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc 5.4.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: bazel test -c opt //tensorflow/python/kernel_tests:decode_raw_op_test

### Describe the problem
Observing a failure in [testToFloat16](https://github.com/tensorflow/tensorflow/blob/v1.4.1/tensorflow/python/kernel_tests/decode_raw_op_test.py#L77) sub test, while running `decode_raw_op_test`. It seems that the [byte-reversal logic](https://github.com/tensorflow/tensorflow/blob/v1.4.1/tensorflow/core/kernels/decode_raw_op.cc#L80) for big endian is not needed for **float16 input**(and float16 output). While the other sub tests like int16/uint16 which have byte array input need byte-swapping for consistent results. What would be the best way to correct this?
@rmlarsen, @jiefangxuanyan , Could you please share your thoughts on this?
 
### Source code / logs
```
FAIL: testToFloat16 (__main__.DecodeRawOpTest)
----------------------------------------------------------------------
.
AssertionError:
Arrays are not equal
(mismatch 100.0%)
 x: [repr failed for <matrix>: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()]
 y: array([[  3.576279e-06,   1.144409e-05,   1.156330e-05,   4.053116e-06]], dtype=float16)
----------------------------------------------------------------------
Ran 7 tests in 0.089s

FAILED (failures=1)
not equal where =  (array([0, 0, 0, 0]), array([0, 1, 2, 3]))
not equal lhs =  [[ 1. -2. -3.  4.]]
not equal rhs =  [  3.57627869e-06   1.14440918e-05   1.15633011e-05   4.05311584e-06]
```
",0,,2,2018-01-01T11:06:24Z,CONTRIBUTOR
15758,Getting rid of all_opensource_files,,"This ticket is for tracking the progress of removing the `all_opensource_files` bazel target.
See the discussion in #15368.

- [x] Turn `check_futures_test` into a sanity check #15671
- [x] De-Bazel `check_load_py_test` sanity check #15677
- [x] De-Bazel `pip_smoke_test` sanity check #15678
- [ ] Rewrite `//tensorflow/contrib/makefile:build_all_linux` #16491",1,,4,2017-12-31T14:27:44Z,CONTRIBUTOR
15753, ImportError: cannot import name 'checkpoint_ops',stat:awaiting response,"
keras version =2.0.8
tensorflow version =1.2.1
anconda and windows 10
install a binary 

> `C:\Windows\System32\YOLO_Object_Detection-master>python flow --h
Traceback (most recent call last):
  File ""flow"", line 4, in <module>
    from darkflow.cli import cliHandler
  File ""C:\Windows\System32\YOLO_Object_Detection-master\darkflow\cli.py"", line 3, in <module>
    from .net.build import TFNet
  File ""C:\Windows\System32\YOLO_Object_Detection-master\darkflow\net\build.py"", line 5, in <module>
    from .ops import op_create, identity
  File ""C:\Windows\System32\YOLO_Object_Detection-master\darkflow\net\ops\__init__.py"", line 1, in <module>
    from .simple import *
  File ""C:\Windows\System32\YOLO_Object_Detection-master\darkflow\net\ops\simple.py"", line 1, in <module>
    import tensorflow.contrib.slim as slim
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\__init__.py"", line 22, in <module>
    from tensorflow.contrib import bayesflow
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\bayesflow\__init__.py"", line 24, in <module>
    from tensorflow.contrib.bayesflow.python.ops import csiszar_divergence
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\bayesflow\python\ops\csiszar_divergence.py"", line 26, in <module>
    from tensorflow.contrib.bayesflow.python.ops.csiszar_divergence_impl import *
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\bayesflow\python\ops\csiszar_divergence_impl.py"", line 43, in <module>
    from tensorflow.contrib import framework as contrib_framework
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\framework\__init__.py"", line 89, in <module>
    from tensorflow.contrib.framework.python.ops import *
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\framework\python\ops\__init__.py"", line 24, in <module>
    from tensorflow.contrib.framework.python.ops.checkpoint_ops import *
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\framework\python\ops\checkpoint_ops.py"", line 22, in <module>
    from tensorflow.python.training import checkpoint_ops
ImportError: cannot import name 'checkpoint_ops'`
  ",0,,2,2017-12-31T11:13:22Z,NONE
15751,Uninitialised Classifier or invalid context,stat:awaiting response,"I was able to run the tensorflowlite demo app with no error. But it is not detecting the objects as it is supposed to. I have followed the instructions to be followed  in android studio in readme.
![Uploading Screenshot_20171231-151052.png…]()
",0,,3,2017-12-31T09:46:39Z,NONE
15746,CIFAR10 slows down every 100th step,,"### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: Have tried both binary and source
- **TensorFlow version**: 1.4.0-19-ga52c8d9, 1.4.1
- **Python version**: 2.7.12
- **CUDA/cuDNN version**: 8.0.61
- **Hardware**: GPU: NVIDIA GeForce GTX 1080 Ti (11GB), RAM: 64GB, CPU: Intel i7-6850K
- **Exact command to reproduce**: python cifar10_train.py

### Describe the problem
The [CIFAR10 Tensorflow tutorial](https://www.tensorflow.org/tutorials/deep_cnn) seems to have a few odd patterns when it comes to the number of examples per second it can compute:
 - Step 0 is extremely slow 
 - Every 100th step is significantly slow 
 - The step after a really slow step is either a little slow or average
 - The next 10-30 steps after that are slightly boosted (faster than average)
 - The rest of the steps are average speed

I'm hoping for (in order of importance):
 - An explanation and fix for every 100th step being so slow
 - An explanation and instructions showing me how to make every step run at the boosted speed (the speed shortly after a slow step)
 - An explanation and fix for the slow 0th and 1st step

I can't find any additional logging or processing that happens on every 100th step. Could it be `tf.train.MonitoredSession`?

### Reproducible:
- when training on CPU rather than GPU
- independent of batch size
- on MacBook Pro (Retina, 13-inch, Mid 2014)

### Hardware utilization: 
1. Average:
- CPU: 82-84%
- GPU: 70-85%
- RAM: 3.7GB

2. Every 100th step:
- CPU: 9%
- GPU: 0%
- RAM: 3.7GB

3. Boosted after slow step: 
- GPU: 92%
- CPU: 82-84%
- RAM: 3.7GB

4. Idle:
- CPU: 1%
- GPU: 0%
- RAM: 1.6GB

*Overall CPU and RAM usage (clearly showing CPU trough every 100 steps)*:
![Overall CPU and RAM usage](https://user-images.githubusercontent.com/7654904/34998310-6b153646-fae7-11e7-8e0c-00ccf01349bf.png)

### Logs excerpt [(full logs)](https://github.com/tensorflow/tensorflow/files/1635342/terminalOutput.txt):

> step 0: (587.3 examples/sec; 6.974 sec/batch)
> step 1: (22630.6 examples/sec; 0.181 sec/batch)
> step 2: (36253.6 examples/sec; 0.113 sec/batch)
> step 3: (37966.0 examples/sec; 0.108 sec/batch)
> step 4: (38511.4 examples/sec; 0.106 sec/batch)
> step 5: (38554.6 examples/sec; 0.106 sec/batch)
> step 6: (32112.4 examples/sec; 0.128 sec/batch)
> step 7: (38912.4 examples/sec; 0.105 sec/batch)
> step 8: (39377.0 examples/sec; 0.104 sec/batch)
> step 9: (38206.2 examples/sec; 0.107 sec/batch)
> step 10: (38222.1 examples/sec; 0.107 sec/batch)
> step 11: (38757.5 examples/sec; 0.106 sec/batch)
> step 12: (38833.1 examples/sec; 0.105 sec/batch)
> step 13: (39774.8 examples/sec; 0.103 sec/batch)
> step 14: (39795.9 examples/sec; 0.103 sec/batch)
> step 15: (37850.5 examples/sec; 0.108 sec/batch)
> step 16: (38443.5 examples/sec; 0.107 sec/batch)
> step 17: (39194.6 examples/sec; 0.105 sec/batch)
> step 18: (39164.0 examples/sec; 0.105 sec/batch)
> step 19: (39057.5 examples/sec; 0.105 sec/batch)
> step 20: (33268.7 examples/sec; 0.123 sec/batch)
> step 21: (39459.7 examples/sec; 0.104 sec/batch)
> step 22: (39336.2 examples/sec; 0.104 sec/batch)
> step 23: (39207.1 examples/sec; 0.104 sec/batch)
> step 24: (39330.5 examples/sec; 0.104 sec/batch)
> step 25: (38783.9 examples/sec; 0.106 sec/batch)
> step 26: (39038.9 examples/sec; 0.105 sec/batch)
> step 27: (39214.2 examples/sec; 0.104 sec/batch)
> step 28: (39525.9 examples/sec; 0.104 sec/batch)
> step 29: (37209.0 examples/sec; 0.110 sec/batch)
> step 30: (38356.7 examples/sec; 0.107 sec/batch)
> step 31: (36077.0 examples/sec; 0.114 sec/batch)
> step 32: (37143.8 examples/sec; 0.110 sec/batch)
> step 33: (35961.1 examples/sec; 0.114 sec/batch)
> step 34: (33378.4 examples/sec; 0.123 sec/batch)
> step 35: (37830.3 examples/sec; 0.108 sec/batch)
> step 36: (36789.5 examples/sec; 0.111 sec/batch)
> step 37: (36638.2 examples/sec; 0.112 sec/batch)
> step 38: (36848.1 examples/sec; 0.111 sec/batch)
> step 39: (36041.4 examples/sec; 0.114 sec/batch)
> step 40: (36612.0 examples/sec; 0.112 sec/batch)
> step 41: (35623.9 examples/sec; 0.115 sec/batch)
> step 42: (37589.3 examples/sec; 0.109 sec/batch)
> step 43: (37462.9 examples/sec; 0.109 sec/batch)
> step 44: (35823.6 examples/sec; 0.114 sec/batch)
> step 45: (35911.8 examples/sec; 0.114 sec/batch)
> step 46: (36073.8 examples/sec; 0.114 sec/batch)
> step 47: (36930.2 examples/sec; 0.111 sec/batch)
> step 48: (36142.9 examples/sec; 0.113 sec/batch)
> ...
> step 99: (36434.8 examples/sec; 0.112 sec/batch)
> step 100: (1215.0 examples/sec; 3.371 sec/batch)
> step 101: (35952.9 examples/sec; 0.114 sec/batch)
> step 102: (38422.5 examples/sec; 0.107 sec/batch)
> step 103: (39315.8 examples/sec; 0.104 sec/batch)
> step 104: (38989.1 examples/sec; 0.105 sec/batch)
> step 105: (39091.4 examples/sec; 0.105 sec/batch)
> step 106: (39247.6 examples/sec; 0.104 sec/batch)
> step 107: (38009.7 examples/sec; 0.108 sec/batch)
> step 108: (38746.7 examples/sec; 0.106 sec/batch)
> step 109: (39505.4 examples/sec; 0.104 sec/batch)
> step 110: (39340.0 examples/sec; 0.104 sec/batch)
> step 111: (39065.0 examples/sec; 0.105 sec/batch)
> step 112: (38561.1 examples/sec; 0.106 sec/batch)
> step 113: (39109.0 examples/sec; 0.105 sec/batch)
> step 114: (39203.7 examples/sec; 0.104 sec/batch)
> step 115: (39144.4 examples/sec; 0.105 sec/batch)
> step 116: (38317.6 examples/sec; 0.107 sec/batch)
> step 117: (33757.5 examples/sec; 0.121 sec/batch)
> step 118: (34115.4 examples/sec; 0.120 sec/batch)
> step 119: (35671.4 examples/sec; 0.115 sec/batch)
> step 120: (35297.2 examples/sec; 0.116 sec/batch)
> step 121: (36152.8 examples/sec; 0.113 sec/batch)
> step 122: (35780.1 examples/sec; 0.114 sec/batch)
> step 123: (35847.1 examples/sec; 0.114 sec/batch)
> step 124: (36888.9 examples/sec; 0.111 sec/batch)
> step 125: (36946.2 examples/sec; 0.111 sec/batch)
> ...",0,,6,2017-12-31T09:02:50Z,NONE
15735,Segmentation fault when using cuDNN LSTMs + orthogonal initializer,stat:awaiting tensorflower,"On TF 1.4.0 with CUDA 8.0 and cuDNN 7, I get a segmentation fault if I use an orthogonal initializer for the `kernel_initializer` argument of `cudnn_rnn.CudnnLSTM` (the layers version not the op). I'm aware of #14306 but since I'm running into this problem with the cuDNN LSTMs and not the native TF ones I suspect the underlying cause is different.",0,,2,2017-12-30T15:09:00Z,NONE
15733,"""Failed to load the native TensorFlow runtime."" error on Raspbian stretch",,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Raspbian Strecth
- **TensorFlow installed from (source or binary)**: Source (Compiled from git on raspberry pi 3)
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: gcc version 4.8.5 (Raspbian 4.8.5-4) 
- **CUDA/cuDNN version**: No (nonconfigured)
- **GPU model and memory**:No (nonconfigured)
- **Exact command to reproduce**: python3 "">>> import tensorflow""
Hi,
I have compiled tensorflow's 1.4.1 source code from git source. There was no error while compiling from source but after installition by pip3, I can't import tensorflow library in python3
When I gave ""import tensorflow"" command in the python 3 shell it gives this error:

 "">>> import tensorflow
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws11Environment6GetEnvEPKc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws11Environment6GetEnvEPKc


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems""

",0,,4,2017-12-30T14:40:22Z,NONE
15732,Missing OpKernel when using selective registration header,,"I use the `bazel-bin/tensorflow/python/tools/print_selective_registration_header` to find out all necessary ops and kernels for my `test.pb`, and then compile them into a android executable

`bazel build test/test:test_run --copt=-DSELECTIVE_REGISTRATION  --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a`

The `ops_to_register.h` is as follows

```
// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER
constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || (strcmp(op, ""Add"") == 0)
     || (strcmp(op, ""AddN"") == 0)
     || (strcmp(op, ""ApplyGradientDescent"") == 0)
     || (strcmp(op, ""Assign"") == 0)
     || (strcmp(op, ""AssignAdd"") == 0)
     || (strcmp(op, ""BiasAdd"") == 0)
     || (strcmp(op, ""BiasAddGrad"") == 0)
     || (strcmp(op, ""BroadcastGradientArgs"") == 0)
     || (strcmp(op, ""ConcatOffset"") == 0)
     || (strcmp(op, ""ConcatV2"") == 0)
     || (strcmp(op, ""Const"") == 0)
     || (strcmp(op, ""ExpandDims"") == 0)
     || (strcmp(op, ""Fill"") == 0)
     || (strcmp(op, ""Floor"") == 0)
     || (strcmp(op, ""FloorMod"") == 0)
     || (strcmp(op, ""Gather"") == 0)
     || (strcmp(op, ""Identity"") == 0)
     || (strcmp(op, ""L2Loss"") == 0)
     || (strcmp(op, ""MatMul"") == 0)
     || (strcmp(op, ""Minimum"") == 0)
     || (strcmp(op, ""Mul"") == 0)
     || (strcmp(op, ""Neg"") == 0)
     || (strcmp(op, ""NoOp"") == 0)
     || (strcmp(op, ""Pack"") == 0)
     || (strcmp(op, ""Placeholder"") == 0)
     || (strcmp(op, ""PlaceholderWithDefault"") == 0)
     || (strcmp(op, ""PreventGradient"") == 0)
     || (strcmp(op, ""RandomUniform"") == 0)
     || (strcmp(op, ""RealDiv"") == 0)
     || (strcmp(op, ""Reshape"") == 0)
     || (strcmp(op, ""ScatterSub"") == 0)
     || (strcmp(op, ""Shape"") == 0)
     || (strcmp(op, ""Sigmoid"") == 0)
     || (strcmp(op, ""SigmoidGrad"") == 0)
     || (strcmp(op, ""Size"") == 0)
     || (strcmp(op, ""Slice"") == 0)
     || (strcmp(op, ""Softmax"") == 0)
     || (strcmp(op, ""SparseSoftmaxCrossEntropyWithLogits"") == 0)
     || (strcmp(op, ""Split"") == 0)
     || (strcmp(op, ""SplitV"") == 0)
     || (strcmp(op, ""Sqrt"") == 0)
     || (strcmp(op, ""Squeeze"") == 0)
     || (strcmp(op, ""StridedSlice"") == 0)
     || (strcmp(op, ""Sub"") == 0)
     || (strcmp(op, ""Sum"") == 0)
     || (strcmp(op, ""Tanh"") == 0)
     || (strcmp(op, ""TanhGrad"") == 0)
     || (strcmp(op, ""Tile"") == 0)
     || (strcmp(op, ""TopKV2"") == 0)
     || (strcmp(op, ""Unpack"") == 0)
     || (strcmp(op, ""VariableV2"") == 0)
     || (strcmp(op, ""ZerosLike"") == 0)
     || (strcmp(op, ""_Recv"") == 0)
     || (strcmp(op, ""_Send"") == 0)
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)


    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
""BinaryOp< CPUDevice, functor::add<float>>"",
""AddNOp< CPUDevice, float>"",
""ApplyGradientDescentOp<CPUDevice, float>"",
""AssignOpT<CPUDevice, ::tensorflow::int64>"",
""AssignOpT<CPUDevice, float>"",
""DenseUpdateOp<CPUDevice, ::tensorflow::int64, DenseUpdateType::ADD>"",
""BiasOp<CPUDevice, float>"",
""BiasGradOp<CPUDevice, float>"",
""BCastGradArgsOp"",
""ConcatOffsetOp"",
""ConcatV2Op<CPUDevice, ::tensorflow::int32>"",
""ConcatV2Op<CPUDevice, float>"",
""ConstantOp"",
""ExpandDimsOp"",
""FillOp<CPUDevice, float>"",
""UnaryOp< CPUDevice, functor::floor<float>>"",
""BinaryOp< CPUDevice, functor::safe_floor_mod<int32>>"",
""GatherOp<CPUDevice, float, int32>"",
""IdentityOp"",
""L2LossOp<CPUDevice, float>"",
""MatMulOp<CPUDevice, float, false >"",
""BinaryOp< CPUDevice, functor::minimum<float>>"",
""BinaryOp< CPUDevice, functor::mul<float>>"",
""UnaryOp< CPUDevice, functor::neg<float>>"",
""NoOp"",
""PackOp<CPUDevice, ::tensorflow::int32>"",
""PackOp<CPUDevice, float>"",
""PlaceholderOp"",
""IdentityOp"",
""IdentityOp"",
""PhiloxRandomOp<CPUDevice, random::UniformDistribution< random::PhiloxRandom, float> >"",
""BinaryOp< CPUDevice, functor::div<float>>"",
""ReshapeOp"",
""ScatterUpdateOp< CPUDevice, float, int32, scatter_op::UpdateOp::SUB>"",
""ShapeOp<int32>"",
""UnaryOp< CPUDevice, functor::sigmoid<float>>"",
""SimpleBinaryOp< CPUDevice, functor::sigmoid_grad<float>>"",
""SizeOp<int32>"",
""SliceOp<CPUDevice, ::tensorflow::int32>"",
""SliceOp<CPUDevice, float>"",
""SoftmaxOp<CPUDevice, float>"",
""SparseSoftmaxXentWithLogitsOp<CPUDevice, float, int32>"",
""SplitOpCPU<float>"",
""SplitVOpCPU<float, int32>"",
""UnaryOp< CPUDevice, functor::sqrt<float>>"",
""SqueezeOp"",
""StridedSliceOp<CPUDevice, ::tensorflow::int32>"",
""StridedSliceOp<CPUDevice, float>"",
""BinaryOp< CPUDevice, functor::sub<float>>"",
""ReductionOp<CPUDevice, float, Eigen::internal::SumReducer<float>>"",
""UnaryOp< CPUDevice, functor::tanh<float>>"",
""SimpleBinaryOp< CPUDevice, functor::tanh_grad<float>>"",
""TileOp<CPUDevice>"",
""TopK<float>"",
""UnpackOp<CPUDevice, float>"",
""VariableOp"",
""ZerosLikeOp< CPUDevice, float>"",
""RecvOp"",
""SendOp"",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

#define SHOULD_REGISTER_OP_GRADIENT false
#endif
```

However, when I try to run the executable on my Android device, it says some kernels are missed.

```
Error creating graph: Invalid argument: No OpKernel was registered to support Op 'Placeholder' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: OnlineTraining/Model/Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[2000,400]]()]]
```

How can I generate a complete file for this? If necessary I can also upload the `test.pb` file for testing.",0,,6,2017-12-30T13:27:02Z,NONE
15729,Feature Request: 'msg' parameter for test cases.,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Not relevant
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: Master rev. 3629fc4e98254c37e614ac3f77fa250b75c70f8d
- **Python version**: 2/3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  Not relevant
- **GPU model and memory**: Not relevant
- **Exact command to reproduce**: Not relevant

### Describe the problem
Python's unittest module as well as numpy's testing tools allow to optionally pass a message to various assertion functions. I'd love to have this for all functions in tf.TestCase as well (quite a few already have this paramter). It allows for more descriptive error messages where many permutations of ops/dtype/cpu/gpu configurations are tested (e.g. [here](https://github.com/tensorflow/tensorflow/blob/3629fc4e98254c37e614ac3f77fa250b75c70f8d/tensorflow/python/kernel_tests/segment_reduction_ops_test.py#L109))

As many of the underlying testing functions already have a msg parameter this could easily be implemented, e.g.
```
  def assertAllClose(self, a, b, rtol=1e-6, atol=1e-6, msg=None):
    ...
      self.assertItemsEqual(
          a.keys(), b.keys(),
          msg=""mismatched keys, expected %s, got %s\n%s"" % (a.keys(), b.keys(), msg if msg else """"))
      for k in a:
        self._assertArrayLikeAllClose(
            a[k], b[k], rtol=rtol, atol=atol,
            msg=""%s: expected %s, got %s.\n%s"" % (k, a, b, msg if msg else """"))
    else:
      self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol, msg=msg)
```

Relevant functions:
- `assertAllClose`
- `assertAllCloseAccordingToType`
- `assertAllEqual`
- `assertAlmostEqual`
- `assertAlmostEquals`
- `assertArrayNear`
- `assertDeviceEqual`
- `assertNDArrayNear`
- `assertProtoEquals`
- `assertProtoEqualsVersion`
- (`assertRaises...`) adding a msg parameter to these test functions would probably break lot's of test cases, so I'd omit it
- `assertShapeEqual`
- `checkedThread`


If you agree, I'll submit a quick pull request.
",0,,4,2017-12-30T08:45:43Z,CONTRIBUTOR
15725,Source Built r1.4 on GPUs with CPU optimized is always slower than 'no cpu optimization',,"### System information
- **Have I written custom code**: Yes, the model named PSIque [arXiv:1711.10644](https://arxiv.org/abs/1711.10644)
- **OS Platform and Distribution**: CentOS 7.1/CentOS 7.3
- **TensorFlow installed from**: source build w/ Bazel
- **TensorFlow version**: 1.4
- **Python version**: Anaconda 3.6.2
- **Bazel version**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: gcc version 4.8.3 20140911 (Red Hat4.8.3-9) (GCC)
- **CUDA/cuDNN version**: CUDA 8.0/r375.26/cuDNN 6.0.0 & CUDA 9.0/r384.81/cuDNN 7.0.5 
- **GPU model and memory**: E5-2660v3*2 Socket, K40m 12GB, P100-PCIE-16GB
- **Exact command to reproduce**: python model.py

### Describe the problem
* I built tensorflow from source for boosting operation performance.

* 6 different distributions were built;
  * CPU only & No CPU optimization (NO EXTRA flags)
  * CPU only & CPU optimization (--config=opt)
  * GPU support & CUDA 8/9 & No CPU optimization (--config=cuda)
  * GPU support & CUDA 8/9 & CPU optimization (--config=opt --config=cuda)

* Experiments were basically done by 5 phases; experiments on CPU only are still going on,
so please focus on GPU version results.

* Results are quite frustrating me, because 'most of CPU optimized versions' gave me slow results.
![results](https://user-images.githubusercontent.com/20734988/34451067-1d8c1cf0-ed5e-11e7-9a4f-3ff21a5c9aea.png)

* Test were made on multiple machine with random order.
  * P100: 2 nodes
  * K40m: 7 nodes
  * CPU only: 8 nodes

* I am curious why CPU optimized version is slow
  * on every experiment combinations
  * even different GPU environments
  * even Dual CPU socket (E5-2660v3)

* (Extra) I believe my current model does not require high throughputs

### tf_env_collect.sh
== cat /etc/issue ===============================================
Linux <hostname> 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9)
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux vis5 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = b'unknown'
tf.COMPILER_VERSION = b'unknown'
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Sat Dec 30 12:39:08 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |
| N/A   28C    P0    35W / 250W |      0MiB / 16276MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |
| N/A   35C    P0    38W / 250W |  15661MiB / 16276MiB |     19%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1     68169      C   python                                     15643MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176
/usr/local/cuda-9.0/lib64/libcudart_static.a
",0,,4,2017-12-30T03:46:20Z,NONE
15722,Image Adjustments API doesn't clearly specify input range,type:bug/performance,"### Describe the problem

There is a documentation issue with a possible corresponding tf.keras bug.
The [tf image adjustments guide](https://www.tensorflow.org/api_guides/python/image#Image_Adjustments) doesn't document the inputs. It appears they can be in a `[0, 1]` range or `[0, MAX]` based on comments in tf.slim where the relevant APIs are used. 

This may have led to preprocessing bugs in other utilities such as keras and tf.keras, which believe tf expects the range `[-1, 1]` see https://github.com/keras-team/keras/issues/8916, the following includes additional details from that issue:

It appears Keras' imagenet image preprocessing may be inconsistent with how it is done in tf, in particular keras sets values to `[-1, 1]` while in tf the expected range is `[0, 1]`.

- [slim/preprocessing/inception_preprocessing.py](https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/inception_preprocessing.py#L284) 
    - notes `If dtype is tf.float32 then the range should be [0, 1]`
- [keras preprocess_input()](https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py#L72) 
    - notes `tf: will scale pixels between -1 and 1, sample-wise`.

Here is the key doc from Keras' `preprocess_input()`:

```python

def preprocess_input(x, data_format=None, mode='caffe'):
    """"""Preprocesses a tensor encoding a batch of images.
    # Arguments
        x: input Numpy or symoblic tensor, 3D or 4D.
        data_format: data format of the image tensor.
        mode: One of ""caffe"", ""tf"".
            - caffe: will convert the images from RGB to BGR,
                then will zero-center each color channel with
                respect to the ImageNet dataset,
                without scaling.
            - tf: will scale pixels between -1 and 1,
                sample-wise.
    # Returns
        Preprocessed tensor.
    """"""
```

Here are the key docs from the tf slim function `preprocess_for_train()` which specify a [0, 1] range:

```python
def preprocess_for_train(image, height, width, bbox,
                         fast_mode=True,
                         scope=None,
                         add_image_summaries=True):
  """"""Distort one image for training a network.
  Distorting images provides a useful technique for augmenting the data
  set during training in order to make the network invariant to aspects
  of the image that do not effect the label.
  Additionally it would create image_summaries to display the different
  transformations applied to the image.
  Args:
    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be
      [0, 1], otherwise it would converted to tf.float32 assuming that the range
      is [0, MAX], where MAX is largest positive representable number for
      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).
    height: integer
    width: integer
    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
      where each coordinate is [0, 1) and the coordinates are arranged
      as [ymin, xmin, ymax, xmax].
    fast_mode: Optional boolean, if True avoids slower transformations (i.e.
      bi-cubic resizing, random_hue or random_contrast).
    scope: Optional scope for name_scope.
    add_image_summaries: Enable image summaries.
  Returns:
    3-D float Tensor of distorted image used for training with range [-1, 1].
  """"""
```

side note: 

- https://github.com/tensorflow/models/issues/2217 seems relevant
- https://github.com/keras-team/keras/issues/8916 is the corresponding keras issue

### System information

Not relevant, this is a documentation + input value range issue.

### Source code / logs

relevant links + code included above",1,,6,2017-12-29T23:10:37Z,NONE
15720,How to remove unwanted warning while using GPU with tensorflow,,"### System information
- I am using tensorflow version :
- OS Platform and Distribution: Linux64-:
- TensorFlow installed from pip version 1.4.1
- Python 3.6.3 :: Anaconda custom (64-bit) 
- Cuda-8.0
- GPU model and memory: nVIDIA K20 (Kepler)

### Describe the problem
I am using Adam Optimizer with a normal sequential network created via keras using tensorflow as backend. 


I get the following logs repeatedly for fitting, and creating the network. I also applied batch-normalization for the Dense Layer

/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K20Xm, pci bus id: 0000:84:00.0, compute capability: 3.5
Adam_2/decay: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0
IsVariableInitialized_14: (IsVariableInitialized): /job:localhost/replica:0/task:0/device:GPU:0
Adam_2/decay/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
Adam_2/decay/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0
Adam_2/beta_2: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0
IsVariableInitialized_13: (IsVariableInitialized): /job:localhost/replica:0/task:0/device:GPU:0

training/Adam/gradients/batch_normalization_3_1/batchnorm/mul_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0
training/Adam/gradients/batch_normalization_3_1/batchnorm/mul_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
training/Adam/gradients/batch_normalization_3_1/moments/Squeeze_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
training/Adam/gradients/zeros_87/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0

How to turn off these unwanted logs? 
I have already applied the following solution for switching off the warning logs from the tensorflow.
https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information

### Source code 
from keras.layers.normalization import BatchNormalization

model = Sequential()

model.add(Dense(64, input_dim=14, init='relu'))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Dense(64, init='uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Dense(1, init='uniform'))
model.add(BatchNormalization())
model.add(Activation('softmax'))

model.compile(loss='binary_crossentropy', optimizer=Adam())

model.fit(X_train, y_train)",1,,4,2017-12-29T19:55:43Z,NONE
15717,Performance issues when multiplying constant matrices,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, the code sample is provided below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Installed from official wheel
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**:  Python 3.6.3 | packaged by conda-forge | (default, Dec  9 2017, 16:18:26) 
[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**:  8.0/6.0.21
- **GPU model and memory**: GTX 1070, 8GB
- **Exact command to reproduce**: run the provided code sample

### Describe the problem
_I think this is a bug or an unclear performance issue. I also posted on StackOverflow to check if it was a known issue before posting, but not getting replies and I don't think it's a support problem._

I'm using Tensorflow for some non-DL computation, and I'm running into a behaviour I don't understand. I am testing the multiplication of a square matrix by itself: tf.matmul(a, a):

1. when the matrix is created with tf.constant
2. when the matrix is randomly initialized at each run

My expectation is that the first case should have some overhead for transferring the initial data, 100 MB (5000x5000 matrix using float32) but then the execution of the second case should be slightly slower due to the random initialization at each run.

However, what I see is that the multiplication of the constant is much slower even on successive runs in the same session.

Below I include logs generated on different GPUs: it seems that on lower-level GPUs (K1100M, GTX 940MX) constant multiplication is faster or the same, while on newer GPUs (GTX 1070, Tesla P100) it's slower. Details included in the logs.

### Source code 
```
import tensorflow as tf
import numpy as np
from timeit import timeit
import os

os.environ[""TF_CPP_MIN_LOG_LEVEL""]=""2""
SIZE = 5000
NUM_RUNS = 10

a = np.random.random((SIZE, SIZE))
_const_a = tf.constant(a, dtype=tf.float32, name=""Const_A"")
_mul_const_a = tf.matmul(_const_a, _const_a, name=""Mul_Const"")

_random_a = tf.random_uniform((SIZE, SIZE), dtype=tf.float32, name=""Random_A"")
_mul_random_a = tf.matmul(_random_a, _random_a, name=""Mul_Random"")

with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as s:
    # Run once to make sure everything is initialised
    s.run((_const_a, _mul_const_a, _random_a, _mul_random_a))

    # timeit
    print(""TF with const\t"", timeit(lambda: s.run((_mul_const_a.op)), number=NUM_RUNS))
    print(""TF with random\t"", timeit(lambda: s.run((_mul_random_a.op)), number=NUM_RUNS))

```
### Logs: I have accurate environment details only for the GTX 1070 and the P100, as reported above. 

#### GTX 1070 X (multiplying constants is much slower)
```
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0
TF with const    2.9953213009994215
TF with random   0.513827863998813
```

#### Tesla P100 (multiplying constants is much slower)
```
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0
TF with const     1.5770663949660957
TF with random     0.32687677699141204

```
#### K1100M (multiplying constants is much faster. But I am not sure which version of TF this was run with)
```
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro K1100M, pci bus id: 0000:01:00.0, compute capability: 3.0
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0
TF with const    4.3167382130868175
TF with random   9.889055849542306
```

#### GTX 940 MX (multiplying constants is slightly slower)
```
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/gpu:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
Random_A: (Add): /job:localhost/replica:0/task:0/gpu:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/gpu:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/gpu:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/gpu:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/gpu:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
Const_A: (Const): /job:localhost/replica:0/task:0/gpu:0
TF with const    3.5542741210010718
TF with random   3.519956939999247


```",0,,6,2017-12-29T11:12:36Z,NONE
15706,Feature request: safe_div op,type:feature,"As discussed with @drpngx in #14667 , we found that several PRs are related to division by zero problem, for example, #15443, #14865. 

### why

In `metrics`, `loss` and `math_ops` modules, all create a `_safe_div` or `_safe_scalar_div` method with help of `array_ops.where` to resolve the problem. However, we think those implementations have three disadvantages:
1. Lack of generality: most are designed for only scalar.
2. Not efficient.
3. Since `where` ops propagates NaNs in gradients (#2540), we have to use nested `where` trick which is a little counter-intuitive.

### what

Above all, we propose to create new c++ op: `safe_div`:
+ When denominator is zero, return 0 or numerator. The behavior can be selected by user themselves.
+ Optional: Treat negative as zero, which is sometime useful for loss calculation.
+ Create its own gradient op to avoid NaN problem for `where`.

I think for metric, loss and gradient calculation, they could benefit from the op and get rid of NaN.
And I'd like to contribute the op in **contrib** at first if the proposition is approved by tensorflowers.

### how

By the way, since  the name`safe_div` has been used in cwise_ops.h, whose behavior is opposite: raise an exception for integer when divide by zero. 
https://github.com/tensorflow/tensorflow/blob/3629fc4e98254c37e614ac3f77fa250b75c70f8d/tensorflow/core/kernels/cwise_ops.h#L703
So perhaps we need to either rename it or create a new name for our op. Does anyone has a good idea?",0,,3,2017-12-29T03:33:03Z,CONTRIBUTOR
15701,Cannot run mobilenet_0.25_128_quantized image retrain,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: python tensorflow/examples/image_retraining/retrain.py --image_dir /path/to/image/dir/  --architecture mobilenet_0.25_128_quantized

### Describe the problem
while trying to create a mobilenet model, getting this error. The url being created in the retrain.py file, is not accessible via browser either.

### Source code / logs
tensorflow.python.framework.errors_impl.NotFoundError: /tmp/imagenet/mobilenet_v1_0.25_128_quantized_frozen/quantized_frozen_graph.pb; No such file or directory

  ",0,,3,2017-12-28T18:23:51Z,NONE
15696,A fix for error in tf.layers.conv3d_transpose when inferred batch size,,"## Context
When using the `tf.layers.conv3d_tranpose` Op with a dynamic batch size and when `use_bias=True` then there is a [well known error that occurs](https://github.com/tensorflow/tensorflow/issues/10520).
The error is due to a [tf.reshape Op that chunks together some of the axes before adding the bias for a slight performance improvement](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L1628).
E.g. in the case of `data_format == 'channels_last'`, 
```
outputs_4d = array_ops.reshape(outputs, [
            outputs_shape[0], outputs_shape[1],
            outputs_shape[2] * outputs_shape[3], outputs_shape[4]
        ])
```
gives an error when `outputs_shape[0] == None`, i.e. when batch size is inferred. 

## Simple fix
To fix this with minimal modification to other code, it would be great if someone could replace `outputs_shape[0]` with `-1` in these two lines:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L1627
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L1632",0,,7,2017-12-28T15:27:47Z,NONE
15695,LookupError: No gradient defined for operation for assign,stat:awaiting response,"I wish to do assign ops in a layer such as below 
           **with tf.name_scope('conv1_1') as scope:
                kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,
                                                         stddev=1e-1), name='weights')
                kernel = kernel[:, :, : 0:32].assign(tf.zeros([3, 3, 3, 32]))
                conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')
                biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),
                                     trainable=True, name='biases')
                out = tf.nn.bias_add(conv, biases)
                self.conv1_1 = tf.nn.relu(out, name=scope)
                self.parameters += [kernel, biases]**

But later I train again. I will have error.
**LookupError: No gradient defined for operation for assign**",0,,2,2017-12-28T14:16:59Z,NONE
15694,Latency of simple tf.data.Dataset transformations is higher than raw Python,"stat:contributions welcome,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip install tensorflow (CPU only)
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5.2

### Describe the problem
I'm trying to improve performance by moving to `tf.data.Datasets` to manage epochs and minibatches (particularly I/O performance on a GPU when I come to scaling up). However I'm finding that this is much slower than just using nested `for` loops in Python.

### Source code / logs
Here's an example using a dataset with 10,000 numbers, 10 epochs and a minibatch size of 100:

```python
import tensorflow as tf
import numpy as np
from time import time

MINI_BATCH = 100
EPOCHS = 10

# Dataset consisting of 10000 random numbers
raw_data = np.random.randn(10000)

# Raw Python implementation
start = time()
split_data = np.split(raw_data, 10000 // MINI_BATCH)

for _ in range(EPOCHS):
    for i, batch in enumerate(split_data):
        # Do stuff with batch data
        x = batch * 2
print(""Raw Python done in"", time() - start)


# TensorFlow implementation
start = time()
dataset = tf.data.Dataset.from_tensor_slices(raw_data)
dataset = dataset.repeat(EPOCHS)
dataset = dataset.batch(MINI_BATCH)
iterator = dataset.make_one_shot_iterator()
next_chunk = iterator.get_next()

with tf.Session() as sess:
    while True:
        try:
            batch = sess.run(next_chunk)
            # Do stuff with batch data
            x = batch * 2
        except tf.errors.OutOfRangeError:
            break
print(""TensorFlow done in"", time() - start)

```
Output:
```
Raw Python done in 0.0011773109436035156
TensorFlow done in 0.14212393760681152
```

Does anyone know why this might be the case? 

I'm guessing that most of the overhead is in the evaluation of `iterator.get_next()` on every loop. If this is not supposed to be evaluated it would be useful to have some examples of how it should be used without using `sess.run` each time.
",0,,1,2017-12-28T13:58:01Z,NONE
15693,Pruning some features,stat:awaiting response,"I'm doing some work about pruning VGG16. And my method is set some kernel to be zero.
               **kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,
                                                         stddev=1e-1), name='weights')
                kernel1 = tf.Variable(tf.zeros([3, 3, 3, 64], dtype=tf.float32), name='pruning_weights',
                                      trainable=False)
                kernel1 = kernel1[:, :, :, 0:32].assign(kernel[:, :, :, 0:32])**

But I want to train VGG again. the problem said that, 
**LookupError: No gradient defined for operation 'conv1/conv1_1/conv1/conv1_1/strided_slice/_assign' (op type: StridedSliceAssign)**

Anybody came across such issues? Or have some idea to set the kernel last dim to be zero?
Thanks a lot! ",0,,2,2017-12-28T13:35:41Z,NONE
15692,tf.image.draw_bounding_boxes don't support boxes with different color,"stat:contributions welcome,type:feature","I want to draw boxes with different color for different classes, but it seems that  `tf.image.draw_bounding_boxes` don't support, could you add color paramters to `tf.image.draw_bounding_boxes`?
",0,,2,2017-12-28T13:02:02Z,NONE
15691,The problem of the tensorboard,,"Hi:
  I am the newbie of the tensorflow,  there is a problem during learning the usage of  tensorboard. 
  There is no problem with the first code compilation after start the Compiler(Anaconda spyder), but recompiling the code will go wrong, that is very strange. can anyone help me?

thank you very much!

**First compilation:**
![1](https://user-images.githubusercontent.com/31270354/34410598-60c20af0-ec0c-11e7-9acc-b3a5757b2101.PNG)
![2](https://user-images.githubusercontent.com/31270354/34410606-6776095a-ec0c-11e7-8dcb-6607336bd7d2.PNG)
![3](https://user-images.githubusercontent.com/31270354/34410611-6cab0768-ec0c-11e7-8f39-38a7cee2087f.PNG)
everything is ok during first compilation

**Second compilation:**
![4](https://user-images.githubusercontent.com/31270354/34410636-8f812b64-ec0c-11e7-91c9-22ad651245d9.PNG)
Something was wrong!!!

**the code of the tensorflow:**
```
import tensorflow as tf

x = tf.placeholder(tf.int32)
y = x + 2
                   
sess = tf.Session()

tf.summary.scalar('Accuracy' , y)
merged = tf.summary.merge_all()
writer = tf.summary.FileWriter(""logs/"", sess.graph)

for i in range(200):     
    rs = sess.run(merged , feed_dict = {x: 10})
    writer.add_summary(rs, i)
```
**Error report:**
```
runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')
Traceback (most recent call last):

  File ""<ipython-input-2-66eb2d566452>"", line 1, in <module>
    runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')

  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 866, in runfile
    execfile(filename, namespace)

  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/Users/Administrator/.spyder-py3/temp.py"", line 13, in <module>
    rs = sess.run(merged , feed_dict = {x: 10})

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 895, in run
    run_metadata_ptr)

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1321, in _do_run
    options, run_metadata)

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)

InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype int32
	 [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'Placeholder', defined at:
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\ipython\start_kernel.py"", line 223, in <module>
    main()
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\ipython\start_kernel.py"", line 219, in main
    kernel.start()
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""C:\Program Files\Anaconda3\lib\site-packages\tornado\ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""C:\Program Files\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""C:\Program Files\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-66eb2d566452>"", line 1, in <module>
    runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 866, in runfile
    execfile(filename, namespace)
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File ""C:/Users/Administrator/.spyder-py3/temp.py"", line 3, in <module>
    x = tf.placeholder(tf.int32)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1548, in placeholder
    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 2094, in _placeholder
    name=name)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32
	 [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]    
```




",0,,4,2017-12-28T12:25:23Z,NONE
15690,mkl_cpu_allocator.h is not compiled under windows anymoe,"stat:community support,type:build/install","git branch v1.5/master

[mkl_cpu_allocator.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/mkl_cpu_allocator.h)

is not compiled on windows anymore since in includes unistd.h, which dosn't exist in windows.
",0,,5,2017-12-28T12:12:40Z,NONE
15688,Reduced accuracy with retrained Inception v3 model on Android ,stat:awaiting tensorflower,"I have follow instructions on TensorFlow website and the source code from examples on Github to retrain my own image classifier model which is basing on Inception v3.

The result is, for same picture, if I use python script for prediction I got the right category with confidence 93.3%. But I use Android Inference interface can only get the right category with 81.3% confidence.

I think the problem comes from the way that how to use the model.

In Github code, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/ClassifierActivity.java

Here is a snippet of comments to indicate how to user Inception v3 model:
```java
  // These are the settings for the original v1 Inception model. If you want to
  // use a model that's been produced from the TensorFlow for Poets codelab,
  // you'll need to set IMAGE_SIZE = 299, IMAGE_MEAN = 128, IMAGE_STD = 128,
  // INPUT_NAME = ""Mul"", and OUTPUT_NAME = ""final_result"".
  // You'll also need to update the MODEL_FILE and LABEL_FILE paths to point to
  // the ones you produced.
  //
  // To use v3 Inception model, strip the DecodeJpeg Op from your retrained
  // model first:
  //
  // python strip_unused.py \
  // --input_graph=<retrained-pb-file> \
  // --output_graph=<your-stripped-pb-file> \
  // --input_node_names=""Mul"" \
  // --output_node_names=""final_result"" \
  // --input_binary=true
```
We start from Input named ""Mul"" because DecodeJpeg is NOT supported in Android. So, we need to decode bitmap and resize it to 299 x 299 and flatten it with Android way.  I think that is the difference between python script and Android Inference interface. In python script, we use tf.gFile to get the content of image and direct pass to the start node ""DecodeJpeg""

I review the graph of retrained model, node ""Mul"" is not the direct successor of DecodeJpeg. There are four nodes ""Cast"", ""ExpandDims"", ""ResizeBilinear"", ""Sub"" between ""Mul"" and ""DecodeJpeg"". I think it does the same thing I mentioned to preprocess the image. I think may be we could pass input data a little bit earlier than ""Mul"".

First, I strip the mode with follow command:
```shell
strip_unused \
--input_graph=tf_files/retrained_graph.pb \
--output_graph=tf_files/stripped_retrained_graph..pb \
--input_node_names=""Cast"" \
--output_node_names=""final_result"" \
--input_binary=true
```
Then I change the recognizeImage() to pass input to node Cast
```Java
  @Override
  public List<Recognition> recognizeImage(final Bitmap bitmap) {
    // Log this method so that it can be analyzed with systrace.
    Trace.beginSection(""recognizeImage"");

    Trace.beginSection(""preprocessBitmap"");
    // Preprocess the image data from 0-255 int to normalized float based
    // on the provided parameters.
    int[] origIntValues = new int[bitmap.getWidth() * bitmap.getHeight()];
    float[] flatValues = new float[bitmap.getWidth() * bitmap.getHeight() * 3];
    bitmap.getPixels(origIntValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
    for (int i = 0; i < origIntValues.length; ++i) {
        final int val = origIntValues[i];
        flatValues[i * 3 + 0] = ((val >> 16) & 0xFF);
        flatValues[i * 3 + 1] = ((val >> 8) & 0xFF) ;
        flatValues[i * 3 + 2] = (val & 0xFF);
     }
    Trace.endSection();

    // Copy the input data into TensorFlow.
    Trace.beginSection(""feed"");
    inferenceInterface.feed(inputName, flatValues, new long[] { bitmap.getHeight(), bitmap.getWidth() , 3  });
    Trace.endSection();
```
Here the inputNames is ""Cast"", not ""Mul"". After that I get the exact the same result as python script. 

Conclusion, I think the way currently we used on Android side to preprocess image is NOT doing the same tasks as the nodes ""Cast"", ""ExpandDims"", ""ResizeBilinear"", ""Sub"" do. I suggest to update the code of Android example to fix this problem.
",0,,2,2017-12-28T09:58:43Z,NONE
15687,How to load a metagraph via C++,,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2
- **Python version**: 2.7

### Describe the problem
I want to load a metagraph via C++ code, and later the checkpoint weights. To load the metagraph, I first generate a pb file from it

```
with tf.Session() as sess:
	new_saver = tf.train.import_meta_graph(root_dir + meta_graph)
	tf.train.write_graph(sess.graph_def, root_dir, export_pb, as_text=False)
```
Then I use selective registration to generate the ops and kernels needed

`bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=xinmei/rnn_dict/model_test.pb > tensorflow/core/framework/ops_to_register.h`
Next, I compile my runnable using this registration. However, when I run the executable on my Android device, it says

```
Error creating graph: Invalid argument: No OpKernel was registered to support Op 'Const' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: save/RestoreV2_8/shape_and_slices = Const[_output_shapes=[[1]], dtype=DT_STRING, value=Tensor<type: string shape: [1] values: >]()]]
```
How can I load the metagraph? The motivation of this is that I want to continue training the model on my Android device.
",0,,5,2017-12-28T09:50:09Z,NONE
15684,speech commands check_nans doesnt work,stat:awaiting response,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I'm running the simple audio recognition tutorial code.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:tf-nightly-gpu15
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA8.0/cuDNNv7
- **GPU model and memory**: 1060 6GB
- **Exact command to reproduce**:python train.py --check-nans=True

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
As the tutorial said, by enabling the --check_nans flag I could track down the source of the not-a-number error in model tuning. But I got following errors instead, which I guess maybe a bug or something?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Traceback (most recent call last):
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float
         [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[Node: global_step/read/_18 = _Send[T=DT_INT64, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4_global_step/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](global_step/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train.py"", line 432, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""train.py"", line 217, in main
    dropout_prob: 0.5
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float
         [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[Node: global_step/read/_18 = _Send[T=DT_INT64, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4_global_step/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](global_step/read)]]

Caused by op 'Placeholder_1', defined at:
  File ""train.py"", line 432, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""train.py"", line 106, in main
    FLAGS.testing_percentage, model_settings)
  File ""/home/renq/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 163, in __init__
    self.prepare_processing_graph(model_settings)
  File ""/home/renq/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 355, in prepare_processing_graph
    self.foreground_volume_placeholder_ = tf.placeholder(tf.float32, [])
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1680, in placeholder
    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3141, in _placeholder
    ""Placeholder"", dtype=dtype, shape=shape, name=name)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3143, in create_op
    op_def=op_def)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1611, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float
         [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[Node: global_step/read/_18 = _Send[T=DT_INT64, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4_global_step/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](global_step/read)]]

",0,,2,2017-12-28T06:59:08Z,NONE
15669,Session::Run() allocates a lot of memory after the first call,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**: Binary ([CPU C API](https://www.tensorflow.org/install/install_c))
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

I am working on an application that deploys several TensorFlow models using TensorFlow's C API. I have noticed that there seems to be a behavior where TensorFlow takes a long time to run the first time `TF_SessionRun()` is called, and it allocates a lot of extra memory that hangs around until the session is destroyed. In my case, my program's memory footprint is ~85MB after all of the models are loaded (which makes sense, that's about how large the model .pb files are on disk) but after the first call to `TF_SessionRun()` it jumps to ~250MB. After profiling my code it appears that TensorFlow is the culprit, and I've observed similar behavior on Android as well.

TensorFlow seems to be doing some lazy initialization, but there doesn't appear to be much documentation or discussion about this. Could someone shed some light on what is happening here? Why does it require so much memory? Is this a bug or expected behavior?

### Source code / logs

Here's a memory call tree from Xcode showing *persistent* memory allocations after the first call to `TF_SessionRun()` for one of my models:

<img width=""996"" alt=""screen shot 2017-12-27 at 1 14 59 pm"" src=""https://user-images.githubusercontent.com/3229244/34394457-1af8625c-eb0e-11e7-8cd8-ff61737dcb50.png"">

Let me know if there is any more information that I can provide. I'm curious what's going on here.",0,,4,2017-12-27T22:03:04Z,NONE
15665, Fix NadamOptimizer to work with sparse gradients properly,"awaiting review,cla: yes",Fix for #15035 and  #13980 ,0,,1,2017-12-27T19:26:27Z,CONTRIBUTOR
15662,S3 Support does not work for private bucket,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: -
- **GPU model and memory**: - 
- **Exact command to reproduce**: -



### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When trying to access a file on one of my private S3 buckets, I get an error message that the object does not exist (see below for source code and traceback). Using the AWS CLI downloading the object works fine(aka I'm sure I have the access rights to access the bucket). Also accessing the object in a public S3 bucket (like the one in issue #15159) works fine. I tried looking into the source code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L404) to see if it's maybe an issue with missing or wrong environment variables concerning the AWS credentials, but I couldn't find any code checking for any credentials at all. Am I missing something simple?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

When running the following code

```python
from tensorflow.python.lib.io import file_io
file_io.stat('s3://myprivatebucket/filethatexists')
```

I get the following error

```
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py"", line 98, in size
    return stat(self.__name).length
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py"", line 540, in stat
    return file_statistics
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Object s3://myprivatebucket/filethatexists does not exist
```",0,,7,2017-12-27T17:02:33Z,NONE
15655,"tf.layers.conv3d with ""channels_first"" does not accept batch dimension to be None",,"code to reproduce:

```python
import tensorflow as tf
x = tf.placeholder(dtype=tf.float32, shape=[None, 1, 32, 32, 32])
y = tf.layers.conv3d(x, 32, 9, data_format='channels_first')
```

traceback
```
Traceback (most recent call last):
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 468, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 468, in <listcomp>
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got None

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py"", line 809, in conv3d
    return layer.apply(inputs)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 671, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py"", line 185, in call
    outputs_shape[4]])
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3938, in reshape
    ""Reshape"", tensor=tensor, shape=shape, name=name)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 513, in _apply_op_helper
    raise err
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 510, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 926, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 229, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 472, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 32, 576, 24]. Consider casting elements to a supported type.
```

The error source appears [here][1] and can be simply fixed by adding

```python
if outputs_shape[0] is None:
  outputs_shape[0] = -1
```

however you might suggest a deeper fix?


[1]: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L181-L185",0,,6,2017-12-27T13:55:37Z,NONE
15651,Not found: FeedInputs: unable to find feed output Mul,stat:awaiting tensorflower,"@satok16 I have already set up and was able to run `hexagon_graph_execution` on my hvx board, however, when I tried to use my own [inception-v3 pre-trained model](https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models) that I froze using [this quantization method](https://www.tensorflow.org/performance/quantization), I am receiving this error:

```
[ RUN      ] GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime
native : hexagon_graph_execution_test.cc:519 Fuse and run inception v3 on hexagon with tf runtime
native : hexagon_graph_execution_test.cc:94 Hexagon controller version is 90
native : hexagon_graph_execution_test.cc:142 Read /data/local/tmp/img_299x299.bmp, size = 269156bytes
native : hexagon_graph_execution_test.cc:148 header size = 54
native : hexagon_graph_execution_test.cc:150 image size = 40
native : hexagon_graph_execution_test.cc:152 width = 299
native : hexagon_graph_execution_test.cc:154 height = -299
native : hexagon_graph_execution_test.cc:533 Ioading image finished.
t1(loading image time)=0.026770
native : hexagon_graph_execution_test.cc:546 Build fused graph
native : remote_fused_graph_execute_utils.cc:259 Error during inference: Not found: FeedInputs: unable to find feed output Mul
native : graph_transfer_utils.cc:110 Check failed: status.ok()
Aborted
```
Do you know if the issue is because of an incorrect input argument here: 

```
curl -L ""https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz"" |
  tar -C tensorflow/examples/label_image/data -xz
bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
  --in_graph=tensorflow/examples/label_image/data/inception_v3_2016_08_28_frozen.pb \
  --out_graph=/tmp/quantized_graph.pb \
  **--inputs=input \**
  --outputs=InceptionV3/Predictions/Reshape_1 \
  --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,299,299,3"")
    remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true)
    fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes
    strip_unused_nodes sort_by_execution_order'
```

I found on [this] (https://stackoverflow.com/questions/43022516/tensorflow-inception-feedinputs-unable-to-find-feed-output-input) and also [this][https://github.com/tensorflow/tensorflow/issues/2883#issuecomment-226591095](url) posts that we might have to use `Mul` instead. Tried that with no success. Interestingly, when I test my frozen_quantized graph with:

`bazel-bin/tensorflow/examples/label_image/label_image --graph=/tmp/my_inception_quantized_graph_hvx.pb`

I receive similar results compared to a non-quantized version, so it shows that my frozen_quantized is not faulty. Can you verify the issue here? 
Was the file `https://storage.googleapis.com/download.tensorflow.org/models/tensorflow_inception_v3_stripped_optimized_quantized.pb` used in the original hvx hexgon_graph_execution produced differently?",0,,1,2017-12-27T03:41:28Z,NONE
15649,AttributeError:  'Tensor' object has no attribute 'assign_add',stat:awaiting response,"### Describe the problem
I have constructed an object detector architecture based on ResNet-101. APIs in TF-Slim are mainly used in the structure. However when I finally create a train op by 'slim.learning.create_train_op' I receive such error. Tracebacks are showing below. 
My environments: Ubuntu 16.04, CUDA 8.0, tensorflow 1.3.0

### Source code / logs
![screenshot from 2017-12-27 10-08-30](https://user-images.githubusercontent.com/30883678/34368357-4c744366-eaee-11e7-8dd2-df459b85314c.png)
I found another issue same as mine but I can assure there is no variable accidentally named as 'tf' in my code as that issue suggests. I just try to build the model and no images or labels are feeded since both of them are set as tf.placeholder. It seems that such error emerges during the process of building computation graph for update ops. 
",0,,2,2017-12-27T02:15:54Z,NONE
15644,[Feature request] define axis in 'tf.unique()' and 'tf.unique_with_counts',"stat:contributions welcome,type:feature","Hi, just a small feature request:
It would be cool if one could directly
* use 'tf.unique()' and 'tf.unique_with_counts' in n-dimensional arrays
* define an axis along which 'tf.unique()' and 'tf.unique_with_counts' are applied
",0,,2,2017-12-26T16:29:47Z,NONE
15643,fp16 inference is slower than fp32 on Nvidia Jetson TX2,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.5
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: Cuda 8.0 and cuDNN 7.0
- **GPU model and memory**: Jetson TX2

### The problem
I created a fully convolutional float 16 (half precision) neural network in tensorflow. When I run this network with some inputs, the inference time is slower than when I run the same network in float 32 (full precision) mode. 
I should also note that the following variables are set:

`
os.environ['TF_FP16_CONV_USE_FP32_COMPUTE'] = '0'
os.environ['TF_FP16_MATMUL_USE_FP32_COMPUTE'] = '0'
`

As Nvidia Jetson TX2 support FP16 operations, I expected an inference time not worse than when I use FP32, but surprisingly it is about 1.5 times worse! (36 miliseconds vs 22 miliseconds). I guess it is becuase of the overhead of internal type conversion in the tensorflow core between float16 and float32!

Is it a problem with Tensorflow or TX2?",0,,6,2017-12-26T13:54:57Z,NONE
15641,Compile with selective register on meta file,,"I want to apply the selective registration feature on my model to decrease the lib size. However, I need to apply it on a meta file saved via `saver` rather than a frozen pb file as shown in many posts I have found. When I try to run 

`bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=model_test.ckpt-390760.meta`

it comes to the error

`[libprotobuf ERROR external/protobuf/src/google/protobuf/wire_format_lite.cc:621] String field 'tensorflow.NodeDef.op' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes.`

I tried to add `--proto_fileformat=textproto` but another error comes up:

`raise self.ParseError('Expected identifier or number.')
google.protobuf.text_format.ParseError: 2:1 : Expected identifier or number.`

Is it even possible to do this at all? The ultimate goal of compiling this lib is to restore a pretrained model and incrementally train it on Android.",0,,4,2017-12-26T13:23:09Z,NONE
15640,adding ps_strategy to run_config to enable different placement strate…,"awaiting review,cla: yes","…gy in estimator

This is my first pull request. I noticed that there isn't any way to set the `ps_strategy` in `tf.train.replica_device_setter` if `tf.estimator.Estimator` is used in distributed settings. I guess the best way to notify the estimator which strategy to use is through the `RunConfig` class. I have added a property `ps_strategy` to `RunConfig` and filled in some of the unit tests. I have also modified the `_get_replica_device_setter` in `estimator.py` to return a device setter with the `ps_strategy` included. Please kindly review and let me know if there is anything I need to correct or modify",0,,2,2017-12-26T12:32:30Z,NONE
15638,PS:0 runs nothing but seizes the network in the distributed training,stat:awaiting response,"   It's strange but I think is a bug in tensorflow. When I use multi machine as PS, I specify the operations in PS:* but not PS:0. And I not use the PS:0, but the variable transfer between the PS:* and PS:0. By the way, I  use the lenet5 about 1.6M parameters, but when iterating one time, the data between PS:* and PS:0 is 4.7M in the network using tcpdump to calculate it. I don't know why. The following is my main code in worker machine and PS server just run server.join().
https://github.com/niewuya/tensorflow-distributed-training/blob/master/code.py
I will appreciate your reply.

```python
import tensorflow as tf
slim = tf.contrib.slim

parameter_servers = [""172.16.101.248:2225"",""172.16.101.249:2225"",""172.16.101.105:2225""]
workers = [""172.20.110.94:2225""]
cluster = tf.train.ClusterSpec({""ps"": parameter_servers, ""worker"": workers})
server = tf.train.Server(
    cluster,
    job_name=""worker"",
    task_index=0)

def dataset_input_fn():
    buffer_size = 1024
    batch = 128
    num_epochs = 50
    filenames = ['../datasets/mnist/train.tfrecord']
    dataset = tf.data.TFRecordDataset(filenames)

    def parser(record):
        keys_to_features = {
            ""image/encoded"": tf.FixedLenFeature((), tf.string, default_value=""""),
            ""image/class/label"": tf.FixedLenFeature((), tf.int64,
                                                    default_value=tf.zeros([], dtype=tf.int64)),
        }
        parsed = tf.parse_single_example(record, keys_to_features)

        image = tf.image.decode_jpeg(parsed[""image/encoded""])
        image = tf.image.convert_image_dtype(image, dtype=tf.float32)
        image = tf.reshape(image, [28, 28, 1])
        label = tf.cast(parsed[""image/class/label""], tf.int32)
        label = slim.one_hot_encoding(label, 10)
        return image, label

    dataset = dataset.repeat()
    dataset = dataset.map(parser, num_parallel_calls=8)
    dataset = dataset.prefetch(buffer_size=batch)
    dataset = dataset.prefetch(buffer_size=buffer_size)
    dataset = dataset.shuffle(buffer_size)
    dataset = dataset.batch(batch)
    iterator = dataset.make_one_shot_iterator()
    images, labels = iterator.get_next()
    return images, labels

def lenet(images,labels,flag):
    num_classes = 10
    dropout_keep_prob = 0.5
    scope = tf.variable_scope(""lenet"", reuse=flag)
    with scope, slim.arg_scope([slim.conv2d, slim.fully_connected],
                               activation_fn=tf.nn.relu,
                               weights_initializer=tf.truncated_normal_initializer(stddev=0.1),
                               weights_regularizer=slim.l2_regularizer(0.0)):
        net = slim.conv2d(images, 20, [5, 5], scope='conv1_1')
        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_1')
        net = slim.conv2d(net, 50, [5, 5], scope='conv1_2')
        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_2')
        net = slim.flatten(net)
        net = slim.fully_connected(net, 500, scope='fc1_3')
        net = slim.dropout(net, dropout_keep_prob, scope='dropout1_3')
        logits = slim.fully_connected(net, num_classes, activation_fn=None, scope='fc1_4')
        loss = tf.losses.softmax_cross_entropy(
            logits=logits, onehot_labels=labels)
        loss = tf.reduce_mean(loss)
        optimizer = tf.train.AdagradOptimizer(0.01)
        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        grads = optimizer.compute_gradients(loss)
    return grads, accuracy, optimizer

with tf.Graph().as_default():
    with tf.device('/CPU:0'):
        all_grads = []
        with tf.device('/job:ps/task:2'):
            images, labels = dataset_input_fn()
            grads, accuracy_ps, optimizer =lenet(images,labels,False)

        all_grads.clear()
        all_grads.append(grads)
        train_op_all=[]
        for i, grad_and_vars in enumerate(zip(*all_grads)):
            grads = []
            for g, _ in grad_and_vars:
                g = tf.expand_dims(g, 0)
                grads.append(g)
            grad = tf.concat(axis=0, values=grads)
            grad = tf.reduce_mean(grad, 0)
            v = grad_and_vars[0][1]
            train_op_all.append(optimizer.apply_gradients([(grad, v)]))
        train_op=tf.group(*train_op_all)

    with tf.train.MonitoredTrainingSession(master=server.target,
                                               is_chief=True
                                           )as mon_sess:
        frequency=10
        for i in range(1000):
            _ ,accuracy= mon_sess.run([train_op,accuracy_ps])
            if i % frequency ==0 :
                print(""accuracy is :%f""%accuracy)
```",0,,2,2017-12-26T08:08:35Z,NONE
15636,Read tflite file failed on iOS,"comp:lite,stat:awaiting response","Hi

I tried the examples on iOS according to TF Lite guide, but failed when assign data to tflite because address ""out"" is NULL. probably my tflite file is incorrect, but I am not sure, can anybody give some help? 

My test step is as follows:
1.  Try the following code(https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite),  get the tflite file converteds_model.tflite

```
import tensorflow as tf
img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name=""out"")
with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open(""converteds_model.tflite"", ""wb"").write(tflite_model)
```

2. Integrated the tflite into my app, which is from iOS sample code ""simple""(/Users/Sensteer/Software/tensorflowclone/tensorflow/tensorflow/contrib/lite/examples/ios/simple).But exception happed because address ""out"" is NULL

```
int input = interpreter->inputs()[0];                                 //input is 3
float* out = interpreter->typed_tensor<float>(input);          //out is NULL
```

So my questions are:
1. The tflite created above is right or not?
2. The reading tflite code is right or not?
2. If the tflite file is not right, do I must create tflite with  ""pb"", ""ckpt"" and ""FrozenGraphDef"" mentioned in guide?

Thanks
",0,,4,2017-12-26T07:37:09Z,NONE
15635,Android: Op type not registered 'GatherTree' in binary running on localhost.,,"-----------------------

# System information
- **OS Platform and Distribution : Linux Ubuntu 14.04
- **TensorFlow installed from source 
- **TensorFlow version 1.4.0
- **Python 2.7
- **Bazel version [bazel release 0.8.0]
- **GCC/Compiler version gcc version 4.9.4 (GCC)
- **CUDA/cuDNN (only for cpu)


# Describe the problem
Hi.  I have tried to load the rnn model inside Android that I generated from python for machine translation. When I want to use beam_search in decode I meet an (can't find ** op) error at Android. I have tried below solutions but the error is continue.
## solution 1:
use python script “tensorflow/python/tools/print_selective_registration_header.py” to create ""ops_to_register.h"", then copy it into ""tensorflow/core/framework/"", then generate ""//tensorflow/contrib/android:libtensorflow_inference.so""
### I change ""print_selective_registration_header.py"":
`parser.add_argument(
'--default_ops',
type=str,
#default='NoOp:NoOp,_Recv:RecvOp,_Send:SendOp',
 default='all',`
...)
### cmd like below:
`bazel build tensorflow/python/tools:print_selective_registration_header &&   bazel-bin/tensorflow/python/tools/print_selective_registration_header     --graphs=/path/to/my/model/decode-model_1213_real_model_with_beam.pb > ops_to_register.h`
`bazel build -c opt --copt=""-DSELECTIVE_REGISTRATION""     --copt=""-DSUPPORT_SELECTIVE_REGISTRATION""   //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain  --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a`

## solution 2:
I met the same type of mistake before, and with ""Op type not registered ListDiff"" error. I find ""listdiff_op.cc"" is at ""tensorflow/core/kernels"". Then I add a line at ""tensorflow/core/kernels/BUILD"", and re-generate libtensorflow_inference.so to solve that error. But the ""beam_search_ops.cc"" is at ""tensorflow/contrib/seq2seq/kernels"", when I add it like ""ListDiff"" it's still reporting that error at android studio.
### add line like below:
` filegroup(
name = ""android_extended_ops_group1"",
srcs = [
""listdiff_op.cc"",
#""//tensorflow/contrib/seq2seq/kernels/beam_search_ops.cc"",
...]
)
`

I need some help for solving this problem. thanks.

# Source code / logs
## error log at android studio:
`E/AndroidRuntime: FATAL EXCEPTION: main
                  Process: com.example.phua.mt_1201, PID: 20817
                  java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.phua.mt_1201/com.example.phua.mt_1201.MainActivity}: org.tensorflow.TensorFlowException: Op type not registered 'GatherTree' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.
                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2955)
                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3030)
                      at android.app.ActivityThread.-wrap11(Unknown Source:0)
                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1696)
                      at android.os.Handler.dispatchMessage(Handler.java:105)
                      at android.os.Looper.loop(Looper.java:164)
                      at android.app.ActivityThread.main(ActivityThread.java:6938)
                      at java.lang.reflect.Method.invoke(Native Method)
                      at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:327)
                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1374)
                   Caused by: org.tensorflow.TensorFlowException: Op type not registered 'GatherTree' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.
                      at org.tensorflow.Graph.importGraphDef(Native Method)
                      at org.tensorflow.Graph.importGraphDef(Graph.java:118)
                      at org.tensorflow.Graph.importGraphDef(Graph.java:102)
                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:396)
                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:97)
                      at com.example.phua.mt_1201.tfonandroid.Loadmodel(tfonandroid.java:37)
                      at com.example.phua.mt_1201.MainActivity.onCreate(MainActivity.java:52)
                      at android.app.Activity.performCreate(Activity.java:7174)
                      at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1220)
                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2908)
                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3030) 
                      at android.app.ActivityThread.-wrap11(Unknown Source:0) 
                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1696) 
                      at android.os.Handler.dispatchMessage(Handler.java:105) 
                      at android.os.Looper.loop(Looper.java:164) 
                      at android.app.ActivityThread.main(ActivityThread.java:6938) `


",1,,4,2017-12-26T07:34:31Z,NONE
15633,[Question&Error] Is there detection model like a SSD-Mobile-net in tensorflow-lite?,"comp:lite,type:feature","HI.

Developing an android application using tensorflow-lite.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md
Not found detection model.

Also, I try to convert SSD-Inceptionv2 using tensorflow-lite-API. But there seems to be a problem.

##Command
<pre><code>
bazel run --config=opt --copt=-msse4.1 --copt=-msse4.2 \
  //tensorflow/contrib/lite/toco:toco -- \
  --input_file=/home/danshin/tensorflow_lite/lite_model/fire_incpetion_v2.pb \
  --output_file=/home/danshin/tensorflow_lite/lite_model/fire_inception_v2.lite \
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --input_shape=1,300,300,3 \
  --input_array=image_tensor \
  --output_array={detection_boxes,detection_scores,detection_classes,num_detections}
</code></pre>

##Error code
<pre><code>
2017-12-26 14:59:25.159220: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2029 operators, 3459 arrays (0 quantized)
2017-12-26 14:59:25.251633: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:95] Check failed: other_op->type == OperatorType::kTensorFlowMerge 
</code></pre>

The fire_inception_v2 file is created, but its size is zero bytes.
What is a problem?


also,
**please let me know what's the best way to deploy custom model for object detection?**

Somebody help me plz!.

thank you.",1,,5,2017-12-26T06:41:25Z,NONE
15628,Support truly pluggable protocol/transport for distributed mode,type:feature,"At this moment Distributed TensorFlow supports only one type of transport/protocol which is gRPC, however, it does seem to be configurable (cluster, server, session).

So, there are at least three things that need to be covered:
1. Document the intercommunication protocol (session to a server), i.e. what session sends to a server, what server should respond, etc. The good example here would some kind of swagger spec.
2. Make protocol configurable from Python.
3. Give all a Python interface to implement new types of protocols.

The whole idea is to let developers an ability to implement the protocol that would let distributed TensorFlow spin up and talk a number compute units (serverless, containers, VMs, etc.) instead of having a bunch of processes (cluster servers) running during computations within the session.

Please note, I wasn't able to find any corresponding issues related to given topic.",0,,10,2017-12-25T17:51:11Z,NONE
15626,TensorFlowInferenceInterface's feed method - a performance bottleneck,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Compiled on macos 10.13.2, Observed on Android 
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: commit ab0fcaceda on master - between release of 1.4.0 and 1.4.1 (compared to 1.0.1)
- **Python version**: N/A (java android code)
- **Bazel version (if compiling from source)**: 0.7.0-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Observed on a Huawei Nexus 6P
- **Exact command to reproduce**: N/A (java android code)

### Describe the problem
Following the move to Java API in commit 1a9769dc79fdd27c347633df210ff64f48de8d07, it seems that it is very ineffective to feed nodes.
I am feeding my model an input array of about 1100 floats, and when I sample CPU usage using CPU Profiler on Android Studio (Instrumented) it seems that the feed method takes ~x4 time than running the inference. If I leave everything the same but I use android libs compiled in tensorflow 1.0.1 CPU time of feed method (used to be fillNodeFloat) becomes negligible.
It seems that putting a float array into the Tensor's FloatBuffer is a very costly operation.

### Source code / logs
**TF 1.4.0:**
Relevant inference code:
```
tensorflow.feed(INPUT_NODE_NAME, input, shape);
tensorflow.run(OUTPUT_NAMES);
tensorflow.fetch(OUTPUT_NAMES[0], output);
```

Screenshot of CPU Profiler's call chart: https://www.dropbox.com/s/nx5q730l0fbd05x/TF_1.4_CallChart.png?dl=0
Screenshot of CPU Profiler's top-down breakdown of the 2 methods: https://www.dropbox.com/s/gh9vza3jmb5uzrn/TF_1.4_TopDown.png?dl=0

**TF 1.0.1:**
Relevant inference code:
```
tensorflow.fillNodeFloat(INPUT_NODE_NAME, shape, input);
tensorflow.runInference(OUTPUT_NAMES);
tensorflow.readNodeFloat(OUTPUT_NAMES[0], output);
```

Screenshot of CPU Profiler's call chart: https://www.dropbox.com/s/jrl2ggnsncx97ry/TF_1.0.x_CallChart.png?dl=0
Screenshot of CPU Profiler's bottom-up breakdown of the 2 methods: https://www.dropbox.com/s/tz5ldp4qnavhx17/TF_1.0.x_BottomUp.png?dl=0",1,,4,2017-12-25T14:44:51Z,CONTRIBUTOR
15625,cross compile tensorflow C++ API for armeabi-v7a runtime erreors,stat:awaiting tensorflower,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS Sierra 10.13.2
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.3
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**:0.9.0-homebrew
- **GCC/Compiler version (if compiling from source)**:4.2.1
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
i follow tensorflow/contrib/makefile/README.md to compile static library and there are two *.a file under tensorflow/contrib/makefile/gen. but when i link those two libs with my test application (Android Application with Cmake), there ara some errors.
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Error:error: undefined reference to 'google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)'
Error:error: undefined reference to 'google::protobuf::UnknownFieldSet::MergeFrom(google::protobuf::UnknownFieldSet const&)'
Error:error: ld returned 1 exit status",0,,3,2017-12-25T11:22:49Z,NONE
15624,Problem with tf.data.Dataset managing shapes of sparse tensors,stat:contributions welcome,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.3 LTS (Xenial Xerus)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0-dev20171224
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A

### Describe the problem
The tf-1.5-dev supports `tf.SparseTensor` when using `tf.data.Dataset.from_tensor_slices`, but it cannot infer the shape of new tensor after some operations such as `tf.data.Dataset.map`.

The shape of tensor becomes `Unknown`, which is troublesome for downstream operations. For example, we have to call `set_shape()` if we want to feed the new tensor into a `tf.layers.dense`.

### Source code / logs
<pre>
import tensorflow as tf
x = tf.SparseTensor([[0,0],[1,1],[2,2]], [1,1,1], dense_shape=[3,3])
ds = tf.data.Dataset.from_tensor_slices(x)
ds.output_shapes   # TensorShape([Dimension(3)])
ds = ds.map(lambda x: tf.sparse_tensor_to_dense(x))
ds = ds.batch(1)
ds.output_shapes   # TensorShape([Dimension(None), Dimension(None)])

iterator = ds.make_one_shot_iterator()
next_elem = iterator.get_next()   # TensorShape([Dimension(None), Dimension(None)])

y = tf.layers.dense(next_elem, 100)
ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.

</pre>
@mrry ",1,,5,2017-12-25T08:36:27Z,NONE
15618,Tensorflow does not build in a python3 only environment,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Fedora 27
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.4.1
- **Python version**: 
3.6.3
- **Bazel version (if compiling from source)**:
0.8.1
- **GCC/Compiler version (if compiling from source)**:
Using built-in specs.
COLLECT_GCC=/usr/bin/gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/7/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-redhat-linux
Configured with: ../configure --enable-bootstrap --enable-languages=c,c++,objc,obj-c++,fortran,ada,go,lto --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-gcc-major-version-only --with-linker-hash-style=gnu --enable-plugin --enable-initfini-array --with-isl --enable-libmpx --enable-offload-targets=nvptx-none --without-cuda-driver --enable-gnu-indirect-function --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux
Thread model: posix
gcc version 7.2.1 20170915 (Red Hat 7.2.1-2) (GCC) 
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:

export LANG=""en_US.UTF-8""
export PYTHON_BIN_PATH=""/usr/bin/python3""
export PYTHON_LIB_PATH=""/usr/lib64/python3.6/site-packages""
export TF_NEED_JEMALLOC=""1""
export TF_NEED_S3=""0""
export TF_NEED_GCP=""0""
export TF_NEED_OPENCL=""0""
export TF_ENABLE_XLA=""0""
export TF_NEED_GDR=""0""
export TF_NEED_VERBS=""0""
export TF_NEED_MPI=""0""
export TF_NEED_CUDA=""0""
export TF_NEED_HDFS=""0""
export CC_OPT_FLAGS=""-march=native""
./configure

bazel build --action_env PATH=""$PATH"" --verbose_failures //tensorflow/tools/pip_package:build_pip_package


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When building tensorflow in an environment with only python3 (e.g. no /usr/bin/python but instead /usr/bin/python3) build fails.  As this is likely to become increasingly the case as other distributions drop python2.7 from default installs (and, eventually drop it altogether), this ought to be addressed.

### Source code / logs

ERROR: /builddir/build/BUILD/tensorflow-1.4.1/tensorflow/python/BUILD:4363:1: Executing genrule //tensorflow/python:framework_fast_tensor_util_cython_translation failed (Exit 127): bash failed: error executing command 
  (cd /builddir/.cache/bazel/_bazel_mockbuild/88de5ec7248fb8215eb84aeff796b606/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/sbin:/builddir/.local/bin:/builddir/bin \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib64/python3.6/site-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; PYTHONHASHSEED=0 bazel-out/host/bin/external/cython/cython_binary --cplus tensorflow/python/framework/fast_tensor_util.pyx && python -c '\''import shutil, sys; n = len(sys.argv); [shutil.copyfile(src.split(""."")[0] + "".cpp"", dst) for src, dst in zip(sys.argv[1:], sys.argv[1+n//2:])]'\'' tensorflow/python/framework/fast_tensor_util.pyx bazel-out/k8-py3-opt/genfiles/tensorflow/python/framework/fast_tensor_util.cpp')
/usr/bin/env: 'python': No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 575.085s, Critical Path: 26.26s
FAILED: Build did NOT complete successfully

",2,,4,2017-12-24T23:02:30Z,NONE
15613,Tensorflow doesn't show the Cuda import messages ,stat:awaiting response,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,3,2017-12-24T11:59:45Z,NONE
15608,update _DECORATED_OPS for each latest call,"awaiting review,cla: yes","This fixes a race condition where the arg list is not being reliably extracted during `add_arg_scope` .
The simple solution is to always update `_DECORATED_OPS` on each latest call to `_add_op`.

fixes #11923",0,,2,2017-12-24T02:45:51Z,NONE
15606,Fix issue #15588 by simplifying the code,"awaiting review,cla: yes","The allocator.h code tried to be clever and use 32 byte alignment for SSE/AVX2/etc use,
and 64 byte alignment for AVX512.

Unfortunately, the #ifdef in use (from EIGEN) is not useful; the bazel BUILD files do
not propagate the tf_copts() compiler flags when the allocator.cc/allocator.h files get
compiled, to EIGEN does not see the actual AVX512 using compiler flags...

Rather than changing compiler flag propagation throughout a whole bunch of code,
there's an opportunity to just simplify the code and always use 64 byte alignment.
Yes it wastes a bit of space, but on the other hand now these allocations are
cache line aligned which isn't a bad thing... and an ifdef can be dropped

Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>",0,,11,2017-12-23T23:37:14Z,NONE
15595,"Issue #15572, support for unspecified spatial dimensions in layers.Conv3d_transposed","awaiting review,cla: yes,stat:awaiting response",Patch to 3d transposed convolution to use the same code for adding biases that regular 3d conv uses.  This allows transposed convolution to add biases if the spatial dimensions are not specified and the dimension ordering is channel last.  The case with channel first ordering still requires spatial dimensions be specified for both conv3d and conv3d_transposed because add_bias doesn't support 5d dimension ordering specifications.,1,,9,2017-12-22T21:21:53Z,NONE
15590, [CMake] Extract more file lists,"awaiting review,cla: yes","like #14877
@mrry /cc",1,,8,2017-12-22T18:36:03Z,CONTRIBUTOR
15588,Tensorflow crashes on AVX512 systems (Core i9 / Xeon etc),,"(for now, placeholder for notes while investigating)
using the r1.5 branch (but 1.4 and earlier have the same issues)

Tensorflow crashes when compiled for AVX512. The cause is a misalignment exception; AVX512 has a 64 byte natural alignment, and Eigen and others often use instructions that explicitly fault on misaligned loads.

tensorflow/core/framework/allocator.h has this code
class Allocator {
 public:
#ifdef EIGEN_VECTORIZE_AVX512
  // Align to 64 byte boundary.
  static constexpr size_t kAllocatorAlignment = 64;
#else
  // Align to 32 byte boundary.
  static constexpr size_t kAllocatorAlignment = 32;
#endif


which implies that at least this allocator tries to do the right thing, however it seems EIGEN_VECTORIZE_AVX512 is not properly defined (in cpp meaning) at this place, because when adding an #error in the 32 byte alignment case, the #error hits, so the 64 bit alignment case is not used.

This is not the only case; brute forcing the 32 to be 64 still faults in misalignment... just later on in a different place.

",1,,8,2017-12-22T14:49:23Z,NONE
15586,WIP: Remove invalid merge_repeated option from CTC beam decoder,cla: yes,"The CTC beam decoding implicitly collapses repeated characters as part of calculating the optimal path (i.e. 'AAA' will contribute probability mass through the path 'A').

So the correct CTC decoding behavior occurs when merge_repeated=False. In this case, it DOES merge repeated characters. The merge_repeated flag, when true, will merge repeated characters after characters have already been merged/blank symbols removed. As it stands now, the behavior is extremely misleading.

This PR removes the misleading parameter from the ctc beam search op.

Closes #9550.",0,,11,2017-12-22T13:19:30Z,NONE
15585,FP16 slower than FP32,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Partly
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
RHEL 7
- **TensorFlow installed from (source or binary)**:
unknown
- **TensorFlow version (use command below)**:
('unknown', '1.4.0')
- **Python version**: 
python2.7
- **Bazel version (if compiling from source)**:
unknown
- **GCC/Compiler version (if compiling from source)**:
gcc 4.8
- **CUDA/cuDNN version**:
9.0 / 7.0
- **GPU model and memory**:
Pascal P-100
- **Exact command to reproduce**:
N/A

### Describe the problem
I tried running the tutorial/rnn/ptb and tutorial/images/mnist examples with the --use_fp16 option, to see if speedup was achievable by utilizing the new half-precision features.
It turned out that a single training step for MNIST with FP32 took 3.3ms, with FP16 it was 4ms. For PTB small (I had to use lstm_cell=basic, because other types are not yet supported in FP16), the WPS dropped from 24000 to 22000 when switching to FP16.

So the performance **decreases** when using FP16 in real-world examples.

To check this, I've created a small benchmark for myself (since I can't get the nightly tf build on my machine, I can't run the official benchmarks), which is basically one big matrix multiplication in Tensorflow.

I've run it with square matrices with a width of 8k, 16k and 32k. In each case, FP16 and FP32 yielded nearly the same runtime. Profiling with nvprof I found out that the used CUDA function is **maxwell_fp16_segmemm_fp16_128x128_nn** for FP16 and **sgemm_128x128x8_NN_vec** for FP32.

Since I wanted to double check if matrix multiplication in FP16 is really slower than in FP32 on my GPU, I tried to directly benchmark the GPU using cuBlas with a similar operation. It turns out that here, FP16 is nearly twice as fast as FP32. CuBlas internally uses **maxwell_hgemm_256x128_nn** for matrix multiplication of 16k x 16k square matrices in FP16. (again  according to the nvprof profiler)

So I'm wondering why Tensorflow is unable to achieve similar results in terms of speed, or if I'm doing something wrong in my tests.

### Source code

Tensorflow Code snippet:
```
    graph = tf.Graph()
        with graph.as_default():
          tf_input1 = tf.Variable(tf.truncated_normal([FLAGS.size, FLAGS.size], dtype=get_dtype()))
          tf_input2 = tf.Variable(tf.truncated_normal([FLAGS.size, FLAGS.size], dtype=get_dtype()))
          tf_output = tf.matmul(tf_input1, tf_input2)
  
      with tf.Session(graph=graph) as session:
          tf.global_variables_initializer().run()
          print(""Initialized"")
          for i in range(FLAGS.times):
              out = session.run([tf_output])#, feed_dict=feed_dict)
          print(""Done"")
```


cuBlas Code FP16 (Snippet):
```
        uint16_t *d_a;          // d_a - a on the device
        uint16_t *d_b;          // d_b - b on the device
        uint16_t *d_c;          // d_c - c on the device
        cudaStat = cudaMalloc ((void **) &d_a, m * k * sizeof (*a));    // device memory alloc for a
        cudaStat = cudaMalloc ((void **) &d_b, k * n * sizeof (*b));    // device memory alloc for b
        cudaStat = cudaMalloc ((void **) &d_c, m * n * sizeof (*c));    // device memory alloc for c
        stat = cublasCreate (&handle);  // initialize CUBLAS context
        // copy matrices from the host to the device
        stat = cublasSetMatrix (m, k, sizeof (*a), a, m, d_a, m);   //a -> d_a
        stat = cublasSetMatrix (k, n, sizeof (*b), b, k, d_b, k);   //b -> d_b
        stat = cublasSetMatrix (m, n, sizeof (*c), c, m, d_c, m);   //c -> d_c
        uint16_t al = FP_16_ONE;       // al = 1 
        uint16_t bet = FP_16_ONE;      // bet =1
        // matrix - matrix multiplication : d_c = al*d_a *d_b + bet *d_c
        // d_a -mxk matrix , d_b -kxn matrix , d_c -mxn matrix ;
        // al ,bet -scalars

        stat = cublasGemmEx(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, &al, d_a, CUDA_R_16F, m, d_b, CUDA_R_16F, k, &bet, d_c, CUDA_R_16F, m, CUDA_R_16F, CUBLAS_GEMM_DEFAULT); 

        stat = cublasGetMatrix (m, n, sizeof (*c), d_c, m, c, m);   // cp d_c - >c
```
  ",0,,5,2017-12-22T12:03:07Z,NONE
15584,explained function generate_batch in Deep Learning Assignment 5 word2vec,stat:awaiting response,"please explain formula : data_index = (data_index + 1) % len(data) in function generate_batch
thank you so so much",0,,3,2017-12-22T11:38:06Z,NONE
15580,there is no gen_summary_ops,,"when i 
from tensorflow.contrib.summary import summary_ops

it raises an error
---> 29 from tensorflow.contrib.summary import gen_summary_ops
     30 from tensorflow.core.framework import graph_pb2
     31 from tensorflow.python.eager import context

ImportError: cannot import name 'gen_summary_ops'",0,,8,2017-12-22T09:37:02Z,NONE
15576,Feature request: Possible to introduce tf.complex32 datatype,stat:awaiting response,"Just recently I figured out, that our GPU (TitanX 12GB) is not big enough of its memory capacities to process our data. I was wondering whether there are attempts to ""quantize"" the complex datatypes as well. 

I've seen that there are approaches to quantize float32 datatypes for example and was wondering if this is possible for real/imag types as well. 

Thanks a lot! ",0,,3,2017-12-22T08:00:13Z,NONE
15572,layers.Conv3DTranspose doesn't work with unspecified DWH dimensions,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes (n/a)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 (All affected)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: CPU
- **Exact command to reproduce**: n/a

### Describe the problem

tensorflow.layers.Conv3DTranspose doesn't work when the input dimensions are not specified and bias is added.  This occurs because the layer output is reshaped from five dimensions to 4 by combining the depth and height dimensions:  None * None throws an exception.  The code for this is in tensorflow/python/layers/convolutional.py, line 1608.

It appears that this reshaping is done because nn.bias.add can't handle 5 dimensional inputs.  This seems like it should be an easy fix since nn.bias.add just broadcasts across all but the channel dimension anyway.  The *Transpose layers should really all use the same general _ConvTranspose style that the non-transposed convolution layers use, to avoid code duplication.

In the meantime, tensorflow.layers.Conv3D DOES work with unspecified input dimensions and channel-last ordering.  It turns out that Conv3D and Conv3DTranspose use different code for adding the bias.  In lieu of a nn.bias.add fix, this problem can be alleviated by using the Conv3D bias code for Conv3DTranspose.

### Suggested fix (tested)

In tensorflow/python/layers/convolutional.py, replace lines 1609-1625 with (modified from lines 169-189): 

        if self.data_format == 'channels_first':
              outputs_shape = outputs.shape.as_list()
              outputs_4d = array_ops.reshape(outputs,
                                             [outputs_shape[0], outputs_shape[1],
                                              outputs_shape[2] * outputs_shape[3],
                                              outputs_shape[4]])
              outputs_4d = nn.bias_add(outputs_4d, self.bias, data_format='NCHW')
              outputs = array_ops.reshape(outputs_4d, outputs_shape)
          else:
            outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')
",1,,5,2017-12-22T05:25:02Z,NONE
15568,InvalidArgumentError: slice index 0 of dimension 0 out of bounds.,,"Hi,

### Describe the problem
I am trying to encode and decode an image using tf.image.decode_jpeg and b64 encoding. The code is so simple but it seems I have an error regarding StrideSlice. I am not sure if the problem coming from the undefined shape of input placeholder or related to jpeg_decode.  Thanks. 

### Source code / logs
```
import tensorflow as tf
import base64
import functools


def build_graph(input_len=None):
    graph = tf.Graph()
    with graph.as_default():
        image_bytes = tf.placeholder(tf.string, name='input_node')
        images = tf.map_fn(
            functools.partial(tf.image.decode_jpeg, channels=3),
            image_bytes,
            dtype=tf.uint8
        )
        image_floats = tf.cast(images, tf.float32, name=""output_node"") / 255.0

    return graph


if __name__ == '__main__':
    file_name = ""test_1.jpg""
    with open(file_name, ""rb"") as imageFile:
        image_string = imageFile.read()
        image_encode = base64.b64encode(image_string).decode(""utf-8"")

    graph = build_graph(input_len=len(image_encode))

    with tf.Session(graph=graph) as session:
        init_op = tf.group(tf.global_variables_initializer(),
                           tf.local_variables_initializer())
        session.run(init_op)
        input_node = graph.get_tensor_by_name(""input_node:0"")
        output_node = graph.get_tensor_by_name(""output_node:0"")
        image_out = session.run(output_node, feed_dict={input_node: image_encode})
```

These is the traceback:

```
Caused by op u'map/TensorArrayUnstack/strided_slice', defined at:
  File ""/.../Simple_Graph_Design/ImageTest.py"", line 26, in <module>
    graph = build_graph(input_len=len(image_encode))
  File ""/.../Simple_Graph_Design/ImageTest.py"", line 13, in build_graph
    dtype=tf.uint8
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py"", line 354, in map_fn
    elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 107, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 412, in unstack
    num_elements = array_ops.shape(value)[0]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 538, in _SliceHelper
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 706, in strided_slice
    shrink_axis_mask=shrink_axis_mask)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 5430, in strided_slice
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): slice index 0 of dimension 0 out of bounds.
	 [[Node: map/TensorArrayUnstack/strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](map/TensorArrayUnstack/Shape, map/TensorArrayUnstack/strided_slice/stack, map/TensorArrayUnstack/strided_slice/stack_1, map/TensorArrayUnstack/strided_slice/stack_1)]]

```
### System information
- TF version: 1.4.0
- Linux Ubuntu 16.04
- Python version: 2.7
- No CUDA or GPU 




",0,,6,2017-12-21T23:52:52Z,NONE
15564,sparsemax implementation is not infinite-safe,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, but I have a simple reproducer below

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 27
- **TensorFlow installed from (source or binary)**: pip3 install --user tensorflow
- **TensorFlow version (use command below)**:  1.4.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: no
- **GCC/Compiler version (if compiling from source)**: no
- **CUDA/cuDNN version**: no
- **GPU model and memory**: no (x86_64 CPU)
- **Exact command to reproduce**:

### Describe the problem
tf.contrib.sparsemax.sparsemax does not produce the correctly expected results when infinities are present in the input.

Mathematically, a negative infinity should be treated the same as a very large negative number, and produce a 0 in the output.

This is a real-world problem when sparsemax is combined with contrib.seq2seq.LuongAttention (as suggested in its documentation, and also as suggested in the sparsemax paper), because entries past the input length in the batch will have a score of -inf by default.

### Source code / logs

Reproducer (assume tensorflow as tf)
```
>>> tf.contrib.sparsemax.sparsemax([[1., -1e+5]]).eval(session=sess)
array([[ 1.,  0.]], dtype=float32)
>>> tf.contrib.sparsemax.sparsemax([[1., float('-inf')]]).eval(session=sess)
2017-12-21 22:13:55.697302: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
2017-12-21 22:13:55.697997: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
2017-12-21 22:13:55.699634: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
2017-12-21 22:13:55.699980: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
Traceback (most recent call last):
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
	 [[Node: sparsemax_7/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](sparsemax_7/sub, sparsemax_7/stack)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 570, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 4455, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
	 [[Node: sparsemax_7/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](sparsemax_7/sub, sparsemax_7/stack)]]

Caused by op 'sparsemax_7/GatherNd', defined at:
  File ""<stdin>"", line 1, in <module>
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/contrib/sparsemax/python/ops/sparsemax.py"", line 69, in sparsemax
    tau_sum = array_ops.gather_nd(z_cumsum, indices)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1971, in gather_nd
    ""GatherNd"", params=params, indices=indices, name=name)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
	 [[Node: sparsemax_7/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](sparsemax_7/sub, sparsemax_7/stack)]]
```

",0,,6,2017-12-21T21:31:31Z,NONE
15557,tensorflow::gtl::string_as_array crashes on Windows,stat:contributions welcome,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.1
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
None
- **GCC/Compiler version (if compiling from source)**:
None
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
None

### Describe the problem
Compile and run the following code in VS 2017 in **Debug** Mode.
```c++
#include <iostream>
#include <stdint.h>
using namespace std;

inline char* string_as_array(string* str) { return &*str->begin(); }
int main()
{
	string str;
	char* p = string_as_array(&str);
	std::cout << (uint64_t)p << std::endl;
	return 0;
}
```

It will crash.

```
Debug Assertion Failed!

Program: C:\WINDOWS\SYSTEM32\MSVCP140D.dll
File: c:\program files (x86)\microsoft visual studio\2017\enterprise\vc\tools\msvc\14.12.25827\include\xstring
Line: 1219

Expression: cannot dereference string iterator because it is out of range (e.g. an end iterator)

For information on how your program can cause an assertion
failure, see the Visual C++ documentation on asserts.
```

This function is extracted from  tensorflow\core\lib\gtl\stl_util.h

### Source code / logs

",0,,3,2017-12-21T14:39:03Z,CONTRIBUTOR
15554,Tensorflow Lite exhibits longer inference time when build with Android NN API on Google Pixel 1,comp:lite,"

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
'v1.3.0-rc1-6055-gfdf34a8', '1.4.0'
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.8.0
- **GCC/Compiler version (if compiling from source)**:
GCC 5.4.0-6ubuntu1~16.04.5
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:


### Describe the problem
When enabling the NN API usage (edit interpreter.cc) one would expect that due to the HW acceleration, inferece times would be shorter. However, exactly the opposite happens. I tried this using the included demo app, using mobilenet_quant_v1_224.tflite and a custom (not quantized) model that I converted to tflite. In the mobilenet case, inference takes around 80ms without NNAPI, and ~100ms with NNAPI . My custom model, which sadly I cannot share , takes 40ms without , and ~90ms with NNAPI.

Please note that I have also tested this with FAST_SINGLE_ANSWER  and SUSTAINED_SPEED  NNAPI preference settings. There was no significant change in inference times.

My Pixel Build number is: OPM1.171019.011

### Source code / logs
--- a/tensorflow/contrib/lite/interpreter.cc
+++ b/tensorflow/contrib/lite/interpreter.cc
@@ -51,7 +51,7 @@ Interpreter::Interpreter(ErrorReporter* error_reporter)
   tensors_.reserve(kSlotsToReserve);
   nodes_and_registration_.reserve(kSlotsToReserve);
   next_allocate_node_id_ = 0;
-  UseNNAPI(false);
+  UseNNAPI(true);
",1,,6,2017-12-21T12:58:57Z,NONE
15551,MutilGPU Model can't restore model,stat:awaiting response,"Hi,I use multiple GPU training with tensorflow1.0, and save the model sucessfully, when I restore the model, the error appear here  #line:saver=tf.train.Saver(tf.all_variables()),ValueError:No Variable to save.
I try restore model in training,it works.So,i am confused what is wrong?can anybody help me.
Thank you",0,,3,2017-12-21T09:47:26Z,NONE
15549,Segmetation fault(coredump),stat:awaiting response,"Hi guys, am getting Segmentation fault(coredump) while running keras with tensorflow background in CPU . Can anyone help me 
(imag) research2@research-Precision-T1700:~/imag/ftune$ python3 finetune.py
Using TensorFlow backend.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Found 55 images of 2 classes
Found 54 images of 2 classes
Segmentaion falut(Coredump)

",0,,3,2017-12-21T07:51:38Z,NONE
15542,Cannot run run_cc_test_windows.bat: command line too long,,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows Server 2012
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4.1
376e2cfdab31f4da251ea2e50992a9bf97fd171b
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
0.9.0, 
- **GCC/Compiler version (if compiling from source)**:
VS 2015
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
tensorflow/tools/ci_build/windows/cpu/bazel/run_cc_test_windows.bat

### Describe the problem
Indeed, I have some local modification.  I'm trying to fix some failed cc_tests on Windows, and turn on them in bazel_test_lib.sh 

The problem is: As the number of tests is growing,  we can't pass all their names through command line. We need a new way to filter the tests. 
What about: 
Remove the settings in tensorflow/tools/ci_build/windows/cpu/bazel/run_cc_test_windows.bat,  replace them with bazel tags like ""no_windows"", ""gpu_only"", ... ?

### Source code / logs
[build_log.txt](https://github.com/tensorflow/tensorflow/files/1577981/build_log.txt)
",2,,5,2017-12-21T05:05:58Z,CONTRIBUTOR
15535,[iOS/tflite] Add ability to build a specific arch,"awaiting review,cla: yes,comp:lite","Add a flag to build only the arch you want. By default build all.
Also check number of CPUs when invoking the make commands -j

TEST=tensorflow/contrib/lite/build_ios_universal_lib.sh -a arm64",0,,2,2017-12-21T01:23:07Z,CONTRIBUTOR
15530,Bug?: reading from Google Cloud Storage appears to be accessing cached version,,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: observed on CPU & GPU.
- **GPU model and memory**: observed on CPU & GPU.
- **Exact command to reproduce**: See below.

### Describe the problem

How this arose:

We are trying to set up a basic distributed TF version, where we have separate pods (on Kubernetes) doing validation and training (a simple version, with 1 of each).  GCS is used as the backend to store model output (checkpoints, etc.).

The validation pod periodically (via Experiment’s continuous_eval https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L564) periodically polls for new checkpoints to evaluate (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L517).  

If it doesn’t find a new checkpoint, it (per the underlying code) echoes out “No new checkpoint ready for evaluation” and continues to wait for a new one.

In practice, we found that, even as the training pod produces new checkpoints, the validation pod *never* picks up a new checkpoint, beyond the first one.  I.e., it collects an initial checkpoint, does evaluation, and then, in all future cycles, echoes out ""No new checkpoint ready for evaluation"".

In debugging, we found that the checkpoint file the saver tries to load up is always found to be some earlier iteration of the file (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/python/training/saver.py#L1005) -- i.e., it seems like the GCS file loader reads the file once, and, from then on out, is continuous accessing a cached version of the data.  

Digging into the code further, this appears to be an issue with how the file reader (file_io.read_file_to_string(...) and downstream methods) loads GCS files.  We were able to replicate this behavior separately, below.

**Help appreciated!**

* Is this intended behavior?  Is there, e.g., some sort of GCS setting we have incorrectly set?  
* Assuming we're seeing something real, is there any suggested remediation here, with regards to our validation behavior?  Our next step is going to be to try monkey-patching some of the tf functions to just pull the GCS file local to disk and read it from there...although this is of course not preferred.

As a side note, Experiment does have a number of references to special handling around using GCS as the backend, although I don't have enough context to say if this is relevant to what we are seeing or not (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L94, https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L269).

### Source code / logs

Below is a pair of scripts that will replicate this issue.  Run the “Basic Reader” (using the same loading interface from get_checkpoint_state) and the “Basic Writer” simultaneously, and the reader will initially catch whatever is in the file, and then never update, even as the writer continues to write.

Other things we tried:

* Changing the read/write path to local disk, instead of GCS.  This, unsurprisingly, worked.
* A version of a reader with a context manager (below), to try to reset the reader each loop, and an explicit file.close() (not shown).  Both had the same behavior, i.e., new reads didn't provide the updated file.
* Writing from the same file (process) that we read from: probably unsurprisingly, this *does* work; i.e., the writing activity either updates the local cache or otherwise convinces the reader to grab a fresh copy from GCS (we didn’t actually test which this might be).  

Basic Reader:

```python
#!/usr/bin/env python

from tensorflow.python.lib.io import file_io
import time
import os

file='gs://[MYPATH]'

os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = '/usr/src/app/gcloud/keys/google-auth.json'

def read():
    counter=0
    while counter<15:
        print(""reading..."")
        print(""Contents:"")
        print(file_io.read_file_to_string(file))
        print("""")
        print(""Sleeping for a second..."")
        time.sleep(3)
        print("""")
        print("""")
        print("""")
        counter +=1

read()
```

Basic writer

```python
#!/usr/bin/env python

from tensorflow.python.lib.io import file_io
import time
import os

file='gs://[MYPATH]'

os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = '/usr/src/app/gcloud/keys/google-auth.json'

def write():
    counter=0
    while counter<15:
        with file_io.FileIO(file, mode='w') as f:
            f.write(str(counter))
        print(""Wrote {}"".format(counter))
        print("""")
        print(""Sleeping for a second..."")
        time.sleep(3)
        print("""")
        print("""")
        print("""")
        counter +=1

write()
```

Reader with context manager

```python
#!/usr/bin/env python

from tensorflow.python.lib.io import file_io

import time
import os

file='gs://[MYPATH]'

os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = '/usr/src/app/gcloud/keys/google-auth.json'

def read():
    counter=0
    while counter<15:
        print(""reading..."")
        print(""Contents:"")
        with file_io.FileIO(file, mode='r') as f:
           print(f.read())
        print("""")
        print(""Sleeping for a second..."")
        time.sleep(3)
        print("""")
        print("""")
        print("""")
        counter +=1

read()
```",0,,8,2017-12-20T20:21:18Z,NONE
15522,line 123,stat:awaiting response,"buffer failed to be initialized when data_index== len(data) (at the end of file it basically failed to go to the top) and gives the following error << TypeError: sequence index must be integer, not 'slice'
>> one work around is to replace line 123 with << buffer.extend(data[:span]) >> ",0,,3,2017-12-20T16:56:22Z,NONE
15505,Unable to generate my_frozen_graph.pb due to missing conv.ckpt checkpoint file,stat:awaiting response,"------------------------

### System information
Linux ubuntu 16.04
CUDA 9.1
cuDNN 7
TensorFlow version ('v1.4.0-19-ga52c8d9', '1.4.1')

Additional info:

2017-12-20 07:36:22.294690: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU sup
ports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX
2 FMA
2017-12-20 07:36:22.360228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] succe
ssful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA 
node, so returning NUMA node zero
2017-12-20 07:36:22.360615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found de
vice 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 8.42GiB
2017-12-20 07:36:22.360643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating
 TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, 
compute capability: 3.7)

**Exact command to reproduce**:
According to https://www.tensorflow.org/versions/master/tutorials/audio_recognition#custom_training_data, specifically:

To train...
```
python tensorflow/examples/speech_commands/train.py
```
After training is finished, run freeze.py to generate a `my_frozen_graph.pb` which will later be used by `label_wav` for prediction.

```
python tensorflow/examples/speech_commands/freeze.py \
--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-18000 \
--output_file=/tmp/my_frozen_graph.pb
```

### Describe the problem
After training the speech commands app:
A `conv.ckpt-18000` file should appear after training is complete. 

However the only files which appear are ones with extensions:

- *.data-00000-of-00001
- *.meta
- *.index
- checkpoint

I've tried tensorflow releases 1.4.0-rc1, 1.4.0 and 1.4.1 but no luck generating a `conv.ckpt-18000` file.

I've even tried:
```
with tf.Session() as sess:
    new_saver = tf.train.import_meta_graph('/tmp/speech_commands_train/conv.ckpt-18000.meta')
    new_saver.restore(sess, tf.train.latest_checkpoint('./'))
```

which errors out due to:

`ValueError: No op named DecodeWav in defined operations.`

### Source code / logs
```
ls -ltr /tmp/speech_commands_train/
total 18348
...
-rw-r--r-- 1 root root  121649 Dec 20 07:07 conv.pbtxt
-rw-r--r-- 1 root root      60 Dec 20 07:07 conv_labels.txt
-rw-r--r-- 1 root root     315 Dec 20 09:17 conv.ckpt-17600.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:17 conv.ckpt-17600.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:17 conv.ckpt-17600.meta
-rw-r--r-- 1 root root     315 Dec 20 09:18 conv.ckpt-17700.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:18 conv.ckpt-17700.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:18 conv.ckpt-17700.meta
-rw-r--r-- 1 root root     315 Dec 20 09:18 conv.ckpt-17800.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:18 conv.ckpt-17800.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:18 conv.ckpt-17800.meta
-rw-r--r-- 1 root root     315 Dec 20 09:19 conv.ckpt-17900.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:19 conv.ckpt-17900.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:19 conv.ckpt-17900.meta
-rw-r--r-- 1 root root     315 Dec 20 09:20 conv.ckpt-18000.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:20 conv.ckpt-18000.data-00000-of-00001
-rw-r--r-- 1 root root     433 Dec 20 09:20 checkpoint
-rw-r--r-- 1 root root   75448 Dec 20 09:20 conv.ckpt-18000.meta
```
",0,,4,2017-12-20T08:03:55Z,CONTRIBUTOR
15503,Behavior change of tf.app.flags parsing boolean args,,"tf version 1.5.0-dev20171219
for example below args
flags.DEFINE_boolean('pre_calc_image_feature', False, '')

when using tf 1.4.1 it is ok to do --pre_calc_image_feature 0
which got FLAGS.pre_calc_image_feature == False.
But for tf 1.5 you must use --pre_calc_image_feature=0 if you still use --pre_calc_image_feature 0
then you will get FLAGS.pre_calc_image_feature == True. 

Not sure if this is a bug or just by design but personally I think tf version 1.4.1 is better handling this case.
",0,,4,2017-12-20T07:22:34Z,NONE
15501,Env::MatchPath has different behavior on Windows and Linux,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
None
- **GCC/Compiler version (if compiling from source)**:
None
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:



### Describe the problem
For example,

name | pattern |  result on windows | result on Linux
-------|---------|----------------------|--------------
a/a,  |   \*,         |   Matches                 |  No match
a/a/a.txt| \*/\*  |   Matches                 |  No match

As GcsFileSystem uses this function for result filtering,  GcsFileSystem has different behavior on Windows and Linux. It's odd to me. 

### Source code / logs
```c++
#include <Windows.h>
#include <Shlwapi.h>
#include <iostream>
int main()
{
   std::cout << PathMatchSpec(L""aaa\\bbb\\ccc.txt"", L""*"") << std::endl;
    return 0;
}
```

```c
#include <stdio.h>
#include <fnmatch.h>

int main(){
  printf(""%d\n"",fnmatch(""aaa/bbb/ccc.txt"",""*/*"",FNM_PATHNAME));
  return 0;
}
```",0,,3,2017-12-20T06:37:38Z,CONTRIBUTOR
15492,build issue: invalid paths,stat:awaiting response,"### System information
Linux ubuntu 16.04
Bazel 0.9.0
CUDA 9.1
cuDNN 7
TF Branch r1.4

I am getting the following errors / warnings using the set-up above, whilst trying to build the python packages.

```
francesco@franny:~/Repositories/tensorflow$ git checkout r1.4
Branch 'r1.4' set up to track remote branch 'r1.4' from 'origin'.
Switched to a new branch 'r1.4'
francesco@franny:~/Repositories/tensorflow$ ./configure 
Extracting Bazel installation...
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.google.protobuf.UnsafeUtil (file:/home/francesco/.cache/bazel/_bazel_francesco/install/754ae0b065b3dfe883541ff567ae8b5e/_embedded_binaries/A-server.jar) to field java.nio.Buffer.address
WARNING: Please consider reporting this to the maintainers of com.google.protobuf.UnsafeUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
You have bazel 0.9.0 installed.
Please specify the location of python. [Default is /usr/bin/python]: 


Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n
No jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL support? [y/N]: n
No OpenCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 9.1


Please specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 7


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:


Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]5.2


Do you want to use clang as CUDA compiler? [y/N]: n
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 


Add ""--config=mkl"" to your bazel command to build with MKL support.
Please note that MKL on MacOS or windows is still not supported.
If you would like to use a local MKL instead of downloading, please set the environment variable ""TF_MKL_ROOT"" every time before build.
Configuration finished
francesco@franny:~/Repositories/tensorflow$

francesco@franny:~/Repositories/tensorflow$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
.........
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:4:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:6:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:30:9: Traceback (most recent call last):
	File ""/home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD"", line 27
		cc_library(name = ""syclrt"", srcs = [sycl_libr..."")], <3 more arguments>)
	File ""/home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD"", line 30, in cc_library
		sycl_library_path
name 'sycl_library_path' is not defined
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:39:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '@local_config_sycl//sycl:sycl'
ERROR: /home/francesco/Repositories/tensorflow/third_party/eigen3/BUILD:20:1: Target '@local_config_sycl//sycl:sycl' contains an error and its package is in error and referenced by '//third_party/eigen3:eigen3'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Loading failed
INFO: Elapsed time: 13.322s
FAILED: Build did NOT complete successfully (93 packages loaded)
    currently loading: tensorflow/core/kernels ... (2 packages)

```

Any help?",0,,14,2017-12-19T19:40:48Z,NONE
15490,Cannot reshape with shape=[tensorshapes...],stat:awaiting response,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Debian 9.3
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.3.0
- **Python version**: 
2.7.13
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
6.0.21
- **GPU model and memory**:
GTX titan X (pascal) 12GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I have several Conv layers and after the last max pooling step, I want to flatten the last pooled layer shape=(Batchsize, height, width, channels) to (Batchsize, -1). It returned error saying some dims are None.  
I tried to print the BS and other_dims, it can be printed to int numbers, none of them are None
If I entered explicit int numbers tf.reshape(x, [2,10]) it will work.
# top MLP
        shape = tf.shape(pooled_h[-1])
        BS = shape[0]
        other_dims = shape[1] * shape[2] * shape[3]
        last_pooled_flat = tf.reshape(pooled_h[-1], [BS, other_dims])  # (BS, n_flat_feats)
        mlp_h = [last_pooled_flat]  # to store mlp hidden layers
# MLP alyers
        for j in range(self.n_mlp_layers):
            h = tf.layers.dense(
                inputs=mlp_h[j],
                units=self.hidden_sizes[i],
                activation=tf.nn.relu,
                kernel_initializer=tf.contrib.layers.xavier_initializer(
                            uniform=True, seed=None, dtype=tf.float32),
                bias_initializer=tf.zeros_initializer(),
                kernel_regularizer=L2_regularizer,
                bias_regularizer=L2_regularizer,
                name=""mlp_{}"".format(j),
                reuse=False)
            mlp_h.append(h)
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Traceback (most recent call last):
  File ""basemodel_builder.py"", line 143, in <module>
    out = model.apply_rel(x_q, x_d, 1.0)
  File ""basemodel_builder.py"", line 117, in apply_rel
    reuse=False)
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py"", line 215, in dense
    return layer.apply(inputs)
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 503, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 443, in __call__
    self.build(input_shapes[0])
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py"", line 109, in build
    raise ValueError('The last dimension of the inputs to `Dense` '

",0,,3,2017-12-19T19:27:51Z,NONE
15473,tf.contrib.ffmpeg.decode_audio() prints the ffmpeg stdout,stat:awaiting response,"tf.contrib.ffmpeg.decode_audio() prints the ffmpeg stdout for each input and there seems to be not functionality available to suppress that. 


",0,,3,2017-12-19T08:28:27Z,NONE
15469,Compute test accuracy in batches to avoid OOM on GPUs,"cla: yes,stat:awaiting response","Reported here: https://github.com/tensorflow/tensorflow/issues/136
Alternative to this for mnist_deep.py: https://github.com/tensorflow/tensorflow/pull/157

Note that some reports in https://github.com/tensorflow/tensorflow/issues/136 claim that BFC solves the problem and that it would be included in the next binary release, but as this writing is two years after those comments, it stands to reason that the example still doesn't work out of the box for ""low"" memory GPUs.

Also noting for completeness that I am running on a GeForce GTX 670 (2GB) and that avg(avg(x_i)) = avg(x_i) when |x_i| for all i is equal. ",0,,2,2017-12-19T04:30:42Z,NONE
15467,some proposal about  tf.metrics,"stat:contributions welcome,type:feature","Have I written custom code  :  YES
OS Platform and Distribution  -Win10
TensorFlow installed from - pip3
TensorFlow version-1.4
Bazel version
CUDA/cuDNN version-8.0
GPU model and memory-2GB
Exact command to reproduce 
## Describe the problem
    

I want to know true-positive,ture-nagetive,false-positive,false-nagetive,recall,precision for each class.
 Although I can implement it at this version(1.40), it need lots of code. I mean the functions don't
 support the multi-class well, it just for the 2 class condition. I think if I can implement them with few
 code, it looks more elegant. 


",0,,6,2017-12-19T03:24:54Z,NONE
15465,No gradient defined for operation 'MatrixExponential' (op type: MatrixExponential),,"I want to optimize a function which contains tf.linalg.expm, however,

No gradient defined for operation 'MatrixExponential' (op type: MatrixExponential)

",0,,7,2017-12-19T02:09:52Z,NONE
15464,[Feature Request] Sparse compute_gradient,,"I am working on an extremely large scale linear model and have been trying to optimize the performance of the TF optimizer.

**Have I written custom code**
Version I.
My feature size is huge (500Mil) and sparse, so I was testing if I could make TF only compute the necessary gradients and apply it using some function like tf.scatter_sub()
My graph is like this:
```
cost = fn(w)
vars_to_update = tf.gather(w, non_zero_indices)
grads = tf.gradients(cost, vars_to_update)
update_op = tf.scatter_sub(w, non_zero_indeces, grads)
```
I found that tf.graidents() always returns None for tf.gather(). Similar condition if I pass tf.gather() to any optimizer like tf.train.GradientDescentOpitmizer(cost, tf.gather(w, indices)), it will throw unsupported error for tf.gather(). 

I was wondering if I did anything wrong or TF just doesn't support sparse gradient computation? If latter does TF team plan to have that implemented in short future?

Version II.
In stead of creating a sparse tensor and do sparse_tensor_dense_matmul(), I also tried using tf.gather() follow by tf.segment_sum() to implement W*X. By doing this the optimizer apparently automatically performed sparse grad computation and sparse update. However, the speed of the optimizer was **horribly slower (15seconds)** than the sparse tensor approach. And idea why?

Pseudo code:
```
active_weights = tf.gather(weights, non_zero_indices)
total = tf.segment_sum(
                tf.reshape(activated_weights, [-1]),
                segment_ids //which is the row number e.g. [0,0,0,0,1,1,1,2,2,2,3,3,...]
                )
update_op = tf.train.GradientDescentOptimizer().minimize(total, active_weights)
```

**OS Platform and Distribution**
Centos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )

**TensorFlow installed from (source or binary)**
pip install tensorflow

**TF version**
1.3.0

**Python version**
2.7.5

**Bazel version, CUDA/cuDNN, GPU model and memory, Exact command to reproduce**
N/A

**Also there might be a potential bug**
If in the second approach (tf.gather() and tf.segment_sum()) I replace GradientDescentOptimizer with Adam or Adagrad optimizer, the memory would blow up very quickly. I did not look into why that happened so I am not sure if this worth a bug ticket.",0,,7,2017-12-19T00:42:07Z,CONTRIBUTOR
15463,Bug: StagingArea.size() always return 0 when placed on a different device,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:b'v1.3.0-rc1-6044-g0b80606' 1.4.0
- **Python version**:  3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0/7.0
- **GPU model and memory**:
- **Exact command to reproduce**:

```python
import tensorflow as tf
from tensorflow.python.ops.data_flow_ops import StagingArea

areas = []
stage_ops = []
sizes = []
for idx, d in enumerate(['/gpu:0', '/gpu:1']):
    with tf.device(d):
        inputs = [tf.constant(1.0), tf.constant(2, dtype=tf.uint8)]
        dtypes = [k.dtype for k in inputs]
        stage = StagingArea(dtypes, shapes=None)
        stage_ops.append(stage.put(inputs))
        areas.append(stage)
        # sizes.append(stage.size())   # this gives correct result

sizes = [k.size() for k in areas]    # this gives wrong result
with tf.Session() as sess:
    print(sess.run(sizes))    # [0, 0]
    sess.run(stage_ops[0])
    sess.run(stage_ops[1])
    sess.run(stage_ops[0])
    sess.run(stage_ops[1])
    print(sess.run(sizes))  # expected: [2,2]; actual: [2,0]
```",1,,4,2017-12-19T00:39:07Z,CONTRIBUTOR
15455,Add customerized kernel implementation for clip_by_value,"awaiting review,cla: yes","This fix is a follow up on #13998 as it was reverted in https://github.com/tensorflow/tensorflow/commit/943201bf1a959acf6a08b88a488b3db55404835c

This fix adds the customerized kernel implementation for `tf.clip_by_value`.

This fix is related to #13998, also see #15427

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,1,2017-12-18T18:19:05Z,MEMBER
15447,[cmake] CPU only build error in tf_stream_executor.cmake,"stat:community support,stat:contributions welcome","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master
- **Python version**: N/A, building with cmake
- **Bazel version (if compiling from source)**: N/A, building with cmake
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
cd tensorflow/contrib/cmake
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=""../bin"" ..

### Describe the problem
cmake build fails when 
option(tensorflow_ENABLE_GPU ""Enable GPU support"" OFF)
with following error:
.../tensorflow-master/tensorflow/stream_executor/dso_loader.h:32:30: fatal error: cuda/cuda_config.h: No such file or directory
compilation terminated.

### Source code / logs
Pretty sure that the issue lies in this commit:
https://github.com/tensorflow/tensorflow/commit/f1582cf82f06810900ee99870f5d5d3a7478d044#diff-1d799fa350437420218e5e5aa680c481

in CMakeLists.txt the line
""  include_directories(${tensorflow_source_dir}/third_party/gpus)""
is still under tensorflow_ENABLE_GPU

Which is why dso_loader cannot find cuda_config.h

On the other hand, I suppose it should not use this include at all in the CPU mode.",0,,2,2017-12-18T14:48:20Z,NONE
15445,Cannot compile tensorflow lite (TfLiteCameraDemo and tensorflow/python/tools:freeze_graph) on macOS Sierra,"comp:lite,stat:awaiting response","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.1 (fdf34a8 on master branch)
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: 0.8.1-homebrew
- **GCC/Compiler version (if compiling from source)**: Xcode 9.2
- **CUDA/cuDNN version**:  (not using cuda)
- **GPU model and memory**: (not using GPU)
- **Exact command to reproduce**: `bazel build -c opt --cxxopt='--std=c++11' //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo`

### Describe the problem
I can compile tensorflow android demo on macOS, but cannot compile tensorflow lite android demo successfully. What I actually want to do is convert a tensorflow model to tensorflow lite model. Similar errors happen.

**UPDATE on Dec 19, 2017: I found the workaround/solution. See my reply below.**

### Source code / logs
Compiled tensorflow android demo on macOS successfully.
```
$ bazel build -c opt //tensorflow/examples/android:tensorflow_demo
...
Target //tensorflow/examples/android:tensorflow_demo up-to-date:
  bazel-bin/tensorflow/examples/android/tensorflow_demo_deploy.jar
  bazel-bin/tensorflow/examples/android/tensorflow_demo_unsigned.apk
  bazel-bin/tensorflow/examples/android/tensorflow_demo.apk
INFO: Elapsed time: 862.549s, Critical Path: 112.20s
INFO: Build completed successfully, 776 total actions
```

But failed to compile tensorflow lite android demo.
```
$ bazel build -c opt --cxxopt='--std=c++11' //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/types/optional.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/types' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/types:optional.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/base/config_test.cc' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/base' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/base:config_test.cc'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/internal/address_is_readable.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:internal/address_is_readable.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/leak_check.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:leak_check.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/strings/BUILD.bazel' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/strings' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/strings:BUILD.bazel'?)
...
```

Similar errors happen when I wanted to build the tool of converting tensorflow model to tensorflow lite model which is what I really need.
```
$ bazel build tensorflow/python/tools:freeze_graph
WARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/core/BUILD:1806:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/tensorflow.bzl:1131:30
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/types/optional.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/types' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/types:optional.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/base/config_test.cc' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/base' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/base:config_test.cc'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/internal/address_is_readable.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:internal/address_is_readable.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/leak_check.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:leak_check.h'?)
WARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/strings/BUILD.bazel' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/strings' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/strings:BUILD.bazel'?)
...
```

My config in `WORKSPACE`
```
android_sdk_repository(
    name = ""androidsdk"",
    api_level = 23,
    build_tools_version = ""26.0.1"",
    path = ""/Users/XXX/Resources/Android/sdk"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/Users/XXX/Resources/Android/ndk/android-ndk-r14b"",
    api_level=14,
)
```

Other
```
$ python --version
Python 2.7.13 :: Continuum Analytics, Inc.
$ bazel version
Build label: 0.8.1-homebrew
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Dec 5 19:33:07 2017 (1512502387)
Build timestamp: 1512502387
Build timestamp as int: 1512502387
```

```

== cat /etc/issue ===============================================
Darwin ITSG000227-MAC.local 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.0.0 (clang-900.0.39.2)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin ITSG000227-MAC.local 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 25, in <module>
    from tensorflow.python.platform import self_check
ImportError: No module named platform

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
```",0,,16,2017-12-18T11:59:53Z,NONE
15440,Make get_placeholders() accessible and add example,"awaiting review,cla: yes","This is an improvement of PR #14541.
This PR makes get_placeholders() visible in the document as `tf.contrib.framework.get_placeholders` and add example to the docstring.

- [x] Make get_placeholders() accessible
- [x] Add example",0,,4,2017-12-18T09:09:24Z,CONTRIBUTOR
15435,tensorflow-gpu not working with pycharm,stat:awaiting response,"I am trying to get the tensorflow-gpu working on pycharm but it doesn't compile. When I compile it, it gives me the following compile error

> ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL:

I am using Pycharm with the Python 3.6 venv and I am pretty sure I have CUDA 8.0 installed. When I check the directory of CUDA\v8.0\bin, it shows the cudart64_80.dll 

It works perfectly on the CPU version but I want it working on the GPU side",0,,8,2017-12-18T07:15:33Z,NONE
15433,[Feature Request] Automatic node placement,stat:awaiting response,"I read tensorflow white papaer and found node placement which allocates graph nodes to devices without manual configuration.

https://www.reddit.com/r/MachineLearning/comments/4n6a0e/distributed_tensorflow_resource_allocation/

However, this post says this feature was removed because it did not perform well.

I think that automatic allocating graph nodes to devices for optimizing parallel execution is necessary to fully use distributed tensorflow. 

Do you have the plan to add this feature in the future tensorflow?

",0,,3,2017-12-18T04:46:29Z,NONE
15430,Placeholders should have a feeding schedule in TensorFlow?,stat:awaiting response,"I have a parameter which should set **at the beginning** of each epoch and it is **constant** during the epoch's execution. Currently, we defined a placeholder for this param and during the training I have to pass the same value in each iteration:

`sess.run(train_op, feed_dict={param: const_param})`

It's a bit inefficient since pass the same value at each step of the same epoch. Is it possible to define a placeholder and feed it once just at the beginning of each epoch?

This feature is available in _tf.data_ when set the tfrecords file at the beginning and fetch data iteratively.",0,,3,2017-12-17T19:45:08Z,CONTRIBUTOR
15428,[BUG] Cifar10 mutigpu loss does not decrease and is oscillating ,stat:awaiting response,"Hi
I want to develope a resnet50 multigpu system in tensorflow,
so I want to replace my model in [**cifar10_multigpu_train**](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py)
but when I run this code, loss does not decrease efficiently,until step 5000
my question is : can I trust this code? Is  the code correct?
**I use:**
ubuntu 16.04
installed tensorflow with pip2
tensorflow 1.4
cudnn       6 
cuda     8.0.44
Gtx 1080 (2 gpus/8g memory)

command to produce:
go to the above link,download **cifar10_multi_gpu_train.py** and run it 
",0,,3,2017-12-17T19:25:31Z,NONE
15426,"Unsuccessful TensorSliceReader constructor: Failed to find any matching files for          [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",stat:awaiting response,"I am working on a TensorFlow Speech Recognition challenge and following https://www.tensorflow.org/tutorials/audio_recognition tutorial. The model training is completed, but I'm not able to Freeze the model.
This is what I get after typing the required command:

```
`C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\Lib\site-packages\tensorflow\examples\speech_commands>python freeze.py \
2017-12-17 01:43:38.739183: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2017-12-17 01:43:39.455821: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.2415
pciBusID: 0000:03:00.0
totalMemory: 4.00GiB freeMemory: 3.36GiB
2017-12-17 01:43:39.455957: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce 940MX, pci bus id: 0000:03:00.0, compute capability: 5.0)
2017-12-17 01:43:39.580220: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.588122: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.596502: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.601314: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.607839: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.613370: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
Traceback (most recent call last):
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1323, in _do_call
    return fn(*args)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
         [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
         [[Node: save/RestoreV2_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_18_save/RestoreV2_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""freeze.py"", line 180, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""freeze.py"", line 117, in main
    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\Lib\site-packages\tensorflow\examples\speech_commands\models.py"", line 123, in load_variables_from_checkpoint
    saver.restore(sess, start_checkpoint)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1666, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run
    run_metadata_ptr)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
         [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
         [[Node: save/RestoreV2_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_18_save/RestoreV2_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'save/RestoreV2_1', defined at:
  File ""freeze.py"", line 180, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""freeze.py"", line 117, in main
    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\Lib\site-packages\tensorflow\examples\speech_commands\models.py"", line 122, in load_variables_from_checkpoint
    saver = tf.train.Saver(tf.global_variables())
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1218, in __init__
    self.build()
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1227, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1263, in _build
    build_save=build_save, build_restore=build_restore)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 751, in _build_internal
    restore_sequentially, reshape)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 427, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 267, in restore_op
    [spec.tensor.dtype])[0])
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1020, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
         [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
         [[Node: save/RestoreV2_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_18_save/RestoreV2_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]`
```
OS - Windows 10
TensorFlow version - 1.4
Python version - 3.6.3
GPU - CUDA V 8 and cuDNN V 6.0

I came across [https://github.com/tensorflow/tensorflow/issues/6082] and [https://github.com/tensorflow/tensorflow/issues/7547](url) where the suggested fix was to add ""./"" to the model name. But, in this case I'm not able find the list of codes where I'm supposed to make the change. How do I find the code that needs the fix? Or is there another issue that I'm unaware of?

Please help.",0,,3,2017-12-17T12:43:29Z,NONE
15425,TypeError: broadcast() takes 1 positional argument but 2 were given,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**: b'v1.3.0-rc1-6044-g0b80606' 1.4.0    (2 days ago)
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Source code / logs
I ran `tensorflow/benchmarks`, and got the following error.
```
Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 47, in <module>
    tf.app.run()
  File ""/MYHOME/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""tf_cnn_benchmarks.py"", line 43, in main
    bench.run()
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 956, in run
    return self._benchmark_cnn()
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1046, in _benchmark_cnn
    self._build_model_single_session())
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1563, in _build_model_single_session                                                                      all_top_5_ops, phase_train)
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1370, in _build_fetches
    self.variable_mgr.preprocess_device_grads(device_grads))
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/variable_mgr.py"", line 386, in preprocess_device_grads
    agg_small_grads_max_group=self._agg_small_grads_max_group)
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/allreduce.py"", line 332, in sum_gradients_all_reduce
    if is_hierarchical else aux_device_groups[group_index], num_shards))
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/allreduce.py"", line 236, in sum_grad_and_var_all_reduce
    tf.add)
  File ""/MYHOME/.local/lib/python3.6/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py"", line 780, in build_nccl_then_ring
    return _build_nccl_hybrid(input_tensors, red_op, upper_level_f)
  File ""/MYHOME/.local/lib/python3.6/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py"", line 748, in _build_nccl_hybrid
    send_op, dst_tensors = nccl.broadcast(level_2_output[w], dst_devices)
TypeError: broadcast() takes 1 positional argument but 2 were given
```

The reason is that the invocation of `nccl.broadcast` is different from its signature:
https://github.com/tensorflow/tensorflow/blob/17e725c0558581cba19bd6c409698b2c3f88efe5/tensorflow/contrib/all_reduce/python/all_reduce.py#L748
https://github.com/tensorflow/tensorflow/blob/17e725c0558581cba19bd6c409698b2c3f88efe5/tensorflow/contrib/nccl/python/ops/nccl_ops.py#L173-L182 
Problems still exists in current HEAD.",1,,10,2017-12-17T10:31:02Z,CONTRIBUTOR
15421,Add complex64 and complex128 support for `tf.angle` on GPU,"awaiting review,cla: yes","In PR #10643, complex64 and complex128 support have been added for `tf.angle` on CPU. However, because of the compiling errors, the complex support on GPU is not enabled yet.

The issue was that, std::arg is not available on nvidia device for GPU. This fix changes to used atan2 instead, which is available in CUDA.

The relevant test cases have bee enabled.

This fix is related to #10643.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",0,,0,2017-12-16T23:49:16Z,MEMBER
15416,tensorflow-aarch64 with keras,,"
![screenshot_2017-12-17-15-05-30-239_ru iiec pydroid3](https://user-images.githubusercontent.com/31110466/34079284-0cd76cc4-e33c-11e7-8442-438e88e1a38d.png)
![screenshot_2017-12-17-15-04-20-194_ru iiec pydroid3](https://user-images.githubusercontent.com/31110466/34079285-0d1d5edc-e33c-11e7-9109-fbfdce775814.png)
![screenshot_2017-12-17-15-04-36-922_ru iiec pydroid3](https://user-images.githubusercontent.com/31110466/34079287-0d65de50-e33c-11e7-9b62-9d5b5027b131.png)


Hi! I want to use tensorflow library as backend of keras on my android device. I found and installed pydroid3, keras and tensorflow-aarch64. How can i use it? When i run code it throws exception ""no module named tensorflow"". Any ideas?

Ok, i will.
I used Keras. When i import, it throws exception.
My OS is Android 7.1.2 MIUI 9, CPU arch - aarch64 (arm), GPU is Snapdragon 505. Using PyDroid3 app
I installed tensorflow-aarch64 1.2 from pip.
No bazel.
No cuDNN.",0,,4,2017-12-16T18:01:17Z,NONE
15413,Android Failed To Run Inference,stat:awaiting response,"Have I written custom code: No
OS Platform and Distribution: Android
TensorFlow installed from: binary
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

### Describe the problem
With JNI libtensorflow_core.a etc. I can do inference with my model, which is frozen and stripped off unused op by transform_graph [tool](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/tools/graph_transforms/README.md).
But it took so long, about 50 secs to run on a 1x300x400x3 sized input image. I guess maybe the libtensorflow_core.a that I download from [TensorflowPrebuiltWebsite](http://ci.tensorflow.org/job/tensorflow-master-android/) is built in debug mode. The reason why I download libtensorflow_core.a is because I have trouble building it myself.

So I want to use Java API to do inference and see how much time it takes.
This is done by adding dependencies in build.gradle:
`
dependencies {
    compile 'org.tensorflow:tensorflow-android:+'
}
`

But with Java API it throws exceptions for parsing the .pb file. I guess my .pb is incompatible. So I took a step back, I only froze the graph but not stripping off unused op. This time Java API is able to parse the .pb file. But after feed inputs, it throws exception when I call run method on org.tensorflow.contrib.android.TensorFlowInferenceInterface.run().

I have also tried to download prebuilt libandroid_tensorflow_inference_java.jar and libtensorflow_inference.so from [TensorflowPrebuiltWebsite](http://ci.tensorflow.org/view/Nightly/job/nightly-android/lastSuccessfulBuild/artifact/out/), but not working.

Notice that I can do inference with C++ code, that means my neural network model *.pb is CORRECT. I think this is a bug with Java API or its corresponding native implementation.

### logs
12-16 11:33:59.954 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/System.out: debugger has settled (1330)
12-16 11:33:59.998 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/HwCust: Constructor found for class android.app.HwCustHwWallpaperManagerImpl
12-16 11:34:00.026 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance W/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable
12-16 11:34:00.157 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded
12-16 11:34:00.157 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: TensorFlow native methods already loaded
12-16 11:34:00.231 23001-23012/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/art: humin current process: cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance
12-16 11:34:00.231 23001-23012/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/art: current process_level is : 0
12-16 11:34:00.437 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Model load took 169ms, TensorFlow version: 1.4.0
12-16 11:34:00.437 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Successfully loaded model from 'frozen_graph.pb'
12-16 11:34:14.460 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[is_training, feed_input], outputs:[hdr_conv_out/LeakyRelu/Maximum]
12-16 11:34:14.789 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/Process: Sending signal. PID: 23001 SIG: 9


### Source code
My project is on git [here](https://gitee.com/ZhongBaby/TestTensorflowJavaAPIPerformance), please help me, thanks!

",0,,3,2017-12-16T03:34:34Z,NONE
15412,tf.contrib.memory_stats.MaxBytesInUse() got `Op type not registered 'MaxBytesInUse' in binary running` error,,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Should be Yes, as subtitle Source code below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 7 x64
- **TensorFlow installed from (source or binary)**:
`pip install tensorflow-gpu` with Anaconda on windows prompt following the tensorflow official tutorial
- **TensorFlow version (use command below)**:
tensorflow-gpu 1.4.0
- **Python version**: 
3.6, Anaconda
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
8.0/6.0
- **GPU model and memory**:
GTX 1080TI
- **Exact command to reproduce**:
a simply `python code.py` or following source in python

### Describe the problem
The GPU training is all fine on my placement. 
But when I wanna track the memory usage I got the error using MaxBytesInUse(),
the problem is not solved even I upgrade TF from 1.3 to 1.4.
And of course the same error using BytesInUse().

Is any solution or is the possibility that the method not support for Win7? Thanks.

### Source code / logs
The Op created failed even the simple code execute as follow, when I run MaxBytesInUse() to get a tensor to `a` then it failed.

```
import tensorflow as tf
a = tf.contrib.memory_stats.MaxBytesInUse()
```
And got the message
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\contrib\memory_stats\python\ops\memory_stats_ops.py"", line 41, in MaxBytesInUse
    return gen_memory_stats_ops.max_bytes_in_use()
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\contrib\memory_stats\ops\gen_memory_stats_ops.py"", line 88, in max_bytes_in_use
    ""MaxBytesInUse"", name=name)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2958, in create_op
    set_shapes_for_outputs(ret)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2209, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2159, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'MaxBytesInUse' in binary running on MY-PC. Make sure the Op and Kernel are registered in the binary running in this process.
```",0,,8,2017-12-16T02:42:40Z,NONE
15410,Calling tf.contrib.lite.toco_convert results in global name 'tempfile' is not defined error,"comp:lite,stat:awaiting response,type:bug/performance","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

Related SO post - https://stackoverflow.com/questions/47645056/tensorflow-lite-toco-python-apl-nameerror-name-tempfile-is-not-defined

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Followed example on Tensorflow Lite documentation

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS High Sierra

- **TensorFlow installed from (source or binary)**:
Source

- **TensorFlow version (use command below)**:
('v1.3.0-rc1-5910-ge2174cc943', '1.4.0')

- **Python version**: 
2.7.10

- **Bazel version (if compiling from source)**:
bazel release 0.5.4-homebrew

- **GCC/Compiler version (if compiling from source)**:
Apple LLVM version 9.0.0 (clang-900.0.34.1)

- **CUDA/cuDNN version**:
N/A (CPU only)

- **GPU model and memory**:
N/A

- **Exact command to reproduce**:

```
import tensorflow as tf
img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name=""out"")
with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open(""converteds_model.tflite"", ""wb"").write(tflite_model)

```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Opened python on terminal and ran

```
import tensorflow as tf
img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name=""out"")
with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open(""converteds_model.tflite"", ""wb"").write(tflite_model)

```

Resulting output is

```
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/Library/Python/2.7/site-packages/tensorflow/contrib/lite/python/lite.py"", line 198, in toco_convert
    input_data.SerializeToString())
  File ""/Library/Python/2.7/site-packages/tensorflow/contrib/lite/python/lite.py"", line 91, in toco_convert_protos
    with tempfile.NamedTemporaryFile() as fp_toco, \
NameError: global name 'tempfile' is not defined
```

As a sanity check I ran the following

```
import tempfile
with tempfile.NamedTemporaryFile() as fp_toco:
     print fp_toco.name
```
Output was /var/folders/hd/7yc9wgwj5wvd43_d94b4m47m0000gn/T/tmpxxdYMY


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.",1,,7,2017-12-16T00:34:00Z,NONE
15408,New rolling window batch operation for tf.data.Dataset #15044,"awaiting review,cla: yes","This is a new feature

For help pre-processing datasets, creates a transformation function that can be applied to a tf.data.Dataset Object to create a new Dataset by rolling a window across the initial Dataset to create the batches for the new Dataset.

*Fails if Dataset is too large to fit in memory (possible future work?)

",0,,2,2017-12-15T22:24:21Z,NONE
15404,DOCS: Update the description of the fused parameter.,"awaiting review,cla: yes","Update the description of layers.batch_normalization and contrib.layers.python.layers.batch_norm to reflect the fact that fused=None is equivalent to fused=True. In fact, both functions check at the beginning if fused is None, and if yes they set it to True.",0,,3,2017-12-15T19:26:06Z,CONTRIBUTOR
15402,Add complex64 and complex128 support for ApplyAdadelta kernel,"cla: yes,stat:awaiting response","This fix tries to address the issue raised in #13521 where the complex64 and complex128 support for ApplyAdadelta is missing. The test cases have also been updated.

This fix fixes #13521.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,4,2017-12-15T18:26:56Z,MEMBER
15400,setuptools error on upgrading to 1.4.1,,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Sierra
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6 (normal install, NO virtualenv, NO anaconda, ...)
- **Exact command to reproduce**: ```sudo pip3 install --upgrade tensorflow```

When upgrading TF 1.4.0 to 1.4.1 using the command above, I get the error message:
```
Could not import setuptools which is required to install from a source distribution.
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/req/req_install.py"", line 387, in setup_py
    import setuptools  # noqa
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/__init__.py"", line 10, in <module>
    from setuptools.extern.six.moves import filter, map
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/extern/__init__.py"", line 1, in <module>
    from pkg_resources.extern import VendorImporter
ModuleNotFoundError: No module named 'pkg_resources.extern'
```

I have been able to solve the problem with the following command:

```
pip3 install -U setuptools
```
After this, running pip3 install --upgrade Tensorflow runs successfully.",0,,5,2017-12-15T17:34:42Z,NONE
15396,Bug: reshape shape inference for parital defined shape,,"-----------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Python 3.6.3 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: see example

### Describe the problem
When the input shape for 'tf.reshape' is partial defined and the new shape contains a `-1` for known dimensions, 'tf.reshape' does not predict the shape. See the example code.

### Source code / logs

Second and third example have working shape inference:
```python
def foo(*shape):
    x = tf.placeholder(tf.float32, shape)
    return tf.reshape(x, tf.concat([tf.shape(x)[:-2], [-1]], 0))

print(foo(2, 3, 4, 5))  # Tensor(""Reshape_8:0"", shape=(2, 3, 20), dtype=float32)  # correct
print(foo(None, 3, 4, 5))  # Tensor(""Reshape_9:0"", shape=(?, 3, ?), dtype=float32)  # shape inference possible
print(foo(None, None, 4, 5))  # Tensor(""Reshape_10:0"", shape=(?, ?, ?), dtype=float32)  # shape inference possible
print(foo(2, 3, 4, None))  # Tensor(""Reshape_11:0"", shape=(2, 3, ?), dtype=float32)  # correct
```

#### Proof that shape inference is possible:
```python
import functools, operator 
def bar(*shape):
    x = tf.placeholder(tf.float32, shape)
    
    tmp = x.shape[-2:]
    if not tmp == tf.TensorShape(None):
        tmp = functools.reduce(operator.mul, tmp, tf.Dimension(1))
    if str(tmp) == '?' or tmp == tf.TensorShape(None):
        shape = [-1]
    else:
        shape = [tmp]
    
    return tf.reshape(x, tf.concat([tf.shape(x)[:-2], shape], 0))


print(bar(2, 3, 4, 5))  # Tensor(""Reshape_21:0"", shape=(2, 3, 20), dtype=float32)
print(bar(None, 3, 4, 5))  # Tensor(""Reshape_22:0"", shape=(?, 3, 20), dtype=float32)
print(bar(None, None, 4, 5))  # Tensor(""Reshape_23:0"", shape=(?, ?, 20), dtype=float32)
print(bar(2, 3, 4, None))  # Tensor(""Reshape_24:0"", shape=(2, 3, ?), dtype=float32)
```",1,,9,2017-12-15T13:41:46Z,CONTRIBUTOR
15395,OS X + GPU NVIDIA nccl dependency missing,"stat:community support,type:build/install","[Comment](https://github.com/tensorflow/tensorflow/pull/14016#discussion_r156704387) migrated to a full issue here.

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.2 (Any)
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Master @HEAD
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A (CMake)
- **GCC/Compiler version (if compiling from source)**: Xcode 8.3.3 (Any)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `cmake -GXcode ...`

### Describe the problem

I'm trying to extend [CMake-Linux support for GPU-build](https://github.com/tensorflow/tensorflow/pull/14016) to finish CMake + OSX testing w/ (NVIDIA) GPU.   I had started with CUDA 8.0 and cuDNN 6.0, but given recent activity here, it seems better to target a recent master branch w/ CUDA 9.0 + cuDNN 7.0.  The OS X CUDA installation does not come with `nccl` (see `find` output below for contents).  NVIDIA has a (login based) `nccl` download for v2.0, but it only has Linux libraries.  I see three other options to support OS X + GPU Builds:

1. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/nccl (build from bundled source v1.3.5)
2. https://github.com/nvidia/nccl (build from source v1.?)
3. add `option(tensroflow_USE_NCCL ""Use NCCL lib"" ON)` to make it `nccl` optional (I'm not sure how complicated this is) and update the CMake and source code w/ preprocessor definitions as needed

Shall I add the bundled `nccl` (v1.3.5?) files to the CMake build?  I see notes about migrating to v2.0 in commit comments, which seems to be closed source.  If that's the case, then it may be best to try to make any internal tensorflow `nccl` operations optional in order to support single GPU configurations to start with. 

`find /Developer/NVIDIA/CUDA-9.0/lib -name ""*.a""`
```
/Developer/NVIDIA/CUDA-9.0/lib/libcublas_device.a
/Developer/NVIDIA/CUDA-9.0/lib/libcublas_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcudadevrt.a
/Developer/NVIDIA/CUDA-9.0/lib/libcudart_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcufft_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcufftw_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libculibos.a
/Developer/NVIDIA/CUDA-9.0/lib/libcurand_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcusolver_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcusparse_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppc_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppial_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppicc_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppicom_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppidei_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppif_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppig_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppim_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppist_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppisu_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppitc_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnpps_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnvgraph_static.a
```

### Source code / logs

N/A
",0,,3,2017-12-15T12:26:52Z,NONE
15393,"Build tf_core_kernels on With VS2015 stops with ""fatal error C1060: compiler is out of heap space""",stat:awaiting response,"### System information
- Build tf_core_kernels.vcxproj
- Windows 10 Enterprise Build 1607
- TensorFlow installed from source
- TensorFlow version Release 1.4.0 from github
- VS2015 Enterprise 14.0.25431 Update 3 

Cannot build tf_core_kernels.vcxproj (generated with CMake) because of a fatal error C1060: compiler is out of heap space. 

### Source code / logs
1>------ Build started: Project: tf_core_kernels, Configuration: RelWithDebInfo x64 ------
1>  training_ops.cc
1>e:\software\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBase.h(245): fatal error C1060: compiler is out of heap space
1>  INTERNAL COMPILER ERROR in 'C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\x86_amd64\CL.exe'
",0,,7,2017-12-15T11:54:16Z,NONE
15392,build_all_android.sh does not work on TF 1.4 branch,stat:awaiting response,"Run `build_all_android.sh` on the `1.4` branch and it will fail with:

    cp: <PATH>/tensorflow/tensorflow/contrib/makefile/downloads/nsync/public: No such file or directory",0,,3,2017-12-15T10:59:00Z,CONTRIBUTOR
15389,Fatal error while compiling Tensorflow with CUDA 9.1,type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-104-generic x86_64)
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
unknown 1.4.0 (Source code is cloned from 798fa36d11119e6fdc13b90a14abfe1805e7de90)
- **Python version**: 
3.6.3
- **Bazel version (if compiling from source)**:
0.8.1
- **GCC/Compiler version (if compiling from source)**:
gcc version 5.4.0 20160609
- **CUDA/cuDNN version**:
CUDA 9.1
cuDNN 7.0.5
- **GPU model and memory**:
2 * Tesla V100-PCIE-16GB
- **Exact command to reproduce**:
See description below.

### Describe the problem
While trying to compile the latest TensorFlow(cloned from 798fa36d11119e6fdc13b90a14abfe1805e7de90), such error will be raised:
```
ERROR: /home/ubuntu/tensorflow/tensorflow/contrib/seq2seq/BUILD:64:1: error while parsing .d file: /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/k8-py3-opt/bin/tensorflow/contrib/seq2seq/_objs/python/ops/_beam_search_ops_gpu/tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.pic.d (No such file or directory)
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14:0,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/contrib/seq2seq/kernels/beam_search_ops.h:19,
                 from tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.cc:20:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:59:34: fatal error: math_functions.hpp: No such file or directory
```

It turns out that in CUDA 9.1, `math_functions.hpp` is located at `cuda/include/crt/math_functions.hpp`, rather than `cuda/include/math_functions.hpp` (CUDA 9.0 does), which leads to this error.
`ln -s /usr/local/cuda/include/crt/math_functions.hpp /usr/local/cuda/include/math_functions.hpp` will fix this problem and complete the compiling process.

#### Reference
https://stackoverflow.com/a/47807106/2666624

### Source code / logs
Traceback is available above.
",0,,19,2017-12-15T09:19:39Z,NONE
15387,from pb tf_dst_dtype == DT_UINT8 || tf_dst_dtype == DT_INT32 || tf_dst_dtype == DT_FLOAT  Abort trap: 6,stat:awaiting response,"cambridgedeMBP:tensorflow-master cambridge$ bazel-bin/tensorflow/contrib/lite/toco/toco \
>   --input_file=/Users/cambridge/Desktop/test/my_inception_v4_freeze.pb \
>   --output_file=/Users/cambridge/Desktop/test/my_inception_v4_freeze.pb.lite \
>   --input_format=TENSORFLOW_GRAPHDEF \
>   --output_format=TFLITE \
>   --inference_type=FLOAT \
>   --input_shapes=1,299,299,3 \
>   --input_arrays=input \
>   --output_array=InceptionV4/Logits/Predictions
2017-12-15 16:18:25.486891: I tensorflow/contrib/lite/toco/import_tensorflow.cc:140] Unsupported data type in placehoder op: 7
2017-12-15 16:18:25.487509: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: DecodeJpeg
2017-12-15 16:18:25.487725: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: StridedSlice
2017-12-15 16:18:25.487772: F tensorflow/contrib/lite/toco/import_tensorflow.cc:1160] Check failed: tf_dst_dtype == DT_UINT8 || tf_dst_dtype == DT_INT32 || tf_dst_dtype == DT_FLOAT 
Abort trap: 6",0,,3,2017-12-15T08:22:09Z,NONE
15385,Silence warning of graph_replace,"awaiting review,cla: yes","This PR fixes #8661 
The warning is caused by access to deprecated graph key `VARIABLES`.

Update:
Because it is hard to distinguish the deprecated from other graph keys, this fix is somewhat ad-hoc and should be removed after graph key `VARIABLES` is removed.",0,,1,2017-12-15T07:14:37Z,CONTRIBUTOR
15384,"when i convert pb to tflite,report error","comp:lite,stat:awaiting response","cambridgedeMBP:tensorflow-master cambridge$ bazel-bin/tensorflow/contrib/lite/toco/toco \
>   --input_file=/Users/cambridge/Desktop/test/nasnet_mobile_freeze.pb \
>   --output_file=/Users/cambridge/Desktop/test/nasnet_mobile_freeze.lite \
>   --input_format=TENSORFLOW_GRAPHDEF \
>   --output_format=TFLITE \
>   --inference_type=FLOAT \
>   --input_shapes=1,224,224,3 \
>   --input_arrays=input \
>   --output_array=final_layer/predictions
2017-12-15 14:18:22.406487: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39 

] Before general graph transformations: 2988 operators, 4360 arrays (0 quantized)
2017-12-15 14:18:22.659788: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39 

] After general graph transformations pass 1: 663 operators, 1419 arrays (0 quantized)
2017-12-15 14:18:22.673152: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39 

] Before dequantization graph transformations: 663 operators, 1419 arrays (0 quantized)
2017-12-15 14:18:22.678500: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312 

] Total transient array allocated size: 4938176 bytes, theoretical optimal value: 3182720 bytes.
2017-12-15 14:18:22.685171: I tensorflow/contrib/lite/toco/toco_tooling.cc:264 

] Estimated count of arithmetic ops: 1.14687 billion (note that a multiply-add is counted as 2 ops).
2017-12-15 14:18:22.691550: F tensorflow/contrib/lite/toco/tflite/export.cc:192 

] Unsupported operator: Pad
Abort trap: 6",0,,3,2017-12-15T06:25:14Z,NONE
15382,CMake: optionally link to ZLIB as systemlib / shared objects.,"cla: yes,stat:awaiting response","If the user has ZLIB (and devel pkg) installed at the system
and the user wants to keep using that ZLIB for tensorflow,
the cmake option ""-Dsystemlib_ZLIB=ON"" will allow to do so.

Another option ""-Dsystemlib_ALL=ON"" will turn on every
""systemlib_*"" options.

This requires PR #15381 because this exposes the need for -fPIC from png.

This PR is an implementation suggestion to the proposal #13061

Signed-off-by: MyungJoo Ham <myungjoo.ham@samsung.com>",1,,3,2017-12-15T05:46:30Z,CONTRIBUTOR
15379,Only emit PTX code for the most recent CUDA compute architecture,"awaiting review,cla: yes,stat:awaiting tensorflower","When there is no gap in the compute architectures you are compiling
against, there is no point in generating PTX for all architectures but
the latest.

See the CUDA documentation:
http://docs.nvidia.com/cuda/volta-compatibility-guide/index.html#building-volta-compatible-apps-using-cuda-9-0

Signed-off-by: Felix Abecassis <fabecassis@nvidia.com>

Slightly decreases the size of the generated binaries.",1,,9,2017-12-15T04:29:44Z,CONTRIBUTOR
15374,tf.matching_files order of returned files,,"As far as I can tell from `https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/file_system.cc`, the order of filenames returned by `tf.matching_files` can be non-determinstic. 

If that is correct, it would be nice if that were stated in the documentation (and also for `Dataset.list_files` and `train.match_filenames_once`).

Even better would be to guarantee alphabetical order, but I am not sure about the performance overhead that would incur.

This would enable to process files given as e.g.
A/1.png, A/2.png, ... and B/1.png, ... jointly by doing to match_files followed by a zip.

Have I written custom code No
OS Platform and Distribution N/A
TensorFlow installed from pip 
TensorFlow version 1.4.1
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory N/A
Exact command to reproduce N/A",0,,5,2017-12-14T22:57:06Z,CONTRIBUTOR
15370,Add the structural similarity (SSIM) index metric as a built-in loss operation,,"In many cases existed built-in losses in TensorFlow do not satisfy needs.  We can add [ssim](https://en.wikipedia.org/wiki/Structural_similarity) or (1-ssim) as the loss function into TensorFlow.

There is existed solution provided on [StackOverflow](https://stackoverflow.com/questions/39051451/ssim-ms-ssim-for-tensorflow), but it is better to have the built-in function with fully covered unit tests.",0,,5,2017-12-14T19:45:56Z,NONE
15369,CMake OBJECT library Xcode problems,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.2 (Any)
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Master @HEAD
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A (CMake)
- **GCC/Compiler version (if compiling from source)**: Xcode 8.3.3 (Any)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `cmake -GXcode ...`

### Describe the problem

CMake's OBJECT libraries don't play well with Xcode generators.  In particular, there is an incompatibility (effectively a bug) that prevents an object library from containing multiple files with the same base filename (""stem""), i.e.

* tensorflow//core/platform/env_time.cc
* tensorflow//core/platform/posix/env_time.cc

This pattern occurs in quite a few places in the tensorflow source code (and is otherwise perfectly reasonable).  For reference, here is a minimal sample project that directly reproduces a test case originally shared in a [post by Matthew Wheeler](http://cmake.3232098.n2.nabble.com/OBJECT-Libraries-with-Xcode-Generator-td7593197.html) on the CMake mailing list:

https://github.com/headupinclouds/cmake_xcode_object_lib

I'd like to help provide a fix for this, but would like some input on the preferred approach prior to implementing anything.  I see a few options:

1. identify duplicates manually and add an alias for the offending files in the repository: `for i in ${FAILURES}; do echo -e ""#include \""$i\"""" > ${i%.cc}_fix.cc; done` and then update CMake to include those files.  Maybe `_fix` could be replaced with a more unique directory name.  PRO: Reasonably easy; CON: The problem will likely occur again, `#include ""source.cc""` violates some style guides
2. iterate through each list of object files in CMake at generate time and identify duplicates automatically, then map each of these files to an alias for the build using something like `configure_file(${duplicate_file} ${CMAKE_CURRENT_BINARY_DIR}/${duplicat_file_w_suffix} COPYONLY)` (for Xcode only).  PRO: Automatic (future proof); CON: More complicated and users can't apply changes directly in their IDE 
3. (long term) replace OBJECT libraries with standard libraries (static or shared based on `CMAKE_BUILD_SHARED`): In addition to the Xcode related bug above, OBJECT libraries have a number of other limitations which make the CMake code more complicated, or rather, standard libraries have a number of benefits that could make the CMake code cleaner.  Perhaps the most significant drawback is that OBJECT libraries can't be used with `target_link_libraries()`, so we lose the ability to pass along transitive dependency chains and scoped [usage requirements](https://cgold.readthedocs.io/en/latest/rejected/object-libraries.html#usage-requirements) from  `find_package()` (future) system dependencies using `target_link_libraries()`.  This relates to [Proposal: Making the cmake build distribution friendly](https://github.com/tensorflow/tensorflow/issues/13061), where common system dependencies would be included using `find_package()` calls and linked directly to the tensorflow submodules: `target_link_libraries(tf_core_lib PRIVATE ${tensorflow_EXTERNAL_PACKAGES}) # zlib, etc`.  This would also allow most of the manual `add_dependencies()` calls to be removed.  (Note: I've already added CMake package config installation steps to most of the google repository dependencies in forks, and will try to get this stuff accepted upstream.)

The last one is broader in scope, so I'm hoping there is an initial workaround based on some variation of (1) or (2) that would be accepted upstream in the near future for CMake + Xcode.  If there is interest in using standard libraries (3), I can help work on putting an initial solution together in a branch for evaluation as a follow up effort.

I understand CMake status is [currently under discussion](https://github.com/tensorflow/tensorflow/issues/14014#issuecomment-340344678).  In any event, I'd like to help get tensorflow building through CMake for easy integration with other CMake based projects, including iOS builds, where Xcode is required.  I also appreciate tensorflow is an incredibly complicated piece of SW, and I appreciate the work that has gone in to supporting CMake builds to date.  Thanks!

### Source code / logs

Numerous ""no such file or directory"" errors such as these:
```
clang: error: no such file or directory: '/Users/developer/tensorflow/tensorflow/contrib/cmake/_builds/xcode-hid-sections/tensorflow.build/Release/tf_core_lib.build/Objects-normal/x86_64/env.o'
clang: error: no such file or directory: '/Users/developer/tensorflow/tensorflow/contrib/cmake/_builds/xcode-hid-sections/tensorflow.build/Release/tf_core_lib.build/Objects-normal/x86_64/env_time.o'
clang: error: no such file or directory: '/Users/developer/tensorflow/tensorflow/contrib/cmake/_builds/xcode-hid-sections/tensorflow.build/Release/tf_core_lib.build/Objects-normal/x86_64/tracing.o
```",0,,3,2017-12-14T18:40:17Z,NONE
15366,fix that remove_nodes drops input suffixes,"awaiting review,cla: yes","The transform `remove_nodes` didn't take input suffixes into consideration, and might make mistakes if the removed node used not `:0` but `:1`.

E.g.: For a node of `/a/Identity (Identity): [/a/Switch_1:1]`, the old code will make the pb file generate completely unexpected outputs.

The clang-format checking and tests (`//tensorflow/tools/graph_transforms/...`) have been passed.",0,,1,2017-12-14T14:07:53Z,NONE
15364,[BUG] Default MaxPoolingOp/AvgPoolingOp only supports NHWC,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7
- **TensorFlow installed from (source or binary)**: pip install tensorflow with virtualEnv
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 2.7.5
- **Exact command to reproduce**:
```python
import numpy as np
import tensorflow as tf
a = tf.nn.max_pool(np.random.rand(1, 1,10,10), [1,1,2,2], [1,1,1,1], 'VALID', data_format='NCHW')
sess=tf.InteractiveSession()
sess.run(a)
```
### Describe the problem
When I try to run a node of type max or avg pool with data_format : 'NCHW' I got an error.
This seems to be a bug because the TF docs affirms that : 
> data_format: A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported.

### Error logs
With max:
> 2017-12-14 12:40:23.250331: E tensorflow/core/common_runtime/executor.cc:643] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC.
>                 [[Node: MaxPool = MaxPool[T=DT_DOUBLE, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](MaxPool/input)]]

With Avg:
> tensorflow.python.framework.errors_impl.InvalidArgumentError: Default AvgPoolingOp only supports NHWC.
         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](AvgPool_1/input)]]
",1,,11,2017-12-14T11:49:45Z,NONE
15360,"python(2711,0x7fffcc8553c0) malloc: *** error for object 0x120b0fff0: pointer being freed was not allocated",stat:awaiting response,"cambridgedeMBP:tensorflow-master cambridge$ bazel-bin/tensorflow/python/tools/freeze_graph \
> --input_graph=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/inception_v4_inf_graph.pb \
> --input_checkpoint=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/my_train_10/model.ckpt \
> --input_binary=true \
> --output_graph=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/frozen_inception_v4.pb \
> --output_node_names=InceptionV4/Predictions/Reshape_1
python(2711,0x7fffcc8553c0) malloc: *** error for object 0x120b0fff0: pointer being freed was not allocated
*** set a breakpoint in malloc_error_break to debug
Abort trap: 6
",0,,7,2017-12-14T09:27:49Z,NONE
15354,CPU: Support for DT_STRING type in ScatterNd ,"awaiting review,cla: yes","The PR is proposed to fix #15321.

However, the solution seems not idea. Because `ScatterNdOP` use ADD op by default, which doesn't make sense for string type. I prefer to use ASSIGN than ADD, but the modification will change the op's behavior. 

https://github.com/tensorflow/tensorflow/blob/438604fc885208ee05f9eef2d0f2c630e1360a83/tensorflow/core/kernels/scatter_nd_op.cc#L72

### How to test 

+ [x] add test.
+ [ ]  pass all tests.",0,,1,2017-12-14T04:21:58Z,CONTRIBUTOR
15352,matmul causing segmentation fault in rev1.4.0,stat:awaiting tensorflower,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
0.8.1
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
Here is the output from tf_env_collect.sh

== cat /etc/issue ===============================================
Linux Ubuntu 4.4.0-101-generic #124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Ubuntu 4.4.0-101-generic #124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.5.0.post1)
tensorflow (1.4.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = b'v1.3.0-rc1-5916-g18c864c'
tf.COMPILER_VERSION = b'v1.3.0-rc1-5916-g18c864c'
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/lib/nx/X11/Xinerama:/usr/lib/nx/X11
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tensorflow-src/tensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Seeing a segmentation fault on matmul operation.

### Source code / logs
Here is the source code:
import tensorflow as tf
a = tf.random_normal([100, 200])
b = tf.random_normal([200, 300])
res = tf.matmul(a, b)
tf.Session().run(res)

Here is the backtrace from gdb:

#0  0x00007fff513b9296 in Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 48, 16, 0, false, false>::operator()(float*, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer> const&, long, long, long, long) ()
   from /tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007fff5142ce94 in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 48, 16, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 48, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()
   from /tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007fff4eab29c1 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()
   from /tensorflow/python/../libtensorflow_framework.so
#3  0x00007fff4eab07d7 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /tensorflow/python/../---Type <return> to continue, or q <return> to quit---
libtensorflow_framework.so
#4  0x00007fff4e2ecc80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#5  0x00007ffff7bc16ba in start_thread (arg=0x7ffe06ffd700)
    at pthread_create.c:333
#6  0x00007ffff71e73dd in clone ()
    at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,4,2017-12-14T00:16:11Z,NONE
15341,Feature Request: enable rechanging tf.device of a tensor,,"It seems that once a tensor's GPU was defined using tf.device, the GPU cannot be changed anymore. 
When loading saved graphs, the graph will use the same GPU that was chosen years ago and it cannot be set again.

thanks.",0,,6,2017-12-13T15:01:38Z,NONE
15340,StagingArea.get() ignores timeout,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 2.7.14
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
The `get()` method of a `tf.contrib.staging.StagingArea` is a blocking operation. I would expect it to respect any operation timeout that has been set for the Tensorflow session. This is important to avoid deadlocks, e.g., if the StagingArea is empty.

In comparison, the `dequeue()` method of a `tf.FIFOQueue` respects the timeout by raising`tf.errors.DeadlineExceededError`.


### Source code / logs
Example script:
```python
import tensorflow as tf
from __future__ import print_function

print(""Testing tf.FIFOQueue"")
empty_queue = tf.FIFOQueue(capacity=1, shapes=[1,], dtypes=tf.int32)
with tf.Session() as sess:
  try:
    print(sess.run(empty_queue.dequeue(), options=tf.RunOptions(timeout_in_ms = 500)))
  except tf.errors.DeadlineExceededError as e:
    print(""Error:"", e)


print(""Testing tf.contrib.staging.StagingArea"")
empty_stagingArea = tf.contrib.staging.StagingArea([tf.int64], shapes=[(1,)])
with tf.Session() as sess:
  try:
    print(sess.run(empty_stagingArea.get(), options=tf.RunOptions(timeout_in_ms = 500)))
  except tf.errors.DeadlineExceededError as e:
    print(""Error:"", e)
```
Example output:
```
Testing tf.FIFOQueue
Error: Timed out waiting for notification
Testing tf.contrib.staging.StagingArea
```
The final `sess.run` call hangs indefinitely.",0,,4,2017-12-13T13:28:01Z,NONE
15338,Tensorflow AOT examples fail to compile,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 'v1.3.0-rc1-5779-g441571a', '1.4.0'
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: GCC 5.4.0
- **CUDA/cuDNN version**: CUDA 8.0, CUDNN 6.0.21
- **GPU model and memory**: GeForce GTX 1080, 8GB
- **Exact command to reproduce**: cd tensorflow/compiler/aot/tests ; bazel clean ; bazel build all_tests &>gcc5.log

### Describe the problem

I am trying to compile AOT examples, but the compilation fails. I tried to use two different compiler versions (GCC 5.4 and GCC 4.8), but I get errors with both versions. I also tried adding --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" option when using bazel with GCC 5.4, but it doesn't help.

So the exact commands commands were:
bazel build all_tests &>gcc5.log
bazel build --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" all_tests &>gcc5_abi0.log
bazel build all_tests  # Using GCC 4.8, I copied the output manually to gcc_4.8.txt

Tensorflow source code itself was build without any problems both with GCC 5.4 and GCC 4.8. I have built the two versions in separate python virtual environments and afterwards tried to compile aot tests with the corresponding GCC version. I used --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" option when building tensorflow source with GCC 5.4.

### Source code / logs
The logs are attached.
[gcc5.log](https://github.com/tensorflow/tensorflow/files/1555478/gcc5.log)
[gcc5_abi0.log](https://github.com/tensorflow/tensorflow/files/1555479/gcc5_abi0.log)
[gcc_4.8.txt](https://github.com/tensorflow/tensorflow/files/1555485/gcc_4.8.txt)",1,,9,2017-12-13T12:57:06Z,NONE
15337,added crucial documentation on SELU activation,"awaiting review,cla: yes",Users extrememly frequently forget to use the correct initialization with SELUs. Added notes to documentation to use correct initialization wherever possible.,0,,6,2017-12-13T09:47:04Z,NONE
15336,batch normalization layer which translated by toco cannot be run in TF Lite,"comp:lite,stat:awaiting response","## Issue
Resolver for batch normalization layer(`ResolveBatchNormalization`) in toco has four inputs, which are input matrix, mean, multiplier, and offset respectively. Usually, input matrix has four dimensions (NHWC) while mean, multiplier, and offset only have 1 dimension for a channel. This resolver translates this 1 dimension vector to second input of `Mul` and `Add` layers in TF Lite. (first input of these layers is input matrix!) But the problem occurs `Mul` and `Add` layers in TF Lite have a process to check dimension of inputs. Need to fix this contradiction. :) 


## Codes related to this Issue
[Resolver](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc)
[Logic of checking dimension in add layer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/add.cc#L48)
[Logic of checking dimension in mul layer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/mul.cc#L48)
",0,,3,2017-12-13T09:28:21Z,CONTRIBUTOR
15332,Allow tf.Estimator.evaluate() to return summary protos / add tooling to produce useful eval image summaries,"stat:contributions welcome,type:feature","Related to #14042.

`tf.Estimator.train()` writes a summary of all defined summaries (scalar, img) in the given `model_fn` when calling [MonitoredTrainingSession](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L801) ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py#L366)).

`tf.Estimator.evaluate()` does not write summaries defined somewhere in the `model_fn`. A workaround is defining `SummarySaverHook` inside the `model_fn`, which I think is not ideal since the Estimator has all the relevant information for saving summaries (steps, save directory, etc.).

A possible solution would be adding a `SummarySaverHook` during evaluation, (e.g. [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/evaluation.py#L206)) or create a new function `MonitoredEvaluationSession()` in [monitored_session.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py) that creates such a hook.

cc @ispirmustafa @martinwicke
",0,,5,2017-12-13T07:50:00Z,NONE
15323,Beam Search Decoder API,type:feature,"@ebrevdo Why is it that the user needs to call `tile_batch` explicitly for beam search decoders when using attention models? Couldn't the beam search decoder internally tile the provided `initial_state` in its constructor? It seems that this API is prone to wrong usage so I'm trying to understand why it's necessary.

Thank you!",0,,4,2017-12-12T21:45:03Z,CONTRIBUTOR
15322,Add full cmake support for Android builds,stat:contributions welcome,"Currently it doesn't seems like tensorflow support compiling with ndk r16, clang and c++ stl.
Is there any plans to update build flow to support that?
Also it would be nice to have pure CMake build for Android.
",0,,5,2017-12-12T21:08:09Z,NONE
15321,Feature Request: Support for DT_STRING type in ScatterNd kernel.,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: -
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOs, Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binaries
- **TensorFlow version (use command below)**: 
v1.3.0-rc1-5542-g03a1651cbb 1.5.0-dev20171206
and
v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**:
~~~python
import tensorflow as tf
indices = tf.constant(
    [[i] for i in range(37)] +\
    [[i] for i in range(37,37+18)] +\
    [[i] for i in range(37*2,37*2+9)] +\
    [[i] for i in range(37*3,37*3+36)]
)
updates = tf.ones([100,13])
# This line:
updates = tf.as_string(updates)
shape = tf.constant([37*4, 13])
sc=tf.scatter_nd(indices, updates, shape)
with tf.Session() as sess:
    print(sess.run(sc))
~~~

### Describe the problem
`tf.scatter_nd` supports most of the other types except `DT_STRING`, and throws the following error:
~~~console
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-196-71592cd7f940> in <module>()
      9 updates = tf.as_string(updates)
     10 shape = tf.constant([37*4, 13])
---> 11 sc=tf.scatter_nd(indices, updates, shape)

~/tf-nightly/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in scatter_nd(indices, updates, shape, name)
   4395     _attrs = (""T"", _attr_T, ""Tindices"", _attr_Tindices)
   4396     _result = _execute.execute(b""ScatterNd"", 1, inputs=_inputs_flat,
-> 4397                                attrs=_attrs, ctx=_ctx, name=name)
   4398   _execute.record_gradient(
   4399       ""ScatterNd"", _inputs_flat, _attrs, _result, name)

~/tf-nightly/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     64     else:
     65       message = e.message
---> 66     six.raise_from(core._status_to_exception(e.code, message), None)
     67   # pylint: enable=protected-access
     68   return tensors

~/tf-nightly/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

NotFoundError: No registered 'ScatterNd' OpKernel for CPU devices compatible with node ScatterNd = ScatterNd[T=DT_STRING, Tindices=DT_INT32](dummy_input, dummy_input, dummy_input)
	 (OpKernel was found, but attributes didn't match)
	.  Registered:  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT64]
 [Op:ScatterNd]

~~~

### Question
Is it possible to get `tf.scatter_nd` to work with strings, for example, an empty string as a default value?
Also, on the related note, rn the default values are `0` or `0.0`, can the function be extended to use an arbitrary value (e.g. a padding symbol)?
",0,,3,2017-12-12T20:57:31Z,CONTRIBUTOR
15320,Multi-core CPU performance dropped for MKL TF build,,"### System information

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS (64-bit)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: Tensorflow r1.4
- **Python version**: Python version: 2.7.12
- **Bazel version (if compiling from source)**: Bazel release 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
- **CUDA/cuDNN version**: no CUDA
- **GPU model and memory**: no GPU, but i7-6850K with 32Gb ddr4
- **Exact command to reproduce**: run the script below

Tested on two machines:
1) i7-6850K with 32Gb ddr4
2) two Xeon x5650 with 24Gb ddr3

### Describe the problem
When I build Tensorflow with MKL it dropped CPU performance in a strange way. Performance of individual core is much higher, but for multicore is much worse.
It's a big epic bottleneck for my project and I can't solve it by myself. I will appreciate any help!

1) TF installation from sources with MKL support
> Tensorflow r1.4 installed from source. Configured with jemalloc as malloc support and other configure settings ignored.
> $ bazel build --config=mkl -c opt //tensorflow/tools/pip_package:build_pip_package
> $ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
> $ pip install /tmp/tensorflow_pkg/tensorflow-1.4.1-cp27-cp27mu-linux_x86_64.whl

**Run tests:** 
one core: 0.03s
all cores: 0.12s

2) TF installation with pip
> $ pip install tensorflow
> (tensorflow-1.4.1-cp27-cp27mu-manylinux1_x86_64.whl installed)

**Run tests:**
one core: 0.16s
all cores: 0.03s


### Source code / logs

```
    import time
    import numpy as np
    import tensorflow as tf

    from tensorflow.contrib import slim
    from tensorflow.contrib.slim.python.slim.nets.inception_v1 import inception_v1, inception_v1_arg_scope


    input_shape = (1, 224, 224, 3)
    features = tf.placeholder(tf.float32, input_shape)

    with slim.arg_scope(inception_v1_arg_scope()):
        predictions, end_points = inception_v1(features, is_training=False)

    # remove to utilize all cores
    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,
                                  inter_op_parallelism_threads=1)

    with tf.Session(config=session_conf) as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())

        images = np.random.random(input_shape)
        consumption = []
        for i in range(10):
            tick = time.time()
            sess.run(predictions, feed_dict={features: images})
            consumption.append(time.time() - tick)

        print np.mean(consumption)
```",0,,11,2017-12-12T19:43:31Z,NONE
15314,tensorflow.python.framework.errors_impl.NotFoundError: Can not get size for:,,"D:\Python\Python35\models-master\research\object_detection>D:\Python\Python35\python train.py --logtostderr --train_dir=training\ --pipline_config_path=training\ssd_mobilenet_v1_pets.config
Traceback (most recent call last):
  File ""train.py"", line 163, in <module>
    tf.app.run()
  File ""C:\Users\USER\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 106, in main
    overwrite=True)
  File ""C:\Users\USER\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\lib\io\file_io.py"", line 384, in copy
    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)
  File ""D:\Python\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\Users\USER\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: Can not get size for:  : path d\udc92acc\udce8s sp\udce9cifi\udce9 not found",0,,7,2017-12-12T13:43:35Z,NONE
15305,Feature: Tensorflow-native doc2vec implementation planned?,stat:awaiting response,"### System information
Have I written custom code N/A
OS Platform and Distribution N/A
TensorFlow installed from N/A
TensorFlow version N/A
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory N/A
Exact command to reproduce N/A

### Describe the problem

**Situation:**

- We are seeking for a doc2vec implementation based on Tensorflow.
- The reason for this is to be ""as PaaS as possible"" in model training and serving (using Google Cloud ML or AWS Sagemaker).

**Complication:**

- There is no native doc2vec implementation in Tensorflow (word2vec is available)
- [Stackoverflow](https://stackoverflow.com/search?q=tensorflow+doc2vec) does not list too much on this.

**Questions/Feature request:**

- Is a ""native"" doc2vec implementation planned in Tensorflow?
- if not, is there a common implementation to it, e.g. sum up all the individual word vectors and potentially add normalizing to each ""doc""?

### Source code / logs
not applicable",0,,4,2017-12-12T10:08:24Z,NONE
15297,tf.bfloat16 is unsigned on Windows,type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
None
- **GCC/Compiler version (if compiling from source)**:
None
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
```python
import tensorflow as tf
print(tf.bfloat16.is_unsigned)
```
Expected Output: False
Actual: True

### Describe the problem


### Source code / logs
https://ci.tensorflow.org/job/tf-master-win-bzl/2057/console
bfloat16_test/test.log
",2,,8,2017-12-12T06:52:26Z,CONTRIBUTOR
15294,Error tensorflow load library with Cuda 8 and 9,stat:awaiting response,"Hello,
I use TF 1.0.1, and in my PC (Ubuntu 17.03), I already installed both Cuda 8.0 and Cuda 9.0.

When I run a demo code (Fast R_CNN), I got this error:

I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcudnn.so.5. LD_LIBRARY_PATH: /usr/local/cuda-8.0/lib64
I tensorflow/stream_executor/cuda/cuda_dnn.cc:3517] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""./tools/demo.py"", line 11, in <module>
    from networks.factory import get_network
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/__init__.py"", line 8, in <module>
    from .VGGnet_train import VGGnet_train
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/VGGnet_train.py"", line 2, in <module>
    from networks.network import Network
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/network.py"", line 3, in <module>
    import roi_pooling_layer.roi_pooling_op as roi_pool_op
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/roi_pooling_layer/roi_pooling_op.py"", line 5, in <module>
    _roi_pooling_module = tf.load_op_library(filename)
  File ""/home/tung/Envs/Tensor1/lib/python3.4/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: libcudart.so.9.0: cannot open shared object file: No such file or directory

It seem there is a conflict between cuda 8.0 and 9.0
Is there any suggest?
Thanks",0,,5,2017-12-12T04:59:52Z,NONE
15293,Encrypted Data,,"It is not easy/possible to use TensorFlow with encrypted data, such as via Homomorphic Encryption or Multi-Party Computation.  It would be useful if future versions of TensorFlow could support HE/MPC or provide the ability for third-party HE/MPC support.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A
",0,,6,2017-12-12T04:25:15Z,NONE
15292,Converting a .pb file to .meta in TF 1.3,,"Using `tf.slim`'s pre-trained models we can [export_inference_graph](https://github.com/tensorflow/models/tree/master/research/slim#exporting-the-inference-graph) to generate a `.pb` file for a given `.ckpt`, say `inception_v3`. Is there a way to generate `.meta` file of inception_v3 using these two files as well? 

My specific use case is that I need to see the pre-trained weights if inception in each tensor (`tf.variable`) and don't know any other way to retrieve other using .meta and .ckpt to do so and I lack `.meta` here:

```
#retrieve a pre-trained model
sess = tf.Session()
saver = tf.train.import_meta_graph('./model.meta')
saver.restore(sess,'./model.ckpt')
```


**Steps to reproduce:**

I used the instution in export_inference_graph and generated a .pb file, then I exported the .meta file as bellow:

```
sess=tf.Session()
INCEPTION_PB='./inception_v3_inf_graph.pb'
    
f=gfile.FastGFile(INCEPTION_PB,'rb')
graph_def = tf.GraphDef()
graph_def.ParseFromString(f.read())
_= tf.import_graph_def(graph_def,name='')
meta_graph_def = tf.train.export_meta_graph(filename='./inception.meta')
```
However, this results in a `.meta` file without collections, thus can not initialized:

```
>>> saver = tf.train.import_meta_graph('./inception.meta')
INFO:tensorflow:Saver not created because there are no variables in the graph to restore
```

```
 >>> saver.restore(sess,'../../inception_v3.ckpt')
Traceback (most recent call last):
File ""<stdin>"", line 1, in <module>
AttributeError: 'NoneType' object has no attribute 'restore'
```

What is the problem here? I guess it would be nice this conversion feature is added to TF.

Info: 
Have I written custom code: Not much except these above.
OS Platform and Distribution: Ubuntu 14.04.3 - 3.19.0-25-generic
TensorFlow installed from: pip installation 
TensorFlow version - v1.3
Bazel version: v5.4
CUDA/cuDNN version:  v6.0
GPU model and memory: NVIDIA GeForce GTX 1060 6GB - memoryClockRate (GHz) 1.7845



",0,,6,2017-12-12T03:41:58Z,NONE
15290,"Feature request: provide a means to configure, build, and install that includes cc",,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Both Mac and Linux
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6.3, but not relevant 
- **Bazel version (if compiling from source)**: 0.8.1, but not relevant
- **GCC/Compiler version (if compiling from source)**: Both GCC and clang, but not relevant
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Tensorflow doesn't seem to have a clean way to install from sources to support both python and C++ development. When we install from sources, only the core tensorflow framework is installed in the python site-packages directory. The `cc` headers (and maybe others) are not included. Likewise the `libtensorflow_cc.so` is not built. It's surprising that there is so little documentation for how C++ developers are expected to develop tensorflow applications. My use case is probably common: I want to train and test my model using python, but I want to deploy an application that does prediction/inference with the app written in C++. 

I have managed once to successfully install the headers and libraries I need into `/usr/local/...` on a Mac, but in doing so I lost some of the CPU optimizations that I had specified when doing the standard build from sources. Now I need to repeat this process on Linux, where I need GPU support, and want to make sure I get it right.

It would be so nice if there was something close to the standard `./configure; make; make install` that could install headers and libraries into a chosen directory.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",1,,4,2017-12-12T02:12:03Z,NONE
15284,[RFE] Runtime GPU Docker image without Jupyter,,"Current image size for `nightly-gpu`:
```sh
$ docker images tensorflow/tensorflow:nightly-gpu
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
tensorflow/tensorflow   nightly-gpu         8f64c1fbb504        12 hours ago        2.62GB
```
Current Dockerfile:
https://github.com/tensorflow/tensorflow/blob/abd5375ba8d373045321d1eebdb4501c36ab0ccd/tensorflow/tools/docker/Dockerfile.gpu

I see two potential improvements:
1) We already switched the `FROM` to use the `runtime` base image of CUDA. We could go one step further and use `nvidia/cuda:9.0-base`. This flavor of CUDA is new with CUDA 9.0, it just installs the repos and libcudart. You have to manually install the CUDA libraries you want afterwards. The gain wouldn't be that big with TensorFlow since you use most of the libraries from the CUDA toolkit. But we will at least remove NPP from the shipped image.

2) Looks like many dependencies in the current Dockerfile are required for Jupyter. Can we provide a new tag without Jupyter? Or stop shipping Jupyter in the runtime image? Users will still be able to use the `devel` image.

I have a quick Dockerfile proof-of-concept with both improvements:
```
FROM nvidia/cuda:9.0-base-ubuntu16.04

LABEL maintainer=""Gunhan Gulsoy <gunan@google.com>""

RUN echo ""/usr/local/cuda-9.0/extras/CUPTI/lib64"" > /etc/ld.so.conf.d/cupti.conf && \
    apt-get update && apt-get install -y --no-install-recommends \
        libgomp1 \
        libcudnn7 \
        cuda-command-line-tools-9-0 \
        cuda-cudart-9-0 \
        cuda-cufft-9-0 \
        cuda-cublas-9-0 \
        cuda-cusparse-9-0 \
        cuda-curand-9-0 \
        cuda-cusolver-9-0 \
        python-pip \
        && \
    rm -rf /var/lib/apt/lists/

RUN pip --no-cache-dir install --upgrade \
        pip setuptools

RUN pip --no-cache-dir install http://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tf_nightly_gpu-1.head-cp27-cp27mu-manylinux1_x86_64.whl
```
Size is now 1.73 GB, down from 2.62 GB. And there is still room for improvement in CUDA 9.1 when CUPTI has its own package (today we have to pull `cuda-command-line-tools-9-0`), or if we disable CUPTI tracing (not sure if possible).
",0,,33,2017-12-12T00:09:08Z,CONTRIBUTOR
15279,Minor optimization of conv_ops.,"awaiting review,cla: yes","If data_format is NCHW, and the computation is done on the GPU, the temporary tensor `transformed_output` is not needed. One can use directly the `output` tensor. This
leaves more memory for the cudnn scratch allocator, possibly improving performance
of the convolution algorithm.

I also fixed several style issues in `conv_ops.cc` reported by clang-format.

I did not add any tests because the change is covered by `python/kernel_tests/conv_ops_test.py`.",1,,3,2017-12-11T19:12:32Z,CONTRIBUTOR
15274,breaking change to distributed training moving from TF v1.3 to v1.4: “UnavailableError: Trying to connect an http1.x server”,stat:awaiting response,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
n/a
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Red Hat Enterprise Linux Server release 7.3 (Maipo)
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4 (moving from 1,3)
b'v1.4.0-4-g9283868' 1.4.0 in specific
- **Python version**: 
Python 3.6.2 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**:
0.5.4
- **GCC/Compiler version (if compiling from source)**:
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
- **CUDA/cuDNN version**:
N/a
- **GPU model and memory**:
N/a
- **Exact command to reproduce**:
see below. Appears to be any distributed training use case with the cluster spec defined as below.

### Describe the problem

I believe this could be fairly characterized as a BUG.

I raised (and solved) this issue on stackoverflow [here](https://stackoverflow.com/questions/47143043/breaking-change-to-distributed-training-moving-from-tf-v1-3-to-v1-4-unavailabl/47191081#47191081)

In short, upgrading from tf v1.3 to 1.4 distributed training broke with the error
""tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server"".
I was training across multiple CPU cores all on the same localhost.

The fix was to change the ps to the  string ""localhost"" explicitly in the cluster spec instead of the IP ""127.0.0.1"". It stops trying to connect to the localhost via my proxy server (which indeed, was HTTP1.x only i think). I would call this a bug since that IP should be the equivalent, and I'm not sure what other kind of behavior might have inadvertently changed between versions (since this always worked in TF <= 1.3). 

To be fair, I'm also not sure if this is a tensorflow or more gRPC specific issue. In either case, the above is a work around for the problem.
",0,,3,2017-12-11T15:11:23Z,NONE
15270,Fix issue #15269,"awaiting review,cla: yes",A possible solution to fix issue #15269.,1,,14,2017-12-11T11:06:48Z,NONE
15269,tf.layers.Layer.set_scope() problem might cause unexpected duplicate name ValueError,type:bug/performance,"- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: 1.4.1
- **Python version**: 3.5.2
- **CUDA/cuDNN version**: CUDA 8.0, CUDNN 7.0.5
- **GPU model and memory**: GTX1080 (8G)
- **Exact command to reproduce**: python3 test.py
- **Have I written custom code**: True
- **Bazel version**: N/A
- **GCC version**: N/A


Repoduce code:

```python
import tensorflow as tf

_BATCH_NORM_DECAY = 0.997
_BATCH_NORM_EPSILON = 1e-5

def two_batchnorm(inputs):
    with tf.variable_scope('two_batchnorm'):
        inputs = tf.layers.batch_normalization(
            inputs=inputs,
            axis=3,
            momentum=_BATCH_NORM_DECAY,
            epsilon=_BATCH_NORM_EPSILON,
            center=True,
            scale=True,
            training=True,
            fused=True)
        inputs = tf.layers.batch_normalization(
            inputs=inputs,
            axis=3,
            momentum=_BATCH_NORM_DECAY,
            epsilon=_BATCH_NORM_EPSILON,
            center=True,
            scale=True,
            training=True,
            fused=True)
    return inputs

inputs = tf.placeholder(tf.float32, [1, 5, 5, 3])
x = inputs
x = two_batchnorm(x)
x = two_batchnorm(x)
```

It'll trigger an unexpected ValueError as following:

```
ValueError: Variable two_batchnorm/batch_normalization/gamma already exists, disallowed.
```

Removing the variable scope `with tf.variable_scope('two_batchnorm')` in `two_batchnorm` will work as expected.

All variables defined in the graph should be (in creation sequense):

```
two_batchnorm/batch_normalization/gamma:0
two_batchnorm/batch_normalization/beta:0
two_batchnorm/batch_normalization/moving_mean:0
two_batchnorm/batch_normalization/moving_variance:0
two_batchnorm/batch_normalization_1/gamma:0
two_batchnorm/batch_normalization_1/beta:0
two_batchnorm/batch_normalization_1/moving_mean:0
two_batchnorm/batch_normalization_1/moving_variance:0
two_batchnorm/batch_normalization_2/gamma:0
two_batchnorm/batch_normalization_2/beta:0
two_batchnorm/batch_normalization_2/moving_mean:0
two_batchnorm/batch_normalization_2/moving_variance:0
two_batchnorm/batch_normalization_3/gamma:0
two_batchnorm/batch_normalization_3/beta:0
two_batchnorm/batch_normalization_3/moving_mean:0
two_batchnorm/batch_normalization_3/moving_variance:0
```

However, with `tf.layers.Layer`'s `add_variable` logics, it'll result in an unexpected value name as following (in creation sequence):

```
two_batchnorm/batch_normalization/gamma:0
two_batchnorm/batch_normalization/beta:0
two_batchnorm/batch_normalization/moving_mean:0
two_batchnorm/batch_normalization/moving_variance:0
two_batchnorm/batch_normalization_1/gamma:0
two_batchnorm/batch_normalization_1/beta:0
two_batchnorm/batch_normalization_1/moving_mean:0
two_batchnorm/batch_normalization_1/moving_variance:0
two_batchnorm/batch_normalization/gamma:0                        <-- ValueError raised here.
two_batchnorm/batch_normalization/beta:0
two_batchnorm/batch_normalization/moving_mean:0
two_batchnorm/batch_normalization/moving_variance:0
two_batchnorm/batch_normalization_1/gamma:0
two_batchnorm/batch_normalization_1/beta:0
two_batchnorm/batch_normalization_1/moving_mean:0
two_batchnorm/batch_normalization_1/moving_variance:0
```

One solution might be using `self._name` to setup Layer's scope, not `self._base_name`.",0,,13,2017-12-11T11:05:17Z,NONE
15266, //tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel  test fails on ppc64le,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source (v1.3.1)
- **TensorFlow version (use command below)**:
      TF1.3.1
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
       0.5.4
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
      bazel test -c opt //tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel       


**Describe the problem**

Here 2 sub tests are failing on ppc64le i.e.` IsFiniteScalarF32`  and `IsFiniteR1F32s` in file array_elementwise_ops_test.cc

For IsFiniteScalarF32 sub-test , error at line 100 : 
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/compiler/xla/tests/array_elementwise_ops_test.cc#L100
`ComputeAndCompareR0<bool>(&builder, false, {});`
 The failure due to expected: false  vs actual: true

For IsFiniteR1F32s sub-test , error at line 126 :
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/compiler/xla/tests/array_elementwise_ops_test.cc#L126
`ComputeAndCompareR1<bool>(&builder, {false, true, false, true, false, false}, {});`
The failure due to expected: {010100}  vs actual: {111100}

Currently trying to find the root cause , started debugging further on this. Any inputs/help appreciated.Thanks!

**Source code / logs**

1 .**IsFiniteScalarF32 sub-test log :**
```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Note: This is test shard 5 of 25.
[==========] Running 6 tests from 2 test cases.
[----------] Global test environment set-up.
[----------] 5 tests from ArrayElementwiseOpTest
[ RUN      ] ArrayElementwiseOpTest.IsFiniteScalarF32
2017-12-11 09:36:20.653075: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:20.654000: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:20.654482: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x100062a6ea0 executing computations on platform Host. Devices:
2017-12-11 09:36:20.654493: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): <undefined>, <undefined>
tensorflow/compiler/xla/tests/literal_test_util.cc:157: Failure
Value of: Equal(expected, actual)
  Actual: false (expected: false
actual:   true)
Expected: true
expected:
false
        vs actual:
true
tensorflow/compiler/xla/tests/literal_test_util.cc:157: Failure
Value of: Equal(expected, actual)
  Actual: false (expected: false
actual:   true)
Expected: true
expected:
false
        vs actual:
true
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteScalarF32 (60 ms)
[ RUN      ] ArrayElementwiseOpTest.LogicalNotZeroElement
2017-12-11 09:36:20.712501: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.LogicalNotZeroElement (6 ms)
[ RUN      ] ArrayElementwiseOpTest.LogOfPowerF32
2017-12-11 09:36:20.719016: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.LogOfPowerF32 (12 ms)
[ RUN      ] ArrayElementwiseOpTest.Max3DAndScalarZeroElementS32s
2017-12-11 09:36:20.731087: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Max3DAndScalarZeroElementS32s (7 ms)
[ RUN      ] ArrayElementwiseOpTest.Compare1DTo2DS32Ne
2017-12-11 09:36:20.738675: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Compare1DTo2DS32Ne (13 ms)
[----------] 5 tests from ArrayElementwiseOpTest (99 ms total)

[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount
[ RUN      ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/0
2017-12-11 09:36:20.751273: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/0 (34 ms)
[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount (34 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 2 test cases ran. (133 ms total)
[  PASSED  ] 5 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteScalarF32

 1 FAILED TEST

```
2. **IsFiniteR1F32s sub-test log:**

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Note: This is test shard 6 of 25.
[==========] Running 6 tests from 2 test cases.
[----------] Global test environment set-up.
[----------] 5 tests from ArrayElementwiseOpTest
[ RUN      ] ArrayElementwiseOpTest.IsFiniteR1F32s
2017-12-11 09:36:21.201704: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:21.202563: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:21.203145: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x10015cc6ea0 executing computations on platform Host. Devices:
2017-12-11 09:36:21.203154: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): <undefined>, <undefined>
tensorflow/compiler/xla/tests/literal_test_util.cc:157: Failure
Value of: Equal(expected, actual)
  Actual: false (expected: {010100}
actual:   {111100})
Expected: true
expected:
{010100}
        vs actual:
{111100}
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteR1F32s (17 ms)
[ RUN      ] ArrayElementwiseOpTest.CompareEqF32s
2017-12-11 09:36:21.218227: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.CompareEqF32s (10 ms)
[ RUN      ] ArrayElementwiseOpTest.MulOfExpF32
2017-12-11 09:36:21.228744: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.MulOfExpF32 (12 ms)
[ RUN      ] ArrayElementwiseOpTest.Min2DTo1DF32s
2017-12-11 09:36:21.240780: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Min2DTo1DF32s (15 ms)
[ RUN      ] ArrayElementwiseOpTest.Compare1DTo2DS32Ge
2017-12-11 09:36:21.255836: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Compare1DTo2DS32Ge (19 ms)
[----------] 5 tests from ArrayElementwiseOpTest (73 ms total)

[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount
[ RUN      ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/1
2017-12-11 09:36:21.274589: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/1 (73 ms)
[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount (73 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 2 test cases ran. (146 ms total)
[  PASSED  ] 5 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteR1F32s

 1 FAILED TEST

```
",0,,29,2017-12-11T10:06:30Z,CONTRIBUTOR
15257,can't read my own tfrecords and face FailedPreconditionError,stat:awaiting response,"Please go to Stack Overflow for help and support:

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 1604
- **TensorFlow installed from (source or binary)**: conda tensorflow
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7
- **Bazel version: N/A
- **CUDA/cuDNN version: N/A
- **GPU model and memory: N/A

### Describe the problem
I'm tryting to read my own datasets. And there exists FailedPreconditionError.
But my ` test.records` are in the right directory, I don't know why it ocurred.

### Source code / logs
these are the console error.
```
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.FailedPreconditionError'>, /home/tju/0_lvjc/deepnet348/data/tfrecords
	 [[Node: ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/cpu:0""](TFRecordReaderV2, input_producer)]]
Traceback (most recent call last):
  File ""/home/tju/Downloads/pycharm-community-2017.2.4/helpers/pydev/pydev_run_in_console.py"", line 37, in run_file
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/home/tju/0_lvjc/deepnet348/data_input.py"", line 199, in <module>
    coord.join(threads)
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 238, in _run
    enqueue_callable()
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1235, in _single_operation_run
    target_list_as_strings, status, None)
  File ""/home/tju/anaconda2/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
```

these are my codes.
```
#%% Convert data to TFRecord

file_dir='/home/tju/0_lvjc/datasets/SALICON/train_images/*.jpg'
label_dir='/home/tju/0_lvjc/datasets/SALICON/salicon17_maps/train/*.png'

tfrecords_file = '/home/tju/0_lvjc/deepnet348/data/tfrecords'
BATCH_SIZE = 5


#Convert test data: you just need to run it ONCE !
name_test = 'test'
images, labels = get_file(file_dir, label_dir)
convert_to_tfrecord(images, labels, save_dir=tfrecords_file, name=name_test)


#%% TO test train.tfrecord file

def plot_images(images, labels):
    '''plot one batch size
    '''
    for i in np.arange(0, BATCH_SIZE):
        plt.subplot(5, 5, i + 1)
        plt.axis('off')
        plt.title(chr(ord('A') + labels[i] - 1), fontsize = 14)
        plt.subplots_adjust(top=1.5)
        plt.imshow(images[i])
    plt.show()



image_batch, label_batch = read_and_decode(tfrecords_file, batch_size=BATCH_SIZE)

with tf.Session()  as sess:
    
    i = 0
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    
    try:
        while not coord.should_stop() and i<1:
            # just plot one batch size
            image, label = sess.run([image_batch, label_batch])
            plot_images(image, label)
            i+=1
            
    except tf.errors.OutOfRangeError:
        print('done!')
    finally:
        coord.request_stop()
    coord.join(threads)

```",0,,3,2017-12-11T02:53:22Z,NONE
15254,CMake build on Windows (tensorflow.dll) does not include many GPU ops,"stat:community support,type:bug/performance","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
from source
- **TensorFlow version (use command below)**:
1.4

- **Python version**:  3.5.2
- **Bazel version (if compiling from source)**:
using CMake (3.8.2)
- **GCC/Compiler version (if compiling from source)**:
MSVC 14 (C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\CL.exe)
- **CUDA/cuDNN version**:
CUDA 8.0, cuDNN: 6 (6.14)
- **GPU model and memory**:
NVidia GTX 1070 (8GB)
- **Exact command to reproduce**:

### Describe the problem
I build tensorflow from source following these instructions:
 https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake
and I use this CMake command:
`cmake ..  -G ""Visual Studio 14 2015 Win64"" -T v140,host=x64 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DSWIG_EXECUTABLE=e:/dev/swigwin-3.0.12/swig.exe -Dtensorflow_ENABLE_GPU=ON  -DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA""   -Dtensorflow_BUILD_SHARED_LIB=ON -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2  -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF
`
and `MSBuild /p:Configuration=RelWithDebInfo tensorflow.vcxproj`

(I also tried 'Release' as Configuration - same outcome).
The result of the build process is  `tensorflow.dll`. I use a separate C++ program (using Qt) to link against the built DLL. In general, everything works fine: I can load a saved tensorflow graph and run it (=inference).
The problem is now, that many GPU-ops are not linked into tensorflow.dll (for example, `Softmax`) - in my example most ops run on GPU but Softmax on CPU - with a huge performance impact (GPU use <10%). Why I think this is the case:
* `tensorflow::LogAllRegisteredKernels()` lists Softmax, but with CPU only
* looking at tensorflow.dll with DependecyWalker has the same result (Softmax CPU only)
* when I check `tf_core_gpu_kernels.lib`, then GPU code is there (e.g., `tf_core_gpu_kernels_generated_softmax_op_gpu.cu.cc.lib`).

### Workaround
After quite some time trying to figure this out, I found a hackish workaround:
Looking at the output of MSBuild (increased verbosity level), it looks as if the python script create_def_file.py is executed without using the tf_core_kernels.lib (`C:\Python35\python.exe E:/dev/tensorflow/tensorflow/contrib/cmake/tools/create_def_file.py --input E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow_static.lib;E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tf_protos_cc.lib --output E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow.def --target tensorflow.dll`). 
What I did is the following:
* create a def-file including the GPU kernels:
`C:\Python35\python.exe E:/dev/tensorflow/tensorflow/contrib/cmake/tools/create_def_file.py --input E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow_static.lib;E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tf_protos_cc.lib;E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tf_core_gpu_kernels.lib --output E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow_wr.def --target tensorflow.dll`

* Link tensorflow.dll with the created def file (tensorflow_wr.def). This did not work, since I got a couple of missing-unresolved-externals errors. As they were all related to LSTM/RNN, I ended up re-creating `tf_core_gpu_kernels.lib` (issuing the Lib.exe omitting tf_core_gpu_kernels_generated_gru_ops_gpu.cu.cc.obj and tf_core_gpu_kernels_generated_lstm_ops_gpu.cu.cc.obj)

* Finally linking tensorflow.dll worked after I manually dropped a couple of symbols from 'tensorflow_wr.def) (unresolved external symbols).

With this workaround it works fine - all ops (including Softmax) run on GPU, performance increased by a factor of 10. I submit as an issue, since I believe it should work out of the box!

Some more details on [StackOverflow](https://stackoverflow.com/questions/47636903/tensorflow-places-softmax-op-on-cpu-instead-of-gpu)
",0,,3,2017-12-10T18:14:09Z,NONE
15246,Error while running Tensor-Flow examples using Bazel build,"stat:contributions welcome,type:build/install","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Ubuntu 16.04:
- **TensorFlow installed from source:
- **TensorFlow version 1.4.0:
- **Python 3.5.2: 
- **Bazel version 0.8.1:
- gcc version 5.4.1:
- CUDA/cuDNN version:
- GeForce GTX 980M  and 8GB:
- bazel build tensorflow/examples/label_image/...:



I am trying to run this by using the command bazel build tensorflow/examples/label_image/...
but i am getting the following error:

```
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/kernels/range_sampler.h:21,
                 from tensorflow/core/kernels/range_sampler.cc:16:
./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = long long int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
tensorflow/core/kernels/range_sampler.cc:86:5:   required from here
./tensorflow/core/platform/default/logging.h:230:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )
                                   ^
./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (x)
                             ^
./tensorflow/core/platform/default/logging.h:230:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )
 ^
./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long long int; T2 = long unsigned int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
tensorflow/core/kernels/range_sampler.cc:244:3:   required from here
./tensorflow/core/platform/default/logging.h:228:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
                         == )  // Compilation error with CHECK_EQ(NULL, x)?
                         ^
./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (x)
                             ^
./tensorflow/core/platform/default/logging.h:227:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'
 TF_DEFINE_CHECK_OP_IMPL(Check_EQ,
 ^
ERROR: /home/hassaan/Downloads/tensorflow/tensorflow/core/BUILD:1739:1: C++ compilation of rule '//tensorflow/core:framework_internal_impl' failed (Exit 1)
In file included from ./tensorflow/core/framework/allocator.h:23:0,
                 from ./tensorflow/core/framework/tensor.h:20,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
./tensorflow/core/framework/numeric_types.h: In constructor 'tensorflow::bfloat16::bfloat16(float)':
./tensorflow/core/framework/numeric_types.h:49:16: error: 'isnan' was not declared in this scope
     if (isnan(v)) {
                ^
./tensorflow/core/framework/numeric_types.h:49:16: note: suggested alternatives:
In file included from /usr/include/c++/5/complex:44:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:99,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
/usr/include/c++/5/cmath:641:5: note:   'std::isnan'
     isnan(_Tp __x)
     ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:558:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GlobalFunctions.h:88:3: note:   'Eigen::isnan'
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(isnan,scalar_isnan_op,not-a-number test,\sa Eigen::isinf DOXCOMMA Eigen::isfinite DOXCOMMA ArrayBase::isnan)
   ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:392:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h:1111:46: note:   'Eigen::numext::isnan'
 template<typename T> EIGEN_DEVICE_FUNC bool (isnan)   (const T &x) { return internal::isnan_impl(x); }
                                              ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:433:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/Half.h:380:45: note:   'Eigen::half_impl::isnan'
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool (isnan)(const half& a) {
```",0,,5,2017-12-10T07:02:16Z,NONE
15243,Add support for explicit broadcasting in TensorFlow,"cla: yes,stat:awaiting response","This fix tries to adds support for explicit broadcasting in TensorFlow, as was suggested in #14509. This fix adds the op of tf.broadcast_to, which is equivalent to the numpy.broadcast_to in numpy.

This fix fixes #14509.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,3,2017-12-10T05:15:00Z,MEMBER
15242,Error using alexnet with Faster-RCNN?,stat:awaiting response,"Hi everyone, 
I am doing object categories detection on COCO dataset using transfer learning (alexnet as a pre-trained with Faster RCNN). However, I am getting this error.

> Warning: An error occurred while using @(x)d.propose(x,minBoxSize,'MiniBatchSize',miniBatchSize) to process
> /train2014/COCO_train2014_000000256230.jpg:
> Expected input number 2, score, to be of size Mx1, but it is of size 0x0.
> Regions from this image will not be used for training. 
> In fastRCNNObjectDetector.invokeRegionProposalFcn (line 268)
  In fastRCNNObjectDetector>@(x,filename)fastRCNNObjectDetector.invokeRegionProposalFcn(fcnCopy,x,filename) (line 158)
  In fastRCNNObjectDetector.extractRegionProposals (line 218)
  In fastRCNNObjectDetector.train (line 168)
  In trainFasterRCNNObjectDetector (line 359)
  In detection (line 75)


**Can you please help me? 
Please have a look at the code, and let me know if there is any mistake?

Thank you very much for your help and time in advance**

P.S. training data (annotation) is stored in a table, where the first column contains paths and file names to images. The remaining columns contain bounding boxes related to the corresponding images. Each column represents a single object class, such as a person, bicycle, car … etc, as explained on https://uk.mathworks.com/help/vision/ref/trainfasterrcnnobjectdetector.html.

     ‘clear all
    close all
    clc
    Train_data= load('************.mat'); %Load vehicle data set
    addpath('************'); % path of the training images
    numClasses = width(Train_data);
    Train_data(1:3,:)% Display first few rows of the data set.
    I = imread(Train_data.imageFilename{6}); % display one of the images with the bbox, 
    I = insertShape(I, 'Rectangle', Train_data.person{6});
    I = imresize(I, 3);
    figure
    imshow(I)
    net = alexnet; % loading pre-trained model (alexnet in this case)
    net.Layers
    layersTransfer = net.Layers(1:end-3);
    layers = [
        layersTransfer
        fullyConnectedLayer(numClasses,'WeightLearnRateFactor',20,'BiasLearnRateFactor',20)
        softmaxLayer
        classificationLayer];
    optionsStage1 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-5);% Options for step 1.
    optionsStage2 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-5);% Options for step 2.
    optionsStage3 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-6); % Options for step 3.
    optionsStage4 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-6);% Options for step 4.
    options = [
        optionsStage1
        optionsStage2
        optionsStage3
        optionsStage4
        ];
    doTrainingAndEval = true; % Training network 
    if doTrainingAndEval
        rng(0);
        detector = trainFasterRCNNObjectDetector(Train_data, layers, options, ...
            'NegativeOverlapRange', [0 0.3], ...
            'PositiveOverlapRange', [0.6 1], ...
            'BoxPyramidScale', 1.2);
    else
        detector=load('*********.mat').
    end
    Test_data= load('************.mat');% tesing and evaluation  
    addpath('************'); % path of the testing image
    Test_data.imageFilename =Test_data.imageFilename;
    I = imread(Test_data.imageFilename{452}); % Read one of the images.
     [bboxes, scores,label] = detect(detector, I);% Run the detector.
    I = insertObjectAnnotation(I, 'rectangle', bboxes, scores);% Annotate detections in the image.
    figure
    imshow(I)
    if doTrainingAndEval
            resultsStruct = struct([]); % Run detector on each image in the test set and collect results.
        for i = 1:height(Test_data)
             I = imread(Test_data.imageFilename{i});        % Read the image.
            [bboxes, scores, labels] = detect(detector, I);        % Run the detector.
            resultsStruct(i).Boxes = bboxes;        % Collect the results.
            resultsStruct(i).Scores = scores;
           resultsStruct(i).Labels = labels;
       end
         results = struct2table(resultsStruct);    % Convert the results into a table.
    else
        results = data.results;    % Load results from disk.
    end
    expectedResults = testData(:, 2:end); % Extract expected bounding box locations from test data.
     [ap, recall, precision] = evaluateDetectionPrecision(results, expectedResults);% Evaluate the    object detector using Average Precision metric.
    figure;% Plot precision/recall curve
    plot(recall, precision)
    xlabel('Recall')
    ylabel('Precision')
    grid on
    title(sprintf('Average Precision = %.1f', ap))’

  


Have I written custom code: I did the code, following the instructions available on matlab both Faster RCNN detection, and transfer learning webpages (https://uk.mathworks.com/help/vision/examples/object-detection-using-faster-r-cnn-deep-learning.html) and (https://uk.mathworks.com/help/nnet/ug/pretrained-convolutional-neural-networks.html#bvm8b5x) respectively  
OS Platform and Distribution: Linux, MATLAB2017a
CUDA/cuDNN version: 8.0, V8.0.44
GPU model and memory: NVIDIA Tesla K80
",0,,4,2017-12-10T02:56:35Z,NONE
15241,Error using Faster RCNN in MATLAB. ,stat:awaiting response,"Hi there, 
I am working on a project that is about detecting multiple object classes (object classes detection), where the dataset that I am using is MSCOCO (2014). 
The method that I am using is Faster RCNN detection method, where I am using matlab 2017a
Please note that all training is done on a machine with a GPU (NVIDIA Tesla K80)
I have wrote the code attached in the zipped file, dropbox link for downloading is presented below. I have done this code by following the instructions available on matlab transfer learning page; it is about using alexnet as a pre-trained mode for Faster RCNN. Can you kindly have a look at the code and let me know, it has any errors, because I am getting an error when doing the evaluation  
Error is:  
Error using fasterRCNNObjectDetector/parseDetectInputs (line 680)
The size of I must be larger than [227 227]. The minimum size is defined by the network's image input layer.
Error in fasterRCNNObjectDetector/detect (line 447)
            params = this.parseDetectInputs(I, varargin{:});
I have resized the image to [400 400], which passed this errors, but still have another error with plotting the accuracy, IF I use less than 400 (e.g., [300 300]), the error will still appear, which I am not sure why, because alexnet input layer is in the size of [227 227], where 300 is still larger than. 
Error is: I am getting all the average precision (ap), recall values as zeros (0). 

To download the code and all materials: https://www.dropbox.com/sh/9u56ragkuz1ltgd/AADKvUXESezWsoaGfgLyE0Exa?dl=0 
Please note the zipped file contains: 
1) the training (transfer learning) code, named as run_20_classes.m
2) .mat file,  named as pre-trained_20_classes.mat that contains the training and testing labels (annotations), stored as a table, where the first column contains paths and file names to images. The remaining columns contain bounding boxes related to the corresponding images. Each column represents a single object class, such as a person, bicycle, car … etc, as explain on https://uk.mathworks.com/help/vision/ref/trainfasterrcnnobjectdetector.html. This mat file also includes the results of detection, saved as detector  the evaluation results.
3) testing code, named as Testing.m

Training images can be downloaded from: http://images.cocodataset.org/zips/train2014.zip 
Testing images can be downloaded from: http://images.cocodataset.org/zips/val2014.zip 

**Can you please help me on how to improve the accuracy, or if my code is mistaken, can you please correct it?**
Thank you very much for your help and time in advance 


Have I written custom code: I did the code, following the instructions available on matlab both Faster RCNN detection, and transfer learning webpages (https://uk.mathworks.com/help/vision/examples/object-detection-using-faster-r-cnn-deep-learning.html) and (https://uk.mathworks.com/help/nnet/ug/pretrained-convolutional-neural-networks.html#bvm8b5x) respectively
OS Platform and Distribution: Linux, MATLAB2017a
CUDA/cuDNN version: 8.0, V8.0.44
GPU model and memory: NVIDIA Tesla K80
Exact command to reproduce: training code (run_20_classes.m), testing (Testing.m)",0,,4,2017-12-10T02:19:24Z,NONE
15237,"[Feature Request]Add SGDR, SGDW, AdamW and AdamWR",stat:awaiting response,"This is a duplicate request from pytorch issue, which I even reuse their issue title
https://github.com/pytorch/pytorch/issues/3790

And the fix from the paper seems to be trivial but I'm not sure how TF should approach this, perhaps just adding another parameter?",0,,6,2017-12-09T15:33:51Z,NONE
15234,Fix static shape inference for keras.layers.LSTM,"awaiting review,cla: yes","fix #15165

### How to test

+ [x] add test case.
+ [ ] pass all tests.",0,,2,2017-12-09T13:29:16Z,CONTRIBUTOR
15228,"Bug in XLA, if branches optimized by grappler/arithmetic_optimizer",stat:awaiting response,"grappler/arithmetic_optimizer may merge different Const op with same value into one. However, if two Const ops are in different branches (tf.cond, or SwitchOp, user-defined SwitchOp things), XLA will make them into one cluster, which would cause this XlaLaunchOp can't be run forever.

One way to walk around this is to disable arithmetic_optimizer.",0,,4,2017-12-09T04:16:16Z,NONE
15219,tf.while_loop and tf.foldl do not support second order gradients,"stat:contributions welcome,type:feature","The example
```python
import tensorflow as tf
x = tf.Variable(1.)
A = tf.Variable(tf.ones((3,3))) 
cost = tf.trace(tf.foldl(tf.matmul,tf.stack([x*A for _ in range(3)])))
tf.gradients(tf.gradients(cost, A), x)  
# TypeError: Second-order gradient for while loops not supported.
```
illustrates that despite applying `tf.foldl` to a static list, the internal implementation via while loops leads to a type error. The problem disappears if the fold operation is carried out manually using a for loop. While implementing `foldl` using the while loop clearly makes the operation  more widely applicable, it seems problematic if syntactic sugar can lead to code that has qualitative differences from a naive implementation using a static loop. I cannot help but wonder whether `foldl` could be more efficient in the static case as well, although that is more of a conjecture.

I think it would be nice if `foldl` (and other while loop derivatives) had a keyword that enabled or disabled the ""dynamic mode"" using while, or if, at the very least, the TypeError would occur at the `foldl`operation so that the error is easier to trace.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Custom code.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**:
pip install.
- **TensorFlow version (use command below)**:
v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**:
3.5.4 
- **Bazel version (if compiling from source)**:
Not applicable.
- **GCC/Compiler version (if compiling from source)**:
Not applicable.
- **CUDA/cuDNN version**:
Did not use CUDA.
- **GPU model and memory**:
Did not use GPU.
- **Exact command to reproduce**:
```python
import tensorflow as tf
x = tf.Variable(1.)
A = tf.Variable(tf.ones((3,3))) 
cost = tf.trace(tf.foldl(tf.matmul,tf.stack([x*A for _ in range(3)])))
tf.gradients(tf.gradients(cost, A), x)  
# TypeError: Second-order gradient for while loops not supported.
```",0,,6,2017-12-08T17:48:02Z,NONE
15216,"When data become large,parition variables can not initialized successfully",,"i use tensorflow to distributed trainning models,  i use the partition valriables to store an array data, when the data is not so bigger, everything looks ok,but when the array data become larger, when the session initialize, the partition variables can not  initialized and the session will wait util time out.
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. the feat_info can initialize successfully, but the adj_info cannot initialized. the adj_info is larger than feat_info
### Source code / logs
i use ps_num = 4, worker_num =4 and i also try some other distributed config, like ps_num=1, worker_num=4, the result is the same
source code:
    with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d"" % task_id,
        cluster=cluster_spec)):
      
      feat_info = tf.get_variable(""feature_info"", (len(id_map),FLAGS.features_column), tf.float32, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))
      adj_info = tf.get_variable(""adj_info"", (len(id_map),FLAGS.max_degree), tf.int64, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))
     
      with tf.device('/job:worker/task:%d' %task_id):
          adj_local = tf.Variable(tf.constant(minibatch.adj, dtype=tf.int64), trainable=False, name=""adj_local"", collections=[tf.GraphKeys.LOCAL_VARIABLES])
          feat_local = tf.Variable(tf.constant(features, dtype=tf.float32), trainable=False, name=""feat_local"", collections=[tf.GraphKeys.LOCAL_VARIABLES])
     
      length, begin, end = split_node_by_task(len(id_map), task_id, num_workers)
      adj = tf.nn.embedding_lookup(adj_info, [x for x in range(begin, end)])
      adj = adj_local
      
      feat = tf.nn.embedding_lookup(feat_info, [x for x in range(begin, end)])
      feat = feat_local

log:
2017-12-08 23:54:17.377290: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session c2b3ba9b700261ba with config: 
INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15
2017-12-09 00:00:35.637019: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session f35fcf332e3908ec with config: 
INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15
and it will alway waiting adj_info to initialize",0,,10,2017-12-08T16:03:41Z,NONE
15214,tf.profiler overrides shape_invariants in while_loop,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0-dev20171120
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

``` python
import tensorflow as tf

a = tf.zeros((1,))
n = tf.constant(10.)
do_profile = True

_, b = tf.while_loop(
    lambda x, y: x[0] < n,
    lambda x, y: (x + 1, tf.concat((y, x), 0)),
    (a, tf.zeros((0,))),
    shape_invariants=(tf.TensorShape((1,)), tf.TensorShape((None,))))

with tf.Session() as sess:
    for _ in range(2):
        grads = tf.gradients(b, a)

        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
        run_metadata = tf.RunMetadata()
        print(sess.run((b, grads), options=run_options,
                       run_metadata=run_metadata))

        if do_profile:
            tf.profiler.profile(tf.get_default_graph(), run_meta=run_metadata)
```

If `do_profile=True`, this will give an error on the second pass through the for loop:
```
Traceback (most recent call last):
  File "".../tmp3.py"", line 15, in <module>
    grads = tf.gradients(b, a)
  File ""...\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 638, in gradients
    % (op.name, i, t_in.shape, in_grad.shape))
ValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: while/Switch_1.  Input index: 0. Original input shape: (0,).  Calculated input gradient shape: (10,)
```

### Describe the problem

I believe this is caused by [this function](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/tfprof_logger.py#L37), which goes through the graph and fills in missing shapes from the `run_metadata`.  This modifies the graph in-place, so on the second pass through the for loop the loop variable that was intentionally defined with an unknown shape has been overwritten with the fixed shape from the last run.  This causes the shape mismatch error.
  ",0,,6,2017-12-08T15:18:52Z,CONTRIBUTOR
15213,XLA/AOT Windows support,stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.8.0
- **GCC/Compiler version (if compiling from source)**: VS 2017 15.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

Similar to #8310, but specifically about running `tfCompile` on Windows rather than Linux to produce `x86_64-windows-msvc` binaries.

XLA/AOT depends on LLVM which has excellent Windows support via CMake, but Bazel cannot interop with CMake. [llvm.BUILD](https://github.com/tensorflow/tensorflow/blob/master/third_party/llvm/llvm.BUILD) is auto-generated and the script to generate it is not open-sourced, this make it difficult for external contributor to make improvement. [tensorflow/compiler](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler) might not need too much changes as #9908 already addressed some of them.

One possible path is to let user to run CMake in host machine when invoking `configure.py`, then feed CMake generated files into custom script to generate `LLVM.BUILD`.

Note:

[Rumour has it](https://chromium-review.googlesource.com/c/chromium/src/+/753588) that there is a Google-internal tool called `tfNative` to generate `.h/.cpp` files instead of `.lib` binaries, though I suspect that even if the tool is open-sourced, it might not be immediately available for Windows developers.",0,,8,2017-12-08T14:15:08Z,CONTRIBUTOR
15211,Deep MNIST - exit code 139 (interrupted by signal 11: SIGSEGV),stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I have copied all the code lines from the tutorial Deep MNIST for Experts manually into a python file.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux, kernel: 4.13.12-1-ARCH
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})

### Describe the problem
I am trying to run the example code from the tutorial Deep MNIST for Experts by copying every line from the tutorial into a python file and running it. The first part of the script with the model with a single linear layer runs fine, but the second part with a multilayer convolutional network fails to run. When the last line of the script executes: `print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))` I get the following error: `Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)`. 

I tried to evaluate the accuracy with a batch of size 50 from the testing data instead of supplying mnist.test.images and mnist.test.labels and that worked fine.
I was directed here from Stackoverflow because this was believed to be a bug [(Stackoverflow question).](https://stackoverflow.com/questions/47640511/tensorflow-deep-mnist-exit-code-139)

### Source code / logs
I am unfamiliar with gdb so if I have missed to provide any relevant debugging output I'll try to add it if you can tell me how to get it.

[Source code](https://hastebin.com/ebidihiwey.py)
[Stackframe](https://hastebin.com/jukuzejira.cpp)
[Backtrace](https://hastebin.com/baqecavora.vbs)
",0,,6,2017-12-08T13:02:02Z,NONE
15210,Incorrect Result from Add Function,,"### System information

- Have I written custom code: Yes
- OS Platform and Distribution: Linux Ubuntu 16.04.3 LTS
- Bazel version: Not applicable 
- TensorFlow installed from binary
- TensorFlow version: 1.4.0
- Python version: 3.5.2
- CUDA/cuDNN version: 8.0 / 6.0 for CUDA 8.0
- GPU model and memory: GM107M [GeForce GTX 960M] 4GB
- Exact command to reproduce:

Here is a simple program to add: 

session = tf.Session()

a = tf.placeholder(tf.float32)
#print(""first"")
b = tf.placeholder(tf.float32)
#print(""second"")
result_node = tf.add(a,b)
#print(""starting"")
x = session.run(result_node, {a:2.0, b: 3.5})
print(x)

Output should be 5.5, while I am getting 2.0 on 2 machines

![screenshot from 2017-12-08 17-59-49](https://user-images.githubusercontent.com/19254286/33766026-af9682da-dc41-11e7-8f81-1ff054903deb.png)
![screenshot from 2017-12-08 18-00-21](https://user-images.githubusercontent.com/19254286/33766027-afd8aba6-dc41-11e7-9a85-02f2764a9d67.png)

",0,,6,2017-12-08T12:31:12Z,NONE
15209,CMake: If/else statement in CMAKE_CACHE_ARGS breaks CMake build on Ubuntu 17.10,"stat:contributions welcome,type:build/install","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10.
- **TensorFlow installed from (source or binary)**: Source (CMake)
- **TensorFlow version (use command below)**: 2cfb088cf72b52c74a742d780cc5c4f93a74640e (tip of master at time of writing)
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: 7.2.0
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: cmake ../../tensorflow/contrib/cmake && make

### Source code / logs
    [  1%] Performing build step for 'zlib'
    [ 40%] Built target zlibstatic
    [ 42%] Linking C shared library libz.so
    /usr/bin/ld: CMakeFiles/zlib.dir/deflate.o: relocation R_X86_64_PC32 against symbol `deflate' can not be used when making a shared object; recompile with -fPIC
    /usr/bin/ld: final link failed: Bad value
    collect2: error: ld returned 1 exit status

### Cause
In v1.4.0, you will find the argument `-DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON` given to  CMAKE_CACHE_ARGS for several external projects (png, zlip, sqlite etc). In master, this has been changed to 

	CMAKE_CACHE_ARGS
		if(tensorflow_ENABLE_POSITION_INDEPENDENT_CODE)
			-DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON
		else()
			-DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=OFF
		endif()

which yields the following init cache entries on my machine: 

	set(CMAKE_POSITION_INDEPENDENT_CODE ""ON;if;(;tensorflow_ENABLE_POSITION_INDEPENDENT_CODE;);else;(;)"" CACHE BOOL ""Initial cache"" FORCE)
	set(CMAKE_POSITION_INDEPENDENT_CODE ""OFF;endif;(;)"" CACHE BOOL ""Initial cache"" FORCE)

and the build fails because `CMAKE_POSITION_INDEPENDENT_CODE` ends up not being set to `ON`. I could imagine this breaks a lot of builds. Perhaps CMake behaves differently on Windows and therefore this has not been caught? Is there a reason for this change I am not aware of? 

### Solution
A possible solution is to not inline the if/else statement and instead use the argument

    -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=${tensorflow_ENABLE_POSITION_INDEPENDENT_CODE}

Are you interested in a PR?
",0,,3,2017-12-08T12:13:31Z,CONTRIBUTOR
15206,"Unusual memory allocation while running ""tf.assign""",,"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.4.0
- **Python version**: 2.7
- **Bazel version**: 0.8.1
- **CUDA/cuDNN version**: 8.0.61 / 6.0.21
- **GPU model and memory**: Tesla K80
- **Exact command to reproduce**: run the script attached below

### Describe the problem
In the minimal example below, I am observing an increase in RAM usage when calling `assign_new_values`. Strangely, the extend depends on the dataset size. 
I see no obvious connection between the dataset and the variables that get assigned. Commenting out either the iterator or the `sess.run(assign_op, ...)` prevents additional memory allocation.

How is this possible?

### Source code / logs
```python
import numpy as np
import tensorflow as tf

DATASET_SIZE = 1000000


def create_dataset():
    image_paths = tf.constant(DATASET_SIZE * ['image.jpg'])
    labels = tf.constant(DATASET_SIZE * [0])
    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))
    return dataset


def create_variables():
    for i in range(20):
       tf.get_variable('var_%d' % i, shape=[3, 3, 3, 32])


def create_assign_ops():
    for var in tf.global_variables():
        name = var.op.name
        placeholder = tf.placeholder(tf.float32, shape=var.shape, name=name + '/placeholder')
        tf.assign(var, placeholder, name=name + '/assign_op')


def assign_new_values(sess):
    for var in tf.global_variables():
        name = var.op.name
        assign_op = tf.get_default_graph().get_tensor_by_name(name + '/assign_op:0')
        sess.run(assign_op, feed_dict={name + '/placeholder:0': np.random.random(var.shape)})


if __name__ == '__main__':
    with tf.Graph().as_default():
        with tf.device('/cpu:0'):
            dataset = create_dataset()
            iterator = dataset.make_one_shot_iterator()

        create_variables()
        create_assign_ops()

        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            # Check RAM usage before
            assign_new_values(sess)
            # Check RAM usage after

```
",0,,5,2017-12-08T09:03:33Z,NONE
15201,Remove extra param of concatenation in nnapi/NeuralNetworksShim.h,"awaiting review,cla: yes","The param specifying activation is not documented in [this](https://developer.android.com/ndk/reference/group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a44cbea825c4b224dd3ea757e9b1f65ed). It is actually needed in 8.1 Preview MR1, but not needed anymore in MR2.",1,,7,2017-12-08T04:18:09Z,NONE
15184,Add some sparse operators,"awaiting review,cla: yes",,1,,4,2017-12-07T14:22:11Z,NONE
15183,estimator: allow export_outputs to be a Tensor,"awaiting review,cla: yes","When someone wants to use `tf.estimator.Estimator.export_savedmodel` to save the predictions of a model and `tf.contrib.predictor.from_saved_model` to load the prediction function, it is currently necessary to define boilerplate code. This PR reduces the amount of code.

Currently:
```python
...
ret['export_outputs'] = {
        'predictions': tf.estimator.export.PredictOutput(
            {'predictions': ret['predictions']}
        )
    }
tf.estimator.EstimatorSpec(**ret)
```
With this PR the following is enough:
```python
ret['export_outputs'] = {'predictions': ret['predictions']}
ret['export_outputs'] = ret['predictions']
```
The predictor repr for the first example is equal to the original code
```python
SavedModelPredictor with feed tensors {'x': <tf.Tensor 'Placeholder:0' shape=(1, 10) dtype=float32>} and fetch_tensors {'predictions': <tf.Tensor 'dense/Relu:0' shape=(1, 10) dtype=float32>}
```
and for the second the output name changes
```python
SavedModelPredictor with feed tensors {'x': <tf.Tensor 'Placeholder:0' shape=(1, 10) dtype=float32>} and fetch_tensors {'output': <tf.Tensor 'dense/Relu:0' shape=(1, 10) dtype=float32>}
```

When someone wants to verify the code, here a full example:
```python
from types import SimpleNamespace
import numpy as np
import tensorflow as tf
from tensorflow.contrib import predictor

def model_fn(features, labels, mode):
    assert labels is None, labels
    x = features['x']
    y = features['y']
    
    y_hat = tf.layers.Dense(10, tf.nn.relu)(x)
    loss = tf.losses.mean_squared_error(y, y_hat)
    train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)
    
    ret = dict(
        mode=mode,
        loss=loss,
        predictions=y_hat,
        train_op=train_op,
    )

    # Boilderplate:
    ret['export_outputs'] = {  # <------------------- old
        'predictions': tf.estimator.export.PredictOutput(
            {'predictions': ret['predictions']}
        )
    }
    ret['export_outputs'] = {'predictions': ret['predictions']}  # <------------------- new
    ret['export_outputs'] = ret['predictions']  # <------------------- new alternate
    
    return tf.estimator.EstimatorSpec(**ret)
        
estimator = tf.estimator.Estimator(
    model_fn=model_fn
)

def generator():
    x = np.random.randn(1, 10).astype(np.float32)
    y = np.random.randn(1, 10).astype(np.float32)
    yield {'x': x, 'y': y}

def input_fn():
    ds = tf.data.Dataset.from_generator(generator, {'x': tf.float32, 'y': tf.float32}, {'x': [1, 10], 'y': [1, 10]})
    it = ds.make_one_shot_iterator()
    element = it.get_next()
    return element

estimator.train(input_fn)

def serving_input_receiver_fn():
    x = tf.placeholder(tf.float32, [1, 10])
    y = tf.placeholder(tf.float32, [1, 10])
    
    ret = SimpleNamespace()
    ret.features = {'x': x, 'y': y}  # for graph def
    ret.receiver_tensors = {'x': x}  # for serving
    ret.receiver_tensors_alternatives = None
    return ret


model_path = estimator.export_savedmodel('tmp', serving_input_receiver_fn)

predict_fn = predictor.from_saved_model(model_path)
# predict_fn({'x': np.random.randn(1, 10)})
predict_fn
```",1,,3,2017-12-07T14:16:33Z,CONTRIBUTOR
15176,fix a problem in tflite custom_operators.md,"awaiting review,cla: yes","s/SinResize/SinPrepare/ 
Obviously, it should be SinPrepare instead of SinResize.",1,,4,2017-12-07T06:35:50Z,CONTRIBUTOR
15172,Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed,stat:awaiting response,"ERROR: /Users/lion/Documents/opensoft/tensorflow/tensorflow/python/BUILD:2749:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o ... (remaining 573 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
clang: warning: argument unused during compilation: '-pthread'
ld: library not found for -lgomp
",0,,6,2017-12-07T01:52:36Z,NONE
15168,Adding reading op for hadoop sequence file format (very basic version though).,"cla: yes,stat:awaiting response","This CL allows tensorflow to be able to read tf.Example stored in Hadoop sequence file, which is the one of the well supported output format in the Hadoop eco system (comparing to recordio or sstable).

This enables one to write Hadoop mapreduce in the familiar way, producing tf.Example, storing them into standard output format (on S3 for example), and invoke tensorflow, avoiding the expensive, and sometimes confusing step of converting from Hadoop format into recordio.

To keep things simple, there are some limitations in this implementation:

1. no compressed sequence file (not a big issue if the records are already serialized protos)

2. SEQ5 or SEQ6 format.

3. The value in the sequence file must be encoded using org.apache.hadoop.io.BytesWritable, no text or other format, as the primary goal is to read tf.Example protos stored therein.

Please help me to get this into tensorflow. Thank you.
",1,,7,2017-12-06T20:38:03Z,NONE
15165,LSTM layer in consistent with tf.keras v2.0.8-tf and keras 2.1.2,,"It looks like there are some inconsistencies with the output shape of the LSTM layer. 

Running the following code does not produce an error in `keras 2.1.2`:
```python
model = Sequential()

conv_layer = Conv1D(filters=320,
                    kernel_size=26,
                    strides=1,
                    padding='valid',
                    activation='relu',
                    input_shape=(1000,4))

model.add(conv_layer)
model.add(MaxPooling1D(pool_size=13,
                       strides=13))

model.add(LSTM(320, return_sequences=True))

model.add(Flatten())
model.add(Dense(925,
                activation='relu'))
model.add(Dense(919,
                activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 975, 320)          33600     
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 75, 320)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 75, 320)           820480    
_________________________________________________________________
flatten_1 (Flatten)          (None, 24000)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 925)               22200925  
_________________________________________________________________
dense_2 (Dense)              (None, 919)               850994    
=================================================================
Total params: 23,905,999
Trainable params: 23,905,999
Non-trainable params: 0
_________________________________________________________________
```

but produces this error in `keras v2.0.8-tf`:

```python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-389-956501e5fb90> in <module>()
     16 model.add(Flatten())
     17 model.add(Dense(925,
---> 18                 activation='relu'))
     19 model.add(Dense(919,
     20                 activation='sigmoid'))

~/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/models.py in add(self, layer)
    499           output_tensors=self.outputs)
    500     else:
--> 501       output_tensor = layer(self.outputs[0])
    502       if isinstance(output_tensor, list):
    503         raise TypeError('All layers in a Sequential model '

~/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py in __call__(self, inputs, **kwargs)
    250     """"""
    251     # Actually call the layer (optionally building it).
--> 252     output = super(Layer, self).__call__(inputs, **kwargs)
    253 
    254     # Update learning phase info.

~/anaconda/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    557           input_shapes = [x.get_shape() for x in input_list]
    558           if len(input_shapes) == 1:
--> 559             self.build(input_shapes[0])
    560           else:
    561             self.build(input_shapes)

~/anaconda/lib/python3.6/site-packages/tensorflow/python/layers/core.py in build(self, input_shape)
    125     input_shape = tensor_shape.TensorShape(input_shape)
    126     if input_shape[-1].value is None:
--> 127       raise ValueError('The last dimension of the inputs to `Dense` '
    128                        'should be defined. Found `None`.')
    129     self.input_spec = base.InputSpec(min_ndim=2,

ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.
```

If I keep return_sequences = True and remove Flatten() after the LSTM I get the following:

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_49 (Conv1D)           (None, 975, 320)          33600     
_________________________________________________________________
max_pooling1d_49 (MaxPooling (None, 75, 320)           0         
_________________________________________________________________
lstm_33 (LSTM)               (None, None, 320)         820480    
_________________________________________________________________
dense_92 (Dense)             (None, None, 925)         296925    
_________________________________________________________________
dense_93 (Dense)             (None, None, 919)         850994    
=================================================================
Total params: 2,001,999
Trainable params: 2,001,999
Non-trainable params: 0
_________________________________________________________________
```
More on the discussion in https://github.com/uci-cbcl/DanQ/issues/9#issuecomment-348377899",0,,9,2017-12-06T19:51:34Z,NONE
15164,minor docs addition to fixed_size_partitioner,"awaiting review,cla: yes","Clarifying whether fixed_size_partitioner is equivalent to partition_strategy='div' or ='mod', as described in https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup (to hopefully help use downstream with embedding_lookup).",1,,5,2017-12-06T19:13:42Z,NONE
15161,Create Simple DNNClassifier ,stat:awaiting response,"Hi, I'm beginner in Machine Learning and Tensorflow.
I edited [this](https://www.tensorflow.org/get_started/estimator) to adapt it to my dataset (102 features-input and 4 classes-output).

**Question:**
This simple approach is correct for a simple classifier?
Why can't I change the number of nodes and levels (compilier gives errors)? 

**Code:**

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os
from six.moves.urllib.request import urlopen
import numpy as np
import tensorflow as tf
import EstraiFeature as ef
from pyAudioAnalysis import audioBasicIO
# Datasets (Training and Testing set doesn't refer to iris)
IRIS_TRAINING = ""/Users/giuseppeaccardo/Documents/python/Depressione/TrainingSet.csv"" 
IRIS_TEST = ""/Users/giuseppeaccardo/Documents/python/Depressione/TestingSet.csv"" 

def main():
    # Load datasets.
    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
        filename=IRIS_TRAINING,
        target_dtype=np.int,
        features_dtype=np.float32)
    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(
        filename=IRIS_TEST,
        target_dtype=np.int,
        features_dtype=np.float32)

    # Specify that all features have real-value data
    feature_columns = [tf.feature_column.numeric_column(""x"", shape=[102])]
    
    # Build 3 layer DNN with 10, 20, 10 units respectively. How can I change this values? 
    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,
                                          hidden_units=[10,20, 10],
                                          n_classes=4,
                                          model_dir=""/tmp/depres_model"")
    
   # Define the TRAINING inputs, includes both the feature (DNN input end) and target (DNN output end)
    train_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": np.array(training_set.data)}, #training_set.data
        y=np.array(training_set.target), #training_set.target
        num_epochs=None,
        shuffle=True)
    
    # Fit model.
    print(""Training classfier..."")
    classifier.train(
        input_fn = train_input_fn,
        steps = 2000)

    #Define the TEST inputs, both feature and target
    test_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"":np.array(test_set.data)},
        y=np.array(test_set.target),
        num_epochs=1,
        shuffle=False)

    #Evaluate accuracy after training
    accuracy_score = classifier.evaluate(
        input_fn=test_input_fn)[""accuracy""]

    print(""\nTest Accuracy: {0:f}\n"".format(accuracy_score))
    # Bag of words  approach -> Conta le label più ripetute per ogni mid range
    # PREDIZIONE
    #Predict with new data
    filename = ""/Users/giuseppeaccardo/Documents/python/Depressione/dataset/audio/426_AUDIO.wav""
    [Fs, signal] = audioBasicIO.readAudioFile(filename)  # read audio signal
    [mtFeatures, _] = ef.estraiFeatureMt(signal, Fs)
    mtF = mtFeatures.T       
    new_samples = np.array(
        mtF, dtype=np.float32
    )        

    predict_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"":new_samples},
        num_epochs=1,
        shuffle=False
    )

    predictions = list(classifier.predict(input_fn=predict_input_fn))
    countLabel = [0,0,0,0]
    classPredict = 0
    
    for p in predictions:
        countLabel[int(p[""class_ids""])] +=1
        
    print(countLabel)
    print(""Prevision is ""+ str(countLabel.index(max(countLabel))) ) 
    
if __name__ == ""__main__"":
    main()
```",0,,4,2017-12-06T17:24:12Z,NONE
15156,Tensorflow set_random_seed,,"I use `tf.set_random_seed` to set the seed of graph, and run programs many times, but the result is different.
Is it a bug or precision problem?

```python
import tensorflow as tf
slim =tf.contrib.slim

tf.set_random_seed(0)

def vgg16(inputs):
  with slim.arg_scope([slim.conv2d, slim.fully_connected],
                      activation_fn=tf.nn.relu,
                      weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),
                      weights_regularizer=slim.l2_regularizer(0.0005)):
    net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')
    net = slim.max_pool2d(net, [2, 2], scope='pool1')
    net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')
    net = slim.max_pool2d(net, [2, 2], scope='pool2')
    net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')
    net = slim.max_pool2d(net, [2, 2], scope='pool3')
    net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')
    net = slim.max_pool2d(net, [2, 2], scope='pool4')
    net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')
    net = slim.max_pool2d(net, [2, 2], scope='pool5')
    net = slim.flatten(net)
    net = slim.fully_connected(net, 4096, scope='fc6')
    net = slim.dropout(net, 0.5, scope='dropout6')
    net = slim.fully_connected(net, 4096, scope='fc7')
    net = slim.dropout(net, 0.5, scope='dropout7')
    net = slim.fully_connected(net, 1000, activation_fn=None, scope='fc8')
  return net

outputs = vgg16(tf.random_normal([32, 224, 224, 3]))
loss = tf.reduce_mean(tf.square(outputs-tf.random_normal([32, 1000])))
loss = tf.Print(loss, [loss])
optimizer = tf.train.GradientDescentOptimizer(0.001)
train_op = optimizer.minimize(loss)

with tf.Session() as sess:
    tf.global_variables_initializer().run()
    for i in range(10):
        sess.run([loss, train_op])
```

Sometimes it prints
```
2017-12-06 22:12:46.008551: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00103784]
2017-12-06 22:12:48.309682: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01074851]
2017-12-06 22:12:49.039724: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00621808]
2017-12-06 22:12:49.683761: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00629878]
2017-12-06 22:12:50.326798: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.999040961]
2017-12-06 22:12:50.973835: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.991326749]
2017-12-06 22:12:51.621872: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01098168]
2017-12-06 22:12:52.266909: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.989544928]
2017-12-06 22:12:52.911945: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01077247]
2017-12-06 22:12:53.558982: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00654614]
```
Or

```
2017-12-06 22:14:15.614676: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00103784]
2017-12-06 22:14:17.945809: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01074851]
2017-12-06 22:14:18.633848: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00621808]
2017-12-06 22:14:19.283886: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00629878]
2017-12-06 22:14:19.932923: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.999040902]
2017-12-06 22:14:20.582960: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.99132669]
2017-12-06 22:14:21.231997: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01098168]
2017-12-06 22:14:21.878034: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.989544928]
2017-12-06 22:14:22.525071: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01077247]
2017-12-06 22:14:23.137106: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00654614]
```

The fifth and sixth float number are a little different.

If it is the precision problem, the output of program will be different while running on different situation.

If I use` resnet_v1.resnet_v1_101`, the difference becomes bigger.
See below
```
2017-12-06 22:36:10.263869: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.38138771]
2017-12-06 22:36:10.957909: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.37634754]
2017-12-06 22:36:11.511941: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.37431192]
2017-12-06 22:36:12.065973: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.32495236]
2017-12-06 22:36:12.618004: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.31184864]
2017-12-06 22:36:13.171036: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26968479]
2017-12-06 22:36:13.726067: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26032281]
2017-12-06 22:36:14.282099: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.21301842]
2017-12-06 22:36:14.831131: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.25101829]
2017-12-06 22:36:15.386162: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.14982963]
```
and
```
017-12-06 22:36:46.220926: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.38138771]
2017-12-06 22:36:46.913966: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.3763473]
2017-12-06 22:36:47.466997: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.37354136]
2017-12-06 22:36:48.022029: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.32750821]
2017-12-06 22:36:48.571060: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.30615568]
2017-12-06 22:36:49.126092: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26913476]
2017-12-06 22:36:49.682124: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26520848]
2017-12-06 22:36:50.238156: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.21404171]
2017-12-06 22:36:50.793188: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.25153565]
2017-12-06 22:36:51.347219: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.14605141]
``` 
",1,,10,2017-12-06T14:19:43Z,NONE
15154,Add uint32 and uint64 kernel support for `Invert`,"awaiting review,cla: yes","This fix adds uint32 and uint64 kernel support for `Invert`.

In bitwise_ops.cc, uint32 and uint64 have been registered for `Invert` like other bitwise ops `BitwiseAnd`/`BitwiseOr`/`BitwiseXor`/`LeftShift`/`RightShift`.

However, no uint32 and uint64 kernels available for `Invert` yet.

This fix add uint32 and uint64 kernel for `Invert`, and adds additional test cases to cover the changes.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,5,2017-12-06T13:18:19Z,MEMBER
15153,Tensorflow Unit Test //tensorflow/python/kernel_tests:depthtospace_op_test TIMEOUT,,"System Information
Linux  ppc64le GNU/Linux
commit id 3fe5fa08dbed8134ad400f03be474aeb39bcc922
Python 2.7.5
Bazel Build label: 0.5.4- (@non-git)
gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)
cuda-9.0/
NVIDIA GPU driver 

command to reproduce  - bazel test tensorflow/python/kernel_tests:depthtospace_op_test

*Failure log* 

pci bus id: 0003:01:00.0, compute capability: 6.0)
2017-12-06 08:58:27.675099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0007:01:00.0, compute capability: 6.0)
2017-12-06 08:58:27.699874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0003:01:00.0, compute capability: 6.0)
2017-12-06 08:58:27.699885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0007:01:00.0, compute capability: 6.0)
Terminated
",0,,5,2017-12-06T11:57:39Z,NONE
15150,`variational_recurrent` in contrib DropoutWrapper causes extreme perplexity jumps,,"I have done extensive testing of the `variational_recurrent` option in the tf.contrib dropout wrapper and neither me nor my colleagues can explain the extreme perplexity jumps that are caused by it.

I am training an RNN language model on the Penn Treebank Dataset. The model code is very similar to the one provided in the [TensorFlow Tutorial](https://www.tensorflow.org/tutorials/recurrent), using the same learning parameters, hidden sizes, etc. like the MEDIUM config. I am using the newest TensorFlow version (1.4.0).

Consider the following models together with the dropout values used in the tf.contrib Dropout Wrapper. If not mentioned, no further regularization was used.

**model1:** 

 - input dropout 0.3, state dropout: 0.3, output dropout: 0.3
 - variational_recurrent=True
 - Perplexity test set: 83.81
 - Perplexity validation set: 86.97

**model2:**

 - input dropout 0.5, state dropout: 0.3, output dropout: 0.5
 - variational_recurrent=True   
 - Perplexity test set: 639.65
 - Perplexity validation set: 686.95

**model3 (as a comparison):**

 - input dropout 0.5, output dropout: 0.5
 - variational_recurrent=False
 - Perplexity test set: 82.88
 - Perplexity validation set: 86.11


I have tested various architectures, with and without variational dropout. I could not find an explanation for the fact that the perplexity sometimes jumps up to >600 when using variational dropout. Also, the effects vanish when tying the embedding and softmax weights.
In general, variational dropout does not improve but worsen the results (which is different to the results reported in recent papers using variational dropout on the PTB dataset).

To test this problem further, I have adapted the official tensorflow tutorial to use variational dropout instead of standard dropout, by removing lines 131+132 and replacing lines 218-220 with:

    if is_training and config.keep_prob < 1:
      cell = tf.contrib.rnn.DropoutWrapper(cell,
                input_keep_prob=config.keep_prob,
                output_keep_prob=config.keep_prob,
                state_keep_prob=config.keep_prob,
                variational_recurrent=True, dtype=tf.float32,
                input_size=config.hidden_size)

Training the medium model with this configuration causes the same issues, i.e. perplexity > 600

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom code
- **OS Platform and Distribution**:  Debian GNU/Linux 8.9 (jessie)
- **TensorFlow version **: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Python 3.5.4 
- **GCC/Compiler version**:
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514",1,,12,2017-12-06T10:36:14Z,NONE
15144,Error_Converting_TliteFormat,comp:lite,"  .....................................................## System information##........................................................................
-Python -2.7.12
-OS -Ubuntu 16.04
-Tensorflow version-1.4.0
-Bazel version-0.8.0
     ......................................................##Description ###...............................................................
1. I went through the following link and 
=>https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3
and successfully retrained the last layer of the model.

2. Now i was trying to use that retrained.pb file and convert into.tlite format.
=>https://github.com/tensorflow/tensorflow
--Downloaded the tensorflow-master directory.
--Install Bazel (0.8.0)
--Then, using the retrained.pb file,trying to do model format conversion
--Downloaded the checkpoints from 
=>https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md
But got stucked while running the command for conversion.[bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/ee210201/tensorflow-for-poets-2/tf_files/retrained_graph.pb --input_checkpoint=/tmp/checkpoints/mobilenet_v1_0.50_224.ckpt.data-00000-of-00001 --input_binary=true --output_graph=/tmp/checkpoints/frozen_mobilenet.pb  --output_node_names=Softmax}



.........................................................### Source code ##..........................................................................................
1. 
(tensorflow) root@pcz-ee210201:/u/tensorflow-master# bazel build -c opt --copt=-msse4.1 --copt=-msse4.2 tensorflow/python/tools:freeze_graph

=>INFO: Elapsed time: 1057.269s, Critical Path: 44.92s
INFO: Build completed successfully, 2109 total actions
.................................................................................................................................

2. But while running the below script [To convert into .tlite format] ,i was unable to resolved the following error?
(tensorflow) root@pcz-ee210201:/u/tensorflow-master# bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/ee210201/tensorflow-for-poets-2/tf_files/retrained_graph.pb --input_checkpoint=/tmp/checkpoints/mobilenet_v1_0.50_224.ckpt.data-00000-of-00001 --input_binary=true --output_graph=/tmp/checkpoints/frozen_mobilenet.pb  --output_node_names=Softmax

Error:::::::::::::::::::::::::::::::::::::::::
```
Traceback (most recent call last):
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 56, in <module>
    from tensorflow.python.tools import saved_model_utils
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_utils.py"", line 21, in <module>
    from tensorflow.contrib.saved_model.python.saved_model import reader
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/__init__.py"", line 82, in <module>
    from tensorflow.contrib.eager.python import tfe as eager
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py"", line 75, in <module>
    from tensorflow.contrib.eager.python.datasets import Iterator
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py"", line 23, in <module>
    from tensorflow.contrib.data.python.ops import prefetching_ops
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py"", line 25, in <module>
    resource_loader.get_path_to_datafile(""../../_prefetching_ops.so""))
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py"", line 55, in load_op_library
    ret = load_library.load_op_library(path)
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py"", line 56, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))

=>tensorflow.python.framework.errors_impl.NotFoundError: /u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E
.........................................................................................................................
```
Please let me know what does above error
--(tensorflow.python.framework.errors_impl.NotFoundError: --_ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E)
means and how to solved it.

",1,,24,2017-12-06T04:44:00Z,NONE
15140,CUDA 9.1 planning ticket,,"**Update 23-JAN-2018**
CUDA 9.1 requires an upgrade to device driver 387 (CUDA 9 was 384).  Moving device drivers is painful for production environments.  We are not doing to moving the default builds to CUDA 9.1 or 9.2 we will stick with CUDA 9 likely until CUDA 10.  We will move cuDNN forward which will have a larger impact and not require device drive upgrades.  This space is developing as everyone involved evolves their processes and learns from the past.  

While I cannot promise anything, I do want to create a ""channel"" where we are building and testing the latest CUDA 9.x so we can track performance improvements and have some avenue for people to get those builds.  The testing infrastructure is large and maintaining this has a cost.  I hope to find a middle ground as I like perf testing the latest libraries.  

**Original Message**
The purpose of this thread is to keep CUDA 9.1 questions related to when it will be in TensorFlow in a single area.  Separate issues are fine.  I will try to keep this first comment updated with information as it comes out.  

**Current Status:**  Unknown, waiting for RC and gathering information to formulate a plan.  

p.s. There is a tendency to treat TensorFlow like a one way product.  I want to continue to change that with this type of dialog and transparency.  Many people outside Google will contribute to CUDA 9.1 support for TensorFlow.  ",1,,21,2017-12-05T21:00:58Z,MEMBER
15134,contrib STFT magnitudes different to librosa's,stat:community support,"------------------------

### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: 1.4
- **Python version**: 3.5.2
- **Bazel version**: N/A
- **GCC/Compiler version**: N/A
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: nvidia quadro m2000m 4gb
- **Exact command to reproduce**: See below code

Hi all!

I was comparing the TensorFlow's contrib STFT against librosa's and noticed there are some discrepancies in terms of output between the two. Not sure if this normal between libraries implementations, but I wanted to raise it in case it matters!

I'm also aware it could be some small bug or difference in implementation/argument that I have supplied.

Code:

```
import tensorflow as tf
import numpy as np
import librosa

np.random.seed(666)
np.set_printoptions(precision=5, suppress=True)

audio_length_seconds = 2
sample_rate = 44100
audio_frames_length = int(sample_rate * audio_length_seconds)
audio_shape = [None, audio_frames_length]
fft_size = 1024
hop_size = 512

tf.reset_default_graph()

audio = tf.placeholder(tf.float32, 
                       shape=audio_shape)
stfts = tf.contrib.signal.stft(audio, 
                               frame_length=fft_size, 
                               frame_step=hop_size,
                               fft_length=fft_size,
                               pad_end=True)
real = tf.real(stfts)
imag = tf.imag(stfts)
magnitudes = tf.abs(stfts)
phases = tf.atan2(imag, real)
features = tf.concat([magnitudes, phases], axis=2)

sess = tf.Session()
with sess.as_default():
    
    data = np.random.random((1, audio_frames_length))
    tf_results = magnitudes.eval({audio: data})
    
    lr_results = librosa.core.stft(y=data.reshape((-1)),
                                   n_fft=fft_size,
                                   hop_length=hop_size,
                                   win_length=fft_size)
                                   
    lr_results = np.abs(lr_results)
    
    difference = np.abs(tf_results - lr_results.T)
    print(""Differences:\nmin:"", np.min(difference), 
          ""max:"", np.max(difference), 
          ""mean:"", np.mean(difference), 
          ""std:"", np.std(difference))
```

And the expected output from the print would be:

```
Differences:
min: 6.97374e-05 max: 246.904 mean: 2.92715 std: 2.45132
```",0,,3,2017-12-05T15:55:13Z,NONE
15131,Tensorflow Unit Test: //tensorflow/python/eager:core_test fails,stat:community support,"Tensorflow test failing on power hardware. 

W tensorflow/core/common_runtime/device_mgr.cc:97] Unknown device: GPU:5 all devices: /device:GPU:1, GPU:0, /device:GPU:0,

We are using 2 GPUs.

Any help appreciated",0,,5,2017-12-05T14:58:53Z,NONE
15130,Synchronize threads for safe output,"awaiting review,cla: yes",,1,,3,2017-12-05T14:47:39Z,NONE
15127,OS X ld does not have icf,"awaiting review,cla: yes","when using tflite_linkopts_unstripped() or tflite_linkopts() to build stuff, such as https://github.com/tensorflow/tensorflow/pull/15095, on OS X, identical code folding
flag is not supported.",1,,3,2017-12-05T13:51:53Z,CONTRIBUTOR
15109,Add a setter method variable_scope.auto_reuse_variables() to enable AUTO_REUSE,"awaiting review,cla: yes","Currently we can enable variable reuse in a scope with variable_scope.reuse_variables(). However, there is no handy method to enable auto reuse yet. This PR adds this functionality.",1,,6,2017-12-05T00:55:36Z,CONTRIBUTOR
15098,improve tf.saved_model.loader.load exception,"awaiting review,cla: yes","If the `tags` argument to `tf.saved_model.loader.load` is wrong, the exception does not help.
First: It says use saved_model_cli, but it take a while to figure out that this is a executable and not a python function.
Second: The required information (allowed tags) is known inside `tf.saved_model.loader.load` and now it prints this error
```python
>>> with tf.Session(graph=tf.Graph()) as sess:
>>>    tf.saved_model.loader.load(sess, ['wrong tag'], 'path/to/model')
RuntimeError: MetaGraphDef associated with tags 'wrong tag' could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`available_tags: [{'serve'}]
```",1,,3,2017-12-04T14:21:01Z,CONTRIBUTOR
15092,min_quantize lib and command line,"awaiting review,cla: yes","a quantize/obfuscate lib
1.without Quantize/DeQuantize ops
2.could obfuscate node names
3.use KMeans instead of simple average slice",1,,4,2017-12-04T10:29:19Z,NONE
15090,RNNDROP?,stat:awaiting response,"Has anyone implemented RNNDROP (https://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf) in tensorflow?
According to the paper this method show good performances in speech recognition tasks.",0,,4,2017-12-04T09:12:31Z,NONE
15079,could softmax_cross_entropy_with_logits's  label  has many 1.,stat:contributions welcome,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Mac 10.13.1
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:v1.3.0-rc1-2456-g7abd587 1.4.0-dev20170922
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
```
import numpy as np
import tensorflow as tf

a = np.array([0.0, 1.0, 0.0, 0.0, 0.0, 0.0])
# b = np.array([0.0, 1.0, 0.0, 0.0, 0.0, 0.0])  
b = np.array([0.0, 1.0, 1.0, 0.0, 1.0, 0.0])
sess = tf.Session()
print(str(sess.run(tf.nn.softmax_cross_entropy_with_logits(labels=b, logits=a))))
```
I think it maybe should throw a warn. Because the softmax_cross_entropy_with_logits's labels should not accept the label which has many 1.

If we should fix it. could you let me try to fix it ?I want to try, thanks.
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,14,2017-12-03T15:33:56Z,CONTRIBUTOR
15075,CUDA_ERROR_LAUNCH_FAILED with TensorFlow example,stat:contributions welcome,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, this error happens when using TensorFlow example ""mnist_deep.py"". Modified the file to go for 1.000 iterations instead of the default 20.000 because it took a long time to finish, everything else is the same.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 64-bit
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.3.0-0-g9e76bf3 1.3.0
- **Python version**: Python 3 (Though the issue persists with python 2.7)
- **Bazel version (if compiling from source)**: bazel-0.5.2-dist
- **GCC/Compiler version (if compiling from source)**: GCC 5.4.0 20160609
- **CUDA/cuDNN version**: CUDA: 8.0 cuDNN: 6.0
- **GPU model and memory**: NVIDIA Tegra X2 8GB
- **Exact command to reproduce**: python3 mnist_deep.py

I am using the Nvidia Jetson TX2 developer kit with Jetpack 3.1 (The architecture is aarch64). I have tried installing Tensorflow for Python 2 and 3, but the issue persists with both installations.

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I had no problems installing from source for either Python 2.7 and 3. When executing ""mnist_deep.py"" I get a CUDA_ERROR_LAUNCH_FAILED error. Since I had no problems during install, I believe there is something wrong with communication between Tensorflow and CUDA, which is why I'm posting here.

I had no problems excuting ""mnist_softmax.py"", and so the issue seem to be related to more sophisticated CNNs.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

This is the terminal output:
`nvidia@tegra-ubuntu:~/Desktop/tensorflow-r1.3/tensorflow/examples/tutorials/mnist$ ./mnist_deep.py
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
Saving graph to: /tmp/tmpyJvseo
2017-12-02 00:56:23.092487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:857] ARM64 does not support NUMA - returning NUMA node zero
2017-12-02 00:56:23.092610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: NVIDIA Tegra X2
major: 6 minor: 2 memoryClockRate (GHz) 1.3005
pciBusID 0000:00:00.0
Total memory: 7.67GiB
Free memory: 5.76GiB
2017-12-02 00:56:23.092659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-02 00:56:23.092684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-02 00:56:23.092710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0)
step 0, training accuracy 0.04
step 100, training accuracy 0.86
step 200, training accuracy 0.96
step 300, training accuracy 0.94
step 400, training accuracy 0.86
step 500, training accuracy 0.92
step 600, training accuracy 0.96
step 700, training accuracy 0.96
step 800, training accuracy 0.96
step 900, training accuracy 1
2017-12-02 00:57:17.461035: E tensorflow/stream_executor/cuda/cuda_driver.cc:1068] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.461146: E tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.461188: E tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
Traceback (most recent call last):
  File ""./mnist_deep.py"", line 177, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""./mnist_deep.py"", line 169, in main
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 541, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 4085, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: No algorithm worked!
     [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](reshape/Reshape, conv1/Variable/read)]]
     [[Node: Mean_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_79_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'conv1/Conv2D', defined at:
  File ""./mnist_deep.py"", line 177, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""./mnist_deep.py"", line 138, in main
    y_conv, keep_prob = deepnn(x)
  File ""./mnist_deep.py"", line 64, in deepnn
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File ""./mnist_deep.py"", line 106, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 397, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): No algorithm worked!
     [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](reshape/Reshape, conv1/Variable/read)]]
     [[Node: Mean_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_79_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

2017-12-02 00:57:17.738653: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.738769: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.738800: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.738824: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
nvidia@tegra-ubuntu:~/Desktop/tensorflow-r1.3/tensorflow/examples/tutorials/mnist$`
",0,,6,2017-12-03T10:59:50Z,NONE
15072,Have to reinstall numpy,stat:community support,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.4.0
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Before I installed tensorflow, I have installed numpy through anaconda. But after I run the command provided in the website (https://www.tensorflow.org/install/install_windows), it automatically reinstalled numpy. Then when I import numpy or tensorflow, I got an import error ""cannot import name 'add_newdocs'"" which is required when importing numpy. I have to reinstall my numpy through anaconda to solve this problem. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,2,2017-12-03T06:34:00Z,NONE
15062,Bus Error when running a session,stat:community support,"### System information
- Running on an ODROID-XU4
- Have I written custom code: No
- OS Platform and Distribution: Linux Ubuntu Mate 16.04
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A
- TensorFlow installed from: source
- TensorFlow version: 1.4.0
- Python version: 3.5.2
- Bazel version: 0.8.0
- GCC Version: 5.4.0
- Exact command to reproduce:
python3.5
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow')
sess - tf.Session()
print(sess.run(hello))

### Describe the problem
I have built and installed TensorFlow as a pip package onboard an ODROID-XU4 (32-bit ARM), following the steps in this guide: https://hackernoon.com/running-yolo-on-odroid-yolodroid-5a89481ec141
Everything went smoothly, and I was able to install TensorFlow after a lengthy build time. However, when I try to run any session (such as in the basic example above), the program fails with a Bus Error. Running `pip3 list` shows that Tensorflow is indeed installed, and no errors are thrown when I merely import TensorFlow.

### Source code / logs
I traced the bus error by looking into the /var/log/syslog file and found the following lines associated with the error: `Dec  2 21:24:21 odroid kernel: [ 3658.433306] Alignment trap: python3.5 (10189) PC=0xac0bac42 Instr=0xf9068a1f Address=0xbe8a7da4 FSR 0x811
Dec  2 21:24:21 odroid kernel: [ 3658.433313] Alignment trap: not handling instruction f9068a1f at [<ac0bac42>]
Dec  2 21:24:21 odroid kernel: [ 3658.439021] Unhandled fault: alignment exception (0x811) at 0xbe8a7da4`
So, it appears to be an alignment issue. I tried to force the kernel to attempt to fix the error instead of simply failing by using the following command: `echo 3 > /proc/cpu/alignment`
The three is meant to tell the kernel to fix these alignment issues. However, this strategy has not changed anything about the Bus Error when attempting to run a session. 

Perhaps this is related to the 32-bit architecture I am attempting to run on?
",1,,8,2017-12-02T21:57:41Z,NONE
15061,saved_model.pb needs a different file extension,,'saved_model.pb' file extension type clashes with every other '.pb' file created. Apps that register the '.pb' file extension won't be able to tell apart Saved Models from other protobuf files...,0,,11,2017-12-02T20:52:21Z,NONE
15049,No OpKernel was registered to support Op 'OneHot' with these attrs. Tensorflow1.4,stat:awaiting response,"I have trained and saved a CNN model in python Tensorflow 1.3. 
I can successfully load and run the graph previously saved from my python model in Tensorflow 1.4 using CPU and c++ with no problem; but when I tried to load the same graph using Tensorflow 1.4 using GPU c++ and I get the following error:

`-		status	{state_=unique_ptr {code=INVALID_ARGUMENT (3) msg=""No OpKernel was registered to support Op 'OneHot' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: one_hot = OneHot[T=DT_FLOAT, TI=DT_INT32, _... } }	tensorflow::Status
`

My system:
Windows 10
Cuda 8.0
Cudnn 6
cmake cmake-3.9.4-win64-x64
Python 3.5.2
VS2015
@cuevas1208",0,,9,2017-12-01T21:53:16Z,NONE
15047,no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path,stat:awaiting response,"### System information
- I have not written any of my own code. I downloaded Tensorflow through virtualenv as recommended by tensorflow
- My OS is High Sierra on a macbook pro
- : I am using python 2.7
- **Bazel version Build label: 0.7.0-homebrew:

### I'm following the tensorflow tutorial on how to retrain inception v3, which I have linked here; https://www.tensorflow.org/tutorials/image_retraining

When I input the bazel build tensorflow/examples/image_retraining:retrain  it says there is no build file. How do i get the build file. Im new to tensorflow so if you could put the code in here that would be extremely helpful because I am new to coding and new to github itself

### Source code / logs

bazel build tensorflow/examples/image_retraining:retrain

....................................................................................
ERROR: no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.
INFO: Elapsed time: 2.443s
",0,,5,2017-12-01T20:29:05Z,NONE
15045,"Updated Tensor flow, incompatible function parameters. (Float32>int)",stat:awaiting response,"Hi, 

### System information
Windows 10
TensorFlow installed using pip. 
I am using CDU 
Python 3.6.3 (using Spyder)
TensorFlow version: 1.4.0

Have I written custom code: No
OS Platform and Distribution:
TensorFlow installed from
Bazel version:NA
CUDA/cuDNN version:NA
GPU model and memory: using cpu.
Exact command to reproduce: 
activate myenvrionment
spyder 


This code was written on 0.x tensorFlow, it could be an update issue, but I can't find the outdated function. 

`
    
    from keras import optimizers
    from keras.models import Model
    from keras.layers import Dropout, Lambda
    from keras.layers import Input, average
    from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose
    from keras.layers import ZeroPadding2D, Cropping2D
    from keras import backend as K
    
    
    def mvn(tensor):
        '''Performs per-channel spatial mean-variance normalization.'''
        epsilon = 1e-6
        mean = K.mean(tensor, axis=(1,2), keepdims=True)
        std = K.std(tensor, axis=(1,2), keepdims=True)
        mvn = (tensor - mean) / (std + epsilon)
        
        return mvn
    
    
    def crop(tensors):
        '''
        List of 2 tensors, the second tensor having larger spatial dimensions.
        '''
        h_dims, w_dims = [], []
        for t in tensors:
            b, h, w, d = K.get_variable_shape(t)
            h_dims.append(h)
            w_dims.append(w)
        crop_h, crop_w = (h_dims[1] - h_dims[0]), (w_dims[1] - w_dims[0])
        rem_h = crop_h % 2
        rem_w = crop_w % 2
        crop_h_dims = (crop_h / 2, crop_h / 2 + rem_h)
        crop_w_dims = (crop_w / 2, crop_w / 2 + rem_w)
        cropped = Cropping2D(cropping=(crop_h_dims, crop_w_dims))(tensors[1])
        
        return cropped
    
    
    def dice_coef(y_true, y_pred, smooth=0.0):
        '''Average dice coefficient per batch.'''
        axes = (1,2,3)
        intersection = K.sum(y_true * y_pred, axis=axes)
        summation = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes)
        
        return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)
    
    
    def dice_coef_loss(y_true, y_pred):
        return 1.0 - dice_coef(y_true, y_pred, smooth=10.0)
    
    
    def jaccard_coef(y_true, y_pred, smooth=0.0):
        '''Average jaccard coefficient per batch.'''
        axes = (1,2,3)
        intersection = K.sum(y_true * y_pred, axis=axes)
        union = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes) - intersection
        return K.mean( (intersection + smooth) / (union + smooth), axis=0)
    
    
    def fcn_model(input_shape, num_classes, weights=None):
        ''' ""Skip"" FCN architecture similar to Long et al., 2015
        https://arxiv.org/abs/1411.4038
        '''
        if num_classes == 2:
            num_classes = 1
            loss = dice_coef_loss
            activation = 'sigmoid'
        else:
            loss = 'categorical_crossentropy'
            activation = 'softmax'
    
        kwargs = dict(
            kernel_size=3,
            strides=1,
            activation='relu',
            padding='same',
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None,
            trainable=True,
        )
        
        data = Input(shape=input_shape, dtype='float', name='data')
        mvn0 = Lambda(mvn, name='mvn0')(data)
        pad = ZeroPadding2D(padding=5, name='pad')(mvn0)
    
        conv1 = Conv2D(filters=64, name='conv1', **kwargs)(pad)
        mvn1 = Lambda(mvn, name='mvn1')(conv1)
        
        conv2 = Conv2D(filters=64, name='conv2', **kwargs)(mvn1)
        mvn2 = Lambda(mvn, name='mvn2')(conv2)
    
        conv3 = Conv2D(filters=64, name='conv3', **kwargs)(mvn2)
        mvn3 = Lambda(mvn, name='mvn3')(conv3)
        pool1 = MaxPooling2D(pool_size=3, strides=2,
                        padding='valid', name='pool1')(mvn3)
    
        
        conv4 = Conv2D(filters=128, name='conv4', **kwargs)(pool1)
        mvn4 = Lambda(mvn, name='mvn4')(conv4)
    
        conv5 = Conv2D(filters=128, name='conv5', **kwargs)(mvn4)
        mvn5 = Lambda(mvn, name='mvn5')(conv5)
    
        conv6 = Conv2D(filters=128, name='conv6', **kwargs)(mvn5)
        mvn6 = Lambda(mvn, name='mvn6')(conv6)
    
        conv7 = Conv2D(filters=128, name='conv7', **kwargs)(mvn6)
        mvn7 = Lambda(mvn, name='mvn7')(conv7)
        pool2 = MaxPooling2D(pool_size=3, strides=2,
                        padding='valid', name='pool2')(mvn7)
    
    
        conv8 = Conv2D(filters=256, name='conv8', **kwargs)(pool2)
        mvn8 = Lambda(mvn, name='mvn8')(conv8)
    
        conv9 = Conv2D(filters=256, name='conv9', **kwargs)(mvn8)
        mvn9 = Lambda(mvn, name='mvn9')(conv9)
    
        conv10 = Conv2D(filters=256, name='conv10', **kwargs)(mvn9)
        mvn10 = Lambda(mvn, name='mvn10')(conv10)
    
        conv11 = Conv2D(filters=256, name='conv11', **kwargs)(mvn10)
        mvn11 = Lambda(mvn, name='mvn11')(conv11)
        pool3 = MaxPooling2D(pool_size=3, strides=2,
                        padding='valid', name='pool3')(mvn11)
        drop1 = Dropout(rate=0.5, name='drop1')(pool3)
    
    
        conv12 = Conv2D(filters=512, name='conv12', **kwargs)(drop1)
        mvn12 = Lambda(mvn, name='mvn12')(conv12)
    
        conv13 = Conv2D(filters=512, name='conv13', **kwargs)(mvn12)
        mvn13 = Lambda(mvn, name='mvn13')(conv13)
    
        conv14 = Conv2D(filters=512, name='conv14', **kwargs)(mvn13)
        mvn14 = Lambda(mvn, name='mvn14')(conv14)
    
        conv15 = Conv2D(filters=512, name='conv15', **kwargs)(mvn14)
        mvn15 = Lambda(mvn, name='mvn15')(conv15)
        drop2 = Dropout(rate=0.5, name='drop2')(mvn15)
    
    
        score_conv15 = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='score_conv15')(drop2)
        upsample1 = Conv2DTranspose(filters=num_classes, kernel_size=3,
                            strides=2, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=False,
                            name='upsample1')(score_conv15)
        score_conv11 = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='score_conv11')(mvn11)
        crop1 = Lambda(crop, name='crop1')([upsample1, score_conv11])
        fuse_scores1 = average([crop1, upsample1], name='fuse_scores1')
        
        upsample2 = Conv2DTranspose(filters=num_classes, kernel_size=3,
                            strides=2, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=False,
                            name='upsample2')(fuse_scores1)
        score_conv7 = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='score_conv7')(mvn7)
        crop2 = Lambda(crop, name='crop2')([upsample2, score_conv7])
        fuse_scores2 = average([crop2, upsample2], name='fuse_scores2')
        
        upsample3 = Conv2DTranspose(filters=num_classes, kernel_size=3,
                            strides=2, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=False,
                            name='upsample3')(fuse_scores2)
        crop3 = Lambda(crop, name='crop3')([data, upsample3])
        predictions = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=activation, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='predictions')(crop3)
        
        model = Model(inputs=data, outputs=predictions)
        if weights is not None:
            model.load_weights(weights)
        sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)
        model.compile(optimizer=sgd, loss=loss,
                      metrics=['accuracy', dice_coef, jaccard_coef])
    
        return model
    
    
    if __name__ == '__main__':
        model = fcn_model((100, 100, 1), 2, weights=None)
    

`

# Spyder execution log:
runfile('E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py', wdir='E:/AB/cardiac-segmentation-master/cardiac-segmentation-master')
Using TensorFlow backend.
Traceback (most recent call last):

  File ""<ipython-input-3-d1b60b53383b>"", line 1, in <module>
    runfile('E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py', wdir='E:/AB/cardiac-segmentation-master/cardiac-segmentation-master')

  File ""C:\Users\PC\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 710, in runfile
    execfile(filename, namespace)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 101, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py"", line 197, in <module>
    model = fcn_model((100, 100, 1), 2, weights=None)

  File ""E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py"", line 162, in fcn_model
    crop1 = Lambda(crop, name='crop1')([upsample1, score_conv11])

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\engine\topology.py"", line 603, in __call__
    output = self.call(inputs, **kwargs)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\layers\core.py"", line 651, in call
    return self.function(inputs, **arguments)

  File ""E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py"", line 36, in crop
    cropped = Cropping2D(cropping=(crop_h_dims, crop_w_dims))(tensors[1])

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\engine\topology.py"", line 603, in __call__
    output = self.call(inputs, **kwargs)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\layers\convolutional.py"", line 1874, in call
    self.cropping[1][0]: -self.cropping[1][1],

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 538, in _SliceHelper
    name=name)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 706, in strided_slice
    shrink_axis_mask=shrink_axis_mask)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 5429, in strided_slice
    name=name)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 609, in _apply_op_helper
    param_name=input_name)

  **File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 60, in _SatisfiesTypeConstraint
    "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))

**TypeError: Value passed to parameter 'begin' has DataType float32 not in list of allowed values: int32, int64****


Please help.",0,,4,2017-12-01T18:47:28Z,NONE
15044,rolling window batch operation for tf.data.Dataset,"stat:contributions welcome,type:feature","_This is a feature request_

For Datasets that represent a sequence or time series, it can be useful to have a Dataset op that creates a rolling window batch over the given Dataset. For example, if I have a tf.data.Dataset whose elements represent a time series (line breaks separate elements):
```
1
2
3
4
5
6
7
8
9
```
The rolling window batch would create a dataset with the following elements (for window size 4 and stride 1):
```
1 2 3 4
2 3 4 5
3 4 5 6
4 5 6 7
5 6 7 8
6 7 8 9
```
This operation will be extremely useful for extracting sub sequences from a time series for training RNNs and Reinforcement Learning models.",0,,8,2017-12-01T17:14:14Z,NONE
15041,"Gradient computation occupies too much memories in ""cnn (using while_loop) + lstm"" network",stat:awaiting tensorflower,"### System information
- **Have I written custom code**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 3.6
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: GTX Titan X 12GB
- **Bazel version**: No use 
- **Exact command to reproduce**: using python *.py

### Describe the problem
I'm using while_loop function to build a cnn because of the scale of input tensors. And put the cnn feature into a lstm structure. The problem is that if I only do the forward computatoin it is good, but if I add the backward computation `GradientDescentOptimizer().minimize(loss))` the memory is **significantly insufficient** . 
I tried to split the two part of the model -- cnn and lstm part, and both do well with the whole computation. I think this is the fact:
* Single while_loop cnn net is treated as time distributed when computing gradient. Every temporary feature vector and gradients occupy the same memory location at each time step.
* When coneected with a lstm, the cnn net will be treated as many subnet in computing gradients. At every time step in backward computation, it will occupy new memory for its temporary feature vector and gradients. The number of timesteps is very large so that the memory is significantly not enough.

Here is a simplified code of my project. It will show my cnn+lstm structure:

### Source code
```
import tensorflow as tf
import tensorflow.contrib as contrib

def vgg_m(input_layer, reuse=None):
    # input shape [batch_size, 120, 120, 5]
    with tf.variable_scope('vgg_m', reuse=reuse):
        conv_1 = tf.layers.conv2d(input_layer, 96, [3, 3], padding='same', activation=tf.nn.relu, name='conv_1')
        pool_1 = tf.layers.max_pooling2d(conv_1, 3, 2, padding='same', name='pool_1')
        norm_1 = tf.layers.batch_normalization(pool_1, name='norm_1')

        conv_2 = tf.layers.conv2d(norm_1, 256, [3, 3], padding='same', activation=tf.nn.relu, name='conv_2')
        pool_2 = tf.layers.max_pooling2d(conv_2, 3, 2, padding='same', name='pool_2')
        norm_2 = tf.layers.batch_normalization(pool_2, name='norm_2')

        conv_3 = tf.layers.conv2d(norm_2, 512, [3, 3], padding='same', activation=tf.nn.relu, name='conv_3')

        conv_4 = tf.layers.conv2d(conv_3, 512, [3, 3], padding='same', activation=tf.nn.relu, name='conv_4')

        conv_5 = tf.layers.conv2d(conv_4, 512, [3, 3], padding='same', activation=tf.nn.relu, name='conv_5')
        pool_5 = tf.layers.max_pooling2d(conv_5, 3, 2, padding='same', name='pool_5')

        flatten_6 = contrib.layers.flatten(pool_5)
        fc_6 = tf.layers.dense(flatten_6, 512, name='fc6')

    return fc_6

# [batch, time_step, image_h, image_w, image_channel
input_tensor = tf.random_normal([64, 150, 120, 120, 5], dtype=tf.float32)

# vgg_m is a cnn net whose input and output size is [batch, 120, 120, 5], [batch, 512]
# in order to create vgg_m variables for reuse later.
vgg_m(input_tensor[:, 0, :, :, :])

time_steps = 150
initial_t = tf.constant(0, dtype=tf.int32)
initial_outputs = tf.TensorArray(dtype=tf.float32, size=time_steps)

def _should_continue(t, *args):
    return t < time_steps

def _iteration(t, outputs_):
    # compute cnn feature at time t
    single_output = vgg_m(input_tensor[:, t, :, :, :], reuse=True)
    outputs_ = outputs_.write(t, single_output)
    return t+1, outputs_

_, outputs = tf.while_loop(_should_continue, _iteration, [initial_t, initial_outputs])

# transpose the batch dim and time dim to build a [batch, time_step, 512] feature and send to lstm
outputs = tf.transpose(outputs.stack(), perm=[1, 0, 2])
outputs = tf.reshape(outputs, [-1, 150, 512])

lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(512)
lstm_outputs, lstm_state = tf.nn.dynamic_rnn(
            lstm_cell,
            outputs,
            sequence_length=tf.constant(150, dtype=tf.int32, shape=[64]),
            dtype=tf.float32,
        )

# not really a ""loss"", just perform an loss example
loss = tf.reduce_max(tf.reduce_max(tf.reduce_max(lstm_outputs, -1), -1), -1)
train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run(train_op)
```

### Log
```
2017-12-01 22:44:24.228695: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228717: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228725: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228731: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228736: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:26.620700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:4c:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
2017-12-01 22:44:26.620728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-01 22:44:26.620735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-01 22:44:26.620742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:4c:00.0)
2017-12-01 22:44:29.102674: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-12-01 22:44:29.102971: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-12-01 22:44:29.103146: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 748.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-12-01 22:44:39.103321: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 112.50MiB.  Current allocation summary follows.
2017-12-01 22:44:39.103363: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256):   Total Chunks: 3, Chunks in use: 0 768B allocated for chunks. 20B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103372: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512):   Total Chunks: 1, Chunks in use: 0 512B allocated for chunks. 4B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103379: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024):  Total Chunks: 1, Chunks in use: 0 1.0KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103384: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
...(many Chunks)
2017-12-01 22:44:39.103507: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103514: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103521: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103528: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 112.50MiB was 64.00MiB, Chunk State:
2017-12-01 22:44:39.103536: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x230a3c0000 of size 1280
2017-12-01 22:44:39.103542: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x230a3c0500 of size 256
2017-12-01 22:44:39.103547: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x230a3c0600 of size 512
...(many Chunks)
2017-12-01 22:44:39.104420: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x25cc3c8000 of size 88473600
2017-12-01 22:44:39.104425: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x25d1828000 of size 122539008
2017-12-01 22:44:39.104430: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size:
2017-12-01 22:44:39.104438: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 19 Chunks of size 256 totalling 4.8KiB
...(many Chunks)
2017-12-01 22:44:39.104599: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 245891072 totalling 234.50MiB
2017-12-01 22:44:39.104605: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 268435456 totalling 256.00MiB
2017-12-01 22:44:39.104611: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 353894400 totalling 1.65GiB
2017-12-01 22:44:39.104617: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 405815296 totalling 387.02MiB
2017-12-01 22:44:39.104623: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 513720320 totalling 489.92MiB
2017-12-01 22:44:39.104629: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 4294967296 totalling 4.00GiB
2017-12-01 22:44:39.104635: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 11.22GiB
2017-12-01 22:44:39.104644: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:
Limit:                 12050517197
InUse:                 12049901824
MaxInUse:              12049901824
NumAllocs:                     297
MaxAllocSize:           4294967296

2017-12-01 22:44:39.104660: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ********x************************xxxxxxxxxxx********************************************************
2017-12-01 22:44:39.104678: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,512,30,30]
2017-12-01 22:44:49.104957: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 225.00MiB.  Current allocation summary follows.
2017-12-01 22:44:49.105020: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256):   Total Chunks: 3, Chunks in use: 0 768B allocated for chunks. 20B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:49.105043: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512):   Total Chunks: 1, Chunks in use: 0 512B allocated for chunks. 4B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:49.105063: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024):  Total Chunks: 1, Chunks in use: 0 1.0KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
...(similar chunks)
2017-12-01 22:44:49.107700: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 4294967296 totalling 4.00GiB
2017-12-01 22:44:49.107714: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 11.11GiB
2017-12-01 22:44:49.107731: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:
Limit:                 12050517197
InUse:                 11927362816
MaxInUse:              12049901824
NumAllocs:                     297
MaxAllocSize:           4294967296

2017-12-01 22:44:49.107769: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ********x************************xxxxxxxxxxx*******************************************************_
2017-12-01 22:44:49.107799: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,60,60,256]
2017-12-01 22:44:49.107877: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,512,30,30]
         [[Node: while/vgg_m/conv_4/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](while/vgg_m/conv_3/Relu, while/vgg_m/conv_4/convolution/Enter)]]

....(same thing occuring again and again util it is closed.
```
### Is this an unknown bug
I saw a different processing with `loop_state` in gradients function, so is this an unknown bug with multiple loop operation(lstm contains loop as well)
",0,,5,2017-12-01T14:58:11Z,NONE
15037,"Support ""causal"" padding in tf.layers.convolutional.Conv1D","awaiting review,cla: yes","Because #15000 is closed by mistake, hence the PR is reopened to resolve #14933 issue.

Because we don't see causal padding in other use cases expect of NTC, we choose to modify code at Conv1D, instead of tf.nn.convolution.

Ref: [conv1d implementation](https://github.com/fchollet/keras/blob/d956d19fccf6de6344c282218f1b027453785fa9/keras/backend/tensorflow_backend.py#L3141-3145) in keras.

### How to test

+ [x] add test for layers.Conv1D
+ [x] add test for keras.layers.Conv1D
+ [ ] pass all tests.",0,,6,2017-12-01T11:26:24Z,CONTRIBUTOR
15035,NadamOptimizer does not work with sparse gradients,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.3

Code:
```
import tensorflow as tf
from tensorflow.contrib.opt import NadamOptimizer

optimizer = NadamOptimizer(learning_rate=0.001)
# optimizer = tf.train.AdamOptimizer(learning_rate=0.001)  # this works
w = tf.get_variable(""w"", shape=(100, 10))
idxs = tf.placeholder(tf.int32, shape=(None,))
emb = tf.gather(w, idxs)
loss = tf.reduce_sum(emb ** 2)
minimize = optimizer.minimize(loss)

with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  sess.run(minimize, feed_dict={idxs: [1, 2, 3]})
```

This fails with:
```
...
  File ""/u/zeyer/.local/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/nadam_optimizer.py"", line 83, in _apply_sparse_shared
    m_bar = m_scaled_g_values + beta1_t * m_t
...

InvalidArgumentError (see above for traceback): Incompatible shapes: [3,10] vs. [100,10]
         [[Node: Adam/update_w/add = Add[T=DT_FLOAT, _class=[""loc:@w""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Adam/update_w/mul_1, Adam/update_w/mul_3)]]
```

The bug is pretty obvious in `nadam_optimizer.py`. The fix would be to do it like in `adam.py`:
```
m_t = state_ops.assign(m, m * beta1_t, use_locking=self._use_locking)
with ops.control_dependencies([m_t]):
  m_t = scatter_add(m, indices, m_scaled_g_values)
```

",0,,5,2017-12-01T10:51:58Z,NONE
15034,Optimize graph & graph transform tools do not support NCHW,type:bug/performance,"I tried optimizing graph using both [Graph transform tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md) and [Optimize graph for inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py). Both cases produced the same error because the fused batchnorm used not NCHW, but NHWC. I've got the error like this:

```
InvalidArgumentError (see above for traceback): Must provide as many biases as the channel dimension of the input tensor: [256] vs. 19 in [1,256,19,19]
	 [[Node: prefix/convblock/BatchNorm/FusedBatchNorm = BiasAdd[T=DT_FLOAT, data_format=""NHWC"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefix/convblock/Conv2D, prefix/convblock/Conv2D_bn_offset)]
```

Although NCHW is faster than NHWC in GPU environment, why the tools do not support NCHW?

",1,,5,2017-12-01T10:24:45Z,NONE
15028,ctc_loss with best align path,stat:contributions welcome,"The tf.nn.ctc_loss function only returns negative log probabilities according to truth labels for the sequence's best align path. 
But we also need this best align path in some situations.
Could you please supply this feature, thanks!
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MINGW64_NT-6.1 xsk-PC 2.6.0(0.304/5/3) 2016-09-07 20:45 x86_64 Msys
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6.0
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: None",0,,9,2017-12-01T07:46:49Z,NONE
15017,Update freeze_graph.py,"awaiting review,cla: yes","If there are spaces in multiple parameters, a parameter is not recognized.
ex) ""hypothesis, cost"" (X)  => ""hypothesis,cost"" (O)

So   initializer_nodes.split("","")   =>  initializer_nodes.replace(' ','').split("","")
       variable_names_whitelist.split("","") => variable_names_whitelist.replace(' ','').split("","")
       output_node_names.split("","") => output_node_names.replace(' ','').split("","")",0,,5,2017-11-30T23:57:41Z,NONE
15014,Extend Dataset API to support writing to files (not just reading),stat:awaiting response,"Just as we have a pipeline to read from files and convert them to output vectors/data via some model, It would be very useful to have a pipeline to take data and write it to files.

Otherwise, we have to use TFRecordWriters and a bit more code, but really much of this can be abstracted away, simplifying the data creation process, especially when writing to shards (as one might do using distributed Tensorflow).",0,,4,2017-11-30T23:09:12Z,NONE
15010,feeding_functions._GeneratorFeedFn does not return correct num of batches,,"feeding_functions._GeneratorFeedFn does not return correct #samples in mini batch. It actually returns mini batches with batch_size/key_size (key size is the length of dict yielded by the generator func). 
```python
gff = feeding_functions._GeneratorFeedFn(
    placeholders=placeholders,
    generator=generator_fn, # yields { 'feature_set_1': [] (shape 1x13), 'feature_set_2': [] (shape 1x20) }
    batch_size=32,
    random_start=False,
    seed=None,
    num_epochs=1,
    pad_value=None
)
actual = gff()
for k in actual:
    print(actual[k].shape)
# (16, 1, 13)
# (16, 1, 20)
```
https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/estimator/inputs/queues/feeding_functions.py
`list_dict_size` compared with `self._batch_size` in `_GeneratorFeedFn.__call__`

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, snippet above
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: Code snippet above",0,,6,2017-11-30T21:00:12Z,NONE
15009,Train and release quantized models for other input sizes of mobilenet,type:feature,"Trying to run /tensorflow/examples/image_retraining/retrain.py, getting the following error: 

```
  File ""/home/burjanviktor/DeepLearning/dog_breed/retraining.py"", line 1032, in main
    maybe_download_and_extract(model_info['data_url'])
  File ""/home/burjanviktor/DeepLearning/dog_breed/retraining.py"", line 344, in maybe_download_and_extract
    filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)
... 
  File ""/home/burjanviktor/anaconda3/lib/python3.6/urllib/request.py"", line 650, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 403: Forbidden
```

I am trying to use MobileNet for retraining, but the following url: 

'http://download.tensorflow.org/models/mobilenet_v1_1.0_160_quantized_frozen.tgz'

gives the following error: 

```
<Error>
<Code>AccessDenied</Code>
<Message>Access denied.</Message>
<Details>Anonymous users does not have storage.objects.get access to download.tensorflow.org/models/mobilenet_v1_1.0_160_quantized_frozen.tgz.</Details>
</Error>
```

The 1.0_220 version works, but 1.0_190 does not work also.

Could you advise on this issue please? ",2,,6,2017-11-30T20:28:58Z,NONE
15006,tf.contrib.data: tf-slim training pipeline  raise  GetNext() failed because the iterator has not been initialized.,"stat:awaiting response,type:support","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
```
        dataset = get_dataset()
        iterator = tf.contrib.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)
        train_init_op = iterator.make_initializer(dataset)

        inputs, labels = iterator.get_next()
        prob, end_points = model.nldf(inputs, labels)
        total_loss = tf.losses.get_total_loss()
        optimizer = tf.train.AdamOptimizer(1e-6)
        train_op = slim.learning.create_train_op(
                          total_loss,
                          optimizer,
                          clip_gradient_norm=FLAGS.max_grad_norm)
        def init_fn(sess):
            sess.run(train_init_op)
        slim.learning.train(
                        train_op,
                        FLAGS.checkpoint_dir,
                        init_fn=init_fn,
                        number_of_steps=1000,
                        save_summaries_secs=300,
                        save_interval_secs=600)
```
is going to fail with  

```
FailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,352,352,3], [?,176,176,?]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](Iterator)]]
```

== cat /etc/issue ===============================================
Darwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-serving-api (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.3.0-rc2-20-g0787eee', '1.3.0')

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

`init_fn` of `slim.learning.train` doesn't  init the `tf.contrib.data.Iterator` properly

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

https://github.com/yupbank/NLDF-tf/blob/make-multi-gpu/trainer/multi_gpu_task.py#L148",0,,4,2017-11-30T16:29:39Z,CONTRIBUTOR
15002,fatal error: cuda/include/cuda.h: No such file or directory,type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, I followed the official documentation for custom operations.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

```
Linux pc 4.4.0-81-generic #104-Ubuntu SMP Wed Jun 14 08:17:06 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
```

- **TensorFlow installed from (source or binary)**:
  tried both
- **TensorFlow version (use command below)**:

| version                               | status        | comment |
| -------------                         | ------------- | -----|
| ('v1.2.0-rc1-7529-g8a4d849', '1.4.0') | not working   | from pip or from source |
| ('v1.2.0-rc2-21-g12f033d', '1.2.0')   | working       | from [pypip](https://pypi.python.org/packages/4b/d3/d4fe94f4f370fbb3790444b8f0a007298a795c447e195d88a066de04930d/tensorflow-1.2.0-cp27-cp27mu-manylinux1_x86_64.whl#md5=7e1640384dfd705e17b2f668c1b0427b) |

- **Python version**: 2.7 (*irrelevant*)
- **Bazel version (if compiling from source)**:

```
Build label: 0.6.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Oct 5 21:54:59 2017 (1507240499)
Build timestamp: 1507240499
Build timestamp as int: 1507240499
```

- **GCC/Compiler version (if compiling from source)**: *irrelevant*
  tried both
  - g++4.8
  - g++5.0
- **CUDA/cuDNN version**: *irrelevant*

```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sun_Sep__4_22:14:01_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44
```

- **GPU model and memory**: irrelevant
- **Exact command to reproduce**:

```bash
cd /tmp
mkdir tf_issue
cd tf_issue
virtualenv test
source test/bin/activate
pip install tensorflow # in some way: either tensorflow-gpu or from wheel package created by bazel
git clone https://github.com/cgtuebingen/tf_custom_op
cd tf_custom_op
cmake .
make
```

### Describe the problem
Compiling custom ops with

```cpp
#include ""tensorflow/core/util/cuda_kernel_helper.h""
```

fails due to missing files


```
/code/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h:24:31: fatal error: cuda/include/cuda.h: No such file or directory
```

This file `cuda/include/cuda.h` does not exists! Neither in the pip package nor in the git repository.
Removing `#include ""tensorflow/core/util/cuda_kernel_helper.h""` 

gives plenty of other issues

```
/code/kernels/matrix_add_kernel.cu(13): error: namespace ""tensorflow"" has no member ""CudaLaunchConfig""
/code/kernels/matrix_add_kernel.cu(59): error: namespace ""tensorflow"" has no member ""CudaLaunchConfig""
/code/kernels/matrix_add_kernel.cu(59): error: expected a "";""
/code/kernels/matrix_add_kernel.cu(63): error: identifier ""cfg"" is undefined
/code/kernels/matrix_add_kernel.cu(88): error: namespace ""tensorflow"" has no member ""CudaLaunchConfig""
/code/kernels/matrix_add_kernel.cu(88): error: expected a "";""
/code/kernels/matrix_add_kernel.cu(92): error: identifier ""cfg"" is undefined
```

As I already wrote in a related issue #12860, the commit 2c598e874e6a7b6b3185846ce9bac97a7d5d0169 is causing this issue by changing

```diff
-#include ""third_party/gpus/cuda/include/cuda.h""
+#include ""cuda/include/cuda.h""
```

Copying the old `cuda.h` gives

```
[...]/local/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/platform/default/mutex.h:25:22: fatal error: nsync_cv.h: No such file or directory
```

which does not exist, too.

This problem is not related to custom code, it is related to ignore/omitting files in commit 2c598e874e6a7b6b3185846ce9bac97a7d5d0169

As mention in #12860, this affects many people. In fact, the entire way of writing customs ops with CUDA seems to be broken. Copying own source-code to the TensorFlow-repo was not necessary until TF1.3. Interestingly, even recent NIPS paper implementations state in their readme, they only support TFv1.2. I don't think the proposed workaround of downgrading to TFv1.2 should be the way to go.",2,,22,2017-11-30T13:23:35Z,NONE
14998,Extend reshape with begin_axis and end_axis like in cntk,"stat:contributions welcome,type:feature","------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
CNTK has a generalized version of reshape and it would be nice to have such a version also in Tensorflow
(https://github.com/Microsoft/CNTK/blob/master/bindings/python/cntk/ops/__init__.py#L1972).
```python
def reshape(x, shape, begin_axis=None, end_axis=None, name=''):
    ...
```

The difference is, that the user can provide `begin_axis` and `end_axis` and if they are specified reshape only operate on a subset of the shape.

I can make a PR, when somebody says me, where I have to write the code.

### Source code / logs
Here a working example:
```python
def reshape(tensor, shape, begin_axis=None, end_axis=None, name=None) -> tf.Tensor:
    if begin_axis is None and end_axis is None:
        return tf.reshape(tensor, shape, name=name)

    with tf.name_scope(name, 'reshape', [tensor]):
        tensor_shape = tf.shape(tensor)
        to_concat = [shape]
        if begin_axis is not None:
            bs = tensor_shape[:begin_axis]
            to_concat.insert(0, bs)
        if end_axis is not None:
            es = tensor_shape[end_axis:]
            to_concat.append(es)

        tensor_shape = tf.concat(to_concat, 0)

        return = tf.reshape(tensor, tensor_shape)
```

and an example doctest
```python
    """"""

    Inspired from cntk.reshape to allow begin_axis and end_axis

    Assume you call reshape
    >> out = reshape(in, shape, b, e)
    Than the following will hold
    (Note: If b or e is None, the are interpreted as 0 and/or include the last axis)
    >> in_shape = in.shape
    >> in_shape[b:e] = shape
    >> assert out.shape == in_shape

    First example normal reshape, where the input has unknown dimension
    >>> import numpy as np
    >>> _ = tf.InteractiveSession()
    >>> x = tf.placeholder(tf.float32)
    >>> y = reshape(x, [-1])
    >>> y
    <tf.Tensor 'Reshape:0' shape=(?,) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4])}).shape
    (12,)

    Now keep first and last axis: (No shape inference expected, to difficult)
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape/Reshape:0' shape=<unknown> dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    Now with ndim defined:
    >>> x = tf.placeholder(tf.float32, shape=[None, None, None, None])
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape_1/Reshape:0' shape=(?, ?, ?) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    Now with partial defined shape:
    >>> x = tf.placeholder(tf.float32, shape=[3, 4, None, 6])
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape_2/Reshape:0' shape=(3, ?, 6) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    Now with full defined shape:
    >>> x = tf.placeholder(tf.float32, shape=[3, 4, 5, 6])
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape_3/Reshape:0' shape=(3, 20, 6) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    :param tensor:
    :param shape:
    :param name:
    :return:
    """"""
```
",0,,15,2017-11-30T10:11:22Z,CONTRIBUTOR
14997,Add broadcasting for rank 6 Tensors,"awaiting review,cla: yes","As per @aselle's comment in #14924, this bumps up the broadcasting dimension limit of Tensors from 5 to 6.

I'm making this pull request to make it easy to merge this change if it is wanted; perhaps it is not wanted.",0,,6,2017-11-30T10:02:56Z,NONE
14995,Bug: tf.estimator.Estimator.export_savedmodel does not work with pathlib.Path in py36,stat:awaiting tensorflower,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: 

### Describe the problem
The function `tf.estimator.Estimator.export_savedmodel` does not accept a `pathlib.Path` object, because 
`tensorflow.python.util.compat.as_bytes` used in `tensorflow.python.estimator.export.get_timestamped_export_dir` can not convert `pathlib.Path` to bytes.
Here the code snippet from `tensorflow.python.estimator.export.get_timestamped_export_dir`:
```python
    export_dir = os.path.join(
        compat.as_bytes(export_dir_base),
        compat.as_bytes(str(export_timestamp)))
```
I would write a PR, but I am not sure how to solve this problem in Python2. The following works in Python3.6 (If I remember correctly it was py36, where `os.path` start to accept `pathlib.Path`):

```python
    export_dir = compat.as_bytes(os.path.join(
        export_dir_base,
        str(export_timestamp)))
```
Since the name `tensorflow.python.util.compat.as_bytes` does not imply that the input is a path, I am not sure if that would be a better place to solve the problem.

### Source code / logs
Here some pseudo code (I hope with this example the tensoflowers are able to reproduce this bug in py36): 
```python
from pathlib import Path
tf.estimator.Estimator(...).export_savedmodel(
            Path('path/to/save'),
            export_input_fn,
            as_text=True,
        )
```",0,,6,2017-11-30T08:43:15Z,CONTRIBUTOR
14994,Tensorflow,stat:awaiting response," >>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: cuDevicePrimaryCtxRetain


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
",0,,4,2017-11-30T08:41:25Z,NONE
14993,Using tfdbg with errors.,,"VERSION: TF-1.4.0

Problem:
  I want to use tfdbg to debug NaN problem with `tf_debug.LocalCLIDebugHook()` , but encounter thie problem.
  One more question, how to lower the size of dump files?

Logging is below:
```
Traceback (most recent call last):
  File ""./train.py"", line 166, in <module>
    _, loss, l2_loss, predicted, labels, label_lengths, step = sess.run(ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1032, in run
    run_metadata=run_metadata))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/wrappers/hooks.py"", line 157, in after_run
    self._session_wrapper.on_run_end(on_run_end_request)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py"", line 321, in on_run_end
    self._dump_root, partition_graphs=partition_graphs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 495, in __init__
    self._load_all_device_dumps(partition_graphs, validate)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 517, in _load_all_device_dumps
    self._load_partition_graphs(partition_graphs, validate)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 798, in _load_partition_graphs
    self._validate_dump_with_graphs(debug_graph.device_name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 874, in _validate_dump_with_graphs
    (node, datum.timestamp, repr(pending_inputs[node])))
ValueError: Causality violated in timing relations of debug dumps: model_train/model/model/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge (1512027705071447): these input(s) are not satisfied: [(u'model_train/model/model/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1', 1)]
```

",1,,11,2017-11-30T07:55:04Z,NONE
14986,improvement in the tf.nn.raw_rnn documentation,"awaiting review,cla: yes",PR for #14963. This exposes the advanced use-case of the raw_rnn where the user can project the cell_output into logits as a part of the `loop_fn` computations. Earlier it mislead the users that it is mandatory for the `loop_fn` to return `emit_output` such that it matches the `cell.output_size`.,0,,7,2017-11-30T04:24:09Z,NONE
14980,tensorflow-gpu install from pip breaks conda on windows,type:build/install,"Your instructions for installing tensorflow-gpu on windows often breaks peoples conda installations forcing a complete reinstall. This also forces a rebuilding of previous environments which no longer function.

https://stackoverflow.com/questions/46356732/anaconda-prompt-corrupts-after-installation/46493533#46493533

Some kind of warning or recommendation to check the above thread could really help. This seems like a problem with the tensorflow website instructions as opposed to a tensorflow issue.",1,,10,2017-11-29T20:12:24Z,NONE
14974,Support passing layer instances to produce attentional hidden states,"awaiting review,cla: yes,stat:awaiting tensorflower","This PR closes #14972.
  ",1,,7,2017-11-29T12:53:26Z,CONTRIBUTOR
14972,Support optional activation function to produce attentional hidden states,"stat:awaiting tensorflower,type:feature","*This is a feature request.*

When using an `AttentionWrapper` with the `attention_layer_size` argument set, the cell output and the context are combined and fed through a dense layer to produce an attentional hidden state.

However, it is also common to apply an activation function on this layer output (typically *tanh*). This is for example described in:

> Minh-Thang Luong, Hieu Pham, Christopher D. Manning. ""Effective Approaches to Attention-based Neural Machine Translation."" EMNLP 2015.  https://arxiv.org/abs/1508.04025

I would be happy to contribute. Do we want to add a new argument `attention_layer_activation=None` to the `AttentionWrapper` constructor?",1,,4,2017-11-29T09:46:10Z,CONTRIBUTOR
14964,Has anybody ever written a gradient for the operator 'SparseReduceSumSparse' ?,"stat:community support,type:feature","I could only find a gradient for `SparseReduceSum`.

```
@ops.RegisterGradient(""SparseReduceSum"")
def _SparseReduceSumGrad(op, out_grad):
  """"""Similar to gradient for the Sum Op (i.e. tf.reduce_sum()).""""""
  sp_indices = op.inputs[0]
  sp_shape = op.inputs[2]
  output_shape_kept_dims = math_ops.reduced_shape(sp_shape, op.inputs[3])
  out_grad_reshaped = array_ops.reshape(out_grad, output_shape_kept_dims)
  scale = sp_shape // math_ops.to_int64(output_shape_kept_dims)
  # (sparse_indices, sparse_values, sparse_shape, reduction_axes)
  return (None, array_ops.gather_nd(out_grad_reshaped, sp_indices // scale),
          None, None)
```

It seems uneasy to write a similar gradient for operator `SparseReduceSumSparse`.
Could anyone give me a hand? Thanks.",0,,5,2017-11-29T06:28:35Z,NONE
14963,Documentation of tf.nn.raw_rnn is confusing,stat:contributions welcome,"The documentation for the tf.nn.raw_rnn displays the following line as the pseudocode for the function:
<br>
`(finished, next_input, initial_state, _, loop_state) = loop_fn(
    time=time, cell_output=None, cell_state=None, loop_state=None)`
<br>
This is the first time the loop_fn is called by the raw_rnn interface. Here, the '_' for the emit_output returned by the loop_fn is a **_do not care_** for the function. This misleads the user into believing that returning `None` for the first time as the `emit_output` is OK.

However, the actual code has the line:
<br>
`(elements_finished, next_input, initial_state, emit_structure,
     init_loop_state) = loop_fn(
         time, None, None, None)  # time, cell_output, cell_state, loop_state`
<br>
The code uses the `emit_structure` from the `emit_output` that then determines the shape of the emitted output to be aggregated in the `emit_ta` array. 
So, even for the first time the `loop_fn` needs to output a mock tensor for setting the shape of the output values.

The documentation needs to include this as going through the framework implementation for figuring this out is too tiresome. 

Cheers!",0,,2,2017-11-29T06:08:00Z,NONE
14953,Tensor roll op implementation,"API review,cla: yes","Closes #10761
Added a tf.manip.roll op that works similarly to numpy's np.roll. This was a feature requested in #10761 and was marked as contributions welcome.

### Usage:

Rolls the elements of a tensor by the offsets of `shift` along the dimensions
of `axis`. Elements that roll passed the last position will wrap around
to the first.
For example:
```
# 't' is [0, 1, 2, 3, 4]
roll(t, shift=2, axis=0) ==> [3, 4, 0, 1, 2]
# shifting along multiple dimensions
# 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
roll(t, shift=[1, -2], axis=[0, 1]) ==> [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]
# shifting along the same axis multiple times
# 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
roll(t, shift=[2, -3], axis=[1, 1]) ==> [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]
```
shift: `shift[i]` specifies the number of places by which elements are shifted
  along the dimension specified by `axis[i]`. Negative shifts will roll the
  elements in the opposite direction.
axis: `axis[i]` specifies the dimension that the shift `shift[i]` should occur.
  if the same axis is referenced more than once, the total shift for that axis
  will be the sum of all the shifts that belong to that axis.
output: Has the same shape and size as the input. The elements are shifted by
  the offsets of `shift` along the dimensions of `axis`.

### Unit tests:
```
[==========] Running 24 tests from 1 test case.
[----------] Global test environment set-up.
[----------] 24 tests from RollOpTest
[ RUN      ] RollOpTest.ScalarIndices
[       OK ] RollOpTest.ScalarIndices (5 ms)
[ RUN      ] RollOpTest.ScalarIndices_NoMemcpy
[       OK ] RollOpTest.ScalarIndices_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.ScalarIndices_Complex
[       OK ] RollOpTest.ScalarIndices_Complex (0 ms)
[ RUN      ] RollOpTest.Simple_TwoD32
[       OK ] RollOpTest.Simple_TwoD32 (0 ms)
[ RUN      ] RollOpTest.Simple_TwoD32_NoMemcpy
[       OK ] RollOpTest.Simple_TwoD32_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.Simple_ThreeD32
[       OK ] RollOpTest.Simple_ThreeD32 (1 ms)
[ RUN      ] RollOpTest.Simple_ThreeD32_NoMemcpy
[       OK ] RollOpTest.Simple_ThreeD32_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.Simple_TwoD64
[       OK ] RollOpTest.Simple_TwoD64 (0 ms)
[ RUN      ] RollOpTest.Simple_TwoD64_NoMemcpy
[       OK ] RollOpTest.Simple_TwoD64_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.Simple_ThreeD64
[       OK ] RollOpTest.Simple_ThreeD64 (0 ms)
[ RUN      ] RollOpTest.Simple_ThreeD64_NoMemcpy
[       OK ] RollOpTest.Simple_ThreeD64_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.ZeroShift_ThreeD32
[       OK ] RollOpTest.ZeroShift_ThreeD32 (0 ms)
[ RUN      ] RollOpTest.ZeroShift_ThreeD32_NoMemcpy
[       OK ] RollOpTest.ZeroShift_ThreeD32_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.ZeroSize_ThreeD32
[       OK ] RollOpTest.ZeroSize_ThreeD32 (0 ms)
[ RUN      ] RollOpTest.ZeroSize_ThreeD32_NoMemcpy
[       OK ] RollOpTest.ZeroSize_ThreeD32_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.OneSize_ThreeD32
[       OK ] RollOpTest.OneSize_ThreeD32 (1 ms)
[ RUN      ] RollOpTest.OneSize_ThreeD32_NoMemcpy
[       OK ] RollOpTest.OneSize_ThreeD32_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.DuplicateShifts_TwoD32
[       OK ] RollOpTest.DuplicateShifts_TwoD32 (0 ms)
[ RUN      ] RollOpTest.DuplicateShifts_TwoD32_NoMemcpy
[       OK ] RollOpTest.DuplicateShifts_TwoD32_NoMemcpy (0 ms)
[ RUN      ] RollOpTest.Error_InputMustBeVectorOrHigher
[       OK ] RollOpTest.Error_InputMustBeVectorOrHigher (0 ms)
[ RUN      ] RollOpTest.Error_AxisMustBeScalarOrVector
[       OK ] RollOpTest.Error_AxisMustBeScalarOrVector (0 ms)
[ RUN      ] RollOpTest.Error_ShiftMustBeScalarOrVector
[       OK ] RollOpTest.Error_ShiftMustBeScalarOrVector (0 ms)
[ RUN      ] RollOpTest.Error_ShiftAndAxisMustBeSameSize
[       OK ] RollOpTest.Error_ShiftAndAxisMustBeSameSize (0 ms)
[ RUN      ] RollOpTest.Error_AxisOutOfRange
[       OK ] RollOpTest.Error_AxisOutOfRange (0 ms)
[----------] 24 tests from RollOpTest (7 ms total)

[----------] Global test environment tear-down
[==========] 24 tests from 1 test case ran. (8 ms total)
[  PASSED  ] 24 tests.
```

```
//tensorflow/python/kernel_tests:manip_ops_test                          PASSED in 0.9s
```

### Benchmarks:
```
Running main() from test_main.cc
Benchmark                     Time(ns) Iterations
-------------------------------------------------
BM_cpu_roll_outer/256/256        46739      16065	 5608.7MB/s 1402.2M items/s
BM_cpu_roll_outer/512/512       124247       5135	 8439.5MB/s 2109.9M items/s
BM_cpu_roll_outer/1024/1024     638245       1149	 6571.6MB/s 1642.9M items/s
BM_cpu_roll_outer/2048/2048    5261260        100	 3188.8MB/s 797.2M items/s
BM_cpu_roll_all/256/256         135631       5353	 1932.8MB/s 483.2M items/s
BM_cpu_roll_all/512/512         286927       2263	 3654.5MB/s 913.6M items/s
BM_cpu_roll_all/1024/1024       981417        727	 4273.7MB/s 1068.4M items/s
BM_cpu_roll_all/2048/2048      4549074        149	 3688.1MB/s 922.0M items/s
```

I had made a pull request for this before but accidentally closed it",1,,6,2017-11-28T19:57:27Z,NONE
14950,Incorrect GPU memory usage ,"stat:awaiting tensorflower,type:support","    with tf.device('/gpu:0') :
    	with tf.variable_scope('network1') :
    		x = tf.get_variable('inp1',shape = [256,50,50,3],dtype = tf.float32)
    		w1 = tf.get_variable('weight1',shape = [1,1,3,256],dtype = tf.float32)
    		y1 = tf.nn.conv2d(x, w1, strides=[1, 1, 1, 1], padding='VALID')
    		w1 = tf.get_variable('weight2',shape = [1,1,256,256],dtype = tf.float32)
    		y1 = tf.nn.conv2d(y1, w1, strides=[1, 1, 1, 1], padding='VALID')
    		w1 = tf.get_variable('weight3',shape = [1,1,256,1],dtype = tf.float32)
    		y1 = tf.nn.conv2d(y1, w1, strides=[1, 1, 1, 1], padding='VALID')
    	
    
    with tf.device('/gpu:0') :
    	with tf.variable_scope('network2') :
    		x1 = tf.get_variable('inp2',shape = [1,3],dtype = tf.float32)
    		w2 = tf.get_variable('weight4',shape = [3,8192],dtype = tf.float32)
    		y2 = tf.matmul(x1,w2)
    		w2 = tf.get_variable('weight5',shape = [8192,8192],dtype = tf.float32)
    		y2 = tf.matmul(y2,w2)
    		w2 = tf.get_variable('weight6',shape = [8192,1],dtype = tf.float32)
    		y2 = tf.matmul(y2,w2)

If I have the above model graph, then running it on a GPU and checking memory usage via nvidia-smi shows usage of 4200MB . However when running only the network1 and commenting out network2, nvidia-smi shows usage of 2200 MB. With only network2, it shows usage of 700MB.I have already set gpu_options.allow_growth = True

How is then the total graph using 4200 MB when it should have used only 2900(2200 + 700)MB ?

I am using Ubuntu 14.04, python version - 2.7 , tensorflow version - 1.2",0,,7,2017-11-28T19:06:35Z,NONE
14948,Setup.py on CentOS7 pywrap_tensorflow_internal Error,"stat:community support,type:build/install","System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux CentOS7
TensorFlow installed from (source or binary):
Setup.py
TensorFlow version (use command below):
1.3
Python version:
2.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
4.8.5
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:
import tensorflow as tf
You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

tf_env_collect.sh output:

== cat /etc/issue ===============================================
Linux rs-control1 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-16)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

== uname -a =====================================================
Linux rs-control1 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
File """", line 1, in 
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/init.py"", line 24, in 
from tensorflow.python import *
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/init.py"", line 49, in 
from tensorflow.python import pywrap_tensorflow
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in 
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in 
from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal

Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions. Include the entire stack trace
above this error message when asking for help.

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Installing using setup.py works until trying to import tensorflow, causing an Import Error for pywrap_tensorflow_internal

Dependencies I believe are met and using setup.py because I'm building this into an rpm to deploy to different nodes and clusters.

Source code / logs

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Simply running setup.py and then import tensorflow as tf produces Import Error:
Traceback (most recent call last):
File ""/tmp/check_tf.py"", line 1, in 
import tensorflow as tf;
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/init.py"", line 24, in 
from tensorflow.python import *
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/init.py"", line 49, in 
from tensorflow.python import pywrap_tensorflow
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in 
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in 
from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal",0,,6,2017-11-28T16:53:57Z,NONE
14947,Tensorflow minimize operation runs into shape mismatch with StridedSliceGrad,,"System Info:
   - custom code
   - Linux Ubuntu 16.04
   - Tensorflow 1.4.0 installed with pip install tensorflow-gpu
   - python 2.7
   - CuDa 8
   - terminal command just calls my script with ""python GAN.py""

Source code:

input_points = tf.placeholder(shape=[batch_size, 2048, 3], dtype=tf.float32)
latent_vector = encoder(input_points, encoder_weights, encoder_biases)                       
reconstructed_points = decoder(latent_vector, decoder_weights, decoder_biases)               
                                                                                                 
AE_loss = chamfer_distance(input_points, reconstructed_points, batch_size)                   
                                                                                        
AE_optimizer = tf.train.AdamOptimizer(learning_rate=0.0005, beta1=0.9)                       
AE_minimizer = AE_optimizer.minimize(AE_loss)



Context: The input points and reconstructed points are the same shape. After the call to chamfer_distance(), AE_loss becomes a tf.constant.



Upon calling AE_minimizer, I receive the following error log:
Traceback (most recent call last):
  File ""GAN.py"", line 168, in <module>
    main()
  File ""GAN.py"", line 162, in main
    AE_minimizer = AE_optimizer.minimize(AE_loss, var_list=AE_parameters)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 343, in minimize
    grad_loss=grad_loss)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 414, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 353, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/array_grad.py"", line 245, in _StridedSliceGrad
    shrink_axis_mask=op.get_attr(""shrink_axis_mask"")), None, None, None
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 5572, in strided_slice_grad
    shrink_axis_mask=shrink_axis_mask, name=name)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 546, in _apply_op_helper
    inferred_from[input_arg.type_attr]))
TypeError: Input 'begin' of 'StridedSliceGrad' Op has type int64 that does not match type int32 of argument 'shape'.



I have seen traffic regarding problems with type mismatches with input 'begin', such as in Issue 11380. I have, however, seen nothing online for this specific problem, where the fields 'begin' and 'shape' have different types.",0,,8,2017-11-28T16:17:06Z,NONE
14946,Getting the given error while installing gpu version of tensorflow,"stat:awaiting response,type:build/install","Exception:
Traceback (most recent call last):
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\commands\install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\req\req_set.py"", line 784, in install
    **kwargs
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\req\req_install.py"", line 851, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\req\req_install.py"", line 1064, in move_wheel_files
    isolated=self.isolated,
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\wheel.py"", line 345, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\wheel.py"", line 323, in clobber
    shutil.copyfile(srcfile, destfile)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\shutil.py"", line 121, in copyfile
    with open(dst, 'wb') as fdst:
PermissionError: [Errno 13] Permission denied: 'C:\\Users\\Shivam\\Anaconda2\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\multiarray.cp35-win_amd64.pyd'",0,,8,2017-11-28T14:57:13Z,NONE
14943,Update docker images and documentation to not use nvidia-docker by default.,,"`nvidia-docker` is not used anymore by the [nvidia-docker](https://github.com/NVIDIA/nvidia-docker) project.  Rather `nvidia-docker2` should be used:

```
$ docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi
```",1,,5,2017-11-28T14:21:23Z,NONE
14939,Add complex dtypes support for `tf.squared_difference`,"awaiting review,cla: yes","This fix tries to address the issue raised in #14932 where complex dtypes are not supported for `tf.squared_difference`, which is different from the doc string in `math_ops.cc` (see `BINARY_FEWER`).

This fix adds the `complex64` and `complex128` support in kernel, and adds additional test cases.

This fix fixes #14932.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",0,,1,2017-11-28T13:37:22Z,MEMBER
14937,_dynamic_rnn_loop flat_output_size prevents arbitrary-shaped output tensors,"comp:eager,stat:awaiting response","I want a custom RNN cell to output multiple tensors, each with a different shape. I can handle the logic internally, but I'm running into the issue that `_dynamic_rnn_loop` automatically constructs initial outputs using `flat_output_size = nest.flatten(cell.output_size)`. This is problematic because the flattening prevents me from specifying arbitrary-shapes for my output tensors.

For concreteness, I'd like to output three tensors with shapes (batch size, a), (batch size, b), (batch size, c, d, e). However, both

    @property
    def output_size(self):
        return (a, b, (c, d, e))

and 

    @property
    def output_size(self):
        return (a, b, c, d, e)

fail to create a third tensor with shape (batch size, 210, 160, 3). In the first case, `zero_output` is a tuple of (batch size, a), (batch_size, b), ((batch size, c), (batch size, d), and (batch size, e)). In the second case, the `zero_output` is a tuple of (batch size, a), (batch_size, b), (batch size, c), (batch size, d), and (batch size, e).

I feel that RNN cell outputs should be permitted to be arbitrary shapes. I don't know if this is a desired feature or a bug.

Linux Ubuntu 16.04
TensorFlow versions: ('v1.3.0-rc1-5211-gab0fcac', '1.5.0-dev20171127')",0,,18,2017-11-28T12:50:11Z,NONE
14934,Multi-arch docker images,"stat:awaiting tensorflower,type:build/install","Are there non-x86 (ppc64le, arm etc) docker images available for tensorflow? 

This looks like an intel image : https://hub.docker.com/r/tensorflow/tensorflow/

",1,,4,2017-11-28T11:26:51Z,CONTRIBUTOR
14933,"Support ""causal"" padding in tf.keras.layers.Conv1D by adding support to tf.layers.convolutional.Conv1D",stat:contributions welcome,"TensorFlow version:1.4.0


In the API docs, tf.keras.layers.Conv1D supports ""causal"". However, if I use ""causal"" as the argument of 'padding', there will be an error like this: The 'padding' argument must be one of"" valid "","" same "". Received : causal.

I check the source code, the Conv1D uses the methods in tensorflow.python.layers.convolutional, but the default implementations of tensorflow do not support  ""causal"" as the padding.

(p.s., fchollet/keras uses the conv1d method in tensorflow_backend.py)

",0,,17,2017-11-28T11:01:21Z,CONTRIBUTOR
14932,tf.squared_difference does not work with complex dtypes,"stat:contributions welcome,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, the provided minimal example
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (tensorflow-gpu)
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: GeForce GTX 980 4GB

### Describe the problem

`tf.squared_difference` does not work with complex dtypes `tf.complex64` and `tf.complex128` although the documentation says so: https://www.tensorflow.org/api_docs/python/tf/squared_difference.

### Source code / logs

Minimal (not) working example:

```python
import tensorflow as tf

for dtype in [tf.complex128, tf.complex64]:
    try:
        print(f'*************** {dtype} ***************')
        x = tf.constant(1, dtype=dtype)
        y = tf.constant(2, dtype=dtype)
        result = tf.squared_difference(x, y)

        with tf.Session() as sess:
            sess.run(result)
    except Exception as e:
        print(e)
```

The error output:

```
*************** <dtype: 'complex128'> ***************
2017-11-28 10:33:08.695995: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2017-11-28 10:33:08.836822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785
pciBusID: 0000:04:00.0
totalMemory: 3.94GiB freeMemory: 3.86GiB
2017-11-28 10:33:08.836855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)
No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference = SquaredDifference[T=DT_COMPLEX128](Const, Const_1)]]

Caused by op 'SquaredDifference', defined at:
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/net/home/neumann/workspace/python/tensorflow/tf_speech/tf_speech/complex_squared_difference_example.py"", line 9, in <module>
    res = tf.squared_difference(x, y)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4601, in squared_difference
    ""SquaredDifference"", x=x, y=y, name=name)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference = SquaredDifference[T=DT_COMPLEX128](Const, Const_1)]]

*************** <dtype: 'complex64'> ***************
2017-11-28 10:33:08.858858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)
No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference_1 = SquaredDifference[T=DT_COMPLEX64](Const_2, Const_3)]]

Caused by op 'SquaredDifference_1', defined at:
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/net/home/neumann/workspace/python/tensorflow/tf_speech/tf_speech/complex_squared_difference_example.py"", line 9, in <module>
    res = tf.squared_difference(x, y)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4601, in squared_difference
    ""SquaredDifference"", x=x, y=y, name=name)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference_1 = SquaredDifference[T=DT_COMPLEX64](Const_2, Const_3)]]
```",0,,1,2017-11-28T09:51:31Z,NONE
14928,Variable size multi-label candidate sampling.,"cla: yes,stalled,stat:awaiting response","A fix that adresses the following issue https://github.com/tensorflow/tensorflow/issues/12968.
Makes candidate sampling ops accept a `tensor` instead of an `int` per batch as a `num_true` parameter. Interface change (switching the `.attr` to `.input`). I left out one check in `ComputeAccidentalHits` - `.SetShapeFn()`, and would be open to any suggestion on how to fix that.
",1,,4,2017-11-28T05:10:38Z,CONTRIBUTOR
14924,What is supported by broadcasting? Is the dimensions still limited?,type:feature,"This is related to issue #1519.

This is OK:

```
import tensorflow as tf
sess = tf.InteractiveSession()
xx = tf.constant(1, shape=[32,1,4,4,1], dtype=tf.float32)
yy = tf.constant(1, shape=[1,32,1,4,4], dtype=tf.float32)
zz = xx * yy
sess.run([zz])
```

However:
```
x2 = tf.constant(1, shape=[10,32,1,4,4,1])
y2 = tf.constant(1, shape=[10,1,32,1,4,4])
z2 = x2 * y2
sess.run(z2)
```
Gives an error:
`UnimplementedError (see above for traceback): Broadcast between [10,32,1,4,4,1] and [10,1,32,1,4,4] is not supported yet.
	 [[Node: mul_1 = Mul[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Const_2, Const_3)]]`

Log:
```

---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-2-eef82717f8d8> in <module>()
      2 y2 = tf.constant(1, shape=[10,1,32,1,4,4])
      3 z2 = x2 * y2
----> 4 sess.run(z2)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    887     try:
    888       result = self._run(None, fetches, feed_dict, options_ptr,
--> 889                          run_metadata_ptr)
    890       if run_metadata:
    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1119       results = self._do_run(handle, final_targets, final_fetches,
-> 1120                              feed_dict_tensor, options, run_metadata)
   1121     else:
   1122       results = []

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1315     if handle is None:
   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1317                            options, run_metadata)
   1318     else:
   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1334         except KeyError:
   1335           pass
-> 1336       raise type(e)(node_def, op, message)
   1337 
   1338   def _extend_graph(self):

UnimplementedError: Broadcast between [10,32,1,4,4,1] and [10,1,32,1,4,4] is not supported yet.
	 [[Node: mul_1 = Mul[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Const_2, Const_3)]]

Caused by op u'mul_1', defined at:
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tornado/ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2821, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-eef82717f8d8>"", line 3, in <module>
    z2 = x2 * y2
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 894, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 1117, in _mul_dispatch
    return gen_math_ops._mul(x, y, name=name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 2726, in _mul
    ""Mul"", x=x, y=y, name=name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

UnimplementedError (see above for traceback): Broadcast between [10,32,1,4,4,1] and [10,1,32,1,4,4] is not supported yet.
	 [[Node: mul_1 = Mul[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Const_2, Const_3)]]
```",1,,8,2017-11-27T21:06:06Z,NONE
14920,Fix issue in tf.nn.softmax where negative dims could only be -1,"awaiting review,cla: yes","This fix tries to address the issue raised in #14916 where negative dims could only be -1 in tf.nn.softmax.

The issue was that dims=-1 was handled as a case of ""last dim"" with `is_last_dim = (dim is -1) or (dim == shape.ndims - 1)`, but the generic negative dims were never processed.

This fix adds `dim += shape.ndims` for generic negative dims, and add additional test cases.

This fix fixes #14916.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
",0,,4,2017-11-27T19:41:04Z,MEMBER
14918,This build requires an Android SDK. Please add the android_sdk_repository rule to your WORKSPACE,"comp:lite,type:build/install","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**:  Source
- **TensorFlow version (use command below)**:  Master from November 17 (11eefcd21f9f3d92740cb85d9576198507eeb118)
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc version 5.4.0 20160609
- **CUDA/cuDNN version**: N/A (not trying to build Tensorflow GPU)
- **GPU model and memory**: 
- **Exact command to reproduce**:  `sudo tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`

### Describe the problem
I am trying to run unit tests following the instructions here: https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#running-unit-tests

I have installed Docker and am running: 
`sudo tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`

I receive the following error:
```
ERROR: /home/jovarty/git/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/bazel_tools/tools/android/BUILD:230:1: Executing genrule @bazel_tools//tools/android:no_android_sdk_repository_error failed (Exit 1): bash failed: error executing command
  (cd /home/jovarty/git/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; echo     This build requires an Android SDK. Please add the android_sdk_repository     rule to your WORKSPACE. ;     exit 1 ').
```

After this error I see that no tests were run: `Executed 0 out of 1666 tests: 1666 were skipped.`


Is the Android SDK required when running unit tests? Is this something that should be included in the Dockerfile? (I'm not very familiar with Docker)",1,,7,2017-11-27T18:54:18Z,CONTRIBUTOR
14916,"tf.nn.softmax(input, dim=-1, name=None), argument `dim` cannot take negative index other than -1?","stat:contributions welcome,type:bug/performance","I expect that in the function `tf.nn.softmax(input, dim=-1, name=None)`, the argument `dim` can take dim either positive or negative. However, it seems the only negative index can be taken is -1?

```
import tensorflow as tf

tf.__version__
> '1.4.0'

xx = tf.constant(1, shape=[10, 28, 28, 3], dtype=tf.float32)

tf.nn.softmax(xx, dim=-1)
> <tf.Tensor 'Reshape_1:0' shape=(10, 28, 28, 3) dtype=float32>

tf.nn.softmax(xx, dim=3)
> <tf.Tensor 'Reshape_3:0' shape=(10, 28, 28, 3) dtype=float32>

tf.nn.softmax(xx, dim=-2)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-8-c0dec6c1fa17> in <module>()
----> 1 tf.nn.softmax(xx, dim=-2)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in softmax(logits, dim, name)
   1665       dimension of `logits`.
   1666   """"""
-> 1667   return _softmax(logits, gen_nn_ops._softmax, dim, name)
   1668 
   1669 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in _softmax(logits, compute_op, dim, name)
   1624   # Swap logits' dimension of dim and its last dimension.
   1625   input_rank = array_ops.rank(logits)
-> 1626   logits = _swap_axis(logits, dim, math_ops.subtract(input_rank, 1))
   1627   shape_after_swap = array_ops.shape(logits)
   1628 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in _swap_axis(logits, dim_index, last_index, name)
   1596     return array_ops.transpose(logits,
   1597                                array_ops.concat([
-> 1598                                    math_ops.range(dim_index), [last_index],
   1599                                    math_ops.range(dim_index + 1, last_index),
   1600                                    [dim_index]

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc in range(start, limit, delta, dtype, name)
   1232       delta = cast(delta, inferred_dtype)
   1233 
-> 1234     return gen_math_ops._range(start, limit, delta, name=name)
   1235 
   1236 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc in _range(start, limit, delta, name)
   3257   if _ctx.in_graph_mode():
   3258     _, _, _op = _op_def_lib._apply_op_helper(
-> 3259         ""Range"", start=start, limit=limit, delta=delta, name=name)
   3260     _result = _op.outputs[:]
   3261     _inputs_flat = _op.inputs

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)
    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,
    786                          input_types=input_types, attrs=attr_protos,
--> 787                          op_def=op_def)
    788       return output_structure, op_def.is_stateful, op
    789 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2956         op_def=op_def)
   2957     if compute_shapes:
-> 2958       set_shapes_for_outputs(ret)
   2959     self._add_op(ret)
   2960     self._record_op_seen_by_control_dependencies(ret)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)
   2207       shape_func = _call_cpp_shape_fn_and_require_op
   2208 
-> 2209   shapes = shape_func(op)
   2210   if shapes is None:
   2211     raise RuntimeError(

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in call_with_requiring(op)
   2157 
   2158   def call_with_requiring(op):
-> 2159     return call_cpp_shape_fn(op, require_shape_fn=True)
   2160 
   2161   _call_cpp_shape_fn_and_require_op = call_with_requiring

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc in call_cpp_shape_fn(op, require_shape_fn)
    625     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,
    626                                   input_tensors_as_shapes_needed,
--> 627                                   require_shape_fn)
    628     if not isinstance(res, dict):
    629       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)
    689       missing_shape_fn = True
    690     else:
--> 691       raise ValueError(err.message)
    692 
    693   if missing_shape_fn:

ValueError: Requires start <= limit when delta > 0: 0/-2 for 'range' (op: 'Range') with input shapes: [], [], [] and with computed input tensors: input[0] = <0>, input[1] = <-2>, input[2] = <1>.
```",0,,2,2017-11-27T18:26:25Z,NONE
14898,r1.4 build failed constexpr constructor calls non-constexpr function,"stat:community support,type:build/install","BLUF:
Build fails on OSX.
./tensorflow/core/framework/variant.h(343): error: constexpr constructor calls non-constexpr function ""std::__1::unique_ptr<_Tp, _Dp>::unique_ptr() [with _Tp=tensorflow::Variant::ValueInterface, _Dp=std::__1::default_delete<tensorflow::Variant::ValueInterface>]""

1 error detected in the compilation of ""/var/folders/96/nq247q_92n99r8hkfvlxg_6w0000gn/T//tmpxft_00004cf5_00000000-7_beam_search_ops_gpu.cu.cpp1.ii"".
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: output 'tensorflow/contrib/seq2seq/_objs/python/ops/_beam_search_ops_gpu/tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.pic.o' was not created.
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: not all outputs were created or valid.


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
10.13.1 (17B48)
- **TensorFlow installed from (source or binary)**:
Trying to compile with sources. 
- **TensorFlow version (use command below)**:
r1.4 branch
- **Python version**: 
Python 3.6.3
- **Bazel version (if compiling from source)**:
0.7.0
- **GCC/Compiler version (if compiling from source)**:
Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin17.2.0
Thread model: posix
- **CUDA/cuDNN version**:
CUDA Driver Version: 8.0.61
cuDNN 6 April 2017
- **GPU model and memory**:
NVIDIA GTX TITAN X, 12 GB, DVI, HDMI, 3 DP (3072 CUDA cores)
- **Exact command to reproduce**:
 bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures

### Describe the problem
Failed to build with
./tensorflow/core/framework/variant.h(343): error: constexpr constructor calls non-constexpr function ""std::__1::unique_ptr<_Tp, _Dp>::unique_ptr() [with _Tp=tensorflow::Variant::ValueInterface, _Dp=std::__1::default_delete<tensorflow::Variant::ValueInterface>]""

1 error detected in the compilation of ""/var/folders/96/nq247q_92n99r8hkfvlxg_6w0000gn/T//tmpxft_00004cf5_00000000-7_beam_search_ops_gpu.cu.cpp1.ii"".
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: output 'tensorflow/contrib/seq2seq/_objs/python/ops/_beam_search_ops_gpu/tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.pic.o' was not created.
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: not all outputs were created or valid.
Target //tensorflow/tools/pip_package:build_pip_package failed to build



",0,,11,2017-11-27T03:21:08Z,NONE
14895,Add `tf.unravel_index` as an equivalent of `np.unravel_index`,cla: yes,"This fix tries to address the issue raised in #2075 where there was no implementation of  `tf.unravel_index`.

The `tf.unravel_index` could be quite useful in many places.

This fix adds the `tf.unravel_index` in CPU kernel. Note `order` in `np.unravel_index` has not been added yet.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",0,,4,2017-11-27T01:14:24Z,MEMBER
14886,"avg_pool ignores channel stride dimension, but max_pool does not","stat:contributions welcome,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (conda-tensorflow-gpu)
- **TensorFlow version (use command below)**: `b'unknown' 1.3.0`
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9/7
- **GPU model and memory**: GeForce GTX 1050 Ti
- **Exact command to reproduce**:
```
import tensorflow as tf

x = tf.get_variable('x', shape=(100, 32, 32, 64),
        initializer=tf.constant_initializer(5), dtype=tf.float32)
ksize = (1, 2, 2, 2)
strides = (1, 2, 2, 2)
max_pool = tf.nn.max_pool(x, ksize, strides, padding='SAME')
avg_pool = tf.nn.avg_pool(x, ksize, strides, padding='SAME')
print(max_pool.shape)
print(avg_pool.shape)
``` 

The unexpected output is
```
(100, 16, 16, 32)
(100, 16, 16, 64)
```

It says [here](https://github.com/Hvass-Labs/TensorFlow-Tutorials/issues/19#issuecomment-274249942) that first and last stride dimension must be 1, but apparently it isn't implemented like this. If this is a feature, there should be consistent behaviour and documentation.

Link to StackOverflow question: https://stackoverflow.com/q/47423172/2397253",1,,8,2017-11-26T11:11:25Z,CONTRIBUTOR
14879,Extend estimators.md to cover Keras,stat:contributions welcome,Can you extend the estimators.md tutorial to cover `tf.keras.estimator.model_to_estimator` use case?,0,,11,2017-11-25T14:54:11Z,NONE
14872,Add DT_HALF support for SpaceToDepth on GPU,"awaiting review,cla: yes","This fix tries to address the issue raised in #14871 where there were no DT_HALF support for SpaceToDepth on GPU.

This fix adds DT_HALF support on GPU and adds aditional test cases.

This fix fixes #14871.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",0,,3,2017-11-25T01:40:06Z,MEMBER
14871,SpaceToDepth for DT_HALF is not supported on GPU,"stat:community support,type:bug/performance","space_to_depth can be placed on GPU for float32, but there is no a GPU kernel for float16",0,,1,2017-11-25T00:01:43Z,NONE
14865,Fix bug: divide by zero in embedding_lookup_sparse,"awaiting review,cla: yes,stalled,stat:awaiting response","Fix #14851


### How to test

+ [x] add test case
+ [ ] pass all tests.",1,,20,2017-11-24T13:27:11Z,CONTRIBUTOR
14859,Accuracy drop down after freezing,stat:awaiting tensorflower,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.3.0
Python version: 2.7.12
Bazel version (if compiling from source): 0.5.4
CUDA/cuDNN version: 8.0.61
GPU model and memory: NVIDIA Corporation Device 1b06
Exact command to reproduce:

Evaluate the accuracy of ckeckpoint
```
python eval_image_classifier.py \
    --batch_size=100 \
    --checkpoint_path=.../model.ckpt-100000 \
    --dataset_dir=.../coco_tfrecord \
    --dataset_name=flowers \
    --dataset_split_name=validation \
    --model_name=mobilenet_v1 \
    --eval_dir=/tmp/eval
```

Export slim inference graph
```
python export_inference_graph.py \
--alsologtostderr \
--model_name=mobilenet_v1 \
--dataset_name=flowers \
--is_training=False \
--batch_size=1 \
--image_size=224 \
--output_file=.../mobilenet_v1.pb
```

Freeze checkpoint using slim inference graph
```
bazel-bin/tensorflow/python/tools/freeze_graph \
--input_checkpoint=.../model.ckpt-100000 \
--input_graph=.../mobilenet_v1.pb \
--input_binary=true \
--output_graph=.../frozen_graph.pb \
--output_node_names=MobilenetV1/Predictions/Reshape_1
```

### Describe the problem
I am doing some fine-tune of Mobilenet using the pretrained model.

And I follow the tutorial of slim to freeze and evaluate the performence.

I separate the validation set from train set , evaluate it using checkpoint , and do it again after freezing model , however the evaluation of  the accuracy of frozen model is far away from ckeckpoint's .

Here is some familiar issues , the situations are a little different , but I think it's referable.
#9724 
#12450

@MyHumbleSelf said "" some docs should probably be adjusted "" , means slim tutorial ? Do these problems remain ? 
Where might be wrong ?

Thank you ! ",0,,7,2017-11-24T10:27:16Z,NONE
14857,how can I ues Dataset to shuffle a large  whole dataset?,stat:awaiting response,"I know we can ues dataset.shuffle(buffer=10000) to shuffle dataset.
But I have a large image dataset with 2,325,000 images, if I use the follwing code with 'dataset = dataset.shuffle(buffer_size=2325000) ' ,the cost of time to load images is too long for me.

Is there any way to shuffle the whole dataset in Dataset  API??

```
from tensorflow.contrib import data
def input_pipeline(filenames, batch_size):
    # Define a `tf.contrib.data.Dataset` for iterating over one epoch of the data.
    dataset = data.TextLineDataset(filenames)
    dataset = dataset.map(decode_func)
    dataset = dataset.shuffle(buffer_size=2325000)  # Equivalent to min_after_dequeue=10000.
    dataset = dataset.batch(batch_size)

    # Return an *initializable* iterator over the dataset, which will allow us to
    # re-initialize it at the beginning of each epoch.
    return dataset.make_initializable_iterator() 
```",0,,7,2017-11-24T07:13:57Z,NONE
14853,Automate download and unzip of the model file,"awaiting review,cla: yes","Also added the Exception to the log message when the ImageClassifier fails to initialize. :-)  When the model file is missing the Logcat error is now much more helpful:
```
Failed to initialize an image classifier. java.io.FileNotFoundException: mobilenet_quant_v1_224.tflite
        at android.content.res.AssetManager.openAssetFd(Native Method)
        at android.content.res.AssetManager.openFd(AssetManager.java:329)
        at com.example.android.tflitecamerademo.ImageClassifier.loadModelFile(ImageClassifier.java:137)
```

TESTING

Used Android Studio 3.0.1 and started with a `./gradlew clean`.  I was able to launch on a Samsung S8+ and successfully use the app.

Doing a `./gradlew clean` then a command line build shows the download is happening before the build:
```
$ ./gradlew assemble
<snip>
:app:downloadModel
Downloading https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip
:app:unzipModel
Unzipping build/intermediates/mobilenet_v1_224_android_quant_2017_11_08.zip
:app:preBuild
:app:preDebugBuild
<snip>
:app:assembleRelease UP-TO-DATE
:app:assemble UP-TO-DATE

BUILD SUCCESSFUL
```

Running it a second time does not download the model again:
```
:app:downloadModel UP-TO-DATE
:app:unzipModel UP-TO-DATE
```",0,,5,2017-11-24T04:43:22Z,CONTRIBUTOR
14851,"Got NAN when calling embedding_lookup_sparse with weights and ""mean"" combiner",stat:awaiting response,"### System information
- **OS Platform and Distribution**: Win7 64bit
- **TensorFlow installed from**: anaconda binary
- **TensorFlow version**: 1.2.1
- **Python version**: 3.6

### Describe the problem
I always got nan when I call embedding_lookup_sparse with weights and ""mean"" combiner.
Code pieces are listed below:

### Source code / logs
from __future__ import absolute_import
from __future__ import print_function
import os
import numpy as np
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

a = np.arange(192).reshape(24, 8)
print(a)

a = tf.Variable(a, dtype=tf.float32)
ids = tf.SparseTensor(
    indices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],
    values=[10, 1, 2, 3, 4, 5],
    dense_shape=[1, 1])
weights = tf.SparseTensor(
    indices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],
    values=[1, 0.2, 0.4, 0.4, 1, 1],
    dense_shape=[1, 1])
b = tf.nn.embedding_lookup_sparse(
    a, ids, weights, partition_strategy='mod', combiner='sum')
c = tf.pad(b, [[0, 16 - tf.shape(b)[0]], [0, 0]], mode='CONSTANT')

sess = tf.Session()
sess.run(tf.global_variables_initializer())
[value] = sess.run([c])
print(value)
",0,,11,2017-11-24T03:53:11Z,NONE
14850,Tensorflow v1.4.0 rpc crash,type:support,"I built tensorflow v1.4.0 from source code, sometimes it crashed inside kernel. This happened on both Linux and Windows platform.

Linux call stack:
```
C  [_pywrap_tensorflow_internal.so+0x1117eef]  cc_destroy_call_elem+0xdf
C  [_pywrap_tensorflow_internal.so+0x1138c77]  grpc_call_stack_destroy+0x57
C  [_pywrap_tensorflow_internal.so+0x114b2fc]  grpc_exec_ctx_flush+0x5c
C  [_pywrap_tensorflow_internal.so+0x115d8ad]  grpc_call_unref+0xed
C  [_pywrap_tensorflow_internal.so+0x10fa9ae]  grpc::ClientContext::~ClientContext()+0x1e
C  [_pywrap_tensorflow_internal.so+0x1027e07]  tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::~RPCState()+0x197
C  [_pywrap_tensorflow_internal.so+0x103180e]  tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::OnCompleted(bool)+0x29e
```

Windows call stack:
```
00 00000042`801ef5c0 00007ffa`737e3c67 ucrtbase!abort+0x4e [d:\rs1\minkernel\crts\ucrt\src\appcrt\startup\abort.cpp @ 77]
01 00000042`801ef5f0 00007ffa`737a96d8 _pywrap_tensorflow_internal!tensorflow::Allocator::AllocatedSize+0x227d7
02 00000042`801ef630 00007ffa`737ba61f _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0x10ee8
03 00000042`801ef660 00007ffa`737cc5ac _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0x21e2f
04 00000042`801ef6a0 00007ffa`737a4eb7 _pywrap_tensorflow_internal!tensorflow::Allocator::AllocatedSize+0xb11c
05 00000042`801ef6d0 00007ffa`7379111e _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0xc6c7
06 00000042`801ef740 00007ffa`737964ca _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x1244e
07 00000042`801ef790 00007ffa`73785fb2 _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x177fa
08 00000042`801ef810 00007ffa`72077041 _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x72e2
09 00000042`801ef860 00007ffa`720778b4 _pywrap_tensorflow_internal!tensorflow::GrpcRemoteWorker::RPCState<google::protobuf::Message>::~RPCState<google::protobuf::Message>+0xf1
0a 00000042`801ef8a0 00007ffa`72078803 _pywrap_tensorflow_internal!tensorflow::WorkerInterface::~WorkerInterface+0x574
0b 00000042`801ef8d0 00007ffa`72082cf0 _pywrap_tensorflow_internal!tensorflow::GrpcRemoteWorker::RPCState<google::protobuf::Message>::OnCompleted+0x283
0c 00000042`801efa10 00007ffa`71b8ae25 _pywrap_tensorflow_internal!tensorflow::WorkerCachePartial::~WorkerCachePartial+0xf0
```
Both indicating that tensorflow rpc framework may have some bug.",0,,10,2017-11-24T03:08:47Z,CONTRIBUTOR
14847,Add label_wav_dir.py,"awaiting review,cla: yes","Predicts all wave files in a directory.

```
python tensorflow/examples/speech_commands/label_wav_dir.py \
 --graph=/tmp/my_frozen_graph.pb \
 --labels=/tmp/speech_commands_train/conv_labels.txt \
 --wav_dir=/tmp/speech_dataset/left
```

> 93ec8b84_nohash_0.wav
> no (score = 0.10860)
> go (score = 0.09965)
> on (score = 0.09433)
> 
> a7545b9f_nohash_1.wav
> off (score = 0.10953)
> right (score = 0.10349)
> _unknown_ (score = 0.10015)
> 
> 6272b231_nohash_1.wav
> right (score = 0.10766)
> yes (score = 0.10450)
> left (score = 0.09779)
> 
> 439c84f4_nohash_1.wav
> no (score = 0.11556)
> right (score = 0.10160)
> go (score = 0.09805)
> 
> 2f813234_nohash_1.wav
> no (score = 0.12223)
> go (score = 0.11225)
> on (score = 0.10878)",0,,2,2017-11-24T01:42:31Z,CONTRIBUTOR
14843,Fix crash on closing the app when classifier failed to initialize,"awaiting review,cla: yes","When testing on an API 21 emulator, the classifier fails to initialize.
`E/TfLiteCameraDemo: Failed to initialize an image classifier.`

In this situation, the app crashes when pressing Back to exit.  Here's the cause:
```
java.lang.NullPointerException: Attempt to invoke virtual method 'void com.example.android.tflitecamerademo.ImageClassifier.close()' on a null object reference
                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment.onDestroy(Camera2BasicFragment.java:331)
                                                                                        at android.app.Fragment.performDestroy(Fragment.java:2266)
```
The fix is to check for null before calling `.close()`.

I'll investigate why the classifier is failing to initialize separately. :-)  FTR, the UI does report the error nicely:
![screen shot 2017-11-23 at 12 58 23 pm](https://user-images.githubusercontent.com/739125/33185236-3e6cbb68-d04f-11e7-9deb-c1bf90a46e50.png)
",0,,4,2017-11-23T18:07:43Z,CONTRIBUTOR
14842,Update .gitignore files for Android Studio,"awaiting review,cla: yes","Without these, Git shows lots of noisy build/IDE config files.

These files are based on these two sources (plus the list of added files that Git shows when I build in Android Studio):
https://github.com/github/gitignore/blob/master/Android.gitignore
https://github.com/github/gitignore/pull/2103/files

Tested in Android Studio 3.0 Beta 2.",0,,2,2017-11-23T17:51:31Z,CONTRIBUTOR
14835,"tensorflow_serving build error on Windows, bazel 0.7, tensorflow 1.4",stat:community support,"C:\serving>bazel build //tensorflow_serving/example:mnist_saved_model
ERROR: error loading package 'tensorflow_serving/example': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf_archive//': Traceback (most recent call last):
File ""C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl"", line 119
_apply_patch(repo_ctx, repo_ctx.attr.patch_file)
File ""C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl"", line 111, in _apply_patch
_execute_and_check_ret_code(repo_ctx, cmd)
File ""C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl"", line 92, in _execute_and_check_ret_code
fail(""Non-zero return code({1}) when ...))
Non-zero return code(127) when executing 'C:\msys64\usr\bin\bash.exe -l -c patch -p1 -d C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/protobuf_archive -i C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/third_party/protobuf/add_noinlines.patch':
Stdout:
Stderr: /usr/bin/bash: patch: command not found
.
INFO: Elapsed time: 42.062s",0,,6,2017-11-23T12:32:53Z,NONE
14833,Fix of issue #10479,"cla: yes,stalled,stat:awaiting response",Fixes issue #10479,0,,8,2017-11-23T11:17:33Z,NONE
14807,seg fault training tf.nn.conv3d with minibatch size >2,,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code! You can find it here: https://github.com/NERSC/CosmoFlow/tree/master/SegFault
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: SUSE Linux 12.2
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: ('v1.3.0-rc1-3112-g65b6a75', '1.4.0-rc0') Note this is NOT compiled with the Intel MKL options. 
- **Python version**: 2.7.13 
- **Bazel version (if compiling from source)**: 0.6.0
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A, Running on x86_64 Intel Haswell node
- **Exact command to reproduce**: See README in https://github.com/NERSC/CosmoFlow/tree/master/SegFault


### Describe the problem

A seg fault when training a tf.nn.conv3d with minibatch size more than 2 on a single Intel Haswell. The seg fault occurs at [line 187](https://github.com/NERSC/CosmoFlow/blob/master/SegFault/CosmoNet.py#L187).  

### Source code / logs

GDB log: https://github.com/NERSC/CosmoFlow/blob/master/SegFault/gdbTrace.log
It looks like some kind of cyclic dependency in Eigen::TensorEvaluator. ",0,,8,2017-11-22T20:05:42Z,NONE
14787,TF Lite README.md lacks link to the mentioned mobilenet_v1_224.pb file,"comp:lite,type:docs",https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/README.md,1,,6,2017-11-22T07:35:36Z,CONTRIBUTOR
14784,"Does TF provide C++ interface corresponding to the Python ops ""tensorflow.nn.ctc_greedy_decoder""?",,"As the title, thanksss!",0,,5,2017-11-22T06:51:22Z,NONE
14783,Debugging control flow gradients code,stat:awaiting response,"Hi,

I've been trying to debug some code I have for computing gradients over control flow ops and I've encountered a couple issues:

1. @itsmeolivia The shape check introduced in commit bac56b3 breaks the code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L2466) when creating a backprop indexed slices accumulator. That's because when concatenating the indices in line [2528](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L2528), the shape changes.
2. I have implemented most of the same unit tests and all works well. I also have support for RNNs and things are fine. However, when I implement a decoder that involves a while loop with a cond nested within it, there are cases where I have a problem. More specifically, if I use an existing tensor (created outside the while loop) within a cond branch, I get this error: `Retval[0] does not have value`. I realize this comes from a switch output of a dead branch being used, but can't figure out exactly what's wrong. Note that this only happens when computing gradients and only when I use an existing tensor within a branch. What would be a good way to debug this?
3. More generally, how can I debug error like `Retval[0] does not have value`. No stack trace is provided and I'm not sure how I could configure TensorFlow when compiling to add some debugging information (e.g., stack trace). @asimshankar @skye @alextp Is there some way to setup and run TensorFlow in a debug mode of some sort?

Thanks! :)",0,,14,2017-11-22T05:49:33Z,CONTRIBUTOR
14776,tf.keras.estimator.estimator_from_model does not respect options set in RunConfig,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tf.VERSION = 1.4.0 tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0.61/6.0.21
- **GPU model and memory**: NVIDIA Tesla M60 8 GB
- **Exact command to reproduce**: See Below

### Describe the problem
When trying to use an estimator that is derived from ```tf.keras.estimator.estimator_from_model()``` and training with ```tf.estimator.train_and_evaluate()```, setting ```gpu_options``` in the ```session_config``` of ```tf.estimator.RunConfig``` does not cause the settings to be respected when passed to the estimator_from_model function. For example setting ```per_process_gpu_memory_fraction=0.5``` does not decrease the memory allocated to the process on the GPU, similarly setting ```allow_growth=True``` continues to allocate all of the memory and does not allow memory growth.

I also tested this with the canned estimator ```tf.estimator.DNNRegressor```, and the settings were applied as expected when the RunConfig was passed to the estimator.

Below is code to demonstrate this issue. 

### Source code / logs
Minimal example, runs to completion and trains successfully. But, changing the GPUOptions settings does not cause the GPU memory to be utilized as expected:
```python
import os
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

# Neither of these GPUOptions are respected
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)
#gpu_options = tf.GPUOptions(allow_growth=True)
sess_config = tf.ConfigProto(gpu_options=gpu_options)
run_config = tf.estimator.RunConfig(session_config=sess_config)

inputs = tf.keras.layers.Input(shape=(10,))
outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.models.Model(inputs, outputs)
model.compile(optimizer='sgd', loss='mse')
est_keras = tf.keras.estimator.model_to_estimator(keras_model=model, config=run_config)

input_name = model.input_names[0]
data = np.random.rand(1000,10).astype(np.float32)
train_input_fn = tf.estimator.inputs.numpy_input_fn({input_name:data}, data, batch_size=10, num_epochs=None, shuffle=False)

train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=100000)
eval_spec = tf.estimator.EvalSpec(input_fn=train_input_fn, steps=10)
tf.estimator.train_and_evaluate(est_keras, train_spec, eval_spec)
```",3,,12,2017-11-22T00:35:51Z,NONE
14775,tf.set_random_seed doesn't work after any operations have been constructed,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, just switching the order of this:
```
tf.set_random_seed(1234)
a = tf.random_uniform([1])
b = tf.random_normal([1])
```

to this:

```
a = tf.random_uniform([1])
b = tf.random_normal([1])
tf.set_random_seed(1234)
```

in this example:

https://www.tensorflow.org/api_docs/python/tf/set_random_seed

No longer sets the seed.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:

Binary via pip

- **TensorFlow version (use command below)**:
```
$ python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
v1.3.0-rc2-20-g0787eee 1.3.0
```

- **Python version**: 
```
$ python --version
Python 3.6.1
```

- **Bazel version (if compiling from source)**:
n/a
- **GCC/Compiler version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a

- **Exact command to reproduce**:
`python tf-test.py`

where tf-test is below:




You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

If we would like to deterministically run a tensorflow graph, we want to be able to pass in the seed without rebuilding the graph from scratch (which is slow in our interactive application).

Also, this ordering constraint makes it tricky to debug what's going on and no mention is given to the fact that the seed is read in the op _creation_ not _execution_ in the documentation as far as I can tell.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

As written on example page:

```
$ python tf-test.py 
Session 1
2017-11-21 15:38:24.133822: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-21 15:38:24.133854: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
[ 0.96046877]
[ 0.83621562]
[ 0.4987599]
[ 0.54880583]
Session 2
[ 0.96046877]
[ 0.83621562]
[ 0.4987599]
[ 0.54880583]


```


With `set_random_seed` after:
```
$ python tf-test.py 
Session 1
2017-11-21 15:41:57.602615: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-21 15:41:57.602638: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
[ 0.53137994]
[ 0.32236636]
[ 1.07008374]
[ 0.49122357]
Session 2
[ 0.07862437]
[ 0.18420935]
[ 0.76287955]
[ 0.47924194]
```



Full tf-test.py:

```
import tensorflow as tf

a = tf.random_uniform([1])
b = tf.random_normal([1])

tf.set_random_seed(1234)

# Repeatedly running this block with the same graph will generate the same
# sequences of 'a' and 'b'.
print(""Session 1"")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'

print(""Session 2"")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A1'
  print(sess2.run(a))  # generates 'A2'
  print(sess2.run(b))  # generates 'B1'
  print(sess2.run(b))  # generates 'B2'
```",0,,5,2017-11-21T23:43:47Z,NONE
14772,TFRecordReader keeps files locked after session closes,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:windows 7 64bit
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:-
- **GCC/Compiler version (if compiling from source)**:-
- **CUDA/cuDNN version**:-
- **GPU model and memory**:-
- **Exact command to reproduce**:

Running this script (you need some tfrecords from [here][1]):

```python
import os
import shutil
import sys
import tempfile

import tensorflow as tf

data_dir = r'/path/to/tfrecords'

def test_generate_tfrecords_from_csv():
    with tempfile.TemporaryDirectory() as tmpdirname:
        filenames = os.listdir(data_dir)
        for f in filenames:
            shutil.copy(os.path.join(data_dir, f), os.path.join(tmpdirname, f))
        filenames = sorted([os.path.join(tmpdirname, f) for f in filenames])
        # Create a queue that produces the filenames to read.
        queue = tf.train.string_input_producer(filenames, num_epochs=1,
                                               shuffle=False)
        with tf.Session() as sess:
            sess.run(tf.local_variables_initializer()) # Local !
            tf.train.start_queue_runners(sess=sess)
            reader = tf.TFRecordReader()
            for j in range(len(filenames)):
                key, value = reader.read(queue)
                features_dict = tf.parse_single_example(value, features={
                    'label': tf.FixedLenFeature([], tf.string),})
                # the decode call below is needed, if you replace it with
                # label = tf.constant(0) no files are locked
                label = tf.decode_raw(features_dict['label'], tf.float32)
                _ = sess.run([label]) # files are locked here
        listdir = os.listdir(tmpdirname)
        print(tmpdirname, listdir)
        for f in sorted(listdir):
            os.remove(os.path.join(tmpdirname, f))

print(tf.__version__)
print(sys.version)
test_generate_tfrecords_from_csv()
```


Produces:


```
C:\_\Python35>python.exe C:\Users\MrD\.PyCharm2017.2\config\scratches\so_46259067.py
1.4.0
3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)]
C:\Users\MrD\AppData\Local\Temp\tmp3hqhkgy0 ['img_2013-01-01-00-00.tfrecords', 'img_2013-01-01-00-01.tfrecords', 'img_2013-01-01-00-02.tfrecords']
Traceback (most recent call last):
  File ""C:\Users\MrD\.PyCharm2017.2\config\scratches\so_46259067.py"", line 38, in <module>
    test_generate_tfrecords_from_csv()
  File ""C:\Users\MrD\.PyCharm2017.2\config\scratches\so_46259067.py"", line 34, in test_generate_tfrecords_from_csv
    os.remove(os.path.join(tmpdirname, f))
  File ""C:\_\Python35\lib\tempfile.py"", line 808, in __exit__
    self.cleanup()
  File ""C:\_\Python35\lib\tempfile.py"", line 812, in cleanup
    _shutil.rmtree(self.name)
  File ""C:\_\Python35\lib\shutil.py"", line 488, in rmtree
    return _rmtree_unsafe(path, onerror)
  File ""C:\_\Python35\lib\shutil.py"", line 383, in _rmtree_unsafe
    onerror(os.unlink, fullname, sys.exc_info())
  File ""C:\_\Python35\lib\shutil.py"", line 381, in _rmtree_unsafe
    os.unlink(fullname)
PermissionError: [WinError 5] Access is denied: 'C:\\Users\\MrD\\AppData\\Local\\Temp\\tmp3hqhkgy0\\img_2013-01-01-00-02.tfrecords'
```

(I had also asked at stack overflow [here](https://stackoverflow.com/questions/46259067/tfrecordreader-keeps-files-locked-after-session-closes). Unless I am doing something stupid shouldn't the tfrecord file be free for deleting after the session closes ? Do I have to explicitly close it (is it even possible) ?

The equivalent dataset code has the same issue:

```python
def test_generate_tfrecords_from_csv_dataset():
    with tempfile.TemporaryDirectory() as tmpdirname:
        filenames = os.listdir(data_dir)
        for f in filenames:
            shutil.copy(os.path.join(data_dir, f), os.path.join(tmpdirname, f))
        filenames = sorted([os.path.join(tmpdirname, f) for f in filenames])
        def _parse_rec(value):
            features_dict = tf.parse_single_example(value, features={
                    'label': tf.FixedLenFeature([], tf.string),})
            # return tf.constant(0, tf.float32)  # files are locked all the same
            return tf.decode_raw(features_dict['label'], tf.float32)
        dataset = tf.data.TFRecordDataset(filenames).map(_parse_rec)
        get_next = dataset.make_one_shot_iterator().get_next
        with tf.Session() as sess:
            for j in range(len(filenames)):
                label = get_next()
                _ = sess.run([label]) # files are locked here
        listdir = os.listdir(tmpdirname)
        print(tmpdirname, listdir)
        for f in sorted(listdir):
            os.remove(os.path.join(tmpdirname, f))
```

It seems in both cases it locks the last file - the others are removed ok.

  [1]: https://www.dropbox.com/sh/wrx8pv546rq4iev/AACER-9HbMxE6T3w9hJdieLCa?dl=0",1,,11,2017-11-21T22:32:08Z,NONE
14759,Version 1.4.0 Can't enable peer access between some devices,stat:awaiting response,"
If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7-3
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**:  3.4.5
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.3.0
- **CUDA/cuDNN version**: CUDA 9.0.175 / cuDNN 7.0
- **GPU model and memory**:  10 x GeForce GTX 1080 Ti  12 GB
- **Exact command to reproduce**: 

### Describe the problem
System has 10 GPUs on one pci root hub but Tensorflow can not enable peer access to all devices. Nvidia CUDA-Example 1_Utilities/p2pBandwidthLatencyTest is able to enable these

### Source code / logs
Tensorflow output:
> 2017-11-21 13:58:12.914211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
totalMemory: 10.91GiB freeMemory: 10.72GiB
2017-11-21 13:58:13.249428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:05:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:13.574464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:06:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:13.899631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:07:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:14.219023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 4 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:08:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:14.553864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 5 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0b:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:14.888727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 6 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0c:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.208341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 7 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0d:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.524748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 8 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0e:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.831437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 9 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:0f:00.0
totalMemory: 10.91GiB freeMemory: 10.74GiB
2017-11-21 13:58:15.837982: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 0 and 9
2017-11-21 13:58:15.843596: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 1 and 9
2017-11-21 13:58:15.848661: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 2 and 9
2017-11-21 13:58:15.852889: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 3 and 9
2017-11-21 13:58:15.856213: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 4 and 9
2017-11-21 13:58:15.858748: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 5 and 9
2017-11-21 13:58:15.860537: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 6 and 9
2017-11-21 13:58:15.861548: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 7 and 9
2017-11-21 13:58:15.861791: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 8 and 9
2017-11-21 13:58:15.861915: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 0
2017-11-21 13:58:15.862038: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 1
2017-11-21 13:58:15.862161: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 2
2017-11-21 13:58:15.862283: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 3
2017-11-21 13:58:15.862405: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 4
2017-11-21 13:58:15.862523: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 5
2017-11-21 13:58:15.862642: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 6
2017-11-21 13:58:15.862759: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 7
2017-11-21 13:58:15.862878: W tensorflow/core/common_runtime/gpu/gpu_device.cc:918] Unable to enable peer access between device ordinals 9 and 8
2017-11-21 13:54:16.736201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Device peer to peer matrix
2017-11-21 13:54:16.736590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1051] DMA: 0 1 2 3 4 5 6 7 8 9 
2017-11-21 13:54:16.736598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 0:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 1:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 2:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 3:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 4:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 5:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 6:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 7:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 8:   Y Y Y Y Y Y Y Y Y Y 
2017-11-21 13:54:16.736633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 9:   Y Y Y Y Y Y Y Y Y Y 


Nvidia CUDA P2P Output:

> [P2P (Peer-to-Peer) GPU Bandwidth Latency Test]
Device: 0, GeForce GTX 1080 Ti, pciBusID: 4, pciDeviceID: 0, pciDomainID:0
Device: 1, GeForce GTX 1080 Ti, pciBusID: 5, pciDeviceID: 0, pciDomainID:0
Device: 2, GeForce GTX 1080 Ti, pciBusID: 6, pciDeviceID: 0, pciDomainID:0
Device: 3, GeForce GTX 1080 Ti, pciBusID: 7, pciDeviceID: 0, pciDomainID:0
Device: 4, GeForce GTX 1080 Ti, pciBusID: 8, pciDeviceID: 0, pciDomainID:0
Device: 5, GeForce GTX 1080 Ti, pciBusID: b, pciDeviceID: 0, pciDomainID:0
Device: 6, GeForce GTX 1080 Ti, pciBusID: c, pciDeviceID: 0, pciDomainID:0
Device: 7, GeForce GTX 1080 Ti, pciBusID: d, pciDeviceID: 0, pciDomainID:0
Device: 8, GeForce GTX 1080 Ti, pciBusID: e, pciDeviceID: 0, pciDomainID:0
Device: 9, GeForce GTX 1080 Ti, pciBusID: f, pciDeviceID: 0, pciDomainID:0
Device=0 CAN Access Peer Device=1
Device=0 CAN Access Peer Device=2
Device=0 CAN Access Peer Device=3
Device=0 CAN Access Peer Device=4
Device=0 CAN Access Peer Device=5
Device=0 CAN Access Peer Device=6
Device=0 CAN Access Peer Device=7
Device=0 CAN Access Peer Device=8
Device=0 CAN Access Peer Device=9
Device=1 CAN Access Peer Device=0
Device=1 CAN Access Peer Device=2
Device=1 CAN Access Peer Device=3
Device=1 CAN Access Peer Device=4
Device=1 CAN Access Peer Device=5
Device=1 CAN Access Peer Device=6
Device=1 CAN Access Peer Device=7
Device=1 CAN Access Peer Device=8
Device=1 CAN Access Peer Device=9
Device=2 CAN Access Peer Device=0
Device=2 CAN Access Peer Device=1
Device=2 CAN Access Peer Device=3
Device=2 CAN Access Peer Device=4
Device=2 CAN Access Peer Device=5
Device=2 CAN Access Peer Device=6
Device=2 CAN Access Peer Device=7
Device=2 CAN Access Peer Device=8
Device=2 CAN Access Peer Device=9
Device=3 CAN Access Peer Device=0
Device=3 CAN Access Peer Device=1
Device=3 CAN Access Peer Device=2
Device=3 CAN Access Peer Device=4
Device=3 CAN Access Peer Device=5
Device=3 CAN Access Peer Device=6
Device=3 CAN Access Peer Device=7
Device=3 CAN Access Peer Device=8
Device=3 CAN Access Peer Device=9
Device=4 CAN Access Peer Device=0
Device=4 CAN Access Peer Device=1
Device=4 CAN Access Peer Device=2
Device=4 CAN Access Peer Device=3
Device=4 CAN Access Peer Device=5
Device=4 CAN Access Peer Device=6
Device=4 CAN Access Peer Device=7
Device=4 CAN Access Peer Device=8
Device=4 CAN Access Peer Device=9
Device=5 CAN Access Peer Device=0
Device=5 CAN Access Peer Device=1
Device=5 CAN Access Peer Device=2
Device=5 CAN Access Peer Device=3
Device=5 CAN Access Peer Device=4
Device=5 CAN Access Peer Device=6
Device=5 CAN Access Peer Device=7
Device=5 CAN Access Peer Device=8
Device=5 CAN Access Peer Device=9
Device=6 CAN Access Peer Device=0
Device=6 CAN Access Peer Device=1
Device=6 CAN Access Peer Device=2
Device=6 CAN Access Peer Device=3
Device=6 CAN Access Peer Device=4
Device=6 CAN Access Peer Device=5
Device=6 CAN Access Peer Device=7
Device=6 CAN Access Peer Device=8
Device=6 CAN Access Peer Device=9
Device=7 CAN Access Peer Device=0
Device=7 CAN Access Peer Device=1
Device=7 CAN Access Peer Device=2
Device=7 CAN Access Peer Device=3
Device=7 CAN Access Peer Device=4
Device=7 CAN Access Peer Device=5
Device=7 CAN Access Peer Device=6
Device=7 CAN Access Peer Device=8
Device=7 CAN Access Peer Device=9
Device=8 CAN Access Peer Device=0
Device=8 CAN Access Peer Device=1
Device=8 CAN Access Peer Device=2
Device=8 CAN Access Peer Device=3
Device=8 CAN Access Peer Device=4
Device=8 CAN Access Peer Device=5
Device=8 CAN Access Peer Device=6
Device=8 CAN Access Peer Device=7
Device=8 CAN Access Peer Device=9
Device=9 CAN Access Peer Device=0
Device=9 CAN Access Peer Device=1
Device=9 CAN Access Peer Device=2
Device=9 CAN Access Peer Device=3
Device=9 CAN Access Peer Device=4
Device=9 CAN Access Peer Device=5
Device=9 CAN Access Peer Device=6
Device=9 CAN Access Peer Device=7
Device=9 CAN Access Peer Device=8

Any idea how i can fix it ?
",0,,5,2017-11-21T13:03:10Z,CONTRIBUTOR
14749,Feature Request : Hierarchical Softmax implementation using Tensorflow,stat:contributions welcome,"I am trying to multi-level classify with Hierarchical Softmax by using Tensorflow. But I could find any existing HS implementation in Tensorflow.

Is there any other way to implement HS using tensorflow?

It would be helpful if Hierarchical Softmax support is given in TF.",0,,1,2017-11-21T10:05:43Z,NONE
14744,Quantization: error during quantizing inception v3 model,stat:awaiting response,"Hi experts,

I met issues during quantizing retained inception v3 model. could someone help take a look? Thanks!

**Environment:** tensorflow-1.4.0, python 3.5.2(Anaconda 4.2.0)
**Issue description:**
I am using the downloaded inception v3 model, and try to follow the guide written by @petewarden [,](https://petewarden.com/2016/05/03/how-to-quantize-neural-networks-with-tensorflow/). always met the error below:
```
ValueError: No inputs to quantize for op: name: ""conv/Conv2D""
op: ""Conv2D""
input: ""Mul""
input: ""conv/conv2d_params""
...
```
my python script is as below:
```
from tensorflow.contrib.quantize.python import quantize_graph
from tensorflow import gfile, GraphDef,import_graph_def,get_default_graph

model_file=""classify_image_graph_def.pb""
with gfile.FastGFile(model_file,'rb') as f:
    graph_def = GraphDef()
    graph_def.ParseFromString(f.read())
    import_graph_def(graph_def,name='')

    graph=get_default_graph()
    q_graph=quantize_graph.create_eval_graph(graph)
    with gfile.FastGFile(""output.pb"",'wb') as f1:
        f1.write(q_graph.as_graph_def().SerializeToString())
```

",0,,4,2017-11-21T07:36:48Z,NONE
14732,Eager: Eager execution of tf.data pipelines,"comp:eager,stat:awaiting tensorflower,type:feature","# System information
Tensorflow version:

1.5.0-dev20171120

Python version:

python 3.6.3 |Anaconda, Inc.| (default, Nov  8 2017, 15:10:56) [MSC v.1900 64 bit (AMD64)]

# Problem

When debugging, calling the `numpy()` method on a `Tensor` object results in `AttributeError: 'Tensor' object has no attribute 'numpy' ` in certain situations.

# Steps to reproduce

1.  Put this code in a script:


```
import tensorflow as tf
import tensorflow.contrib.eager as tfe
import numpy as np
import tensorflow as tf
from collections import defaultdict, Counter

tfe.enable_eager_execution()

class_probs = dict(
    a=0.15,
    b=0.3,
    c=0.8,
    d=0.9,
    e=0.2,
    f=0.02
)
num_classes = len(class_probs)

class_probs = {k: v / sum(class_probs.values()) for k, v in class_probs.items()}
class_mapping = {n: i for i, n in enumerate(class_probs.keys())}

class_names = list(class_probs.keys())
class_weights = list(class_probs.values())
sampled_dataset = np.random.choice(class_names, size=1000, p=class_weights)

dataset_data = defaultdict(list)
for i, d in enumerate(sampled_dataset):
    dataset_data['class_name'].append(d)
    dataset_data['class_id'].append(class_mapping[d])
    dataset_data['data'].append(np.array([i]))
    dataset_data['class_prob'].append(class_probs[d])

    dataset_data['class_target_prob'].append(1 / num_classes)

for k, v in dataset_data.items():
    dataset_data[k] = np.array(dataset_data[k])

class_counts = Counter(sampled_dataset)

oversampling_coef = 0.9


def oversample_classes(example):
    """"""
    Returns the number of copies of given example
    """"""
    class_prob = example['class_prob']
    class_target_prob = example['class_target_prob']
    prob_ratio = tf.cast(class_target_prob / class_prob, dtype=tf.float32)

    prob_ratio = prob_ratio ** oversampling_coef

    prob_ratio = tf.maximum(prob_ratio, 1)
    # Breakpoint 1
    repeat_count = tf.floor(prob_ratio)

    repeat_residual = prob_ratio - repeat_count  # a number between 0-1
    residual_acceptance = tf.less_equal(
        tf.random_uniform([], dtype=tf.float32), repeat_residual
    )

    residual_acceptance = tf.cast(residual_acceptance, tf.int64)
    repeat_count = tf.cast(repeat_count, dtype=tf.int64)

    return repeat_count + residual_acceptance


dataset = tf.data.Dataset.from_tensor_slices(dict(dataset_data))

dataset = dataset.flat_map(
    lambda x: tf.data.Dataset.from_tensors(x).repeat(oversample_classes(x))
)

i = tfe.Iterator(dataset)
x = i.next()['class_id']

# Breakpoint 2
print('end')
```

2. Insert the breakpoints in the lines following the comments Breakpoint 1 and Breakpoint 2

3. Debug the script

4. When breakpoint 1 is reached, evaluate the following:
     `prob_ratio.numpy()`
     This will result in the attribute error message.

5. When breakpoint 2 is reached, evaluate the following:
     `x.numpy()`
     This will not result in the attribute error message.",2,,6,2017-11-20T18:09:32Z,NONE
14731,Tensorflow lite - object detection - ssd-mobilenet-v1,"comp:lite,stat:awaiting tensorflower,type:feature","Hi guys,

I have trained a custom ssd-mobilenet-v1 (300x300 input) and currently running it via Tensorflow Android demo (Tensorflow mobile). I would love to convert this model to the lite format and possibly quantize it and run it via Tensorflow Lite to see how much has the performance improved. Currently the inference takes around 400-500ms on Google Pixel (version 1). 

Could you please let me know what's the best way to deploy my custom model for object detection?

Thank you very much in advance!

Martin Peniak ",1,,8,2017-11-20T16:52:11Z,NONE
14729,Unhelpful error for dynamic_rnn in version 1.4.0,stat:contributions welcome,"This code:
```python
import tensorflow as tf

x = tf.constant([
		[[0,0],[5,0],[1,0],[1,0],[2,3],[4,0]],
		[[0,0],[0,0],[1,3],[2,0],[0,0],[0,0]]
	], dtype=tf.int32) #changing this to tf.float32 solves the problem


cell = tf.nn.rnn_cell.LSTMCell(num_units=15) 
initial_state = cell.zero_state(tf.shape(x)[0], dtype=tf.float32)
outputs, state = tf.nn.dynamic_rnn(cell, x, initial_state=initial_state, dtype=tf.float32)

init_op = tf.group(tf.global_variables_initializer(),
		tf.local_variables_initializer())

with tf.Session() as sess:
	sess.run(init_op)
	print(sess.run([outputs, state]))
```
Does not work, because the inputs to the LSTM are integers and they need to be float. However, in version 1.4.0 I get this error:
```
ValueError: Initializer for variable rnn/lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.
```
Which has nothing to do with what is wrong with the code. Version 1.2.0 however, generates this error which correctly refers to the problem:
```
TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match.
```
",0,,5,2017-11-20T16:26:40Z,NONE
14727,New Feature: #12686 Softmaxcrossentropywithlogits gradient function,"cla: yes,stalled,stat:awaiting response",The test case is failing. Submitting a PR for review as I am unable to debug what's wrong with the code. I'll continue debugging but submitting the PR in the interim.,1,,8,2017-11-20T16:10:36Z,NONE
14716,"failed to convert model with ""FusedBatchNorm"" to TFLITE format","comp:lite,stat:awaiting response,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
14.04
- **TensorFlow installed from (source or binary)**:
both source and binary tried
- **TensorFlow version (use command below)**:
1.4
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
7
- **GCC/Compiler version (if compiling from source)**:
4.8
- **CUDA/cuDNN version**:
8.0-5.1
- **GPU model and memory**:
gtx1080-8G
- **Exact command to reproduce**:


###Problem###
My original model is with node ""FusedBatchNorm"", when I run the script  ```bazel build tensorflow/contrib/lite/toco:toco``` and ```bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/home/wz/Desktop/rt-mobilenet.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE --output_file=/home/wz/Desktop/tflite-pose.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=image --output_arrays=Openpose/concat_stage7 --input_shapes=1,368,368,3``` 
Everything seems fine, but the result file is empty. And I traced the code, founding that code returned at file 'resolve_constant_binary' 's function 'EvaluateBinaryOperatorOnConstantInputs'.
My model can be get [here](https://www.dropbox.com/s/09xivpuboecge56/mobilenet_0.75_0.50_model-388003.zip?dl=0).
God help me! Thanks a lot!
",1,,4,2017-11-20T10:45:40Z,NONE
14713,Estimator API and transfer learning/fine-tuning,,"I've been using the Estimator API with the model_fn and input_fn as shown in the official examples (https://github.com/tensorflow/models/blob/master/official/resnet/cifar10_main.py for instance).

This all looks great and wonderful. However, I'm now facing an issue for going further with it. I'd like to use a model trained on a dataset and transfer it to another dataset. In practice, I would like to take the weights from the trained model up to the softmax layer and only initialize randomly this final layer. Then, I can do fine-tuning on the new dataset, which has different labels for instance.

I haven't found a way to do what I want. Is it something missing in the interface? Can we have something  like a variable list to restore from a checkpoint and some other not? Ideally, it would be also good to specify variables to be frozen. Does that all make sense?",0,,19,2017-11-20T10:06:12Z,NONE
14712,cmake error on MacOS,stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.6
- **TensorFlow installed from (source or binary)**: source
- **Python version**: python 3.6.2
- **TensorFlow version**: master
- **Bazel version**: 0.7.0-homebrew. Build timestamp: 1510456291
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)
- **Exact command to reproduce**:
```
# in tensorflow directory
cd tensorflow/contrib/cmake
mkdir build
cd build
cmake .. -DCMAKE_BUILD_TYPE=Release -DPYTHON_EXECUTABLE=/usr/local/bin/python3
make tf_tutorials_example_trainer
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm following the instructions [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md) to build using cmake on Mac. However during make, the following error is thrown.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
# ...
Scanning dependencies of target tf_tutorials_example_trainer
[100%] Building CXX object CMakeFiles/tf_tutorials_example_trainer.dir/Users/kevenwang/VirtualBoxShared/another_tf/tensorflow/cc/tutorials/example_trainer.cc.o
[100%] Linking CXX executable tf_tutorials_example_trainer
Undefined symbols for architecture x86_64:
  ""_ares_cancel"", referenced from:
      on_readable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
      on_writable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_destroy"", referenced from:
      grpc_ares_ev_driver_unref(grpc_ares_ev_driver*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_free_data"", referenced from:
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_txt_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_gethostbyname"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_getsock"", referenced from:
      grpc_ares_notify_on_event_locked(grpc_exec_ctx*, grpc_ares_ev_driver*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_inet_ntop"", referenced from:
      on_hostbyname_done_cb(void*, int, int, hostent*) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_init"", referenced from:
      _grpc_ares_ev_driver_create in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
     (maybe you meant: _grpc_ares_init, _grpc_resolver_dns_ares_init )
  ""_ares_library_cleanup"", referenced from:
      _grpc_ares_cleanup in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_library_init"", referenced from:
      _grpc_ares_init in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_parse_srv_reply"", referenced from:
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_parse_txt_reply_ext"", referenced from:
      on_txt_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_process_fd"", referenced from:
      on_readable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
      on_writable_cb(grpc_exec_ctx*, void*, grpc_error*) in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
  ""_ares_query"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_search"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_set_servers_ports"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
  ""_ares_strerror"", referenced from:
      grpc_dns_lookup_ares_impl(grpc_exec_ctx*, char const*, char const*, char const*, grpc_pollset_set*, grpc_closure*, grpc_lb_addresses**, bool, char**) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      _grpc_ares_init in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_hostbyname_done_cb(void*, int, int, hostent*) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_srv_query_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      on_txt_done_cb(void*, int, int, unsigned char*, int) in libgrpc_unsecure.a(grpc_ares_wrapper.cc.o)
      _grpc_ares_ev_driver_create in libgrpc_unsecure.a(grpc_ares_ev_driver_posix.cc.o)
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[3]: *** [tf_tutorials_example_trainer] Error 1
make[2]: *** [CMakeFiles/tf_tutorials_example_trainer.dir/all] Error 2
make[1]: *** [CMakeFiles/tf_tutorials_example_trainer.dir/rule] Error 2
```",0,,4,2017-11-20T09:10:43Z,CONTRIBUTOR
14703,tf.layers uses wrong variable scope,stat:awaiting tensorflower,"TF 1.4.
```python
import tensorflow as tf
def f(x):
    return tf.layers.conv2d(x, 30, 3)

x = tf.zeros([3, 20, 20, 1])

with tf.variable_scope('a'):
    print(f(x))
with tf.variable_scope('a', reuse=True):
    print(f(x)) # works

print(f(x))
with tf.variable_scope(tf.get_variable_scope(), reuse=True):
    print(f(x)) # failed with:
""""""
ValueError: Variable conv2d_1/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
""""""
```

From what I can see, tf.layers is trying to create the variables under a wrong variable scope name, making variable sharing impossible if used under the root scope.

I found that this works:
```python
with tf.variable_scope(tf.get_variable_scope()):
    print(f(x))
with tf.variable_scope(tf.get_variable_scope(), reuse=True):
    print(f(x)) # works
```
But the first line seems redundant and counter-intuitive.",0,,13,2017-11-19T14:33:03Z,CONTRIBUTOR
14699,"A very strange bug with tf.cond, update_ops and global_step",,"I'm using tf.Estimator with custom model_fn. When training, the estimator usually outputs log like:

INFO:tensorflow:loss = 1109.14, step = 1
INFO:tensorflow:loss = 937.876, step = 101 (6.245 sec)
INFO:tensorflow:loss = 632.192, step = 201 (6.195 sec)

By default, the printed steps should be 1, 101, 201... However, when I use the following function (which is simplified to reproduce the bug) in any place of the model:

```
def my_op(inputs, name=None):
  with tf.variable_scope(name, default_name='my_scope', reuse=False):
    count = tf.get_variable('count', shape=[],
      initializer=tf.zeros_initializer(), trainable=False)

    def myfunc1():
      return 1

    def myfunc2():
      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, count.assign_add(10.0))
      return 1

    tf.cond(tf.less(1, 2), myfunc1, myfunc2)
    return inputs

```

The log becomes something like:

INFO:tensorflow:loss = 1130.58, step = 0
INFO:tensorflow:loss = 940.298, step = 0 (6.352 sec)

The global step is always 0. After some tests, I found that the global step is not updated if myfunc2 is not executed. For example, if I write
`    tf.cond(tf.less(count, 2), myfunc1, myfunc2)`
then the global step is always 1.

I suspect that this is caused by the tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, ...) in myfunc2, in which my intend is to update a variable when some condition holds. Maybe op created inside tf.cond can not be used as a dependency outside, but no error message is reported.

If I cannot add ops to UPDATE_OPS inside tf.cond, does this imply that stateful operations (like tf.layers.batch_normalization) can not be used inside tf.cond? So I cannot dynamically choose a network module from a set of network modules to execute if the network modules use any stateful operations like tf.layers.batch_normalization?

my tensorflow version: ('v1.4.0-rc0-10-g756a7fc', '1.4.0-rc1')",0,,10,2017-11-19T05:21:59Z,NONE
14692,Does 'distributed tensorflow' support Keras training?,stat:awaiting response,"[distributed tensorflow in the official site](https://www.tensorflow.org/deploy/distributed)

Instread of tensorflow model,  is Keras model and training possible?

 If I put the Keras model and training, is it working??
![image](https://user-images.githubusercontent.com/9244296/32982719-3394322e-cccc-11e7-9b58-ea5f326e63ff.png)
I want to know if distributed tensorflow support keras model too.",0,,4,2017-11-18T16:52:40Z,NONE
14690,Added a check for a macro to specify that an ARM device is not mobile,"awaiting review,cla: yes",I've copied the existing mechanism for Raspberry Pi to allow other ARM platforms to be designated as not a mobile platform and thus get the full feature set.,0,,5,2017-11-18T13:02:58Z,NONE
14684,Does SavedModelBuilder save checkpoints ?,,"Does SavedModelBuilder.save() create checkpoint files ? The documentation says this is a wrapper for Saver but doesn't mention checkpoints. It looks like this function doesn't create checkpoints.   

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A",0,,6,2017-11-18T06:38:03Z,NONE
14676,XLA operation semantics documentation BatchNormTrain error,,"Hey! I think there are a few errors in the documentation for the XLA BatchNormTrain operation in https://www.tensorflow.org/performance/xla/operation_semantics#batchnormgrad.

The gradient of the scaling factor `gamma` should be
<a href=""https://www.codecogs.com/eqnedit.php?latex=\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;\frac{(&space;x&space;-&space;\mu&space;)}{&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}}&space;\Big)"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;\frac{(&space;x&space;-&space;\mu&space;)}{&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}}&space;\Big)"" title=""\nabla \gamma = \text{sum}\Big( \nabla y * \frac{( x - \mu )}{ \sqrt{\sigma^2 + \epsilon}} \Big)"" /></a>
instead of 
<a href=""https://www.codecogs.com/eqnedit.php?latex=\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;(&space;x&space;-&space;\mu&space;)&space;*&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}&space;\Big)"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\nabla&space;\gamma&space;=&space;\text{sum}\Big(&space;\nabla&space;y&space;*&space;(&space;x&space;-&space;\mu&space;)&space;*&space;\sqrt{\sigma^2&space;&plus;&space;\epsilon}&space;\Big)"" title=""\nabla \gamma = \text{sum}\Big( \nabla y * ( x - \mu ) * \sqrt{\sigma^2 + \epsilon} \Big)"" /></a>

Moreover, the gradient for the input tensor is also not correct. It should instead read something like this:
<a href=""https://www.codecogs.com/eqnedit.php?latex=\Big(&space;\nabla&space;y&space;-&space;\frac{\hat{x}&space;\times&space;\nabla&space;\gamma&space;&plus;&space;\nabla&space;\beta}{m&space;w&space;h}\Big)&space;\times&space;\frac{\gamma}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\Big(&space;\nabla&space;y&space;-&space;\frac{\hat{x}&space;\times&space;\nabla&space;\gamma&space;&plus;&space;\nabla&space;\beta}{m&space;w&space;h}\Big)&space;\times&space;\frac{\gamma}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" title=""\Big( \nabla y - \frac{\hat{x} \times \nabla \gamma + \nabla \beta}{m w h}\Big) \times \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}}"" /></a>

Where the products and summations are done in a ""broadcasted"" manner when shapes don't match and <a href=""https://www.codecogs.com/eqnedit.php?latex=\hat{x}"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\hat{x}"" title=""\hat{x}"" /></a> is the whitened input tensor. That is:
<a href=""https://www.codecogs.com/eqnedit.php?latex=\hat{x}&space;=&space;\frac{x&space;-&space;\mu}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\hat{x}&space;=&space;\frac{x&space;-&space;\mu}{\sqrt{\sigma^2&space;&plus;&space;\epsilon}}"" title=""\hat{x} = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}"" /></a>


There also seem to be a typo in the table explaining the output of this XLA node. The second row should say `grad_offset` in the first column, `ComputationalDataHandle` in the second column, and the semantics column should say something like `gradient with respect to input offset`.

 
Finally, it may be good if it could be specified that the summation used for the gradients of the scaling and offset tensors is performed over all dimensions that were used to compute the different statistics during normalization.",1,,5,2017-11-18T00:30:18Z,NONE
14675,Small change to graph changes initial values of variables,stat:awaiting tensorflower,"I'm running TensorFlow 1.2 with CUDA.

Error case:
I call ``tf.set_random_seed(2017)`` and then build a graph ``g1`` that includes trainable variables and an optimizer. I create a session, run the ``tf.global_variables_initializer()`` op, and then immediately fetch the value of a scalar variable (without running any train steps, so this is the initial value of the variable). As expected, this value stays the same if I launch this process multiple times.

I then build a graph ``g2`` that is identical to ``g1`` except for a slight change. ``g1`` contained ``mu = tf.reduce_sum(x) / tf.size(x)[0]``, and ``g2`` contains ``mu = tf.reduce_mean(x)``. ``g2`` is seeded the same way as ``g1`` and has the same variable names and shapes as ``g1``. The only differently named tensors are those relating to the modification mentioned above. When I fetch the initial value of the same scalar variable from ``g2``, there is a completely different value from when fetched from ``g1``.

I've tried to isolate this into a small test case but have not been successful yet. I will continue to work on this. Apologies for bug report without test case.
My current intention is to workaround this with a Numpy based initialization scheme.

Questions:
(1) Is this expected behavior? Ideally the variables would be initialized in the same way to help make results more reproducible. In my case, the different variable initialization makes it more difficult to test that ``g1`` and ``g2`` produce the same values. If variables were initialized the same way, would be easy to see that refactoring the mean computation in the graph did not break anything.

(2) Any idea why this occurs? Perhaps relevantly, ``tf.make_template`` is used within this graph. My current (evidence-free) hunch is the small change in graph causes a variable to move from CPU resident to GPU resident and caused a different PRNG kernel (provided with the same seed) to be used.",0,,14,2017-11-17T23:31:21Z,NONE
14670,Tensorflow Lite toco conversion error on SSD fails,"comp:lite,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX 10.12.6
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**: master
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.7.0-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: see below

### Describe the problem
I'm trying to convert a model from the object-detection framework to a tflite file. Here's the command I run:

 bazel run --config=opt tensorflow/contrib/lite/toco:toco -- \
                                                         --input_file=(path)/models/research/object_detection/output_inference_graph/frozen_inference_graph.pb \
                                                         --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \
                                                         --output_file=(pwd)/mobilenet_v1_1.0_224.lite --inference_type=FLOAT \
                                                         --input_type=FLOAT --input_arrays=image_tensor \
                                                         --output_arrays=detection_boxes --input_shapes=1,320,320,3

here's the output:

...
2017-11-17 22:02:12.888007: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: TensorArrayGatherV3
2017-11-17 22:02:12.888037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice
2017-11-17 22:02:12.888065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice
2017-11-17 22:02:12.888077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: LogicalAnd
2017-11-17 22:02:12.888123: F tensorflow/contrib/lite/toco/import_tensorflow.cc:281] Check failed: GetInputsCount(node, model->flags.drop_control_dependency()) == 2 (3 vs. 2)

I freezed the model using the python script from the object detection framework:

python export_inference_graph.py  --input_type image_tensor --pipeline_config_path samples/configs/ssd_mobilenet_v1_coco.config  --trained_checkpoint_prefix ../../../ssd_mobilenet_v1_coco_11_06_2017/model.ckpt  --output_directory output_inference_graph --input_shape 1,320,320,3

Any idea why the conversion fails?
Thanks for any help!",1,,10,2017-11-17T21:16:16Z,NONE
14669,Feature Request | Set keras random state with tensorflow,stat:awaiting tensorflower,Is it possible to set the `random_seed` in `keras` with `tensorflow`?  Would you need to set it to a specific graph? I have not found out how to set the random state in `keras` and if this doesn't exist could this be a feature in future versions? ,0,,6,2017-11-17T21:13:10Z,NONE
14666,feature request in examples/image_retraining/retrain.py,stat:awaiting response,"Hi all, 
This script is working great but please add projector / embedding and images in tensorboard. 
",0,,4,2017-11-17T19:50:48Z,NONE
14663,DropoutWrapper and dynamic_rnn with parallel iterations not reproducible,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: CPU Binary (pip wheel)
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.3 and 3.5.2
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
The following script fails with an assertion error, even though I've explicitly set the random seed:
```python
import tensorflow as tf
import numpy as np

def run():
    tf.reset_default_graph()
    tf.set_random_seed(0)

    sess = tf.Session()
    x = tf.placeholder(tf.float32, [None, None, 1])
    cell = tf.nn.rnn_cell.DropoutWrapper(
        tf.nn.rnn_cell.LSTMCell(100), input_keep_prob=0.5)
    output, state = tf.nn.dynamic_rnn(
        cell, x, dtype=tf.float32, parallel_iterations=100)
    # if parallel_iterations=1, then everything works

    sess.run(tf.global_variables_initializer())
    return sess.run([output, state], {x: np.arange(100).reshape(1, 100, 1)})

o1, (c1, h1) = run()
o2, (c2, h2) = run()
  
assert (o1 == o2).all()
assert (c1 == c2).all()
assert (h1 == h2).all()
```

### Describe the problem
It looks like using parallel iterations options creates some non-determinism when using `DropoutWrapper` (and `parallel_iterations=32` by default). Ideally, when setting the random seed, all TensorFlow operations should be deterministic and reproducible (or the non-determinism should at least be documented).

cc @tudorgt @adamAlnatsheh",0,,10,2017-11-17T19:10:56Z,CONTRIBUTOR
14661,TensorFlowMaximum operator in TF Lite,"comp:lite,stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Docker 
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:


### Describe the problem
I am trying to convert a graph from .pb to .lite format using toco, but I get this error:
`2017-11-17 10:20:47.738777: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: TensorFlowMaximum`

I had a look inside the code, and found `TensorFlowMaximum` operator defined inside `lite/kernels/internal/optimized/optimized_ops.h`, but apparently it's not linked or defined anywhere else.

What's the fastest way to get this defined and linked?

Thanks a lot.
",1,,12,2017-11-17T18:54:23Z,CONTRIBUTOR
14659,Feature request: tf.nn.ctc_loss lacks the API to handle sequences with all blanks,stat:awaiting tensorflower,"It is trivial to calculate the CTC loss of a sequence with all blanks. But tf.nn.ctc_loss cannot handle the situation that one or more sequences in the batch have no non-blank labels. This is a big limitation.   

P.S.: I pulled these requests before:
I reported this previously at
https://github.com/tensorflow/tensorflow/issues/13457
I asked this on stackoverflow
https://stackoverflow.com/questions/46652720/how-to-calculate-ctc-loss-of-a-sequence-with-all-blanks-using-tf-nn-ctc-loss  ",0,,4,2017-11-17T18:09:19Z,NONE
14658,tf.metrics.mean_relative error doesn't handle complex inputs,stat:community support,"The offending line is here: 

https://github.com/tensorflow/tensorflow/blob/9c4bdb865452e418a1d69cd5f5cdccb51d6a0e1d/tensorflow/python/ops/metrics_impl.py#L1057

`array_ops.where` expects the second and third inputs to be of the same shape and **type**. Unfortunately, when the `labels` input is complex, `array_ops.zeros_like(labels)` returns an (unnecessarily) complex tensor, whereas the third input returns a float tensor. 

I haven't checked, but suspect similar problems might occur with other metrics (and perhaps elsewhere). ",0,,2,2017-11-17T17:56:22Z,NONE
14629,Documentation error in attention_wrapper.py,,"In tf.contrib.seq2seq.attention_wrapper.py file, in line 295, it should be [batch_size, 1, max_time], instead of [batch_time, ...], hope to fix it soon!! Thanks !!",0,,6,2017-11-16T17:40:38Z,NONE
14626,[FR] Target for Cortex-M7,"comp:lite,type:feature","With the recent availability of TensorFlow Lite, it seems now possible to target embedded systems other than mobiles. [Cortex-M7](https://developer.arm.com/products/processors/cortex-m/cortex-m7) is the highest performing processor in the Cortex MCU family has ICs from [several](http://www.st.com/en/microcontrollers/stm32-high-performance-mcus.html?querycriteria=productId=SC2154) [big](https://www.microchip.com/design-centers/32-bit/sam-32-bit-mcus/sam-s-mcus) [names](https://www.nxp.com/products/processors-and-microcontrollers/arm-based-processors-and-mcus/kinetis-cortex-m-mcus/v-seriesreal-time-ctlm0-plus-m4-m7/kinetis-kv5x-240-mhz-motor-control-and-power-conversion-ethernet-mcus-based-on-arm-cortex-m7:KV5x). Would it be feasible to get a target for the M7? For those interested in playing around with one, I'd suggest the ST [NUCLEO-F767ZI](http://www.st.com/content/st_com/en/products/evaluation-tools/product-evaluation-tools/mcu-eval-tools/stm32-mcu-eval-tools/stm32-mcu-nucleo/nucleo-f767zi.html) as it is affordable and available (I got one at an event.) Its bigger brother, the [NUCLEO-H743ZI](http://www.st.com/content/st_com/en/products/evaluation-tools/product-evaluation-tools/mcu-eval-tools/stm32-mcu-eval-tools/stm32-mcu-nucleo/nucleo-h743zi.html), doesn't seem to be available just yet.",0,,6,2017-11-16T16:40:26Z,NONE
14625,float16 support for separable_convolutions,"stat:awaiting tensorflower,type:feature","### System information
- **Have I written custom code**:
No
- **OS Platform and Distribution **:
16.04
- **TensorFlow installed from**:
from pip package
- **TensorFlow version**:
1.4.0
- **Python version**: 
3.5.2
- **CUDA/cuDNN version**:
CUDA 8.0, cuDNN 6.0
- **GPU model and memory**:
1080Ti with 12GB Memory
- **Exact command to reproduce**:

It appears that half precision support is still not available for separable_convolutions even with tf 1.4.0 release.

```
inputs_32 = tf.placeholder(tf.float32, shape=(1,16,16,3))
inputs_16 = tf.placeholder(tf.float16, shape=(1,16,16,3))
slim.separable_conv2d(inputs_32,16,[3,3],depth_multiplier=1)
slim.separable_conv2d(inputs_16,16,[3,3],depth_multiplier=1)
```

The first call succeeds (as expected), while the second fails with the following error:
`TypeError: Value passed to parameter 'input' has DataType float16 not in list of allowed values: float32, float64`

I also tried that with tf.nn.separable_conv2d(.), but with same results.

**Full Error Traceback**
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-6-61a1fd560923> in <module>()
----> 1 slim.separable_conv2d(inputs_16,16,[3,3],depth_multiplier=1)

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    179       current_args = current_scope[key_func].copy()
    180       current_args.update(kwargs)
--> 181     return func(*args, **current_args)
    182   _add_op(func)
    183   setattr(func_with_args, '_key_op', _key_op(func))

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py in separable_convolution2d(inputs, num_outputs, kernel_size, depth_multiplier, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)
   2500           _scope=sc,
   2501           _reuse=reuse)
-> 2502       outputs = layer.apply(inputs)
   2503 
   2504       # Add variables to collections.

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)
    669       Output tensor(s).
    670     """"""
--> 671     return self.__call__(inputs, *args, **kwargs)
    672 
    673   def _add_inbound_node(self,

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    573         if in_graph_mode:
    574           self._assert_input_compatibility(inputs)
--> 575         outputs = self.call(inputs, *args, **kwargs)
    576 
    577         if outputs is None:

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py in call(self, inputs)
    982         padding=self.padding.upper(),
    983         rate=self.dilation_rate,
--> 984         data_format=utils.convert_data_format(self.data_format, ndim=4))
    985 
    986     if self.use_bias:

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py in separable_conv2d(input, depthwise_filter, pointwise_filter, strides, padding, rate, name, data_format)
    488         padding=padding,
    489         data_format=data_format,
--> 490         op=op)
    491 
    492     return nn_ops.conv2d(

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py in with_space_to_batch(input, dilation_rate, padding, op, filter_shape, spatial_dims, data_format)
    343                              spatial_dims=spatial_dims,
    344                              data_format=data_format)
--> 345   return new_op(input, None)
    346 
    347 

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)
    497 
    498   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin
--> 499     return self.call(inp, filter)
    500 
    501 

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py in <lambda>(inp, _)
    334 
    335   def build_op(num_spatial_dims, padding):
--> 336     return lambda inp, _: op(inp, num_spatial_dims, padding)
    337 
    338   new_op = _WithSpaceToBatch(input_shape,

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py in op(input_converted, _, padding)
    480           padding=padding,
    481           data_format=data_format,
--> 482           name=""depthwise"")
    483 
    484     depthwise = nn_ops.with_space_to_batch(

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py in depthwise_conv2d_native(input, filter, strides, padding, data_format, name)
   1159     _, _, _op = _op_def_lib._apply_op_helper(
   1160         ""DepthwiseConv2dNative"", input=input, filter=filter, strides=strides,
-> 1161         padding=padding, data_format=data_format, name=name)
   1162     _result = _op.outputs[:]
   1163     _inputs_flat = _op.inputs

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    607               _SatisfiesTypeConstraint(base_type,
    608                                        _Attr(op_def, input_arg.type_attr),
--> 609                                        param_name=input_name)
    610             attrs[input_arg.type_attr] = attr_value
    611             inferred_from[input_arg.type_attr] = input_name

~/.virtualenvs/p3.5-tf1.4/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)
     58           ""allowed values: %s"" %
     59           (param_name, dtypes.as_dtype(dtype).name,
---> 60            "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))
     61 
     62 

TypeError: Value passed to parameter 'input' has DataType float16 not in list of allowed values: float32, float64
```

",0,,6,2017-11-16T16:26:34Z,NONE
14623,[BUG] tf.while_loop creates a seg-fault when setting parallel_iterations to high values,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: both
- **TensorFlow version (use command below)**: 1.3 / 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8
- **GPU model and memory**: Tesla P100-PCIE-16GB
- **Exact command to reproduce**:
### Describe the problem

The following code crashes on all of my test systems, with tensorflow 1.3 or 1.4.
Doesn't matter if build with MKL or without or using the pip-version.
```
import numpy as np
import tensorflow as tf

num_dim = 20
FORMAT = tf.float64 #32 or 64 does not matter
n = 3500 #reducing the number results in normal execution

def simpeLoop(alpha):
      i = tf.constant(0)
      m0 = tf.zeros([num_dim, 1], dtype=FORMAT)
      cond = lambda i, m: i < n
      def body(ic, vec): 
            #a meaningless example, summing up the first num_dim elements of a vector 
            op = alpha[ic * num_dim:(ic + 1) * num_dim, :]
            # with tf.control_dependencies([op]): #if you uncomment this, it will not fault!
            return ic + 1, vec + op
      loop = tf.while_loop(cond, body, [i, m0], parallel_iterations=10**4, back_prop=False)
      return loop[1]

with tf.device('/cpu:0'):
      alpha = tf.placeholder(FORMAT, [None, 1], name=""alpha"")
      fdict = {
          alpha: np.random.rand(n * num_dim, 1),
      }
      op = simpeLoop(alpha)
      op = tf.reduce_sum(op) #not necessary for the seg fault
      init = tf.global_variables_initializer()

config = tf.ConfigProto()
threads = 1
config.intra_op_parallelism_threads = threads
config.inter_op_parallelism_threads = threads
sess = tf.Session(config=config)
sess.run(init, feed_dict=fdict)
print(""init"")
print(sess.run(op, feed_dict=fdict))
```
Adding the control_dependencies results in normal execution.

The documentation states 

> The maximum number of parallel iterations can be controlled by parallel_iterations, which gives users some control over memory consumption and execution order

so I would expect parallel_iterations to be some kind of upper bound. 
Small tests like presented in  #12937 showed that increasing the parallel_iterations number results in higher performance. But setting it to high results in a seg fault.
 



",0,,4,2017-11-16T14:45:07Z,NONE
14617,ValueError: graph_def is invalid at node u'decode/DecodeJpeg': Input tensor 'image_feed:0' Cannot convert a tensor of type float32 to an input of type string.,stat:awaiting response,"when i try to quantize the graph after optimize, i get the error 
ValueError: graph_def is invalid at node u'decode/DecodeJpeg': Input tensor 'image_feed:0' Cannot convert a tensor of type float32 to an input of type string.

python ./tensorflow/tools/quantization/quantize_graph.py \
--input=/Users/jie/tensorflow/models/models/im2txt/im2txt/model/train/optimize_graph.pb \
--output=/Users/jie/tensorflow/models/models/im2txt/im2txt/model/train/rounded_graph.pb \
--output_node_names=lstm/initial_state,softmax,lstm/state \
--mode=weights_rounded 



",0,,5,2017-11-16T09:10:20Z,NONE
14615,"For Android, Tensorflow Lite  C++ interface and static library","comp:lite,stat:awaiting response,type:support","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**: master latest
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.7

### Describe the problem
For Android, Tensorflow Lite currently only supports Java interface calls, how do I use the C++ interface and static library? have any reference materials or guidance ? @aselle @petewarden
",0,,5,2017-11-16T07:49:54Z,NONE
14613,tf.data.Iterator.from_string_handle() breaking behaviour in r1.4 compared to r1.3.1,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: +
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Python 3.5.2
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04
- **GPU model and memory**: NVIDIA® Tesla® K80 (GCE)
- **Exact command to reproduce**:

### Context:
Same setup/context as in the previous issue https://github.com/tensorflow/tensorflow/issues/12859 including this fix https://github.com/tensorflow/tensorflow/issues/12859#issuecomment-327783827.
In addition the training is now in a Multi-task Learning mode, so feedable contrib Iterator was used to accommodate different datasets for each task.
Simplified snippet:
~~~python
        self.handle = tf.placeholder(tf.string, shape=[])

        ...

        # targets -> Multi-task training targets.
        # datasets -> dict of Multi-task target tf.Datasets.
        for target in self.targets:
            self.datasets[target] = self.create_TFDataset()

        self.iterator = tf.contrib.data.Iterator.from_string_handle(
            self.handle,
            self.datasets[targets[-1]].output_types,
            self.datasets[targets[-1]].output_shapes)

        # iter_init_ops and iter_handles -> init_ops & handles per each task.
        for target in self.targets:
            self.iterators[target] = self.datasets[target].make_initializable_iterator()
            self.iter_init_ops[target] = self.iterators[target].initializer
            self.iter_handles[target] = self.iterators[target].string_handle()

        ...
        # Within tf.train.MonitoredTrainingSession as mon_sess.
        for target in targets:
            # Get all target datasets handles.
            handle[target] = mon_sess._coordinated_creator.tf_sess.run(
                training_model.iter_handles[target])
            # Init all target datasets.
            mon_sess._coordinated_creator.tf_sess.run(training_model.iter_init_ops[target])

        ...
        # Training step for a specific target.
        input_feed = {self.handle:handle[target]}
        output_feed = [
            self.update_ops[target],
            self.losses[target], 
            self.metrics[target],
        ]
        outputs = session.run(output_feed, input_feed, options=options,
                                             run_metadata=run_metadata)
~~~
### Problem:
This system worked flawlessly for tf 1.3 & tf 1.3.1. 
After a planned update this week to tf 1.4 the following Error would appear at absolute random (it might appear after 5 seconds or after a few hours of training):
~~~console
...
W tensorflow/core/framework/op_kernel.cc:1192] Unavailable: Endpoint read failed
	 [[Node: Model/Generate_BiRNN/BiRNN_Logic/bidirectional_rnn/fw/carry_w_S543 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:ps/replica:0/task:1/device:CPU:0"", send_device_incarnation=-458934800929363750, tensor_name=""edge_9_Model/Generate_BiRNN/BiRNN_Logic/bidirectional_rnn/fw/carry_w"", tensor_type=DT_FLOAT, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/Select_G315 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device_incarnation=3243841103411587778, tensor_name=""edge_4692_Training_Graph/Model/TARGET/TARGET_Metrics/Select"", tensor_type=DT_DOUBLE, _device=""/job:worker/replica:0/task:0/device:CPU:0""]()]]
...
W tensorflow/core/framework/op_kernel.cc:1192] Not found: Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]
...
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""dist_train.py"", line 684, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""dist_train.py"", line 640, in main
    create_job()
  File ""dist_train.py"", line 628, in create_job
    run_worker(server, cluster)
  File ""dist_train.py"", line 429, in run_worker
    profile=profile
  File ""/HARNN.py"", line 1576, in step_dist_gpu
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python3.5/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 1024, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 827, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'Training_Graph/Model/IteratorFromStringHandle', defined at:
  File ""dist_train.py"", line 684, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""dist_train.py"", line 640, in main
    create_job()
  File ""dist_train.py"", line 628, in create_job
    run_worker(server, cluster)
  File ""dist_train.py"", line 272, in run_worker
    training_model.build_graph()
  File ""/HARNN.py"", line 221, in build_graph
    self._init_dataset()
  File ""/HARNN.py"", line 329, in _init_dataset
    self.datasets[self.targets[-1]].output_shapes)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 189, in from_string_handle
    output_shapes=nest.flatten(output_shapes))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 662, in iterator_from_string_handle
    output_types=output_types, output_shapes=output_shapes, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Resource worker/_3_Training_Graph/Model/Iterator/N10tensorflow12_GLOBAL__N_116IteratorResourceE does not exist.
	 [[Node: Training_Graph/Model/IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?,?], [?,?,?], [?], [?,?], [?,?], [?], [?]], output_types=[DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_FLOAT, DT_INT32], _device=""/job:worker/replica:0/task:0/device:CPU:0""](_recv_Training_Graph/Model/Placeholder_0)]]
	 [[Node: Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26_G1265 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/device:GPU:0"", send_device=""/job:worker/replica:0/task:0/device:CPU:0"", send_device_incarnation=-3380386273340330983, tensor_name=""edge_4280_Training_Graph/Model/TARGET/TARGET_Metrics/DenseToDenseSetOperation_26"", tensor_type=DT_INT64, _device=""/job:worker/replica:0/task:0/device:GPU:0""]()]]
~~~

### Statement:
What exactly have changed in tf.data.Iterator between versions r1.4 and r1.3.1 that causes such an unpleasant behaviour? What can be done to counteract `NotFoundError`?",0,,14,2017-11-16T06:13:56Z,CONTRIBUTOR
14611,"KeyError: ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options""",stat:awaiting response,"My tensorflow was working fine a few days ago and now I get this error:

```
Last login: Mon Nov 13 17:56:32 on ttys001
pWed Nov 15 22:38:01 :~$ python
Python 3.6.2 |Anaconda custom (x86_64)| (default, Jul 20 2017, 13:14:59)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/tensorflow/core/framework/graph_pb2.py"", line 10, in <module>
    from google.protobuf import descriptor_pb2
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/google/protobuf/descriptor_pb2.py"", line 409, in <module>
    options=None),
  File ""/Users/mona/anaconda/lib/python3.6/site-packages/google/protobuf/descriptor.py"", line 501, in __new__
    return _message.default_pool.FindFieldByName(full_name)
KeyError: ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options""
>>>
```

And my sys info is:
```
Wed Nov 15 23:41:58 :~$ uname -a
Darwin Monas-MacBook-Pro.local 17.0.0 Darwin Kernel Version 17.0.0: Thu Aug 24 21:48:19 PDT 2017; root:xnu-4570.1.46~2/RELEASE_X86_64 x86_64
Wed Nov 15 23:42:05 :~$ conda list | grep tensorflow
tensorflow                1.1.0               np112py36_0
tensorflow                1.4.0                     <pip>
tensorflow-tensorboard    0.1.8                     <pip>
```",0,,7,2017-11-16T04:43:00Z,NONE
14607,Tensorflow Lite Support for Windows,"comp:lite,type:feature",Are you planning to support Tensorflow Lite on Windows? Specifically Windows 32bit.,1,,4,2017-11-16T03:17:53Z,NONE
14606,Converting unsupported operation: Dequantize,"comp:lite,stat:awaiting tensorflower,type:feature","
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: centos 7
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I use the command:
bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/guoxiang/workspace/tensorflow/sms_model/optimized_sms.pb' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--output_file=/home/guoxiang/workspace/tensorflow/sms_model/sms_char_cnn.lite' '--inference_type=QUANTIZED_UINT8' '--input_type=QUANTIZED_UINT8' '--input_arrays=embedding_matrix' '--output_arrays=final_scores' '--input_shapes=1,5000,64,1' --logtostderr '--v=2'

to convert a quantized model to a  lite model, got the following error:
Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: Dequantize) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).

so , now qutianzed model is still not supported ?
",1,,5,2017-11-16T03:06:08Z,NONE
14601,Conv2D operator with SAME padding when Stride > kernel size showing unexpected results,,"### System information
- **Have I written custom code -- YES, only to demonstrate the problem (source code is below)**:
- **OS Platform and Distribution (Linux Ubuntu 16.04)**:
- **TensorFlow installed from (binary (PIP))**:
- **TensorFlow version (1.4.0)**:
- **Python version (2.7.12)**: 
- **Bazel version (N/A)**:
- **GCC/Compiler version (N/A)**:
- **CUDA/cuDNN version (N/A)**:
- **GPU model and memory (N/A -- CPU only)**:
- **Exact command to reproduce (See Source Code Below)**:

### Describe the problem
There is an inconsistency between the convolution documentation on padding with 'SAME' located [here](https://www.tensorflow.org/api_guides/python/nn#Convolution) and the behavior of the tf.nn.conv2d operator. In the example below I create a 3x1 input with values [[1.0][1.1][1.2]] and a 1x1 filter of value [1.0]. I specify the stride to be 1x3x1x1 which should result in only a single element be output and the padding to be 'SAME'. From the padding calculation in the above link: 

pad_along_height:
    
    in_height ( = 3) % strides[1]( = 3) == 0 so
    pad_along_height = max(filter_height ( = 1) - strides[1] ( = 3), 0)
    pad_along_height = max(-2, 0) = 0

pad along_width:

    in_width ( = 1) % strides[2] ( = 1) == 0 so
    pad_along_width = max(filter_width( = 1) - strides[2] ( = 1), 0
    pad_along_width = max(0,0) = 0

My hypothesis is that pad_along_* is not using the max(x,0) and as a result, pad_along_height = -2. Therefore pad_top = -1 and pad_bottom = -1. If that was the case, then our input is reduced to only the middle element [1.1] which explains why the TF result of the code below is 1.1 rather than the expected 1.0 (value of first input).

If I change the padding to be VALID (no padding) then this code below gives the result of 1.0 or if i instead change the stride to 1,2,1,1 i get the expected value of 1.0 (although in this case my hypothesis proposes that pad_bottom is still -1).

### Source code / logs
    import tensorflow as tf
    import numpy as np

    i = tf.constant((np.ones(3) + np.arange(3) * 0.1).reshape(1,3,1,1), dtype=tf.float32, name='input')
    f = tf.constant(np.ones(1).reshape(1,1,1,1), dtype=tf.float32, name='filter')

    conv = tf.nn.conv2d(input=i, filter=f, strides=(1,3,1,1), padding='SAME')

    with tf.Session() as sess:
        out = sess.run(conv)
        print out

Output:
`[[[[ 1.10000002]]]]`",0,,7,2017-11-16T01:09:19Z,NONE
14598,upgrade minSdkVersion to 21,"awaiting review,cla: yes,stat:awaiting tensorflower",Fix all 56 lint errors about NewApi: Calling new methods on older versions,1,,3,2017-11-15T22:41:13Z,NONE
14595,Adding a custom Tensorflow Op under Windows/cmake does not work with TF_LoadLibrary,stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I have a custom fork (https://github.com/stefanseibert/tensorflow/tree/r1.3) which is forked from r1.3 and the only modifications are some commented out lines to be able to build AVX support as described in another ticket, and the recent added fix for wide strings.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10, 64 bit, cmake

- **TensorFlow installed from (source or binary)**:
Built from source under windows with the cmake setup

- **TensorFlow version (use command below)**:
1.3.1

- **Python version**: 
3.6

- **Bazel version (if compiling from source)**:
Does not apply

- **GCC/Compiler version (if compiling from source)**:
Microsoft (R) Build Engine version 14.0.25420.1

- **CUDA/cuDNN version**:
CUDA 8 / cuDNN 5.1`

- **GPU model and memory**:
GTX 980 Ti 6GB, 64GB main memory

- **Exact command to reproduce**:
Does not apply

### Describe the problem
When using the cmake setup on windows to build Tensorflow from source and using AddUserOps which was added from @guschmue some time ago (example like https://gist.github.com/guschmue/2908e4411edc2faef6ddfe87a2ce4a1d), I am able to build GPU enabled tensorflow ops. I can load the DLL in python with tf.load_op_library() and can actually use it there. I can built GraphDefs with my custom Op and export it as protobuf file.

When I try to use this graph for inference in another application where I use the C++ API its not possible for me to get the op loaded and registered. Loading the same DLL (as which with the python API succeeds) works on a system level with C/C++ (the DLL is loaded successfully as seen through procmon.exe or dependency walker and TF_LoadLibrary returns with status ok) but when trying to run the Graph afterwards the custom op is not recognized from Tensorflow and Tensorflow errors with ""Not found: Op type not registered..."". Trying to get the OpList afterwards with the Lib handle also returns no ops. So somehow the ops are not seen here even though they are recognized from python side. I tried a lot of different things to circumvent this like described in my Stack Overflow Question here:

https://stackoverflow.com/questions/47309425/tensorflow-op-and-kernel-do-not-register-on-windows-with-cmake

but none of the approaches worked. It seems like that the op registration which is done after loading the DLL on python side is not properly done when performing the same operation with TF_LoadLibrary from C/C++. Since I cannot get tensorflow built with debug symbols I dont have a callstack where this registration fails unfortunately.
",0,,7,2017-11-15T20:38:27Z,NONE
14592,add photo selection and some changes in ios simple app,"awaiting review,cla: yes",add photo selection and image preview for tensorflow lite simple app,1,,14,2017-11-15T18:17:04Z,NONE
14589,Tensorflow Lite Support for Raspberry PI,"comp:lite,type:feature","### Describe the problem
Are you planning to support Tensorflow Lite on Raspberry Pi? Specifically Raspberry Pi 3.
",1,,6,2017-11-15T17:13:20Z,NONE
14584,Contradicting behaviour in variations of tf.cond usage with tf.nn.static_state_saving_rnn,,"[Model.txt](https://github.com/tensorflow/tensorflow/files/1474854/Model.txt)
[Training.txt](https://github.com/tensorflow/tensorflow/files/1474855/Training.txt)

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.2/1.3/1.4 (tested on all)
- **Bazel Version** : N/A
- **Python version**: 2.7
- **CUDA/cuDNN version**: Cuda 8, CuDNN 6
- **GPU model and memory**: GeForce GTX 1080 , 12 GB
- **Exact command to reproduce**: python Training.py

### Problem
I am dealing with long sequential data which has to be passed to an RNN. To do truncated BPTT and batching, I am using tf.contrib.training.batch_sequences_with_states API with tf.nn.static_state_saving_rnn API to transfer RNN state information to subsequent segments of the same sequence. I am using tf.RandomShuffleQueue() to store my data and to decouple the I/O from training I am running the enqueue operations asynchronously in a different thread. 

To facilitate a testing run after each training epoch I am using two separate `tf.RandomShuffleQueue()` structures and hence two different `tf.contrib.training.batch_sequences_with_states()` and `tf.nn.static_state_saving_rnn()` instances for train/test data correspondingly. Just the RNN cell which is passed to `tf.nn.static_state_saving_rnn` instances remains the same, so that the modified set of weights are used at test time.

Moreover, I use a placeholder which is a boolean flag using which the appropriate nodes in the computation graph are switched at train/test time. This switching is done using `tf.cond()` operation.

#### Situation 1

The problem is that of a deadlock situation at a specific stage between the enqueue operations and training operations, both running in separate threads. The enqueue operation timeouts mostly because the queue has reached the maximum capacity and for some reason training operation never returns and is waiting to get some more data and hence no dequeue operation is called.

#### Situation 2

In file Model.py, if I uncomment the lines from 97-101 and comment line 104, then there is no such deadlock situation. The only difference is in the way that specific `tf.cond()` operation is written. One is in a declarative form(working code) and other is in an inline form(broken/deadlock code).

#### Situation 3

In file - Training.py, dummy data is generated by the `gen_data()` procedure(lines - 43-48) and called on line 61. The second parameter to this function is the number of time steps for each sequence. If this number is fixed to a value which is less than the unroll length parameter of `tf.contrib.training.batch_sequences_with_states()` instances(i.e. each sequence can very well fit in one batch itself), this deadlock does not occur irrespective of situation 1 or situation 2 described above.

Hence, we suspect there is some minute intricacy in `tf.cond()` and `tf.nn.static_state_saving_rnn()` which gives rise to such a deadlock.

### Source code / logs
Two files are attached(.txt files since the interface does not allow attaching files with extension .py) - 

1. Model.txt - Contains the Model class and the inference() method where the majority of the computation graph is built.
2. Training.txt - Contains the client code which generates dummy data and calls to sess.run()

The current code is according to Situation 1 as described above and the behaviour can be seen by running the command - `python Training.py`

Regards,
Daksh

",1,,7,2017-11-15T13:34:08Z,NONE
14583,contrib.slim.conv2d doesn't check input dimension,stat:contributions welcome,"tensorflow version: v1.4.0-rc1-11-g130a514 (installed from pip)

contrib.slim.conv2d doesn't check for input dimensionality. So if you give it a 5D tensor it instead performs a 3D convolution.

Here is a quick way to see this:
```
sess = tf.InteractiveSession()

image_ph = tf.placeholder(tf.float32,
                          shape=(None, None, 10, 10),
                          name='image')
image = tf.expand_dims(image_ph, -1)
conv = tf.contrib.slim.conv2d(image, 3, 3, padding=""VALID"")

sess.run(tf.global_variables_initializer())
conv_out = conv.eval({image_ph: np.random.random((16, 20, 10, 10))})
```

conv_out will have shape `[16, 18, 8, 8, 3]`, meaning that the time dimension (dim 1) has decreased due to the VALID padding. 

As a side note I think it would be convenient if all conv2d implementations let you specify which dimensions to act on (or acted on the last 3 dims of the input by default). This is useful for example if you have sequential data and want to apply a 2d convolution to each frame independently.  ",0,,12,2017-11-15T11:36:10Z,NONE
14580,"freeze_graph ""No variables to save""",,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I do not modify any of the source code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5
_ **Bazel version
N
_ **CUDA/cuDNN version
N
_ **GPU model and memory
N

### Describe the problem
First, I download mobilenet_v1_0.25_224 pretrained model from [here](http://download.tensorflow.org/models/mobilenet_v1_0.25_224_2017_06_14.tar.gz)

Then,Exporting the Inference Graph, I use the commond:
python export_inference_graph.py \
  --alsologtostderr \
  --model_name=mobilenet_v1_025 \
  --image_size=224 \
  --output_file=/tmp/mobilenet_v1_025_224.pb

Next, freeze graph, I use the command:
python tensorflow/python/tools/freeze_graph.py --input_graph= tmp/mobilenet_v1_025_224.pb --input_checkpoint=tmp/mobilenet_v1_0.25_224.ckpt --input_binary=true --output_graph=tmp/frozen_mobilenet_v1_025_224.pb --output_node_names=MobileNetV1/Predictions/Reshape_1

Finally, I got the error:
 I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
Traceback (most recent call last):
  File ""tensorflow/python/tools/freeze_graph.py"", line 350, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tensorflow/python/tools/freeze_graph.py"", line 249, in main
    FLAGS.saved_model_tags)
  File ""tensorflow/python/tools/freeze_graph.py"", line 239, in freeze_graph
    input_meta_graph_def, input_saved_model_dir, saved_model_tags.split("",""))
  File ""tensorflow/python/tools/freeze_graph.py"", line 127, in freeze_graph_with_def_protos
    saver = saver_lib.Saver(var_list=var_list)
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1218, in __init__
    self.build()
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1227, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/libs/anaconda3/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1251, in _build
    raise ValueError(""No variables to save"")
ValueError: No variables to save

Another machine:
windows 7
tensorflow 1.4.0
python 3.6

Using the same operations, I can get the frozen .pb file successfully.

All source code are not modified.I also  changed the other models to test, and get the same error, need your help?",1,,4,2017-11-15T10:04:09Z,NONE
14578,Implements LayerNormBasicGRUCell,"cla: yes,stat:awaiting response","LayerNormBasicGRUCell add layer normalization to basic GRU unit.

Layer Normalization implementation is based on https://arxiv.org/abs/1607.06450 (""Layer Normalization"", Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton) and is applied before the internal nonlinearities.",1,,11,2017-11-15T09:42:02Z,NONE
14575,How to configure gpu memory fraction outside of my own code?,stat:awaiting response,"My tensorflow automatically allocates all of my GPU memory.
I know the way to configure 'gpu memory fraction' in my own code like the below
```
import tensorflow as tf
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
```
I added the codes at the front of my code, so it worked well.

BUT I want to use tensorflow in distributed processing (e.g. spark)
Adding the configuration code in the code is not working in the distributed processing since configuration in the code is applied to only master machine, not to other machines.

SO, I try to configure gpu memory fraction of tensorflow itself.
how can I do??",0,,4,2017-11-15T09:05:06Z,NONE
14573,bazel build failure of current master in Docker container due to contrib/lite,"comp:lite,type:bug/performance","Building current GPU version of master branch tensorflow/tensorflow@31b79e42b9e1643b3bcdc9df992eb3ce216804c5 fails in Docker container, saying

    /usr/bin/ld: warning: libcuda.so.1, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scc_Cops_Sdata_Uflow_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)

and I find that it is due to [`contrib/lite`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite): when I comment out the related dependencies in [`tensorflow/tools/pip_package/BUILD`](https://github.com/tensorflow/tensorflow/blob/31b79e42b9e1643b3bcdc9df992eb3ce216804c5/tensorflow/tools/pip_package/BUILD#L164-L166), the build success.

I know this error is typically solved when I create a soft link inside the container before to build (c.f. #10776):

    RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1

but this time, it doesn't help.",1,,10,2017-11-15T08:40:46Z,NONE
14572,it's slow to train model when loading dataset and checkpoints from S3,stat:awaiting response,"# System information

**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**  No

**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Amazon Linux, P2 Instance

**TensorFlow installed from (source or binary):** pip

**TensorFlow version (use command below):** 1.5.0.dev20171113

**Python version:** 2.7

**CUDA/cuDNN version:** CUDA 8.0 / cuDNN 6.0

**GPU model and memory:** Tesla K80 12GB

# Describe the problem

The dataset and checkpoints are stored in S3 filesystem. It's slowly when training model. Howevery, The structure of network is simple and the speed is fast when load dataset and checkpoints from local filesystem

# Source code / logs

some code like 

```bash
def input_fn(mode):
    """""" Input callback for Estimator
    
    Arguments
    ----
    mode: str, tf.estimator.ModelKey
    file_pattern: tensorflow file pattern, refer to `tf.gfile.Glob`

    Return
    ---
    features: dict of Tensor, the input features for model
    label: single Tensor, the input label for model, must be integeral
    """"""
    is_train = tf.estimator.ModeKeys.TRAIN == mode

    vocab_dir = hparams.vocab_dir

    ds_dir = 'train' if is_train else 'test'
    file_pattern = os.path.join(hparams.dataset_dir, ds_dir, 'part-')

    tfrecords_files = [] 
    if file_pattern.startswith('s3'):
        tfrecords_files = list_s3_file(file_pattern)
    else:
        tfrecords_files = tf.gfile.Glob(file_pattern)

    example = create_example(vocab_dir)
    example_spec = tf.feature_column.make_parse_example_spec(feature_columns=example)

    batch_size = hparams.batch_size
    num_epochs = hparams.num_epochs if is_train else 1
    example_parsed = tf.contrib.learn.read_batch_record_features(file_pattern=tfrecords_files,
                            batch_size=batch_size,
                            num_epochs=num_epochs,
                            features=example_spec)

    label = example_parsed.pop('label')
    features = example_parsed

    return features, label
```

The log 

```bash

INFO:tensorflow:Into main function
INFO:tensorflow:vocab_dir: s3://experiements/yajun/youtube-match/data/raw/vocab
INFO:tensorflow:Create Estimator
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efcfa4bff90>, '_model_dir': 's3://experiements/yajun/youtube-match/data/model', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
INFO:tensorflow:Begin to train model
INFO:tensorflow:List files in S3 according to the file pattern: s3://experiements/yajun/youtube-match/data/raw/train/part-
INFO:tensorflow:Create CheckpointSaverHook.
2017-11-15 03:03:41.798030: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-15 03:03:45.623759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-15 03:03:45.624258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties:
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2017-11-15 03:03:45.624285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
INFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1400
^[[O^[[I
^[[OINFO:tensorflow:Saving checkpoints for 1401 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.
INFO:tensorflow:loss = 4.90536, step = 1401
INFO:tensorflow:global_step/sec: 188.871
INFO:tensorflow:loss = 7.86743, step = 1501 (0.530 sec)
INFO:tensorflow:global_step/sec: 219.692
INFO:tensorflow:loss = 2.34025, step = 1601 (0.455 sec)
INFO:tensorflow:global_step/sec: 224.707
INFO:tensorflow:loss = 2.32145, step = 1701 (0.445 sec)
2017-11-15 03:14:24.980234: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_4_dequeue_record_examples/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)
	 [[Node: dequeue_record_examples/fifo_queue_Dequeue = QueueDequeueV2[component_types=[DT_INT64, DT_INT64, DT_STRING, DT_INT64, DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](dequeue_record_examples/fifo_queue)]]
INFO:tensorflow:Saving checkpoints for 1750 into s3://experiements/yajun/youtube-match/data/model/model.ckpt.
INFO:tensorflow:Loss for final step: 6.49392.
INFO:tensorflow:Begin to export model to s3://experiements/yajun/youtube-match/data/model/exports
2017-11-15 03:14:29.600289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
INFO:tensorflow:Restoring parameters from s3://experiements/yajun/youtube-match/data/model/model.ckpt-1750
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: s3://experiements/yajun/youtube-match/data/model/exports/temp-1510715669/saved_model.pb
INFO:tensorflow:Finish to run
```",0,,4,2017-11-15T08:25:55Z,NONE
14567,Convert SavedModel files into TFLite file with toco convertor,"comp:lite,stat:awaiting tensorflower,type:feature","### Feature request

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

TensorFlow Lite is great and we can use the [toco](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/toco) tools to convert freeze_graph. And we can specify the input and output tensors for this model.

However, we use SavedModel a lot for TensorFlow Serving. It has all the weights of the model and described the model signature in the better way.

It would be great if we can convert SavedModel file format into the final TFLite so that we don't need to export the model in many ways.

",2,,4,2017-11-15T03:41:12Z,CONTRIBUTOR
14566,Feature request for making dynamic gradient clipping ,"stat:contributions welcome,type:feature","That I know about gradient, tf has 
https://www.tensorflow.org/versions/r0.12/api_docs/python/train/gradient_clipping

But I need the clipping gradient can change at training, and I see the all clip gradient doc, not found this function.

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: python pip 
- **TensorFlow version (use command below)**: v 1.3.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:5.4.0
- **CUDA/cuDNN version**:Cuda compilation tools, release 8.0, V8.0.61
- **GPU model and memory**: 1080Ti 8G
- **Exact command to reproduce**:

Thanks",0,,8,2017-11-15T03:06:15Z,NONE
14552,Make sparse_to_dense differentiable by wrapping scatter_nd_add.,"cla: yes,stalled,stat:awaiting response","Make `sparse_to_dense` a wrapper of `scatter_nd_add`, as the two have very similar functionality and the latter is differentiable while the former is not. Ran into this because there apparently is no warning when trying to differentiate not differentiable ops.

Related: https://github.com/tensorflow/tensorflow/issues/6391#issuecomment-268392143

If this has potential to be merged and further changes are required, I am happy to work on those.

edit: Misleading commit message, wrapping `scatter_nd_add` in order to allow a default value.",1,,10,2017-11-14T15:57:14Z,NONE
14544,"ValueError: Variable RNNLM/RNNLM/embedding_layer/embedding/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?","stat:awaiting response,type:support","  when running following code, 
    
**with tf.variable_scope('RNNLM') as scope:
          model = RNNLM_Model(config)
          scope.reuse_variables()
          gen_model = RNNLM_Model(gen_config)**

this problem occurs:
       **ValueError: Variable RNNLM/RNNLM/embedding_layer/embedding/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?**
 why it is 'RNNLM/RNNLM/embedding_layer'?

the following code can run successfully
 
 **model = RNNLM_Model(config)
  tf.get_variable_scope().reuse_variables()
  gen_model = RNNLM_Model(gen_config)**

  ",0,,4,2017-11-14T12:00:54Z,NONE
14540,Wrong protobuf BUILD rule while compiling tensorflow on powerpc ,"stat:community support,type:build/install","### System Info
- **No custom code is written**
- **Ubuntu 16.04 on powerpc (ppc64le)**
- **Installing from source**
- **Tensorflow v1.4.0**
- **python 3.5.2**
- **bazel 0.7.0**
- **`gcc --version` output: gcc (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609**
- **CUDA 8.0, cuDNN 5.1**
- **NVIDIA Tesla P100**

### Describe the problem
I tried to build Tensorflow from sources. While `./configure`ing, I did the following;

`Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -mcpu=native]: -mcpu=native -mtune=native`

because I'm on a powerpc. (-march=native is not recognized, already denoted by [Default -mcpu=native])

After executing `bazel build --config=opt --config=cuda tensorflow/tools/pip_package:build_pip_package`, it starts to download and compile protobuf, I immediately get the following, 

`ERROR: /home/powerpc/.cache/bazel/_bazel_powerpc/7ad07c846e34c4f733a905eaa47f3cba/external/protobuf_archive/BUILD:265:1: C++ compilation of rule '@protobuf_archive//:js_embed' failed (Exit 1).
gcc: error: unrecognized command line option '-march=native'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 18.579s, Critical Path: 6.01s`

I believe this stems from a wrong BUILD rule for protobuf, it defaults to [-march=native]. I wasn't able to find the relevant BUILD file to fix.

### Edit
After trying again, this time I get the same error for highwayhash. This is about third_party packages, should I have to edit all BUILD rules manually?",1,,6,2017-11-14T09:29:06Z,NONE
14535,Can not import transformed and quantized model using tf.import_graph_def,stat:awaiting tensorflower,"Hello guys,
I am trying to quantized the pretrain SSD_mobilenet_v1_coco from the Tensorflow Object Detection API using the following command:
`bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=MobileNetSSD.pb \
--out_graph=optimized_SSD.pb \
--inputs='image_tensor' \
--outputs='detection_boxes,detection_scores,detection_classes,num_detections' \
--transforms='
  add_default_attributes
  strip_unused_nodes(type=uint8, shape=""1,300,300,3"")  
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  quantize_nodes
  strip_unused_nodes
  sort_by_execution_order'`

The command run successfully and I had the optimized_SSD.pb with only 6MB. However, when I try to use this pb model in the provided IPython Notebook file [title](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) I received this error:
`Traceback (most recent call last):
  File ""/home/phong/PycharmProjects/ConvertDarknet2VOC/evaluation.py"", line 52, in <module>
    tf.import_graph_def(od_graph_def, name='')
  File ""/home/phong/.virtualenvs/tensorflow_pycharm/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 283, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named QuantizedResizeBilinear in defined operations.`

Is there any way to load the quantized model using tensorflow ? 


",0,,8,2017-11-14T08:16:34Z,NONE
14528,Tensorflow would sometimes get rather slow during training,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.5
- **CUDA/cuDNN version**: CUDA 8.0 / cuDNN 6.0
- **GPU model and memory**: GTX1060 6GB
### Describe the problem
When I train my network, at first it works properly, however sometimes it gets rather slower (about 10 times slower than normal speed, shown below). When I type nvidia-smi to check the GPU state, I find the GPU-Util is rather low (2-3%)
The normal speed is about 1 minute per 100 steps while it would sometimes cost 10 minminutes per 100 steps. 
I used to use Tensorflow v1.1 and did not find this problem. However I updated Tensorflow to v1.4 several days ago and this problem occurred.

### Source code / logs
> 2017-11-12 23:43:55  Step: 770900, loss: 1.6261, accuracy: 68.7500%
2017-11-12 23:45:37  Step: 771000, loss: 1.4571, accuracy: 65.6250%
2017-11-12 23:48:37  Step: 771100, loss: 1.3790, accuracy: 73.4375%
2017-11-12 23:49:50  Step: 771200, loss: 1.6311, accuracy: 57.8125%
2017-11-12 23:51:11  Step: 771300, loss: 1.3248, accuracy: 67.1875%
2017-11-12 23:52:31  Step: 771400, loss: 1.6924, accuracy: 64.0625%
2017-11-12 23:53:44  Step: 771500, loss: 1.3097, accuracy: 67.1875%
2017-11-12 23:55:02  Step: 771600, loss: 1.7720, accuracy: 64.0625%
2017-11-12 23:56:15  Step: 771700, loss: 1.5915, accuracy: 68.7500%
2017-11-12 23:57:28  Step: 771800, loss: 1.7489, accuracy: 60.9375%
2017-11-12 23:58:50  Step: 771900, loss: 1.2855, accuracy: 68.7500%
2017-11-13 00:00:03  Step: 772000, loss: 1.3734, accuracy: 65.6250%
2017-11-13 00:01:16  Step: 772100, loss: 1.4637, accuracy: 70.3125%
2017-11-13 00:02:38  Step: 772200, loss: 1.6229, accuracy: 60.9375%
2017-11-13 00:03:51  Step: 772300, loss: 1.3330, accuracy: 65.6250%
2017-11-13 00:05:04  Step: 772400, loss: 1.7729, accuracy: 56.2500%
2017-11-13 00:06:37  Step: 772500, loss: 1.2806, accuracy: 65.6250%
2017-11-13 00:07:59  Step: 772600, loss: 1.0916, accuracy: 70.3125%
2017-11-13 00:09:31  Step: 772700, loss: 1.4440, accuracy: 73.4375%
2017-11-13 00:10:43  Step: 772800, loss: 0.9338, accuracy: 76.5625%
2017-11-13 00:13:03  Step: 772900, loss: 1.6038, accuracy: 57.8125%
2017-11-13 00:14:15  Step: 773000, loss: 1.2853, accuracy: 64.0625%
2017-11-13 00:16:43  Step: 773100, loss: 1.1761, accuracy: 75.0000%
2017-11-13 00:17:56  Step: 773200, loss: 1.0927, accuracy: 68.7500%
2017-11-13 00:23:23  Step: 773300, loss: 1.3884, accuracy: 73.4375%
2017-11-13 00:24:37  Step: 773400, loss: 1.3729, accuracy: 67.1875%
2017-11-13 00:25:50  Step: 773500, loss: 1.0257, accuracy: 76.5625%
2017-11-13 00:29:01  Step: 773600, loss: 1.4766, accuracy: 68.7500%
2017-11-13 00:38:35  Step: 773700, loss: 1.3401, accuracy: 68.7500%
2017-11-13 00:47:49  Step: 773800, loss: 1.4850, accuracy: 68.7500%
2017-11-13 00:57:39  Step: 773900, loss: 1.2555, accuracy: 68.7500%
2017-11-13 01:06:59  Step: 774000, loss: 1.6202, accuracy: 60.9375%
2017-11-13 01:16:28  Step: 774100, loss: 1.4673, accuracy: 59.3750%
2017-11-13 01:26:11  Step: 774200, loss: 1.3678, accuracy: 67.1875%
2017-11-13 01:35:38  Step: 774300, loss: 1.2268, accuracy: 67.1875%
2017-11-13 01:45:14  Step: 774400, loss: 1.5675, accuracy: 60.9375%
2017-11-13 01:55:00  Step: 774500, loss: 1.7380, accuracy: 59.3750%
2017-11-13 02:04:42  Step: 774600, loss: 1.9971, accuracy: 56.2500%
2017-11-13 02:15:26  Step: 774700, loss: 1.9669, accuracy: 54.6875%
2017-11-13 02:28:05  Step: 774800, loss: 1.3680, accuracy: 67.1875%
2017-11-13 02:39:03  Step: 774900, loss: 1.1381, accuracy: 76.5625%",1,,6,2017-11-14T04:42:16Z,NONE
14518,DataSet user provided shuffled order,type:feature,"It would be very useful if a user will be able to provide the order of examples within a dataset (with repetitions allowed, as only indices are shuffled).
This would allow having a more complicated logic (which involves balancing data of different types).

I assume it can be somehow supported by zip-ing together different DataSets, but it would be MUCH easier and more flexible if we could just pass a list of indices. Probably light as well as it shouldn't be a big deal passing one list per epoch.

Please tell me if this feature already exists, and if not, please add it :)",1,,9,2017-11-13T14:08:19Z,NONE
14509,Function for explicit broadcasting,stat:contributions welcome,"It would be convenient to have an explicit function for broadcasting in TensorFlow's Python API, like to [`numpy.broadcast_to`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.broadcast_to.html) or XLA's [Broadcast](https://www.tensorflow.org/performance/xla/operation_semantics#broadcast), and as [requested on StackOverFlow](https://stackoverflow.com/questions/34362193/how-to-explicitly-broadcast-a-tensor-to-match-anothers-shape-in-tensorflow). This would facilitate adding broadcasting-like behavior to the many TensorFlow operations that don't support it out of the box.

I understand that in general TensorFlow does not implement NumPy's the strided N-dimensional array data model, so unlike the case for NumPy, broadcasting (e.g., with Eigen tensors) can require a copy. This is a good reason to not necessarily build such a version of broadcasting into ops. However, explicit broadcasting rather than using tile/expand_dims can still be very convenient.
",0,,8,2017-11-13T05:36:12Z,MEMBER
14507,XLA reports error with 1000 steps of static_bidirectional_rnn,stat:contributions welcome,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.1 or 1.3
- **Python version**: 2.7.4
- **Bazel version (if compiling from source)**: 0.4.5
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 5.1
- **GPU model and memory**: M40
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
This issue can only be reproduced when XLA works with static_bidirectional_rnn with 1000 steps, and the ""seq_len"" of static_bidirectional_rnn must be assigned, which means it works with ""dynamic calculation"". When the issue is reproduced, it reports:

```
2017-11-01 18:47:16.497266: E tensorflow/stream_executor/cuda/cuda_driver.cc:731] failed to load PTX text as a module: CUDA_ERROR_NO_BINARY_FOR_GPU
2017-11-01 18:47:16.497294: E tensorflow/stream_executor/cuda/cuda_driver.cc:736] error log buffer (163 bytes): ptxas application ptx input, line 7231; error   : Kernel '_fusion_1' exceeds parameter space limit of 4352 bytes
ptxas fatal   : Ptx assembly aborted due to error

```
From my analysis, a fused XLA instruction requires for more than 1000 input parameters. This further leads to a PTX kernel with 1000+ parameters, which is not accepted by the cuda driver.

This is what I found from the PTX ISA documents:
`The maximum memory size supported by PTX for normal (non-opaque type) parameters is 4352 bytes. Prior to PTX ISA version 1.5, the maximum size was 256 bytes.`

Read more at: http://docs.nvidia.com/cuda/parallel-thread-execution/index.html#ixzz4yGwCVOB7
Follow us: @GPUComputing on Twitter | NVIDIA on Facebook


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,8,2017-11-13T01:49:50Z,NONE
14506,poor performance when XLA works with dynamic control_flow ops,"stat:awaiting response,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**:  2.7.14
- **Bazel version (if compiling from source)**: 0.4.5
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 8.0/5.1.10
- **GPU model and memory**: M40
- **Exact command to reproduce**: 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When XLA works with:
1, dynamic_rnn
2, static_rnn with ""dynamic calculation"" enabled, specificaly, when the seq_len is assigned.

In these cases, the performance of XLA is poor, even result in negative performance optimization.
From the time line it seems that the switch/merge ops are breaking the XLA fused instructions into pieces. But i still don't understand why it leads to negative optimization.

Pls let me know if this is a known issue, are there any special reasons for XLA not to support control flow ops? or if there's anything i can do to fix it. Thanks.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",1,,8,2017-11-13T01:37:38Z,NONE
14504,Cannot use keras estimator_from_model() in distributed cluster,"stat:awaiting tensorflower,type:support","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tf.VERSION = 1.4.0 tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0.61/6.0.21
- **GPU model and memory**: NVIDIA Tesla M60 8 GB
- **Exact command to reproduce**: See Below

### Describe the problem
When trying to use an estimator that is derived from ```tf.keras.estimator.estimator_from_model()``` and training with ```tf.estimator.train_and_evaluate()```, it will work as expected if in a standalone non-distributed session. However, when in a distributed training cluster and the TF_CONFIG has the cluster information set, there is a an explicit device assignment of an op to a device that is not valid in the current cluster spec.

Below is code to reproduce this issue. When ```simulate_cluster``` is set to True an error is throws as shown in the log below. When ```simulate_cluster``` is set to False the network is constructed and trained as intended. It should be noted that the error occurs when calling ```tf.keras.estimator.model_to_estimator(keras_model=model)``` and not when doing the training, the cluster config is required for the distributed training to take place.

The TF_CONFIG that is set below is derived from calling the code using the gcloud SDK as follows:
```gcloud ml-engine local train --distributed --parameter-server-count=1 --worker-count=2 --package-path=trainer --module-name=trainer.task --```

### Source code / logs
Minimal example:
```python
import os
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

simulate_cluster = True
if simulate_cluster:
    os.environ[""TF_CONFIG""] = '{""environment"": ""cloud"", ""cluster"": {""worker"": [""localhost:27184"", ""localhost:27185""], \
               ""ps"": [""localhost:27183""], ""master"": [""localhost:27182""]}, ""job"": {""args"": [""""], \
               ""job_name"": ""trainer.task""}, ""task"": {""index"": 0, ""type"": ""master""}}'
else:
    os.environ[""TF_CONFIG""] = ''

inputs = tf.keras.layers.Input(shape=(10,))
outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.models.Model(inputs, outputs)
model.compile(optimizer='Adam', loss='binary_crossentropy')
est_keras = tf.keras.estimator.model_to_estimator(keras_model=model) # InvalidArgumentError thrown here if simulate_cluster is True

input_name = model.input_names[0]
data = np.random.rand(1000,10).astype(np.float32)
train_input_fn = tf.estimator.inputs.numpy_input_fn({input_name:data}, data, batch_size=10, num_epochs=None, shuffle=False)

train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=100)
eval_spec = tf.estimator.EvalSpec(input_fn=train_input_fn, steps=10)
tf.estimator.train_and_evaluate(est_keras, train_spec, eval_spec)
```

InvalidArgumentError emitted when ```simulate_cluster = True```:
```python
Traceback (most recent call last):
  File ""minimal.py"", line 19, in <module>
    est_keras = tf.keras.estimator.model_to_estimator(keras_model=model)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 280, in model_to_estimator
    _save_first_checkpoint(keras_model, est, custom_objects, keras_weights)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 217, in _save_first_checkpoint
    model.set_weights(keras_weights)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 766, in set_weights
    K.batch_set_value(tuples)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 2406, in batch_set_value
    get_session().run(assign_ops, feed_dict=feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 376, in get_session
    _initialize_variables(session)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 554, in _initialize_variables
    [variables_module.is_variable_initialized(v) for v in candidate_vars])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'loss/dense_1_loss/sub': Operation was explicitly assigned to /job:master/task:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1, /job:localhost/replica:0/task:0/device:GPU:2, /job:localhost/replica:0/task:0/device:GPU:3 ]. Make sure the device specification refers to a valid device.
         [[Node: loss/dense_1_loss/sub = Sub[T=DT_FLOAT, _device=""/job:master/task:0""](loss/dense_1_loss/sub/x, loss/dense_1_loss/Const)]]

Caused by op u'loss/dense_1_loss/sub', defined at:
  File ""minimal.py"", line 19, in <module>
    est_keras = tf.keras.estimator.model_to_estimator(keras_model=model)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 280, in model_to_estimator
    _save_first_checkpoint(keras_model, est, custom_objects, keras_weights)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 209, in _save_first_checkpoint
    custom_objects)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/estimator.py"", line 124, in _clone_and_build_model
    target_tensors=target_tensors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 840, in compile
    output_loss = weighted_loss(y_true, y_pred, sample_weight, mask)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 444, in weighted
    score_array = fn(y_true, y_pred)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/losses.py"", line 78, in binary_crossentropy
    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 3027, in binary_crossentropy
    output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 910, in r_binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 4636, in _sub
    ""Sub"", x=x, y=y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'loss/dense_1_loss/sub': Operation was explicitly assigned to /job:master/task:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1, /job:localhost/replica:0/task:0/device:GPU:2, /job:localhost/replica:0/task:0/device:GPU:3 ]. Make sure the device specification refers to a valid device.
         [[Node: loss/dense_1_loss/sub = Sub[T=DT_FLOAT, _device=""/job:master/task:0""](loss/dense_1_loss/sub/x, loss/dense_1_loss/Const)]]
```

Full logs, tf_env, and more are here: https://gist.github.com/droidicus/2abd4ddad81a1e9169a1c7a100057b15
",2,,7,2017-11-12T20:24:11Z,NONE
14496,Building with MKL reduces CPU performance,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: both
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8
- **GPU model and memory**: Tesla P100-PCIE-16GB
- **Exact command to reproduce**:

### Describe the problem
Building tensorflow with mkl (--config=mkl) prevents the system from using all its cores.
CPU load remains always below 20% in my testcase. Using the same build flags but without mkl achieve 100% CPU load and a nearly 10 times faster execution.

While playing with the MKL flags described here https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu
i noticed some strange behavior:

Running the MKL-build with 
`OMP_NUM_THREADS=27 KMP_SETTINGS=1 KMP_AFFINITY=verbose `
results in the following print:

```
User settings:

   KMP_AFFINITY=verbose
   KMP_SETTINGS=1
   OMP_NUM_THREADS=27

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=224
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=200
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=false
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_FORKJOIN_FRAMES=true
   KMP_FORKJOIN_FRAMES_MODE=3
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_INIT_WAIT=2048
   KMP_ITT_PREPARE_DELAY=0
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NEXT_WAIT=1024
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=4M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=56
   KMP_TOPOLOGY_METHOD=all
   KMP_USER_LEVEL_MWAIT=false
   KMP_VERSION=false
   KMP_WARNINGS=true
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=2147483647
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED=false
   OMP_NUM_THREADS='27'
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='false'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=4M
   OMP_THREAD_LIMIT=2147483647
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='verbose,warnings,respect,granularity=core,none'

OMP: Info #209: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #207: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #156: KMP_AFFINITY: 56 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 14 cores/pkg x 2 threads/core (28 total cores)
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35708 thread 0 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35706 thread 1 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35707 thread 2 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35704 thread 3 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35701 thread 4 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35711 thread 5 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35712 thread 6 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35713 thread 7 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35705 thread 8 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35710 thread 9 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35702 thread 10 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35717 thread 11 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
...
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35678 thread 78 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35672 thread 79 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
OMP: Info #247: KMP_AFFINITY: pid 35537 tid 35674 thread 80 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
....
(continues with a higher thread number each time)
```

If I use the same execution flags with a build without MKL or with the pip version I get the same ouput up to 
`
...
OMP: Info #247: KMP_AFFINITY: pid 36958 tid 37191 thread 27 bound to OS proc set {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55}
`
Afterwards no OMP prints are created. It seems like, if I build with mkl, tensorflow continues to create more and more threads but cant utilize them. 

Is this a configuration issue or a bug? 
If its a known issue, please expand the performance guide :) 

pinging @skye because of its help with the performance issue with while_loop 

",0,,17,2017-11-12T13:52:22Z,NONE
14489,sess.run hangs forever despite operation_timeout_in_ms being set,stat:contributions welcome,"`sess.run` waits indefinitely on worker when one of the parameter server machines in the cluster fails despite `operation_timeout_in_ms` being set.

Because waiting happens inside TensorFlow runtime, there's no way for client to regain control to provide a helpful error message/fix the situation.

```
sess=tf.Session(config=...operation_timeout_in_ms=1000)  # succeeds even though TF cluster is partially dead
sess.run(remote_op)       # hangs forever
```
You see this during worker's `session.run`
```
2017-11-11 16:06:12.524442: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-11 16:06:22.525582: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2017-11-11 16:06:32.525718: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
```

Suggestion: since `CreateSession` happens during `session.run`, make it subject to `.operation_timeout_in_ms` deadline

cc @mrry 
",0,,2,2017-11-12T00:09:17Z,CONTRIBUTOR
14482,[Fetaure Request] Bicubic interpolation using map coordinates,stat:contributions welcome,"I would like to train a two CNN in single graph. The architecture of model is 
![capture](https://user-images.githubusercontent.com/18436807/32688705-3ea9e54c-c6d6-11e7-84ba-fb01a3be2755.PNG)

This one is not like end to end training. In the warping of images(refer attachment), I use scipy for mapping coordinates from the disparity map to an input image and I am unable to build a model(graph) in tensorflow using scipy. Tensorflow supports only resize of images using bicubic/bilinear interpolation. [https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.map_coordinates.html](url)

For reference, original paper is implemented using matconvnet in [matlab.](http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/SIGASIA16/) 


",0,,2,2017-11-11T10:57:44Z,NONE
14477,error message show while compiling tensorflow from source,stat:community support,"bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamin_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSscal_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmBatched'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDznrm2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsymm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardTraining'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyrk_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSger_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgbmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamax_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetStream'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSasum_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxSetFlags'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2D'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgbmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCreate_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlanMany'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotu_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScasum_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCscal_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormal'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamax_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmm_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgeru_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdrot_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan3d'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpsv_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Smemory_Ustats_Cgen_Umemory_Ustats_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr_v2'
",0,,4,2017-11-11T04:27:55Z,NONE
14456,Windows native library (tensorflow_jni.dll) is dynamically linked to msvcp140.dll,,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 SP1 x64
- **TensorFlow installed from (source or binary)**: Downloaded from Maven repository
- **TensorFlow version (use command below)**: 1.4.0

### Describe the problem
I need to run TensorFlow on a Windows PC where I don't have admin rights. So I cannot install MS Visual C++ 2015 Redistributable package. And TensorFlow Windows native library (tensorflow_jni.dll) is dynamically linked to msvcp140.dll from that package.

Thus the only option to run TensorFlow for me is to download the DLL from some untrusted ""get any DLL"" site and put it somewhere in PATH.

I believe it should not be the case. Please consider dropping dependency on MS Visual C++ 2015 Redistributable package.
Or at least mention this dependency clearly in the ""Using TensorFlow with a Maven project"" section as well as ""Install on Windows"" here https://www.tensorflow.org/install/install_java

### Source code / logs
The problem manifests itself as
`Exception in thread ""main"" java.lang.UnsatisfiedLinkError: C:\Users\...\AppData\Local\Temp\tensorflow_native_libraries-...-0\tensorflow_jni.dll: Can't find dependent libraries`",1,,13,2017-11-10T16:53:19Z,NONE
14454,cuda_config.h is required to build non-CUDA release,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: NixOS 18.03.git.869485a (Impala)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 6.4.0
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
TensorFlow with CUDA support disabled doesn't build. CUDA support is disabled in `./configure`.

### Source code / logs
```
./tensorflow/stream_executor/dso_loader.h:32:30: fatal error: cuda/cuda_config.h: No such file or directory
 #include ""cuda/cuda_config.h""
```",0,,7,2017-11-10T15:48:20Z,NONE
14452,Bug - freeze_graph producing invalid graph_def in tensorflow 1.4,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: release 1.4
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: GTX 970, 4GB
- **Exact command to reproduce**: 

1. Download [dbg.zip](https://github.com/tensorflow/tensorflow/files/1461735/dbg.zip) (contains `graph.pbtxt`, checkpoint and the resulting `frozen_model.pb` generated on my machine .)
2. Unzip and open terminal in the unzipped folder
3. Run <tensorflow_root>/python/tools/freeze_graph.py --input_graph=graph.pbtxt --input_binary=False --input_checkpoint=model.ckpt-1 --output_node_names=softmax_tensor --output_graph=frozen_model_test.pb --clear_devices=True
4. Start python, attempt to import the frozen graph:
```
import tensorflow as tf
from tensorflow.python.platform import gfile
with gfile.FastGFile('frozen_model_test.pb','rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='')
```
### Describe the problem
Trying to import the graph, I get this error:
> ValueError: graph_def is invalid at node 'IsVariableInitialized': Input tensor 'global_step:0' Cannot convert a tensor of type int64 to an input of type int64_ref.

The error is raised in `tf.import_graph_def(graph_def, name='')`. The dump of `str(graph_def)` can be seen in this text file: [graph_def_dbg.txt](https://github.com/tensorflow/tensorflow/files/1461768/graph_def_dbg.txt)

The error happens sine the upgrade to TF 1.4, with TF 1.3 the graph freezing and importing works as expected.
",0,,17,2017-11-10T15:18:08Z,NONE
14448,[Feature request] Improve syntax for accessing Python objects in dataset pipelines,"stat:contributions welcome,type:feature","------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary 
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: 

### Describe the problem

Hey, I have a python database class
```python
class MyDatabase:
    def __len__(self): return ...
    def __getitem__(self, item): return ...  # slow code without gitlock, i.e. io and numpy
```
that supports indexing and returns a dict. The loading of the data is longer than a NN iteration, therefore it would be nice when tensorflow loads the data in parallel. When I use tf.data.Dataset.from_generator I have to convert my Database to a generator
```python
def generator():
    db = MyDatabase()
    yield from [db[i] for i in range(len(db))]
```
`from_generator` has no argument `num_parallel_calls`, therefore the loading is serial.
I am not sure how difficult it is to add such an argument. 
But in the case that `MyDatabase` has above structure it is possible to combine `tf.data.Dataset.range` with `tf.data.Dataset.map` and `tf.py_func` to get a parallel load. 
In my mind, it could be easier to implement a parallel load for an indexable object.

Further point the interface of `tf.py_func` has more constraints than `tf.data.Dataset.from_generator` (dict's are not allowed and it hat no output_shape argument).

Since I am new to tensorflow and have problems to understand the `tf.data.Dataset` code, here my feature request for a `num_parallel_calls` argument in `tf.data.Dataset.from_generator` or a new function `tf.data.Dataset.from_generator` with a `num_parallel_calls` argument.

### Source code / logs

Here a toy example, that demonstrate the non-parallel from_generator

```python
import time

start = time.perf_counter()
    
def body(i):
    global start
    if i == 0:
        start = time.perf_counter()
    time.sleep(0.2)
    return np.array([float(i), time.perf_counter() - start])

def gen():
    for i in range(5):
        yield body(i)
        
ds = tf.data.Dataset.from_generator(gen, tf.float64)
ds = ds.prefetch(5)
iterator = ds.make_one_shot_iterator()

entry = iterator.get_next()

with tf.Session() as sess:
    
    try:
        while True:
            print(sess.run(entry))
    except tf.errors.OutOfRangeError:
        pass
# Serial execution:  [index, time from start of first load to return of current load]
# [ 0.          0.20034038]
# [ 1.          0.40189139]
# [ 2.          0.60322792]
# [ 3.          0.80472201]
# [ 4.          1.00612245]
```
and here the parallel version (Less nice code and does not generalise so good as from_generator, e.g. no return dict support)
```python
ds = tf.data.Dataset.range(5)

def map_func(i):
    return tf.py_func(body, [i], tf.float64, stateful=False)

ds = ds.map(map_func, num_parallel_calls=4)
ds = ds.prefetch(1)
iterator = ds.make_one_shot_iterator()

entry = iterator.get_next()

with tf.Session() as sess:
    
    try:
        while True:
            print(sess.run(entry))
    except tf.errors.OutOfRangeError:
        pass

# Parallel execution:  [index, time from start of first load to return of current load]
# [ 0.          0.20026697]
# [ 1.          0.20084557]
# [ 2.          0.20095535]
# [ 3.          0.20048737]
# [ 4.          0.40154806]
```",0,,7,2017-11-10T13:48:06Z,CONTRIBUTOR
14441,GPU support for sparse_dense_binary_op_shared.cc,"stat:contributions welcome,type:feature","Are you planning to add GPU support for the operations defined in 
tensorflow/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc

I see that there is a GPU version for the sparse to dense Matrix-Multiplication version 
tensorflow/tensorflow/core/kernels/sparse_tensor_dense_matmul_op.cc 

but being able to use the GPU for Component-Wise operations would be very helpful.

Thank you.

Regards,
Pierre",0,,6,2017-11-10T07:49:04Z,NONE
14436,Setting up a Jenkins job for ppc64le for Tensorflow ,,"We are interested in setting up a Jenkins job for ppc64le for Tensorflow  @ http://ci.tensorflow.org/. We can work on providing and configuring a ppc64le slave node that can be hooked in to the Jenkins master. Please let me know if that can be done and if yes, what would be the minimum configuration requirements for the slave node? Thanks.",0,,9,2017-11-10T05:54:04Z,CONTRIBUTOR
14428,error when I try mpi_collectives features,stat:contributions welcome,"I want to try mpi_collectives features in tensorflow 1.4, but when I run mpi_allreduce_test.py example using python2.7 in contrib/mpi_collectives, I got error.

I installed tensorflow with openmpi.

mpirun -n 2 python mpi_allreduce_test.py
======================================================================
ERROR: test_mpi_allreduce (__main__.AllreduceTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""mpi_allreduce_test.py"", line 82, in test_mpi_allreduce
    average=average_allreduce)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/mpi_collectives/__init__.py"", line 160, in allreduce
    mpi_size = tf.cast(size(), tensor.dtype)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/mpi_collectives/mpi_ops.py"", line 71, in size
    return MPI_LIB.mpi_size(name=name)
AttributeError: 'module' object has no attribute 'mpi_size'

----------------------------------------------------------------------
Ran 2 tests in 0.034s
",0,,3,2017-11-10T01:12:09Z,NONE
14425,Support Windows builds through clang,stat:contributions welcome,"Right now, the tested configurations for Linux, Mac and Windows use gcc, clang and MSVC, as seen at 
https://www.tensorflow.org/install/install_sources#tested_source_configurations

Linux can be made to compile with clang, too, if you use the right magic trick (`--config=cuda_clang`). All that's left is Windows, which is probably the trickiest of the three.

Bonus points for allowing to cross-build for Windows under Linux. The main problem there might be with CUDA and getting its SDK installed on a Linux system (just a wild guess).

(Forked from an existing discussion under https://github.com/tensorflow/tensorflow/issues/12052)",0,,1,2017-11-09T23:40:45Z,NONE
14423,Using newer NVIDIA drivers causes TF to freeze the entire system if terminated,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.3 LTS (Xenial Xerus)""
- **TensorFlow installed from (source or binary)**: Binary, through `pip install tensorflow-gpu`
- **TensorFlow version (use command below)**: 1.3.0, Git Version - `v1.3.0-rc2-20-g0787eee`
- **Python version**: 2.7.13
- **CUDA/cuDNN version**: CUDA - 8.0.61, cuDNN - 6
- **GPU model and memory**: GeForce GTX 950M, 2GB

### Describe the problem
I had changed my NVIDIA driver version to 387.12 some time ago. After that, sometimes when I'd terminate TF code (either with `^C` in terminal or closing IPython tab in Spyder) it would successfully terminate with `KeyBoardInterrupt`. However the other times when I'd terminate, my entire computer would freeze and become unresponsive. Couldn't use `Ctrl + Alt + F1` to login into a virtual console and kill the process as keyboard also became unresponsive. However, if I was playing music through Spotify, it would continue playing without any interruption. 
This would happen with different files, not one specific file. But I noticed it would usually happen during the run of `sess.run(tf.global_variables_initializer())` in any of the files. It also has happened some other times like - 
 - Training completed in Spyder console and Python was idle and I closed the console tab in Spyder
 - Training completed in Spyder IPython tab and another file was run in terminal. I closed the IPython tab (which was idle) in Spyder when the new TF session in the terminal was initializing variables and then my computer froze completely. 

I don't think the contents of the code mattered. It would still freeze even if all my code did was define a variable and then initialize it.
So I tried reverting back to NVIDIA 384.98 to see if anything changed but it was still freezing. Now I've reverted back to NVIDIA 381.22 and I've tried terminating TF when it is initializing variables and so far the freezing hasn't happened. 

Another thing I'd noticed after changing to NVIDIA 387 is that `tf.global_variables_initializer()` became very slow, always taking 10+ seconds. I found #7755 where I saw it could be because of CUDA generating PTX. So I tried calling the init a second time in the same session and it would run in milliseconds. Same for calling init on CPU. I understand the init can be slow when run on GPU, however I never noticed it running slow prior to when I changed to a newer NVIDIA driver. Even after the revert to 381, it still runs slow. 


### Source code / logs
I'd really like to know what I can log and how to do that. I'm not sure if I can use gdb as my computer becomes unresponsive so I have no way of going into a terminal. 
Below is the sample code I would run and terminate during init to see if computer froze.
```
import tensorflow as tf
initial = tf.Variable(tf.truncated_normal([1,3], stddev=0.01, seed=1))
sess = tf.Session()
print ""Starting initialization""
sess.run(tf.global_variables_initializer())
```
",1,,7,2017-11-09T22:09:59Z,NONE
14374,Get all placeholders of the graph,"stat:contributions welcome,type:feature","According to [this](https://stackoverflow.com/questions/38933793/how-to-get-reference-by-name-of-variable-placeholder):, there are two ways to get placeholders of the graph. 

However, neither of them are very convenient.  

When I reuse a pretrained model, it is common to inspect the shape of **all placeholders**. But there is no API to **get all placeholders easily**.

Is it good for all placeholders to be added to a ""placeholder"" collection automatically? ",0,,6,2017-11-08T18:34:28Z,NONE
14369,configure.py should remember previous session as defaults,"stat:awaiting response,type:feature","### System information
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1454666/tf_env.txt)

Branch tensorflow-r1.4

### Describe the problem

Using instructions at https://www.tensorflow.org/install/install_sources to build from source.  When run configure.py a second time, defaults should be the options chosen the previous time.  Filling out all the questions again is exceedingly tedious.
",0,,4,2017-11-08T16:47:28Z,NONE
14366,Question: How to feed a batch of variable sized images to the Tensorflow C/C++ or Java API on Android?,stat:awaiting tensorflower,"I asked this question on Stackoverflow before but got no answers: https://stackoverflow.com/questions/46906269/how-to-process-variable-sized-images-with-tensorflow-java-api

In short: I have a CNN model that is doing some preprocessing of the images in the tensorflow graph before running the CNN on the data. This preprocessing includes resizing the images after normalizing them etc. Thus, I need to feed my model with a batch of differently sized images. While I could try to do this in OpenCV, I don't want to, as it seems messy to reimplement the complicated preprocessing and not as efficient. 

I found a way to do it in the standard version of tensorflow. I encoded the images as png strings and used the new Java API 1.4 to feed a batch of these strings to my tensorflow model. There I first decoded the png string to get back the image.

Unfortunately, this does not work on Android. There are several problems:
* png encoding is not available (I then used .bmp; but that has no grayscale support; I then made my gray image colored and make it gray again in the model (https://github.com/tensorflow/tensorflow/issues/13942) )
* The Android API does not seem to be able to handle string tensors (https://github.com/tensorflow/tensorflow/issues/14291)

So my question is, if it is possible to feed a model with a batch of differently sized images via the C/C++ or Java API on Android.",0,,5,2017-11-08T15:30:32Z,CONTRIBUTOR
14357,Following instructions in batch_normalization docs produces an exception,type:docs,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: Binary (pip install tensorflow)
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.3
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: (see the ""Source code"" section)

### Describe the problem
I was following the instructions for updating `moving_mean` and `moving_variance` by using the code snippet provided in [batch_normalization documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) and it resulted in an ""tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value"" exception.

### Source code / logs

Full instructions to reproduce: 

    git clone -b control-dependencies-exc https://github.com/naktinis/language-id.git ctrl-dep-exc
    cd ctrl-dep-exc/
    python3 -m venv venv
    . venv/bin/activate
    pip install tensorflow==1.4.0 Pillow
    python3 main.py --image-dir test_data/ --label-file test_data/labels.csv --model rnn

The specific code change that was enough to produce the exception (seems to match the snippet in the official [documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization)):
https://github.com/naktinis/language-id/commit/50740f

Full exception:
```
Traceback (most recent call last):
  File ""main.py"", line 173, in <module>
    tf.app.run(main=run_experiment)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""main.py"", line 165, in run_experiment
    hparams=params,
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 218, in run
    return _execute_schedule(experiment, schedule)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 46, in _execute_schedule
    return task()
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 625, in train_and_evaluate
    self.train(delay_secs=0)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 367, in train
    hooks=self._train_monitors + extra_hooks)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 807, in _call_train
    hooks=hooks)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 783, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1024, in run
    run_metadata=run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 827, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value

```",0,,6,2017-11-08T10:32:36Z,NONE
14353,variance goes negative when set layers.batch_norm reuse=True,,"#### TF 1.2.1 running on cpu & distributed version

#### layers.batch_norm set reuse=True
I use a sequence of items features which contains n (feature length) * N (sequence length) real-value features. And do batch_norm on each item of the sequence, then do some full_connected, etc. Finally concat them as dnn input.
Here is a simple code of the this. In order to make variance quickly go negative, I set decay=0.6.

	import tensorflow as tf
	from tensorflow.contrib import layers
	import numpy as np
	
	seq_length = 1000
	batch = 100
	length = 3
	place_holders = []
	seq_raw_f = []
	for i in range(seq_length):
	  x = True if i != 0 else None
	  sequence_place_holder = tf.placeholder(dtype=tf.float32, shape=[None, length])
	  place_holders.append(sequence_place_holder)
	  sequence = layers.batch_norm(inputs=sequence_place_holder, scope=""bn"", reuse=x, decay=0.6, scale=True,
	                               # updates_collections=None,
	                               zero_debias_moving_mean=True)
	  seq_raw_f.append(sequence)
	
	input = tf.concat(seq_raw_f, axis=0)
	
	update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
	
	sess = tf.Session()
	sess.run(tf.initialize_all_variables())
	
	place_holder = {}
	for i in range(seq_length):
	  place_holder[place_holders[i]] = np.random.rand(batch, length)
	
	for i in range(10000):
	  sess.run(update_ops, place_holder)
	  # sess.run(input, place_holder)
	  print sess.run(""bn/moving_variance:0"")
	  
#### variance can be :

	[ 0.08063364  0.08680637  0.08229597]
	[ 0.09141719  0.08313672  0.08208766]
	[ 0.07279671  0.08088712  0.08174741]
	[-0.1192904  -0.13598624 -0.31083935]
	[ 0.24966593  0.26548591  0.16420737]
	[ 0.07931737  0.07920683  0.0833094 ]
	[ 0.08559028  0.08299339  0.08146621]
	[ 0.08117087  0.08168832  0.08265808]
	

#### Reason probably the code below. 
When reuse=True, this code will subtract update_delta many times according to reuse times. Then the formula goes wrong. `a * m_v - (1-a) v -> a * m_v -N * (1-a) v.`
	
	update_delta = (variable - value) * decay
	return state_ops.assign_sub(variable, update_delta, name=scope)
	
when, updates_collections=None,  to force update variance, it still happened.

#### temporary fix
     
     if not zero_debias:
       # variable * decay + value * (1 - decay)
       state_ops.assign(variable, variable * decay + value * (1 - decay))

	

",0,,4,2017-11-08T08:21:05Z,NONE
14351,memmap changes,"cla: yes,stat:awaiting response","@andrewharp  @martinwicke 
Here is the new PR with changes as discussed in 12922
",2,,15,2017-11-08T08:02:15Z,NONE
14319,add not equal op to tf_op_files.txt,"awaiting review,cla: yes,stat:awaiting tensorflower",Adding the kernel op `NotEqual` to tf_ops_list.txt,1,,4,2017-11-07T11:39:26Z,CONTRIBUTOR
14318,updated keras backend with missing methods,"awaiting testing (then merge),cla: yes,stat:awaiting response","Hi,

The keras backend in the tensorflow repository is currently missing:

conv3d_transpose 
cumprod
cumsum
depthwise_conv2d
identity
local_conv1d
local_conv2d
logsumexp
tile

from the __init__.py file.

They are present in the _impl.backend package but haven't been brought through via imports in the __int__.py file.

Regards,

Alex



",1,,14,2017-11-07T10:44:42Z,NONE
14306,Segmentation fault when using bidirectional_dynamic_rnn + orthogonal_initializer,,"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Ubuntu 14.04 LTS (kernel: 3.16.0-77-generic)
- **TensorFlow installed from**: source
- **TensorFlow version**: 1.4.0rc1 (ae04712e3b74bc85445e12c90e375f980a907e2d) 
- **Python version**:  2.7.10
- **Bazel version**: 0.7.0
- **GCC/Compiler version**: 4.8.5
- **CUDA/cuDNN version**: 8.0/6.0.21
- **GPU model and memory**: Maxwell Titan X with 12 GiB memory
- **Exact command to reproduce**: see https://gist.github.com/nryant/57f7810e333fa94379cad201eeff24c8


### Describe the problem
I recently upgraded from 1.4.0-rc0 to 1.4.0-rc1 and found that a number of my model architectures fail to compile. After a bit of a detective work, I tracked the issue down to the use of ``bidirectional_dynamic_rnn`` in conjunction with a ``VariableScope`` in which ``initializer=orthogonal_initializer()``. See, for example, the test program at

    https://gist.github.com/nryant/57f7810e333fa94379cad201eeff24c8

Running this will result in a segfault with 1.4.0-rc1, but not with earlier versions. The problem is specific to the combination of ``orthogonal_initializer`` and ``bidirectional_dynamic_rnn`` and does not replicate with other initializers (e.g., ``uniform_unit_scaling_initializer``) or ``dynamic_rnn``. Nor does the choice of RNN cell appear to matter.
",0,,4,2017-11-07T00:47:34Z,NONE
14302,TF CNN benchmark resnet-50 not freeing up GPU memory after being terminated,,"Hi

I've ran some of the cnn benchmarks on an cluster that uses SLURM, on a Nvidia XP. One of my jobs got stuck. When I cancelled the script, it seems not to free up the GPU memory anymore after that.
totalMemory: 11.90GiB freeMemory: 365.94MiB

Now I can't run any more scripts. How can I free up my GPU memory again?

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: cnn_benchmarks 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Cluster node with amd cpu and NVidia XP
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 2.7 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) 
- **CUDA/cuDNN version**: Cuda8, Cudnn 6
- **GPU model and memory**: Nvidia XP
- **Exact command to reproduce**: python tf_cnn_benchmarks.py --model=resnet50 --num_gpus=1 --local_parameter_device=gpu

### Source code / logs
2017-11-06 21:45:35.243801: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX FMA
2017-11-06 21:45:35.832723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:41:00.0
totalMemory: 11.90GiB freeMemory: 365.94MiB
2017-11-06 21:45:35.832780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:41:00.0, compute capability: 6.1)
2017-11-06 21:45:46.271894: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 144.00MiB.  Current allocation summary follows.
2017-11-06 21:45:46.271976: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 18, Chunks in use: 18. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 576B client-requested in use in bin.
2017-11-06 21:45:46.271992: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.
2017-11-06 21:45:46.272005: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.
2017-11-06 21:45:46.272016: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272029: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 1, Chunks in use: 1. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 3.9KiB client-requested in use in bin.
2017-11-06 21:45:46.272040: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272052: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 2, Chunks in use: 2. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2017-11-06 21:45:46.272063: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272076: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 1, Chunks in use: 1. 90.8KiB allocated for chunks. 90.8KiB in use in bin. 90.8KiB client-requested in use in bin.
2017-11-06 21:45:46.272087: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272097: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272108: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272120: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.17MiB allocated for chunks. 1.17MiB in use in bin. 1.17MiB client-requested in use in bin.
2017-11-06 21:45:46.272131: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 5.91MiB allocated for chunks. 5.91MiB in use in bin. 5.91MiB client-requested in use in bin.
2017-11-06 21:45:46.272143: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 1, Chunks in use: 1. 5.06MiB allocated for chunks. 5.06MiB in use in bin. 5.06MiB client-requested in use in bin.
2017-11-06 21:45:46.272153: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272164: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272176: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272186: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272197: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 1, Chunks in use: 0. 128.66MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272208: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:46.272220: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 144.00MiB was 128.00MiB, Chunk State: 
2017-11-06 21:45:46.272296: I tensorflow/core/common_runtime/bfc_allocator.cc:649]   Size: 128.66MiB | Requested Size: 0B | in_use: 0, prev:   Size: 1.0KiB | Requested Size: 1.0KiB | in_use: 1
2017-11-06 21:45:46.272309: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400000 of size 1280
2017-11-06 21:45:46.272318: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400500 of size 256
2017-11-06 21:45:46.272326: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400600 of size 256
2017-11-06 21:45:46.272341: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400700 of size 256
2017-11-06 21:45:46.272350: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400800 of size 256
2017-11-06 21:45:46.272358: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400900 of size 256
2017-11-06 21:45:46.272368: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400a00 of size 768
2017-11-06 21:45:46.272376: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400d00 of size 256
2017-11-06 21:45:46.272385: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400e00 of size 256
2017-11-06 21:45:46.272393: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400f00 of size 1536
2017-11-06 21:45:46.272402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401500 of size 256
2017-11-06 21:45:46.272411: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401600 of size 256
2017-11-06 21:45:46.272420: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401700 of size 1536
2017-11-06 21:45:46.272428: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401d00 of size 256
2017-11-06 21:45:46.272438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401e00 of size 256
2017-11-06 21:45:46.272447: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401f00 of size 1024
2017-11-06 21:45:46.272455: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402300 of size 256
2017-11-06 21:45:46.272465: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402400 of size 256
2017-11-06 21:45:46.272474: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402500 of size 16384
2017-11-06 21:45:46.272482: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406500 of size 256
2017-11-06 21:45:46.272491: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406600 of size 256
2017-11-06 21:45:46.272499: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406700 of size 16384
2017-11-06 21:45:46.272507: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a700 of size 256
2017-11-06 21:45:46.272516: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a800 of size 256
2017-11-06 21:45:46.272528: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a900 of size 4096
2017-11-06 21:45:46.272537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40b900 of size 92928
2017-11-06 21:45:46.272546: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422400 of size 256
2017-11-06 21:45:46.272554: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422500 of size 1228800
2017-11-06 21:45:46.272562: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e500 of size 768
2017-11-06 21:45:46.272571: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e800 of size 2654208
2017-11-06 21:45:46.272580: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6800 of size 1536
2017-11-06 21:45:46.272589: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6e00 of size 5308416
2017-11-06 21:45:46.272597: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece6e00 of size 1536
2017-11-06 21:45:46.272606: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece7400 of size 3538944
2017-11-06 21:45:46.272614: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047400 of size 1024
2017-11-06 21:45:46.272623: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f047800 of size 134907904
2017-11-06 21:45:46.272631: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2017-11-06 21:45:46.272645: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 18 Chunks of size 256 totalling 4.5KiB
2017-11-06 21:45:46.272655: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 768 totalling 1.5KiB
2017-11-06 21:45:46.272665: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1024 totalling 2.0KiB
2017-11-06 21:45:46.272675: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-06 21:45:46.272686: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 1536 totalling 6.0KiB
2017-11-06 21:45:46.272695: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 4096 totalling 4.0KiB
2017-11-06 21:45:46.272706: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 16384 totalling 32.0KiB
2017-11-06 21:45:46.272716: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 92928 totalling 90.8KiB
2017-11-06 21:45:46.272725: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1228800 totalling 1.17MiB
2017-11-06 21:45:46.272735: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2654208 totalling 2.53MiB
2017-11-06 21:45:46.272749: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 3538944 totalling 3.38MiB
2017-11-06 21:45:46.272760: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5308416 totalling 5.06MiB
2017-11-06 21:45:46.272772: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 12.28MiB
2017-11-06 21:45:46.272786: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                   147783680
InUse:                    12875776
MaxInUse:                 12875776
NumAllocs:                      35
MaxAllocSize:              5308416

2017-11-06 21:45:46.272799: W tensorflow/core/common_runtime/bfc_allocator.cc:277] *********___________________________________________________________________________________________
2017-11-06 21:45:46.272823: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[9216,4096]
2017-11-06 21:45:56.273596: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 64.00MiB.  Current allocation summary follows.
2017-11-06 21:45:56.273635: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 18, Chunks in use: 18. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 576B client-requested in use in bin.
2017-11-06 21:45:56.273649: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.
2017-11-06 21:45:56.273661: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.
2017-11-06 21:45:56.273672: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273684: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 2, Chunks in use: 2. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 7.8KiB client-requested in use in bin.
2017-11-06 21:45:56.273695: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273707: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 4, Chunks in use: 4. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.
2017-11-06 21:45:56.273718: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273731: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 2, Chunks in use: 1. 181.5KiB allocated for chunks. 90.8KiB in use in bin. 90.8KiB client-requested in use in bin.
2017-11-06 21:45:56.273742: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273754: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273765: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273777: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 2, Chunks in use: 1. 2.34MiB allocated for chunks. 1.17MiB in use in bin. 1.17MiB client-requested in use in bin.
2017-11-06 21:45:56.273788: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 3, Chunks in use: 1. 8.44MiB allocated for chunks. 2.53MiB in use in bin. 2.53MiB client-requested in use in bin.
2017-11-06 21:45:56.273800: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 2, Chunks in use: 2. 10.12MiB allocated for chunks. 10.12MiB in use in bin. 8.44MiB client-requested in use in bin.
2017-11-06 21:45:56.273813: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 1, Chunks in use: 1. 15.64MiB allocated for chunks. 15.64MiB in use in bin. 15.64MiB client-requested in use in bin.
2017-11-06 21:45:56.273823: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273834: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 1, Chunks in use: 0. 40.13MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273852: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 64.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin.
2017-11-06 21:45:56.273863: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273874: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-06 21:45:56.273884: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 64.00MiB was 64.00MiB, Chunk State: 
2017-11-06 21:45:56.273895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400000 of size 1280
2017-11-06 21:45:56.273904: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400500 of size 256
2017-11-06 21:45:56.273913: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400600 of size 256
2017-11-06 21:45:56.273921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400700 of size 256
2017-11-06 21:45:56.273929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400800 of size 256
2017-11-06 21:45:56.273937: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400900 of size 256
2017-11-06 21:45:56.273946: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400a00 of size 768
2017-11-06 21:45:56.273955: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400d00 of size 256
2017-11-06 21:45:56.273963: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400e00 of size 256
2017-11-06 21:45:56.273972: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400f00 of size 1536
2017-11-06 21:45:56.273981: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401500 of size 256
2017-11-06 21:45:56.273989: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401600 of size 256
2017-11-06 21:45:56.273997: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401700 of size 1536
2017-11-06 21:45:56.274005: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401d00 of size 256
2017-11-06 21:45:56.274014: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401e00 of size 256
2017-11-06 21:45:56.274029: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401f00 of size 1024
2017-11-06 21:45:56.274038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402300 of size 256
2017-11-06 21:45:56.274046: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402400 of size 256
2017-11-06 21:45:56.274056: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402500 of size 16384
2017-11-06 21:45:56.274065: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406500 of size 256
2017-11-06 21:45:56.274074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406600 of size 256
2017-11-06 21:45:56.274084: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406700 of size 16384
2017-11-06 21:45:56.274093: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a700 of size 256
2017-11-06 21:45:56.274101: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a800 of size 256
2017-11-06 21:45:56.274109: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a900 of size 4096
2017-11-06 21:45:56.274117: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422400 of size 256
2017-11-06 21:45:56.274126: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e500 of size 768
2017-11-06 21:45:56.274138: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6800 of size 1536
2017-11-06 21:45:56.274149: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6e00 of size 5308416
2017-11-06 21:45:56.274157: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece6e00 of size 1536
2017-11-06 21:45:56.274166: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047400 of size 1024
2017-11-06 21:45:56.274174: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047800 of size 16384
2017-11-06 21:45:56.274182: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f04b800 of size 67108864
2017-11-06 21:45:56.274191: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021304b800 of size 16384
2017-11-06 21:45:56.274199: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021304f800 of size 16400384
2017-11-06 21:45:56.274207: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10213ff3800 of size 4096
2017-11-06 21:45:56.274216: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10213ff4800 of size 92928
2017-11-06 21:45:56.274225: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021400b300 of size 1228800
2017-11-06 21:45:56.274299: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10214137300 of size 2654208
2017-11-06 21:45:56.274308: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102143bf300 of size 5308416
2017-11-06 21:45:56.274317: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e40b900 of size 92928
2017-11-06 21:45:56.274325: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e422500 of size 1228800
2017-11-06 21:45:56.274333: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e54e800 of size 2654208
2017-11-06 21:45:56.274342: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020ece7400 of size 3538944
2017-11-06 21:45:56.274351: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x102148cf300 of size 42077440
2017-11-06 21:45:56.274359: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2017-11-06 21:45:56.274369: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 18 Chunks of size 256 totalling 4.5KiB
2017-11-06 21:45:56.274381: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 768 totalling 1.5KiB
2017-11-06 21:45:56.274391: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1024 totalling 2.0KiB
2017-11-06 21:45:56.274401: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-06 21:45:56.274412: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 1536 totalling 6.0KiB
2017-11-06 21:45:56.274422: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 4096 totalling 8.0KiB
2017-11-06 21:45:56.274433: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 16384 totalling 64.0KiB
2017-11-06 21:45:56.274443: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 92928 totalling 90.8KiB
2017-11-06 21:45:56.274454: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1228800 totalling 1.17MiB
2017-11-06 21:45:56.274463: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2654208 totalling 2.53MiB
2017-11-06 21:45:56.274474: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 5308416 totalling 10.12MiB
2017-11-06 21:45:56.274489: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 16400384 totalling 15.64MiB
2017-11-06 21:45:56.274500: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 67108864 totalling 64.00MiB
2017-11-06 21:45:56.274510: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 93.64MiB
2017-11-06 21:45:56.274522: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                   147783680
InUse:                    98191360
MaxInUse:                101730304
NumAllocs:                      45
MaxAllocSize:             67108864

2017-11-06 21:45:56.274536: W tensorflow/core/common_runtime/bfc_allocator.cc:277] *_*****_****************************************************************____________________________
2017-11-06 21:45:56.274550: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[4096,4096]
TensorFlow:  1.4
Model:       alexnet
Mode:        training
SingleSess:  False
Batch size:  32 global
             32 per device
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating model
Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 46, in <module>
    tf.app.run()
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tf_cnn_benchmarks.py"", line 42, in main
    bench.run()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 892, in run
    return self._benchmark_cnn()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1068, in _benchmark_cnn
    start_standard_services=start_standard_services) as sess:
  File ""/usr/lib64/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 964, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 792, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 953, in managed_session
    start_standard_services=start_standard_services)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 708, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 279, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[9216,4096]
	 [[Node: v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[""loc:@v/cg/affine0/weights""], dtype=DT_FLOAT, seed=1234, seed2=149, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](v/cg/affine0/weights/Initializer/truncated_normal/shape)]]

Caused by op u'v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal', defined at:
  File ""tf_cnn_benchmarks.py"", line 46, in <module>
    tf.app.run()
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tf_cnn_benchmarks.py"", line 42, in main
    bench.run()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 892, in run
    return self._benchmark_cnn()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 986, in _benchmark_cnn
    (image_producer_ops, enqueue_ops, fetches) = self._build_model()
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1236, in _build_model
    gpu_compute_stage_ops, gpu_grad_stage_ops)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1524, in add_forward_pass_and_gradients
    self.model.add_inference(network)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/models/alexnet_model.py"", line 45, in add_inference
    cnn.affine(4096)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 311, in affine
    initializer=tf.truncated_normal_initializer(stddev=stddev))
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 117, in get_variable
    var = tf.get_variable(name, shape, dtype, *args, **kwargs)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1203, in get_variable
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1092, in get_variable
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 417, in get_variable
    return custom_getter(**custom_getter_kwargs)
  File ""/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 86, in inner_custom_getter
    var = getter(*args, **kwargs)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 394, in _true_getter
    use_resource=use_resource, constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 805, in _get_single_variable
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 213, in __init__
    constraint=constraint)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 303, in _init_from_args
    initial_value(), name=""initial_value"", dtype=dtype)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 779, in <lambda>
    shape.as_list(), dtype=dtype, partition_info=partition_info)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 309, in __call__
    shape, self.mean, self.stddev, dtype, seed=self.seed)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py"", line 172, in truncated_normal
    shape_tensor, dtype, seed=seed1, seed2=seed2)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_random_ops.py"", line 588, in _truncated_normal
    name=name)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[9216,4096]
	 [[Node: v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[""loc:@v/cg/affine0/weights""], dtype=DT_FLOAT, seed=1234, seed2=149, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](v/cg/affine0/weights/Initializer/truncated_normal/shape)]]

srun: error: gpu08: task 0: Exited with exit code 1

",1,,5,2017-11-06T21:56:19Z,NONE
14292,Can't import contrib.boosted_trees,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
== cat /etc/issue ===============================================                                               
Linux 5508912-0913 4.4.0-43-Microsoft #1-Microsoft Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux  
VERSION=""16.04.3 LTS (Xenial Xerus)""                                                                            
VERSION_ID=""16.04""                                                                                              
VERSION_CODENAME=xenial                                                                                         
                                                                                                                
== are we in docker =============================================                                               
No                                                                                                              
                                                                                                                
== compiler =====================================================                                               
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609                                                              
Copyright (C) 2015 Free Software Foundation, Inc.                                                               
This is free software; see the source for copying conditions.  There is NO                                      
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.                                     
                                                                                                                
                                                                                                                
== uname -a =====================================================                                               
Linux 5508912-0913 4.4.0-43-Microsoft #1-Microsoft Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux  
                                                                                                                
== check pips ===================================================                                               
numpy (1.13.3)                                                                                                  
protobuf (3.4.0)                                                                                                
tensorflow (1.4.0)                                                                                              
tensorflow-tensorboard (0.4.0rc1)                                                                               
                                                                                                                
== check for virtualenv =========================================                                               
False                                                                                                           
                                                                                                                
== tensorflow import ============================================                                               
tf.VERSION = 1.4.0                                                                                              
tf.GIT_VERSION = v1.4.0-0-gd752244                                                                              
tf.COMPILER_VERSION = v1.4.0-0-gd752244                                                                         
Sanity check: array([1], dtype=int32)                                                                           
                                                                                                                
== env ==========================================================                                               
LD_LIBRARY_PATH is unset                                                                                        
DYLD_LIBRARY_PATH is unset                                                                                      
                                                                                                                
== nvidia-smi ===================================================                                               
../../tf_env_collect.sh: line 105: nvidia-smi: command not found                                                
                                                                                                                
== cuda libs  ===================================================                                               

### Describe the problem
Can't import the boosted_trees module.
Boosted_trees isn't properly listed in contrib/__init__.py, so I get:
>>> import tensorflow as tf
>>> est = tf.contrib.boosted_trees.estimator_batch.estimator.GradientBoostedDecisionTreeClassifier()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/lazy_loader.py"", line 54, in __getattr__
    return getattr(module, item)
AttributeError: 'module' object has no attribute 'boosted_trees'


### Source code / logs
See above.
",0,,12,2017-11-06T15:10:05Z,NONE
14291,map_fn not working with string tensor on Android,stat:awaiting tensorflower,"It seems that the tensorflow Android version (1.4.0) does not include the kernel for TensorArrayScatterV3 for string tensors (see stacktrace below). This leads to the problem that I cannot use map_fn with string tensors on Android. 

The same code and model runs fine with the desktop Java API in the same version. 

Can you please add the missing kernel?

Stacktrace

```
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'TensorArrayScatterV3' with these attrs.  Registered devices: [CPU], Registered kernels:
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_BOOL]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_FLOAT]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_INT32]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err: 	 [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_STRING, _class=[""loc:@image_strings""]](map/TensorArray, map/TensorArrayUnstack/range, image_strings, map/TensorArray:1)]]
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.report(FutureTask.java:94)
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.get(FutureTask.java:164)
11-06 15:14:45.760 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.neuronalnetwork.service.TaskWorkerLoop$Loop.run(TaskWorkerLoop.java:71)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at java.lang.Thread.run(Thread.java:762)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err: Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'TensorArrayScatterV3' with these attrs.  Registered devices: [CPU], Registered kernels:
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_BOOL]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_FLOAT]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:   device='CPU'; T in [DT_INT32]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err: 	 [[Node: map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_STRING, _class=[""loc:@image_strings""]](map/TensorArray, map/TensorArrayUnstack/range, image_strings, map/TensorArray:1)]]
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session.run(Native Method)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session.access$100(Session.java:48)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session$Runner.runHelper(Session.java:298)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at org.tensorflow.Session$Runner.run(Session.java:248)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.brain.Api.run(Api.java:39)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.Evaluator.evaluateBatch(Evaluator.java:66)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.Evaluator.evaluate(Evaluator.java:54)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.EvaluationService.evaluateNN(EvaluationService.java:114)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.client.api.EvaluationService.evaluateSections(EvaluationService.java:73)
11-06 15:14:45.761 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.neuronalnetwork.service.engine.NetworkEngine.lambda$calculate$0(NetworkEngine.java:59)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at de.test.neuronalnetwork.service.engine.NetworkEngine$$Lambda$1.call(Unknown Source)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.run(FutureTask.java:237)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:428)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.FutureTask.run(FutureTask.java:237)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err:     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)
11-06 15:14:45.762 32605-1644/de.test.android.fisheye.local W/System.err: 	... 1 more
```",0,,6,2017-11-06T14:21:30Z,CONTRIBUTOR
14283,Can't use estimator + dataset and train for less than one epoch,"stat:awaiting tensorflower,type:feature","TensorFlow 1.4 moves TF Dataset to core (tf.data.Dataset) and doc/tutorial suggest to use tf.estimator to train models.

However, as recommended at the end of this [page](https://www.tensorflow.org/programmers_guide/datasets), the Dataset object and its iterator must be instantiated inside the input_fn function. This means the iterations through the dataset will start over for each call to estimator.train(input_fn, steps). Thus, calling is with steps < number of samples in epoch, will lead to train the model on a subset of the dataset.

Thus my question. Is it possible to implement something like this with Estimator + Dataset:

```
for i in range(num_epochs):
    # Train for some steps
    estimator.train(input_fn=train_input_fn, steps=valid_freq)

   validation_iterator.
    # Evaluate on the validation set (steps=None, we evaluate on the full validation set)
   estimator.evaluate(input_fn=valid_input_fn)
```

without starting training samples iterations from scratch at each call to `estimator.train(input_fn=train_input_fn, steps=valid_freq)
`

For example, unlike [here](https://www.tensorflow.org/programmers_guide/datasets), instantiate the Dataset and its iterator outside input_fn. I tried it but it does not work because then the input (from the dataset iterator) and the model (from the estimator model_fn) are not part of the same graph.

Thanks",0,,6,2017-11-06T09:50:06Z,NONE
14278,Please provide a better solution for commit 848123e61c95b030a5034b2cdaa504870ebf7da6,stat:awaiting tensorflower,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.4
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
0.7.0
- **GCC/Compiler version (if compiling from source)**:
VS 2017
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
bazel --output_base C:\os\t build --config=monolithic --incompatible_disallow_set_constructor=false --action_env=USE_DYNAMIC_CRT=1  --color=no --compilation_mode fastbuild --verbose_failures --experimental_ui  //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
Compile tensorflow in fastbuild mode( release mode,but without any optimization) failed.

### Source code / logs
848123e61c95b030a5034b2cdaa504870ebf7da6 is a dirty hack for this problem.  First,  you shouldn't simply remove the double type kernel in Windows Debug build, it will make some unitests fail.   Second, this fix doesn't fit for the ""fastbuild"" mode, as ""_DEBUG"" is not defined.

The root cause is VC cannot eliminate the dead code which is introduced by std::is_same. This problem also exists in tensorflow/core/kernels/depthtospace_op.cc and tensorflow/core/kernels/spacetodepth_op.cc.

",0,,4,2017-11-06T07:35:32Z,CONTRIBUTOR
14251,Add int64 support of `axis` (`Tidx`) for ConcatV2,"awaiting review,cla: yes,stat:awaiting tensorflower","In `array_ops.cc`, it was specified that ConcatV2 support both int32 and int64 data types of `axis` (`Tidx`):
```
    .Attr(""Tidx: {int32, int64} = DT_INT32"")
```

However, in actual kernel implementations only int32 is supported as there is an unnecessary `.TypeConstraint<int32>(""Tidx"")` specified.

This fix tries to address the discrepancy between the ops declaration and kernel registration by adding the int64 axis (`Tidx`) support for `ConcatV2`.

This fix removes the TypeConstraint and adds additional processing so that differnt types (int32 or int64) of `axis` could be processed correctly.

Additional test cases have been added to cover the changes as well.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,4,2017-11-04T22:31:04Z,MEMBER
14248,Keras backend functionality changed?,,"Hi,

I have been using keras from within tensorflow since it was included into the contrib package - but it seems that in the 1.4 release the keras backend is missing some functionality ...

For example:

    >> from tensorflow.python.keras import backend as K
    >> K.tile
    Traceback (most recent call last):
      File ""<stdin>"", line 1, in <module>
    AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'tile'

Whereas in tensorflow 1.1:

    >>> from tensorflow.contrib.keras.python.keras import backend as K
    >>> K.tile
    <function tile at 0x7fbd9024fb70>

And using pure keras:

    >>> from keras import backend as K
    Using TensorFlow backend.
    
    >>> K.tile
    <function tile at 0x7fe9743c5950>


Is this just an omission, or has the functionality been deliberately removed?  I know I can use the equivalent tensorflow operation - but it's nice to be able to use a reasonably portable api and if I wanted to switch backend I could just change the import path.  I also try not too mix keras and tensorflow too much as I think the code is more readable just using one!

Regards,

Alex

",0,,7,2017-11-04T17:55:43Z,NONE
14245,Issue building libtensorflow_cc.so for arm64-v8a,"stat:community support,type:build/install","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.5.1
- **GCC/Compiler version (if compiling from source)**: 6.0.3
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

> bazel build -c opt //tensorflow:libtensorflow_cc.so    --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=arm64-v8a


### Describe the problem
I am trying to build libtensorflow_cc.so for android for arm64-v8a  architecture.
I needed it to create and train a model file in Android NDK through C++ at runtime.
I was able do so on Desktop using C++ with the help of 'libtensorflow_cc.so' generated by 

> bazel build -c opt //tensorflow:libtensorflow_cc.so

, but wanted to integrate with Android NDK now and train on mobile.

I tried with 'libtensorflow.so' , but i get below error

> tensorflow_jni.cc:359 Non-OK-status: session->Create (graph_def) status: Invalid argument: No OpKernel was registered to support Op 'SparseSoftmaxCrossEntropyWithLogits' with these attrs.  Registered devices: [CPU], Registered kernels:
>                                                                    <no registered kernels>
>                                                                  
>                                                                  	 [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64](add, Cast)]]

I also tried with 'libtensorflow_inference.so' but I get many undefined reference errors like below

> In function `tensorflow::TensorShapeRep::~TensorShapeRep()':
> /home/ashok/AndroidStudioProjects/Android-arm64-v8a-dnn/facerecognitionlibrary/jni-build/jni/include/include1/tensorflow/core/framework/tensor_shape.h:492: undefined reference to `tensorflow::TensorShapeRep::DestructorOutOfLine()'
> ./obj/local/arm64-v8a/objs-debug/tensorflow_cc1/tensorflowTrian_jni.o: In function `std::pair<std::string, tensorflow::Tensor>::~pair()':
> /home/ashok/Ashok/android-ndk-r12b/sources/cxx-stl/gnu-libstdc++/4.9/include/bits/stl_pair.h:96: undefined reference to `tensorflow::Tensor::~Tensor()'
> ./obj/local/arm64-v8a/objs-debug/tensorflow_cc1/tensorflowTrian_jni.o: In function `std::string* tensorflow::internal::MakeCheckOpString<long, int>(long const&, int const&, char const*)':
> /home/ashok/AndroidStudioProjects/Android-arm64-v8a-dnn/facerecognitionlibrary/jni-build/jni/include/include1/tensorflow/core/platform/default/logging.h:184: undefined reference to `tensorflow::internal::CheckOpMessageBuilder::CheckOpMessageBuilder(char const*)'



### Source code / logs for

> bazel build -c opt //tensorflow:libtensorflow_cc.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=arm64-v8a

> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there
> WARNING: /home/ashok/Ashok/tensorflow/tensorflow/core/BUILD:952:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there
> ERROR: /home/ashok/Ashok/tensorflow/tensorflow/c/eager/BUILD:11:1: in deps attribute of cc_library rule //tensorflow/c/eager:c_api: target '//tensorflow/c/eager:c_api_internal' does not exist. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/ashok/Ashok/tensorflow/tensorflow/tensorflow.bzl:667:12
> ERROR: Analysis of target '//tensorflow:libtensorflow_cc.so' failed; build aborted
> INFO: Elapsed time: 0.252s
> FAILED: Build did NOT complete successfully (0 packages loaded)
> 

Stackoverflow - https://stackoverflow.com/questions/47108420/issue-building-libtensorflow-cc-so-for-arm64-v8a",0,,2,2017-11-04T07:02:16Z,NONE
14237,Added an option to `kernel` to `skip_metropolis_step`.,"cla: yes,stat:awaiting response",Fix #14221 ,1,,35,2017-11-04T01:21:20Z,NONE
14233,graph_editor doesn't update graph_version,"stat:contributions welcome,type:bug/performance","Symptom:
1. session.run
2. modify the graph with tf.contrib.graph_editor
3. session.run

Session.run in step 3 will use the same graph as in step 1 (pre-modification)

The reason is that session.py looks at [self._graph.version]( https://github.com/tensorflow/tensorflow/blob/4e75ae1f1e8c6479cfa86fde1a940453945e6671/tensorflow/python/client/session.py#L1345) when deciding whether to trigger TF_ExtendGraph. Since `graph_editor` doesn't update graph_version, it will reuse the previous graph.

Suggestion: every graph-modifying method in `graph_editor` should increment `version` attribute for the graph

@purpledog ",0,,2,2017-11-03T22:32:02Z,CONTRIBUTOR
14232,[Feature Request] Automatic ClusterSpec Propagation for multiple hosts,stat:awaiting response,"Currently, when launching a distributed TensorFlow job, user need to manually input all the worker hosts' IP and port number. This is not too convenient and does not scale well. It would be really nice to have the native TensorFlow functionality that workers can automatically register themselves on master service without knowing all the host IP and port beforehand. Not sure if there is existing solution to solve this problem. But I used some of the building blocks (ClusterSpec Propagation and ClusterResolver) to enable this feature on my client code. Please let me know if it is a good approach to do this, I'd love to contribute if there's interest in this functionality. 

The solution I have involve the following steps:
1) Master service start server with user specified port and wait for all workers to register
2) Worker register themselves by sending ClusterSpec to Master service and wait for response
3) Master service waits until numbers of workers registered matches requested worker number
4) Master service merges ClusterSpecs and propagates to all registered workers
5) Master service and workers continues",2,,15,2017-11-03T21:39:32Z,NONE
14221,bayeslfow.hmc - provide option for skipping the MH step,"stat:contributions welcome,type:feature","Currently `tf.contrib.bayesflow.hmc.kernel` returns directly the update x and value of the potential after the Metropolis-Hasting steps. It would be useful to have an option to omitting the MH step. This, for instance, is required for implementing HVI [1], where we want to propagate gradients through the HMC step and not reject any samples:

[1] https://arxiv.org/pdf/1410.6460.pdf
",0,,1,2017-11-03T17:26:32Z,NONE
14219,"tf.layers.Network is in the documentation, but not the library","stat:awaiting tensorflower,type:docs","**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.6
- **TensorFlow installed from (source or binary)**: source, latest 1.4 branch
- **TensorFlow version (use command below)**: v1.4.0-rc1-12-gd752244fba 1.4.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

see below

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

The 1.4 version of the documentation mentions tf.layers.Network in its examples of using the new function based layers (here is a link to the specific doc, https://www.tensorflow.org/api_docs/python/tf/layers/Input), so all you have to do is copy/paste the example code and run it.

### Source code / logs
the most basic code to verify is

```
import tensorflow as tf
print(tf.layers.Network)
```

on my system this results in 

```
AttributeError: module 'tensorflow.python.layers.layers' has no attribute 'Network'
```",0,,8,2017-11-03T16:14:33Z,NONE
14217,ios documentation for tensorflow-experimental,"stat:awaiting tensorflower,type:docs","Could we have a proper documentation (either in the pod files with a custom header) or in the readme?
It would help greatly to have the list of available methods and what they do (unless method name is self-explanatory).
Having to dig into ~20 objective-c files to get a grasp of what is possible in swift is not equivalent to a proper documentation",0,,5,2017-11-03T15:19:13Z,NONE
14209,Why eager concat  inputs?,"comp:eager,stat:awaiting tensorflower","I am using eager to implement a seq2seq model. 
Here is a [toy model](https://github.com/soenkyo/toy_seq2seq_4_debug):
No error arise in forward calculate, but in backprop, I get:

`Traceback (most recent call last):
  File ""/home/usr/eager/test.py"", line 18, in <module>
    tf.app.run()
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/usr/eager/test.py"", line 14, in main
    empirical_loss, gradients_and_variables = cal_gradient()
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 362, in grad_fn
    sources)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/imperative_grad.py"", line 230, in imperative_grad
    result.append(vspace.aggregate_fn(g))
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 716, in _aggregate_grads
    for x in indexed_slices_list], 0)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1110, in concat
    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 719, in _concat_v2
    attrs=_attrs, ctx=_ctx, name=name)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/tensorflow/python/eager/execute.py"", line 67, in execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""/home/usr/miniconda2/lib/python2.7/site-packages/six.py"", line 718, in raise_from
    raise value
tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [16,100] vs. shape[1] = [16,400] [Op:ConcatV2] name: concat
`
",0,,5,2017-11-03T13:06:32Z,NONE
14205,TensorFlow r1.4 does not be compiled from 32bit environment.,"stat:community support,type:build/install","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: None
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Slackware 14.2 32bit
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.4
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 5.3.0
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package and set optimization flags to -march=i686

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Installing TensorFlow r1.4 on a Linux system with 32bit kernel does not work. I think the error comes from the configuration of the nsync, which does not care 32bit environment. 

I googled it, and found a workaround.
[https://lengerrong.blogspot.kr/2017/09/fix-up-configurable-attribute-copts.html](https://lengerrong.blogspot.kr/2017/09/fix-up-configurable-attribute-copts.html)

and added 

`""//conditions""default"": []'`

to the appropriate place.

However, I think that it will be much better if the official configure system of the TensorFlow supports the 32bit system.

Thanks.
Sungjin.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

None.
",0,,1,2017-11-03T08:23:44Z,NONE
14196,Dataset memory bottleneck not showing in debug mode,,"im fitting word2vec models using distributed gpus which require me to assemble multiple towers and so copy my model several times over. to load data i am using the get_next method of a contrib.dataset iterator initialized with one_shot. before starting up i run into the 2gb protobuf memory bottleneck. so in debug mode i compared 3 models: one where dataset is given full data, another where dataset is given 30% of my data and a last where dataset is given 1% of my data. the first doesnt run. but most importantly, for the second two, i compared the size of all of my tensors and they are all the same. this makes debugging difficult. any thoughts? i suspect there's something going on with folding of constants? 

Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,5,2017-11-03T02:14:41Z,NONE
14194,Make CMake on TensorFlow Incrementally Compile on Windows,stat:contributions welcome,"I'm working with the tensorflow r1.4 branch on Windows 7 with Visual Studio 2015.   When I configure

```
cmake C:\Users\Kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/Users/Kevin/dev/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:/ProgramData/Anaconda3/python.exe -DPYTHON_LIBRARIES=C:/ProgramData/Anaconda3/libs/python35.lib -DPYTHON_INCLUDE_DIR=C:\ProgramData\Anaconda3\include -DNUMPY_INCLUDE_DIR=C:\ProgramData\Anaconda3\Lib\site-packages\numpy\core\include -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0""
```
and run

```
powershell ""MSBuild /m /p:Configuration=Release tf_python_build_pip_package.vcxproj | tee msbuild.txt""
```
the build always compiles all the projects, even the projects already compiled.

Looking at the first few lines of msbuild.txt I see

```
Microsoft (R) Build Engine version 14.0.25420.1
Copyright (C) Microsoft Corporation. All rights reserved.

Build started 11/2/2017 4:35:58 PM.
     1>Project ""C:\users\kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake\tf_python_build_pip_package.vcxproj"" on node 1 (default targets).
     1>Project ""C:\users\kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake\tf_python_build_pip_package.vcxproj"" (1) is building ""C:\Users\Kevin\dev\tensorflow-r1.4\tensorflow\contrib\cmake\ZERO_CHECK.vcxproj"" (2) on node 1 (default targets).
     2>InitializeBuildStatus:
         Creating ""x64\Release\ZERO_CHECK\ZERO_CHECK.tlog\unsuccessfulbuild"" because ""AlwaysCreate"" was specified.
       CustomBuild:
         Checking Build System
         CMake is re-running because C:/Users/Kevin/dev/tensorflow-r1.4/tensorflow/contrib/cmake/CMakeFiles/generate.stamp is out-of-date.
           the file 'C:/Users/Kevin/dev/tensorflow-r1.4/tensorflow/contrib/cmake/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/tf_core_gpu_kernels_generated_cwise_op_gpu_igammas.cu.cc.obj.depend'
           is newer than 'C:/Users/Kevin/dev/tensorflow-r1.4/tensorflow/contrib/cmake/CMakeFiles/generate.stamp.depend'
           result='-1'
         -- Configuring done
```
The issue isn't the multicore builds, I'm just using multicore builds to speed up the overall build, which takes 5 hours on one core.

The problem appears to be that the generate.stamp isn't what's expected.",0,,6,2017-11-02T23:35:27Z,NONE
14193,"TypeError: Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.","stat:awaiting response,type:support","From this file: https://github.com/llSourcell/pong_neural_network_live/blob/master/RL.py

I've updated the lines 

    #first convolutional layer. bias vector
    #creates an empty tensor with all elements set to zero with a shape
    W_conv1 = tf.Variable(tf.zeros([8, 8, 4, 32]) , name='W_conv1')
    b_conv1 = tf.Variable(tf.zeros([32]), name='b_conv1')

    W_conv2 = tf.Variable(tf.zeros([4, 4, 32, 64]), name='W_conv2')
    b_conv2 = tf.Variable(tf.zeros([64]), name='b_conv2')

    W_conv3 = tf.Variable(tf.zeros([3, 3, 64, 64]), name='W_conv3')
    b_conv3 = tf.Variable(tf.zeros([64]), name='b_conv3')

    W_fc4 = tf.Variable(tf.zeros([3136, 784]), name='W_fc4')
    b_fc4 = tf.Variable(tf.zeros([784]), name='b_fc4')

    W_fc5 = tf.Variable(tf.zeros([784, ACTIONS]), name='W_fc5')
    b_fc5 = tf.Variable(tf.zeros([ACTIONS]), name='b_fc5')

and:

    saver.save(sess, './' + 'pong' + '-dqn', global_step = timestamp )

and in:

    def main():
        # ////
        tf.reset_default_graph()    
        imported_meta = tf.train.import_meta_graph('./' + 'pong' + '-dqn-' + '48000' + '.meta')  
        imported_meta.restore(sess, tf.train.latest_checkpoint('./'))
        # ////

To try and restore the model but I get this error:

TypeError: Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.

When I try this:

     graph = tf.get_default_graph() 
     W_conv1 = graph.get_tensor_by_name(""W_conv1:0"")
     b_conv1 = graph.get_tensor_by_name(""wb_conv1:0"") 
     W_conv2 = graph.get_tensor_by_name(""W_conv2:0"")
     b_conv2 = graph.get_tensor_by_name(""wb_conv2:0"") 
     W_conv3 = graph.get_tensor_by_name(""W_conv3:0"")
     b_conv3 = graph.get_tensor_by_name(""b_conv3:0"") 
     W_fc4 = graph.get_tensor_by_name(""W_fc4:0"")
     b_fc4 = graph.get_tensor_by_name(""b_fc4:0"") 
     W_fc5 = graph.get_tensor_by_name(""W_fc5:0"")
     b_fc5 = graph.get_tensor_by_name(""b_fc5:0"")  

I get this error:

""The name 'W_conv1:0' refers to a Tensor which does not exist. The operation, 'W_conv1', does not exist in the graph.

Why is this happening? I've created my game in pygame and I'm trying to connect it to the RL. I'd like to make sure I can save and load my progress. I'm just having trouble with the logic of how to save and load.

Thanks in advance!

Why is this happening?
",0,,4,2017-11-02T22:43:29Z,NONE
14188,Retval[0] does not have value in a multithreaded context with FIFOQueue and  tf.scan(...),stat:awaiting response,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I provide a working script showing the buggy behaviour
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: none
- **GPU model and memory**: GeForce GTX 280M 1GB

Note: I reproduced the buggy behaviour on different platforms too: macOS High Sierra, openSUSE 42.3 and with Tensorflow 1.3

###  problem context
I found the buggy behaviour in one of the helper methods the queue loader of the DeepSpeech project (ctc_label_dense_to_sparse). That implementation is partially clumsy in particular when using tf.scan where a scan history context is not used. Nevertheless the algorithm should have worked under any circumstances. I could reduce the problem scenario to a small standalone example. This example uses a number of threads for filling a queue from which batches are requested by dequeu_up_to (the same buggy behaviour if replaced by dequeue_many). Afterwards the batch is postproccessed. For this postprocessing I provided the buggy version (function_buggy, using tf.scan) and an own implementation (function_ok). Both versions produce the same output data in cases there the buggy versions does not fail. 

### buggy behaviour description
Very often, but not always a test with a larger batch_size and smaller thread_count leads to the following output: tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value. I include the complete log in the next section. With a larger thread_count and smaller batch_size it works. If the switch-Parameter --use_buggy_version is set to 0 (False) no choice of batch_size and thread_count produces a bug. This proves that the problem is located in the buggy function and the rest of the workflow is OK. I could prove that an implementation without the tf.scan works fine too. In experiments using the context in tf.scan instead of ignoring it didn't change the behaviour. Even as tf.scan doesn't make much sense in the context it was used for in DeepSpeech it  should not have failed and its correct function is essential for many tensorflow based projects. And maybe a similar flaw is hidden in the other ""Higher Order operators"" too: tf.map_fn, tf.foldl, tf.foldr

### log

usage: scan_bug_demo.py [-h] [--batch_size BATCH_SIZE]
                        [--thread_count THREAD_COUNT]
                        [--use_buggy_version USE_BUGGY_VERSION]
batch_size=15
thread_count=1
use_buggy_version=True
using buggy implementation: True
Traceback (most recent call last):
  File ""scan_bug_demo.py"", line 127, in <module>
    retval = do_it(batch_size, thread_count, use_buggy_version, rnd_seed)
  File ""scan_bug_demo.py"", line 99, in do_it
    coord.join(queue_threads)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""scan_bug_demo.py"", line 92, in do_it
    res = sess.run(batch)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value

### bug demonstration python source

import tensorflow as tf
from random import Random
from threading import Thread
import numpy as np
import sys
from argparse import ArgumentParser


def function_buggy(value_sequence_lengths):
    max_len = tf.reduce_max(value_sequence_lengths)

    max_value_seuence_lenght_tns = tf.expand_dims(max_len, 0)
    init = tf.expand_dims(tf.cast(tf.fill(max_value_seuence_lenght_tns, 0), tf.bool), 0)

    def scan_function(previous_state, current_input):
        return tf.expand_dims(tf.range(max_len), 0) < current_input

    retval = tf.squeeze(tf.scan(scan_function, value_sequence_lengths, initializer=init, parallel_iterations=1),
                        axis=[1])

    return retval


def function_ok(value_sequence_lengths):
    max_len = tf.reduce_max(value_sequence_lengths)
    value_sequence_lengths_shape = tf.shape(value_sequence_lengths)

    x_repeated_lenghts = tf.tile(tf.expand_dims(value_sequence_lengths, 1), (1, max_len))
    y_repeated_x_indices = tf.tile(tf.expand_dims(tf.range(max_len), 0), (value_sequence_lengths_shape[0], 1))

    retval = y_repeated_x_indices < x_repeated_lenghts

    return retval


class BatchProvider(object):
    def __init__(self, batch_size, function, thread_count, rnd_seed):
        self._coord = None
        self.batch_size = batch_size
        self._random = Random(rnd_seed)
        self._capacity = 2 * batch_size
        self._thread_count = thread_count
        self._queue = tf.FIFOQueue(shapes=[[]], dtypes=[tf.int32], capacity=self._capacity)
        self._y_length = tf.placeholder(tf.int32, [])
        self._enqueue_op = self._queue.enqueue(self._y_length)
        self._close_op = self._queue.close(cancel_pending_enqueues=True)
        self._function = function

    def start_queue_threads(self, session, coord):
        self._coord = coord
        batch_threads = [Thread(target=self._populate_batch_queue, args=(session,)) for i in range(self._thread_count)]
        for batch_thread in batch_threads:
            self._coord.register_thread(batch_thread)
            batch_thread.daemon = True
            batch_thread.start()
        return batch_threads

    def close_queue(self, session):
        session.run(self._close_op)

    def _populate_batch_queue(self, session):
        while True:
            length = self._random.randint(5, 10)
            target_len = length
            try:
                self._enqueue_op.run(session=session, feed_dict={self._y_length: target_len})
            except tf.errors.CancelledError:
                return

    def next_batch(self):
        target_lengths = self._queue.dequeue_up_to(self.batch_size)
        retval = self._function(target_lengths)
        return retval


def do_it(batch_size, thread_count, use_buggy_version, rnd_seed):
    function = function_buggy if use_buggy_version else function_ok

    batch_provider = BatchProvider(batch_size=batch_size, function=function,
                                   thread_count=thread_count, rnd_seed=rnd_seed)

    sess = tf.Session()

    coord = tf.train.Coordinator()
    queue_threads = batch_provider.start_queue_threads(sess, coord)
    batch = batch_provider.next_batch()

    try:
        for _ in range(1):
            if coord.should_stop():
                break
            res = sess.run(batch)
            print batch
            print res
    except Exception, ex:
        coord.request_stop(ex)
    finally:
        batch_provider.close_queue(sess)
        coord.join(queue_threads)
        sess.close()

    return res


if __name__ == '__main__':
    args = sys.argv[1:]
    argparser = ArgumentParser()
    argparser.add_argument(""--batch_size"", dest=""batch_size"", type=int, default=15)
    argparser.add_argument(""--thread_count"", dest=""thread_count"", type=int, default=1)
    argparser.add_argument(""--use_buggy_version"", dest=""use_buggy_version"", type=int, default=True)
    if len(args) == 0:
        argparser.print_usage()
    parsed = argparser.parse_args(args=args)
    batch_size = parsed.batch_size
    thread_count = parsed.thread_count
    use_buggy_version = parsed.use_buggy_version

    print ""batch_size="" + str(batch_size)
    print ""thread_count="" + str(thread_count)
    print ""use_buggy_version="" + str(use_buggy_version)

    rnd_seed = Random().random()

    print ""using buggy implementation: "" + str(use_buggy_version)
    retval = do_it(batch_size, thread_count, use_buggy_version, rnd_seed)
    print ""success""
",0,,4,2017-11-02T14:50:41Z,NONE
14186,TF 1.4 build_all_android.sh fails with nsync.a,"stat:community support,type:build/install","Running

    NDK_ROOT=""$HOME/Library/Android/sdk/ndk-bundle"" bash $MAKEFILE_DIR/build_all_android.sh

results in this error

```
/Users/era/Library/Android/sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: tensorflow/contrib/makefile/downloads/nsync/builds/armeabi-v7a.android.c++11/nsync.a: malformed archive header name at 8
/Users/era/Library/Android/sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: tensorflow/contrib/makefile/downloads/nsync/builds/armeabi-v7a.android.c++11/nsync.a: malformed archive header name at 8
/Users/era/Library/Android/sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: fatal error: tensorflow/contrib/makefile/downloads/nsync/builds/armeabi-v7a.android.c++11/nsync.a: attempt to map 60 bytes at offset 67800 exceeds size of file; the file may be corrupt
collect2: error: ld returned 1 exit status
make: *** [.../tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1
```

NDK version 15c, Android Studio 3.0, macOS High Sierra 10.13.1",0,,15,2017-11-02T13:46:16Z,CONTRIBUTOR
14183,improve production condition of debug log with VLOG,"cla: yes,stat:awaiting response","This patch improve a debug logging **VLOG** .

New environment variable ```TF_CPP_MAX_VLOG_LEVEL``` is added to suppress log production with VLOG.
if ```TF_CPP_MAX_VLOG_LEVEL``` is set, VLOG only outputs log lower level than it.

For example, if an user sets environment variable ```TF_CPP_MAX_VLOG_LEVEL=2```, you can see the log only lower level than 2. And you can't see the log with level 1.

### Use case:

1. ```TF_CPP_MAX_VLOG_LEVEL=2``` and ```TF_CPP_MIN_VLOG_LEVEL=1```
   * ```VLOG(1)``` and ```VLOG(2)``` will output log
2. ```TF_CPP_MIN_VLOG_LEVEL=1```
   * Only ```VLOG(1)``` will output
3. ```TF_CPP_MAX_VLOG_LEVEL=3```
   * ```VLOG(3)``` , ```VLOG(4)``` ...  will output log",1,,16,2017-11-02T12:53:22Z,NONE
14174,macOS build failed,"stat:community support,type:build/install","macOS 10.13
CUDA9.0 CUDNN7.0
bazel 0.7.0


```
tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (4) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=float, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=float, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int32]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=double, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=double, IntType=tensorflow::int64]"" 
(251): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int32]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int32]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int64]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (8) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex64, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex64, IntType=tensorflow::int64]"" 
(252): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int32, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int32]"" 
(253): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int32, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int32]"" 
(253): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int64, useSmem=true]"" 
(231): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int64]"" 
(253): here

tensorflow/core/kernels/split_lib_gpu.cu.cc(122): error: specified alignment (16) is different from alignment (2) specified on a previous declaration
          detected during:
            instantiation of ""void tensorflow::split_v_kernel<T,IntType,useSmem>(const T *, tensorflow::CudaDeviceArrayStruct<IntType, 8>, IntType, IntType, tensorflow::CudaDeviceArrayStruct<T *, 8>) [with T=tensorflow::complex128, IntType=tensorflow::int64, useSmem=false]"" 
(236): here
            instantiation of ""void tensorflow::SplitVOpGPULaunch<T, IntType>::Run(const Eigen::GpuDevice &, __nv_bool, const T *, int, int, const tensorflow::CudaDeviceArrayStruct<IntType, 8> &, const tensorflow::CudaDeviceArrayStruct<T *, 8> &) [with T=tensorflow::complex128, IntType=tensorflow::int64]"" 
(253): here

16 errors detected in the compilation of ""/var/folders/2f/891g9y691gzcy23blt644z6m0000gn/T//tmpxft_00002e92_00000000-6_split_lib_gpu.cu.cpp1.ii"".
ERROR: /Users/odin/local/tensorflow/tensorflow/core/kernels/BUILD:387:1: output 'tensorflow/core/kernels/_objs/split_lib_gpu/tensorflow/core/kernels/split_lib_gpu.cu.pic.o' was not created.
ERROR: /Users/odin/local/tensorflow/tensorflow/core/kernels/BUILD:387:1: not all outputs were created or valid.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
```",0,,16,2017-11-02T06:50:30Z,NONE
14171,Memory leak in conv2d(),stat:awaiting tensorflower,"### System information

Python: 3.5.2
TensorFlow version 1.3.0 via pip, 1.3.1 via source, 1.4.0-rc1 from source (confirmed the problem on all three of them)
Bazel: 0.7.0
Ubuntu 16.04
GPU: GeForce GTX 1080 with 8GB
Nvidia drivers: 384.90
CUDA: 8.0
CuDNN: 6.0
Optimizer: Adam with default parameters

### Problem Description

I will post here some evidence that makes me think that there's a major leak in `conv_2d()`.
Unfortunately I can't provide code and data replicate this as my employer doesn't allow me to as both are confidential, but hopefully the information i will provide will make it possible for you to replicate it.

The setting:
I'm training a word cnn on text data on GPU. The length of the sequence of text is 256, the dimension of the embeddings is 256, I have 4 convolutional layers in parallel with different sizes (2, 3, 4 and 5 x 256). The inputs to the conv layers are `batch_size x 256 x 256 x 1`.
In my code I run a full epoch of training, then I evaluate on the training set, the validation set and the test set, then I start a new epoch.

The problem:
Depending on the batch_size the memory needed by TensorFlow to compute his operations changes, but it is in the order of few hundreds MB. At the last batch of training, the memory consumption increases dramatically, as happens at the last batch of evaluation on validation set and the last batch of evaluation on the test set.
As _traini_set_size mod batch_size is not 0 (the same happens for validation and test set too), the last batch has a different dimension with respect to all others batches. For instance in my case with a batch_size of 100, the last batch of the validation set is of size 25.
What happens is that, in the `conv2d()` function TF allocates a lot of memory if the batch size is not the same that was used so far. In my case, that operation goes from needing 50 MB to 3.18 GB. As it seems too much, I suspect there's a memory leak somehow.

I'm attaching 2 screenshots taken from TensorBoard. What they show is the same node in the second last batch of the validation set and the last batch of the validation set. The memory consumption is in the node state on the right of the image. I can share the log directory if needed as it contains the graph of the model and the memory information at all steps of training and evaluation.

![eval_vali_step_8](https://user-images.githubusercontent.com/349256/32309260-99a53ab4-bf47-11e7-96d0-a429180f0e1c.png)
![eval_vali_step_9](https://user-images.githubusercontent.com/349256/32309259-99895934-bf47-11e7-8b3f-08306321cb8e.png)

The weird thing is that when batch_size is 256 or 512 it doesn't happen, but with batch_size 100 or 128 or 200 (the other 3 I tested) it happens. testing on another bigger dataset, even with 256 as the batch size the supposed memory leak happens, but in that case TF tries to allocate around 33 GB of ram and goes out of memory. My temporary workaround is just throwing away the last batch of the train, validation and test set. Doing so the memory consumption keeps constant.

Hopefully this is enough information for investigate the problem, otherwise feel free to request me additional information, even if, as I said, unfortunately I can't provide code and data.

",0,,8,2017-11-02T04:02:27Z,NONE
14165,Equivalent of caffe iter_size in TF,stat:contributions welcome,"
Can we get the equivalent of caffe's iter_size parameter in TF? This accumulates gradient calcs over several GPU cycles before doing the weight update. It effectively allows a larger batch size. TensorFlow doesn't natively have this but some ppl seem to have implemented sth like it themselves, e.g

https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients

I think it'd be a useful parameter to have as part of official TF ... or is there some easy way to implement this functionality already?

Shaun",0,,1,2017-11-01T22:42:32Z,NONE
14144,Eager: Device Placement of Constant Eager Tensors,"comp:eager,stat:awaiting tensorflower","When eager execution is enabled on 64bit machine, the following code snippet causes an error:
```python
with tf.device(""/gpu:0""):
  tf.split(np.array([1.0, 2.0]), np.array([1, 1]))`
```
```
Tensors on conflicting devices: cannot compute SplitV as input #1 was expected to be on 
/job:localhost/replica:0/task:0/device:CPU:0 but is actually on 
/job:localhost/replica:0/task:0/device:GPU:0 (operation running on 
/job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(),
or transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT).
Copying tensors between devices may slow down your model [Op:SplitV] name: split
```
There are a couple of ways to fix this:
```python
with tf.device(""/gpu:0""):
  tf.split(np.array([1.0, 2.0]), np.array([1, 1], dtype=np.int32))`
```
or 
```python
with tf.device(""/gpu:0""):
  tf.split(np.array([1.0, 2.0]), [1, 1])`
```

The error is thrown for the following reason. Kernel of operation `split` expects the `num_or_size_splits` argument to be in host memory (CPU RAM). For a tensor to be placed in host memory, it needs to be either created in the CPU context (e.g. `with tf.device(""/cpu:0"")`) or have dtype of `int32`.  `numpy` defaults to creating `int64` tensors on 64bit machines. Hence the fixes - either explicitly request `int32` dtype from numpy or use python list (tensorflow defaults to `int32` for python sequences of small integers)

Another, more global, workaround is to enable automatic copying of tensors between devices as described in https://github.com/tensorflow/tensorflow/issues/14133..",0,,3,2017-11-01T01:05:55Z,MEMBER
14134,Eager: Random seeds,"comp:eager,stat:awaiting tensorflower","(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`) 

Setting the [graph-level random](https://www.tensorflow.org/api_docs/python/tf/set_random_seed) seed exactly once, before any operations are executed, works as intended; however, subsequent invocations to `tf.set_random_seed()` will not reset operation randomness. Furthermore, keyword arguments that set operation-level seeds have no effect when executing in eager mode. Random sequences generated by the same graph-seed will vary depending upon whether you are constructing a graph or executing eagerly.
",0,,3,2017-10-31T17:05:07Z,MEMBER
14133,Eager: Automatic Device Placement,"comp:eager,stat:awaiting tensorflower","When a GPU is available, TensorFlow automatically copies tensors between CPU and GPU memory (see [Using GPUs](https://www.tensorflow.org/tutorials/using_gpu)).

When eager execution is enabled, automatic copying between devices is disabled by default. When executing imperatively, copying data between CPU and GPU is more likely to become a performance bottleneck. Avoiding automatic copying makes it easier to identify such bottlenecks. For example, consider the program:


```python
with tf.device(“/cpu:0”):
  x = tf.ones([2, 2])
with tf.device(“/gpu:0”):
  y = tf.matmul(x, x)
```

This will fail with an error like:

```
Tensors on conflicting devices: cannot compute MatMul as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 …
```


indicating that the `matmul` operation cannot be conducted on the GPU as its inputs were host memory.

If you run into this situation, your options are:

- Accept the potential performance hit by explicitly enabling automatic copying between devices:


```python
tfe.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT)
```

-  Explicitly copy the tensor yourself using `tf.identity` or `Tensor.gpu()`:

```python
with tf.device(“/gpu:0”):
  x = tf.identity(x)
  y = tf.matmul(x, x)
```",0,,3,2017-10-31T16:57:46Z,MEMBER
14132,Eager: Variable item-assignment,"comp:eager,stat:awaiting tensorflower","(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)

Currently, the following does not work:

```python
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()
x = tfe.Variable(tf.ones([10]), name=’x’)
x[3] = 2.
```

That last line, assigning a value to an element of the tensor will fail with: `object does not support item assignment`.

While it would be possible to make item assignment for `Tensor` and `Variable` objects work when eager execution is enabled, it is trickier to make the same line of code work with graph construction (since the line `x[3] = 2.` does not return a `tf.Operation` object that can be provided to a `Session.run()` call).

At this early stage of eager execution, we’re taking the conservative approach and disallowing Tensor assignment. This is probably worth revisiting at a future date. In the meantime, the verbose form of item assignment using `tf.scatter_update`:

```python
tf.scatter_update(x, [3], [2.])
```
",0,,3,2017-10-31T16:57:42Z,MEMBER
14131,Eager: Using graphs in the same Python process,"comp:eager,stat:awaiting tensorflower","Once eager execution is enabled via `tfe.enable_eager_execution()`, it cannot be disabled in the same process. This means that eager and graph execution cannot be mixed in the same Python session.

This issue has been filed to track development of features to make the transition between eager and graph execution smoother -- allowing users to pick and choose portions of the computation that will be “compiled” into graphs for optimized execution, and portions that will execute eagerly.
",0,,3,2017-10-31T16:57:40Z,MEMBER
14130,Eager: CPU Performance/Operation Overheads,"comp:eager,stat:awaiting tensorflower","(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)

Eager execution re-uses most of the same Python code used for constructing TensorFlow graphs. Many of these paths have not been optimized for part of the critical path of computation. As a result, the CPU overheads of executing Python code for every operation are higher than we’d like.

Consequently, the performance of eager execution on models with many small computations, or models executed on CPU may be dominated by these overheads.

Overheads are measured using microbenchmarks such as in [`benchmarks_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/benchmarks_test.py) and model-level benchmarks such as those used for [ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50) and the [PTB RNN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/rnn_ptb)",0,,3,2017-10-31T16:57:38Z,MEMBER
14129,Eager: Distributed Execution,"comp:eager,stat:awaiting tensorflower","(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)


If the model does not involve dynamic control flow in Python (i.e., changing the computation based on input), then the same model code can be used to construct a TensorFlow graph, which can then be trained with [distributed TensorFlow](https://www.tensorflow.org/deploy/distributed)

Some example models like [MNIST](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/mnist), [ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50), and the [PTB RNN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/rnn_ptb) include unittests outlining how the same model code can be used to construct and train TensorFlow graphs.

A smoother path to distributed TensorFlow when eager execution is enabled is being charted out.
",0,,3,2017-10-31T16:57:36Z,MEMBER
14117,Error in CMake generated build script,"stat:community support,type:build/install","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1709
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0-rc1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: - (I use cmake)
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: Notebook 1070 8G
- **Exact command to reproduce**: 
Use cmake to generate build script for `Visual Studio 2017 Win64`
`CMAKE_C_COMPILER`, `CMAKE_CXX_COMPILER` and `CUDA_HOST_COMPILER` should be set manually, otherwise, it will failed the compilation phase calling to NVCC


### Describe the problem
This problem happens when building with Visual Studio 2017.4 + CUDA 9.0 + cuDNN 7 + CMake + GPU build.

Sorry for lack of information. I build it yesterday (and failed) and it take so long the compile through and I didn't keep the log. This problem is LINK ERRORs. What I can identify is they are in the generated build script. The problems happens exactly  in
```
_beam_search_ops.vcxproj
_gru_ops.vcxproj
_lstm_ops.vcxproj
_nearest_neighbor_ops.vcxproj
```
e.g. in  `_beam_search_ops.vcxproj` around line 103
```
    <Link>
      <AdditionalDependencies>\pywrap_tensorflow_internal.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cudart_static.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cuda.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cublas.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cublas_device.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cufft.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\curand.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64\cupti.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cusolver.lib;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\cudnn.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64 /ignore:4049 /ignore:4197 /ignore:4217 /ignore:4221</AdditionalOptions>
      <GenerateDebugInformation>false</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>D:/workspaces/tensorflow/tensorflow/contrib/cmake/build/Release/_beam_search_ops.lib</ImportLibrary>
      <ProgramDataBaseFile>D:/workspaces/tensorflow/tensorflow/contrib/cmake/build/Release/_beam_search_ops.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
```

You can see a `\pywrap_tensorflow_internal.lib` in `<AdditionalDependencies>` cause the LINK ERROR, since the linker can't find file `pywrap_tensorflow_internal.lib`.

The prefix **backslash** seems to be the cause. I suspect it should be some `${BLAH_env_VARIBALE}pywrap_tensorflow_internal.lib` and this `${BLAH_env_VARIBALE}` happens to be empty string and results to a `\pywrap_tensorflow_internal.lib`.

All four `.vcxproj` files comes from function call `AddUserOps` in `tf_python.cmake` , where the `AddUserOps` is defined in `tf_cc_ops.cmake` file. Due to my poor eye sight, I can't decide where is the problem from here...

Notice, I CAN see the file `pywrap_tensorflow_internal.lib` in some directory so it should be problem related with the path .",0,,1,2017-10-31T03:49:01Z,NONE
14107,TensorFlow 1.4.0 takes more resources and is slower on GPU and CPU,"stat:awaiting response,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: https://github.com/tkuanlun350/Tensorflow-SegNet
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 x64
- **TensorFlow installed from (source or binary)**:  https://pypi.python.org/pypi/tensorflow-gpu/1.4.0rc1
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5
- **CUDA/cuDNN version**:  Cuda release 8.0, V8.0.60. cuDNN 6.
- **GPU model and memory**:  NVIDIA P4 
- **Exact command to reproduce**:   `c:\python35\python3 main.py --log_dir=./logs --image_dir={image dir} --val_dir= {validation dir} --batch_size=15 --training=True`

### Describe the problem
Under 1.3.0 I was able to use a batch size of {15, put your max batch size here} for training.  Under 1.4.0 I get Resource Exhausted errors for that batch size.  So use of GPU resources is going up.  Not the right direction.

For me here are the performance effects:

- TensorFlow GPU 1.3.0: 9.8 images/sec for batch size: 15
- TensorFlow GPU 1.4.0:  Can't do batch size: 15. 7.8 images/sec for batch size: 12

### Source code / logs
[tf_bug2.txt](https://github.com/tensorflow/tensorflow/files/1428590/tf_bug2.txt)
",0,,32,2017-10-30T20:11:43Z,NONE
14101,Computing gradients within tf.while_loop,,"I am posting this here because [a similar question on stackoverflow](https://stackoverflow.com/questions/42313788/how-to-do-opt-compute-gradients-multiple-times-in-single-sess-run) is still unanswered, so I suspect it might be a bug. 

Adding gradient ops within a tf.while_loop for computing gradients of loop variables w.r.t external variables results in an error. 

Program reproducing the error:
```
import numpy as np
import tensorflow as tf
tf.reset_default_graph()
F = lambda x: tf.cumsum(x)
G = lambda x: x[-1]
H = lambda x: x
encoder_emb_inp = tf.placeholder(dtype=tf.float32, shape=[4])
encoder_outputs = F(encoder_emb_inp)
decoder_initial_state = G(encoder_outputs)
decoder_initial_output = H(decoder_initial_state)
def cond(time, unused_state, unused_output):
    return tf.less(time, 3)

def body(time, state, inputs):
    step = lambda s, i: (tf.multiply(s,s), tf.multiply(s,i))
    (next_state, next_output) = step(state, inputs)
    next_grads = tf.gradients(next_output, decoder_initial_state)
    tf.Print(next_grads, next_grads)
    return (time + 1, next_state, next_output)

initial_time = tf.constant(0, dtype=tf.int32)


final_time, final_state, final_outputs = tf.while_loop(cond, body, loop_vars = [initial_time, decoder_initial_state, decoder_initial_output])
```
Error message: 
```
<ipython-input-126-5205901211cc> in body(time, state, inputs)
      6     (next_state, next_output) = step(state, inputs)
      7 #    next_grads = tf.gradients(next_output, state)
----> 8     next_grads = tf.gradients(next_output, decoder_initial_state)
      9     tf.Print(next_grads, next_grads)
     10     return (time + 1, next_state, next_output)

/home/pramodkm/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)
    591                 out_grads[i] = loop_state.ZerosLike(op, i)
    592               else:
--> 593                 out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)
    594           with ops.name_scope(op.name + ""_grad""):
    595             # pylint: disable=protected-access

/home/pramodkm/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc in ZerosLikeOutsideLoop(op, index)
   1342     if op_ctxt:
   1343       # We are in a cond context. Use a switch to create zeros only when needed.
-> 1344       pred = op_ctxt.pred
   1345       branch = op_ctxt.branch
   1346       switch_val = switch(op.inputs[0], pred)[1 - branch]

AttributeError: 'WhileContext' object has no attribute 'pred'
```
I am using tf-nightly-gpu 1.5.0-dev20171026

Thanks!",1,,4,2017-10-30T17:47:44Z,NONE
14095,matrix_triangular_solve has broken docstring,"stat:awaiting tensorflower,type:docs","### System information
not applicable (regards documentation)

### Describe the problem
The docstring of matrix_triangular_solve is not clear, see https://www.tensorflow.org/api_docs/python/tf/matrix_triangular_solve. There are formatting issues, but moreover, it is not immediately clear what the effect of `adjoint=True` is. It would be helpful to describe the effect using linear algebra notation.

### Source code / logs
not applicable (regards documentation)",0,,4,2017-10-30T14:32:30Z,NONE
14083,AssetFileDef is not updated when using Saved model builder.,"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
Pulled from current master, but code is same at 1.4
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.5.4
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
-get latest tensorflow-serving
-add to mnist_saved_model.py
```
asset_path = tf.constant(""/tmp/asset.txt"", dtype=tf.string, name=""PreProcessingSettings"")
  tf.add_to_collection(tf.GraphKeys.ASSET_FILEPATHS, asset_path)
....
assets_collection = tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS),
...
builder.save(as_text=True)
```
build mnist_saved_model.py
execute
observe that exported model meta_graph_defs do not have AssetFileDef populated

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
It seems that from the definition of [meta graph def](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/meta_graph.proto)
that AssetFileDef should be populated, however instead the assets are just added to a collection... should it not be both?
It seems it should but it is not implemented. Would not be too hard to implement.

### Source code / logs
N/A",0,,4,2017-10-30T05:24:13Z,NONE
14081,Feature Request: C++ gradient for Cast,"stat:community support,type:feature","Implement the gradient for Cast in C++ so that it is available for TF_AddGradients.

This is the Python code that I believe would need to be ported:

https://github.com/tensorflow/tensorflow/blob/27767d8e9c1325979cf32ff5b81c10df9006fd57/tensorflow/python/ops/math_grad.py#L1109-L1120

Will be asking @bpiel for guidance if I get stuck!",0,,6,2017-10-30T02:26:02Z,NONE
14080,@function.Defun lose input tensor shapes ,type:feature,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.5 (16F73)
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.3.0
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**:NA
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:NA
- **Exact command to reproduce**:
```
import  tensorflow as tf
import numpy as np
from tensorflow.python.framework import function
# Now let us see some property of @function of tf. It will make all its inputs loose ""shape""

@function.Defun(tf.float32, tf.float32)
def plus(A, B):

    result = A + B
    result.set_shape((5, 5))
    print result.get_shape()
    return result

def linear(A, B, C):
    D = plus(A, B) + C
    print D.get_shape()
    return D

# @function.Defun(
#     tf.float32, shape_func=lambda op: [op.inputs[0].get_shape()])
# def Foo(x):
#     print x.get_shape, 'see'
#     return x + 1.0

sess = tf.Session()
sess.run(tf.global_variables_initializer())
A = tf.constant(np.arange(25).reshape((5, 5)), dtype=tf.float32)
B = tf.ones((5, 5))
C = tf.ones((5, 5))
E = plus(A, B)
# d = Foo(tf.constant(2.0))
D = linear(A, B, C)
print sess.run(E)
print sess.run(D)
# print sess.run(d)
```

### Describe the problem
All tensors going through the decorated function lose their shapes, as well as the output tensor. Without this decoration, there is no problem.  btw, shape_fun seems doesn't work
",0,,5,2017-10-30T02:22:34Z,NONE
14075,Momentum SGD is very slow with large embedding layer,stat:contributions welcome,"Hi, I have an (256 col* 500000row) embedding layer in my model and I found that Momentum SGD is 10x slower than adam optimizer. When I printed the global variables using API :tf.global_variables(), I found a large Momentum  variable created by optimizer, does that means Momentum SGD have not  supported sparse update yet?",0,,9,2017-10-29T16:38:27Z,NONE
14070,Feature request : add weight normalization,stat:contributions welcome,"can you implement [weight norm](https://arxiv.org/pdf/1602.07868.pdf) ?

I want to use it as follows.
```python
    x = tf.layers.conv2d(x, filter_size=32, kernel_size=[3,3], strides=2)
    x = weight_norm(x)
```
Is it possible?
",0,,8,2017-10-29T13:09:55Z,NONE
14065,"[feature] ""Periodic"" mode for tf.pad","stat:contributions welcome,type:feature","
### System information
N/A


### Describe the problem
If I have a matrix
```
[[1, 2, 3],
 [4, 5, 6],
 [7, 8, 9]]
```

It would be nice if I could use something like tf.pad( ... 'PERIODIC') to pad around the dimensions to get a matrix like
```
[ [9, 7, 8, 9, 7],
  [3, 1, 2, 3, 1],
  [6, 4, 5, 6, 4],
  [9, 7, 8, 9, 7],
  [3, 1, 2, 3, 1] ]
```

While there seems to be a work around by manually slicing and joining, this would seem nifty to have in tf.pad already to make expressions that assume periodic boundary conditions a bit easier.
### Source code / logs
N/A
",0,,1,2017-10-29T04:20:00Z,NONE
14041,tf.metrics doesn't include cross_entropy.,,"In tensorflow estimator, I want to use _cross entropy_ as the evaluation metrics (`eval_metric_ops` parameter of `EstimatorSpec`)

However, `tf.metrics` doesn't have this function. Also, tensorflow estimator doesn't allow me to use `tf.nn.sigmoid_cross_entropy_with_logits` as the `eval_metric_ops`.",1,,11,2017-10-27T19:52:13Z,NONE
14034,Segmentation fault when using Intel MKL with np.linalg.svd,,"### System information

I am running this on the [Graham supercomputer](https://docs.computecanada.ca/wiki/Graham) of Compute Canada. I tested the bug on computation nodes but it also appears on login nodes without GPUs.

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux - CentOS 7
- **TensorFlow installed from (source or binary)**: Custom build with Intel MKL I guess?
- **TensorFlow version (use command below)**: b'v1.3.0-0-g9e76bf3' 1.3.0
- **Python version**: Python 3.5.2 (default, Jun 25 2016, 21:38:40) [GCC 5.4.0] on linux
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 7.5
- **GPU model and memory**: Tesla P100
- **Exact command to reproduce**:

```
import numpy as np
import tensorflow as tf

a = np.ones((64,256))
u, _, v = np.linalg.svd(a, full_matrices=False)
```

Without the `import tensorflow as tf`, the bug doesn't appear.

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1422363/tf_env.txt)


### Describe the problem

So basically, when using Intel MKL with the python code above you get a segmentation fault. Without the `import tensorflow as tf`, the bug doesn't appear. Strangely, when I change the size of the 2nd axis of matrix `a` to below 201, it works (at some point that I tested, it was 188). When setting the shape of the matrix `a` to something bigger like `(64,256)`, it just using all CPUs without returning anything as if it was in a deadlock or something. When setting `MKL_NUM_THREADS` to 1, both bugs disappear. This bug report seems related to all of these issues: https://github.com/tensorflow/tensorflow/issues/9234 https://github.com/tensorflow/tensorflow/issues/13004 https://github.com/tensorflow/tensorflow/issues/11724 https://github.com/tensorflow/tensorflow/issues/10005. They are not identical to this problem but really similar so this bug report is just to let you know another symptom related to the same problem. 


### Source code / logs

[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1422363/tf_env.txt)
[gdb_segfault.txt](https://github.com/tensorflow/tensorflow/files/1422365/gdb_segfault.txt)

",1,,4,2017-10-27T14:47:34Z,NONE
14025,compile tensorflow-1.4.0-rc1 failed with error: SWIGing tensorflow/python/tensorflow.i failed (Segmentation fault): swig failed: error executing command,stat:community support,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

It must be a bug or a feature request.
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.
Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 17.10 beta2
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): TensorFlow 1.4.0-rc1
Python version: Python 2.7.14
Bazel version (if compiling from source): bazel 0.6.0
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:
bazel build --config=mkl --copt=""-g"" --copt=""-DEIGEN_USE_VML"" --copt=""-mavx2"" --copt=""-mfma"" --copt=""-O3"" --verbose_failures --copt=""-L/opt/intel/gcc/lib64"" -s -c opt //tensorflow/tools/pip_package:build_pip_package
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Failed to use bazel 0.6.0 to compile tensorflow 1.4.0-rc1 on Ubuntu 17.10beta2

install Bazel
download bazel-0.6.0-installer-linux-x86_64.sh
bash bazel-0.6.0-installer-linux-x86_64.sh to install bazel
source /usr/local/lib/bazel/bin/bazel-complete.bash

compile tensorflow
./configure

bazel build --config=mkl --copt=""-g"" --copt=""-DEIGEN_USE_VML"" --copt=""-mavx2"" --copt=""-mfma"" --copt=""-O3"" --verbose_failures --copt=""-L/opt/intel/gcc/lib64"" -s -c opt //tensorflow/tools/pip_package:build_pip_package

compile failed
Source code / logs

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

_ERROR: /home/automation/tensorflow-1.4.0-rc1/tensorflow/python/BUILD:2953:1: SWIGing tensorflow/python/tensorflow.i failed (Segmentation fault): swig failed: error executing command
(cd /root/.cache/bazel/_bazel_root/35d546f7441fd09e73ff30ea3d9aa112/execroot/org_tensorflow && 
exec env - 
bazel-out/host/bin/external/swig/swig -c++ -python -module pywrap_tensorflow_internal -o bazel-out/local-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc -outdir bazel-out/local-opt/bin/tensorflow/python -ltensorflow/python/client/device_lib.i -ltensorflow/python/client/events_writer.i -ltensorflow/python/client/tf_session.i -ltensorflow/python/client/tf_sessionrun_wrapper.i -ltensorflow/python/framework/cpp_shape_inference.i -ltensorflow/python/framework/python_op_gen.i -ltensorflow/python/grappler/cluster.i -ltensorflow/python/grappler/cost_analyzer.i -ltensorflow/python/grappler/item.i -ltensorflow/python/grappler/model_analyzer.i -ltensorflow/python/grappler/tf_optimizer.i -ltensorflow/python/lib/core/py_func.i -ltensorflow/python/lib/core/strings.i -ltensorflow/python/lib/io/file_io.i -ltensorflow/python/lib/io/py_record_reader.i -ltensorflow/python/lib/io/py_record_writer.i -ltensorflow/python/platform/base.i -ltensorflow/python/pywrap_tfe.i -ltensorflow/python/training/quantize_training.i -ltensorflow/python/training/server_lib.i -ltensorflow/python/util/kernel_registry.i -ltensorflow/python/util/port.i -ltensorflow/python/util/py_checkpoint_reader.i -ltensorflow/python/util/stat_summarizer.i -ltensorflow/python/util/tfprof.i -ltensorflow/python/util/transform_graph.i -Ibazel-out/local-opt/genfiles -Iexternal/eigen_archive -Iexternal/grpc -Iexternal/protobuf_archive -Iexternal/swig -Iexternal/boringssl -Ibazel-out/local-opt/genfiles/external/local_config_python -Iexternal/nsync -Iexternal/gemmlowp -Iexternal/jpeg -Iexternal/com_googlesource_code_re2 -Iexternal/mkl -Iexternal/jsoncpp_git -Iexternal/zlib_archive -Iexternal/highwayhash -Iexternal/gif_archive -Iexternal/mkl_dnn -Ibazel-out/local-opt/genfiles/external/jpeg -Iexternal/lmdb -Iexternal/png_archive -Iexternal/farmhash_archive -Iexternal/sqlite_archive -Iexternal/swig/Lib -Iexternal/swig/Lib/cffi -Iexternal/swig/Lib/python -Iexternal/swig/Lib/std -Iexternal/swig/Lib/typemaps tensorflow/python/tensorflow.i): swig failed: error executing command
(cd /root/.cache/bazel/bazel_root/35d546f7441fd09e73ff30ea3d9aa112/execroot/org_tensorflow && 
exec env - 
bazel-out/host/bin/external/swig/swig -c++ -python -module pywrap_tensorflow_internal -o bazel-out/local-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc -outdir bazel-out/local-opt/bin/tensorflow/python -ltensorflow/python/client/device_lib.i -ltensorflow/python/client/events_writer.i -ltensorflow/python/client/tf_session.i -ltensorflow/python/client/tf_sessionrun_wrapper.i -ltensorflow/python/framework/cpp_shape_inference.i -ltensorflow/python/framework/python_op_gen.i -ltensorflow/python/grappler/cluster.i -ltensorflow/python/grappler/cost_analyzer.i -ltensorflow/python/grappler/item.i -ltensorflow/python/grappler/model_analyzer.i -ltensorflow/python/grappler/tf_optimizer.i -ltensorflow/python/lib/core/py_func.i -ltensorflow/python/lib/core/strings.i -ltensorflow/python/lib/io/file_io.i -ltensorflow/python/lib/io/py_record_reader.i -ltensorflow/python/lib/io/py_record_writer.i -ltensorflow/python/platform/base.i -ltensorflow/python/pywrap_tfe.i -ltensorflow/python/training/quantize_training.i -ltensorflow/python/training/server_lib.i -ltensorflow/python/util/kernel_registry.i -ltensorflow/python/util/port.i -ltensorflow/python/util/py_checkpoint_reader.i -ltensorflow/python/util/stat_summarizer.i -ltensorflow/python/util/tfprof.i -ltensorflow/python/util/transform_graph.i -Ibazel-out/local-opt/genfiles -Iexternal/eigen_archive -Iexternal/grpc -Iexternal/protobuf_archive -Iexternal/swig -Iexternal/boringssl -Ibazel-out/local-opt/genfiles/external/local_config_python -Iexternal/nsync -Iexternal/gemmlowp -Iexternal/jpeg -Iexternal/com_googlesource_code_re2 -Iexternal/mkl -Iexternal/jsoncpp_git -Iexternal/zlib_archive -Iexternal/highwayhash -Iexternal/gif_archive -Iexternal/mkl_dnn -Ibazel-out/local-opt/genfiles/external/jpeg -Iexternal/lmdb -Iexternal/png_archive -Iexternal/farmhash_archive -Iexternal/sqlite_archive -Iexternal/swig/Lib -Iexternal/swig/Lib/cffi -Iexternal/swig/Lib/python -Iexternal/swig/Lib/std -Iexternal/swig/Lib/typemaps tensorflow/python/tensorflow.i).",0,,8,2017-10-27T08:50:42Z,NONE
14018,Tutorial request for hybrid model (word+character) ,"type:docs,type:feature","The implementation done in the paper:
http://aclweb.org/anthology/P/P16/P16-1100.pdf

is a hybrid seq2seq model with advancements where the encoder is fed with inputs based on following two cases:

1.Normal vector representation of a word (Embedding vector) - when the word input is present in the vocabulary

2.Output of another LSTM network - when the word is **out of vocabulary** and a separate character based LSTM is used to **generate an embedding on the fly**

Consider the following example sentence:
""The brown fox jumped over the lazy dog""

Assume these are the words present in the vocabulary: _The, brown, jumped, over, dog_ - These words are fed to the seq2seq encoder as such

out of vocabulary(OOV) words are: _fox, lazy_ - These words are passed to a character LSTM and the output of the same is passed to the seq2seq model along with the above words

These both word level and character level encoder needs to be trained end to end simultaneously. 

Since the implementation is a bit different from the normal seq2seq can a tutorial or example of such case be added to the examples section?",0,,7,2017-10-27T06:35:38Z,NONE
14017,image_ops_test failing due to math_ops.sin() behaving differently,stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: v1.2.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.4.5 
- **CUDA/cuDNN version**: No GPU
- **GPU model and memory**: No GPU
- **Exact command to reproduce**: bazel test -c opt //tensorflow/contrib/image:image_ops_test

### Describe the problem
The above test fails with the output array mismatch in [test_rotate_even](https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/image/python/kernel_tests/image_ops_test.py#L48).

The exact cause of failure seems to be at [math_ops.sin(angles)](https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/contrib/image/python/ops/image_ops.py#L115), which only fails for `angle=(np.pi / 4.0) = 0.78539819` (45 deg) and works fine for 0 and 90 deg.

The output of `math_ops.sin(0.78539819).eval()` differs on Intel and s390x as below:
1. Intel(test passes) : 0.70710**6769**
2.  s390x(test fails) : 0.70710**6829**

I verified `np.sin(0.78539819)` gives same output `0.7071067999` on both Intel and s390x.

Why is the difference seen in math_ops.sin()? Any pointers would be helpful.

### Source logs
----------------------------------------------------------------------
FAIL: test_rotate_even (__main__.ImageOpsTest)
----------------------------------------------------------------------
```
Traceback (most recent call last):
  File ""/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/image/image_ops_test.runfiles/org_tensorflow/tensorflow/contrib/image/python/kernel_tests/image_ops_test.py"", line 75, in test_rotate_even
    [1, 7, 13, 19, 25, 31], [0, 6, 12, 18, 24, 30]]])
  File ""/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/image/image_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 699, in assertAllEqual
    np.testing.assert_array_equal(a, b)
  File ""/usr/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 807, in assert_array_equal
    verbose=verbose, header='Arrays are not equal')
  File ""/usr/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 733, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not equal

(mismatch 1.85185185185%)
 x: array([[[ 0,  1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17],...
 y: array([[[ 0,  1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17],...

not equal where =  (array([1, 1]), array([3, 4]), array([3, 4]))
not equal lhs =  [20 32]
not equal rhs =  [21 33]

```




",0,,8,2017-10-27T06:27:46Z,CONTRIBUTOR
14014,Proposal: Compiling TF 1.4.0 GPU w/ CMAKE on Linux x64,,"Currently, I have been playing with the cmake scripts of TensorFlow-GPU to make it CMAKE-buildable in a bare-metal x64 Linux. (isolated environment, without the internet, w/ OBS)
(I'm trying CMAKE because I don't want to port Java)

It's almost done (need code clean) and I'll probably send Pull-Request next week. However, there are a few things I want to check before I write additional features besides simply make it able to build with CMAKE for TF-GPU in Linux.

1. Tensorflow is statically linking to pre-installed devel packages. I think in some cases, it might be better to do dynamic linking (use .so) to other libraries (to save some memory and storage size). May I simply add an option like ""tensorflow_USE_SHARED_LIBS_CUDA""? (e.g., cuda, nccl, ...)

2. Tensorflow is downloading a lot of external packages and use them ""statically"", which is pretty awful for some people. I'd like to make it use shared libraries as well (maybe along with some version restrictions). May I simply add an option like ""tensorflow_USE_SHARD_LIBS_JSONCPP"", which disables downloading ""JSONCPP"" as well?

Some additional benefit with these might be reduced memory requirement for building tensorflow; memory consumption of tensorflow-build gets dangerous at the last step with ```ld```. Probably, for now, I may simply need to be satisfied with letting ```make``` reduce ```-j#``` only for ```ld``` steps.


CC: @leemgs
STATUS: failing at the last step. (without ```-Dtensorflow_BUILD_SHARED_LIB```, it works anyway)
```
...
[ 2457s] /usr/lib64/gcc/x86_64-tizen-linux-gnu/6.2.1/../../../../x86_64-tizen-linux-gnu/bin/ld: libtf_core_gpu_kernels.a(tf_core_gpu_kernels_generated_beam_search_ops_gpu.cu.cc.o): relocation R_X86_64_32 against `.data' can not be used when making a shared object; recompile with -fPIC
[ 2457s] /usr/lib64/gcc/x86_64-tizen-linux-gnu/6.2.1/../../../../x86_64-tizen-linux-gnu/bin/ld: libtf_core_gpu_kernels.a(tf_core_gpu_kernels_generated_resampler_ops_gpu.cu.cc.o): relocation R_X86_64_32 against `.data' can not be used when making a shared object; recompile with -fPIC
[ 2457s] /usr/lib64/gcc/x86_64-tizen-linux-gnu/6.2.1/../../../../x86_64-tizen-linux-gnu/bin/ld: final link failed: Nonrepresentable section on output
[ 2457s] collect2: error: ld returned 1 exit status
[ 2457s] CMakeFiles/tensorflow.dir/build.make:2235: recipe for target 'libtensorflow.so' failed
[ 2457s] make[2]: *** [libtensorflow.so] Error 1
[ 2457s] CMakeFiles/Makefile2:82: recipe for target 'CMakeFiles/tensorflow.dir/all' failed
[ 2457s] make[1]: *** [CMakeFiles/tensorflow.dir/all] Error 2
[ 2457s] make[1]: *** Waiting for unfinished jobs....
[ 2458s] [100%] Linking CXX shared library libpywrap_tensorflow_internal.so
[ 2474s] [100%] Built target grpc_tensorflow_server
[ 2474s] [100%] Built target transform_graph
```

-- STATUS UPDATE: build successful w/ ```-Dtensorflow_BUILD_SHARED_LIB=ON``` as well.",0,,13,2017-10-27T02:23:18Z,CONTRIBUTOR
14013,#tensorflow##PYNQ# Could I install tensorflow in my PYNQ-Z1 ? ,stat:contributions welcome,"I wanna build some Classifier with it. I'm used to build Classifiers with TensorFlow. 
So I want to know whether it is technically possible.THX!!
[http://www.pynq.io/](url)",0,,2,2017-10-27T01:50:29Z,NONE
14012,tfdbg ps -b command does not work on Windows,"stat:contributions welcome,type:bug/performance","Issue:

The tfdbg ps -b command does not annotate the source file source file beginning at the given line i.e. the output of ps -b 10 source.py is the same as ps source.py.

Steps to reproduce:

1. Open the command prompt
2. Run python -m tensorflow.python.debug.examples.debug_mnist --debug
3. Press r
4. Type ps -b 10 path/to/debug_mnist

System information:

* Tensorflow 1.3.0 (installed using Anaconda)
* OS: Windows-10-10.0.15063-SP0
* Python: 3.6.1
",1,,8,2017-10-26T23:40:05Z,NONE
14007,BatchNorm not working in a _FuncGraph,,"I am working on macOS 10.12.6 with TensorFlow 1.3.0, Python version: 3.6.2. CPU only.

I found that if `tf.contrib.layers.batch_norm` is called inside a `Defun`, a `TypeError` will be thrown. To clarify, the function here is a `map_func` that will be used in `Dataset.map` invoke, instead of a normal python function.

To regenerate the scenario, try this piece of code:

```
Dataset.range(27).batch(27) \
  .map(lambda x: tf.cast(tf.reshape(x, (3, 3, 3)), tf.float32) / 32.0) \
  .map(lambda img: tf.contrib.layers.batch_norm(img)) \
  .make_one_shot_iterator().get_next().eval()
```

You will get an error like this:

```
TypeError: In op 'BatchNorm/AssignMovingAvg', input types ([tf.float32, tf.float32]) are not compatible with expected types ([tf.float32_ref, tf.float32])
```

I did some investigation. One thing that I found is that inside the `batch_norm`, we will assign a new value to the `mean` variable by calling `assign_sub`, which accept a variable with **ref** type and a value with a **basic type**. But the variable has been created some where in the `_FuncGraph` with a **basic type**, instead of a **ref** type, which make the compatibility check failed.

I will keep digging into this issue, but I think this seems a bug.",1,,5,2017-10-26T18:29:28Z,NONE
13991,Support fold batch norm for atrous conv2d,"awaiting review,cla: yes,stat:awaiting tensorflower","Describe the problem

 #13990

As we can fold batch norm with convolution, we should also fold batch norm with atrous convolution, which has not been implemented.
",1,,6,2017-10-26T09:42:39Z,NONE
13989,Fused batch norm can be folded with atrous conv2d ,stat:contributions welcome,"### Describe the problem
As we can fold batch norm with convolution, we should also fold batch norm with atrous convolution, which has not been implemented.
",0,,1,2017-10-26T09:14:46Z,NONE
13985,Update adding_an_op.md,"awaiting review,cla: yes,stalled,stat:awaiting response","I am proposing several changes to this file.  I am a new user to TF, and used this documentation extensively while trying to put a together my custom activation function, since I wanted to explore how different activation functions might affect NN training and performace.  I eventually figured out everything I needed to know, but it took weeks because this documentation is lacking in several areas, so I have a good feel for how this documentation can be improved to make life easier for future new users.  Changes 1 and 2 are pretty clear and I expect to not be controversial.  Change 3 you will probably need to think about, and might want to do further work to make things more clear.

1) correct example.cc (221-228):
I added a REGISTER_OP macro to the ""example"" code.  The previous absence of these lines was clearly an omission in the documentaion - the example code does not work without this line.  This is the least controversial change I am making.

2) explain how to use Bazel to compile a CUDA op (1256-1272:
I eventually figured out how to do this on my own, but it sure would have been useful had this information been in this documentation.

3) explaining how the gradient actually works in TF (1293-1301):
Now that I know the answer, I can read the documentation and sort of parse what it means, but I found this extremely confusing when I was reading it for the first (and tenth) time.  I have a masters in physics, so I understand calculus, but it wasn't until I had implemented backpropagation twice by hand and spent a bunch of time trying to imagine how TF must be working under the hood before I got this.  So I was tempted to delete this entire section and start over.  But I am not sure I can win this battle, because a major portion of what makes this confusing for me is the way TF uses the word gradient.  The thing that all of the TF documentation refers to as ""gradient"" I would much prefer to refer to as ""error"".  But I doubt I am going to get everybody to change everything.

So I have opted to just append another paragraph to this section, which I hope will explain things better.  It might be nice to update the mathematical notation a little bit, but since I am currently making these edits in a simple text editor I don't want to wade too deeply into trying to figure out the notation.

4) Putting it all together (1467-1778):
I was able to find pieces of example code while googling, but somehow I wasn't really able to find a complete tutorial that documented all of the steps start to finish of designing and using a custom activation function.  So I think it might be useful to post a complete example here which is just complicated enough to demonstrate all the parts needed to write a custom activation function working together.  But you might decide that this belongs elsewhere.",1,,11,2017-10-25T23:25:05Z,NONE
13983,gradient not working with aggregation on TensorArray in tf.while_loop,stat:awaiting response,"### Problem description
I am trying to compute gradient of an aggregation on the currently available elements in `tf.TensorArray` in a `tf.while_loop`, but got an `InvalidArgumentError: TensorArray TensorArray_4_21@while_63/gradients: Could not write to TensorArray index 0 because it has already been read.`

### Minimum code to reproduce the error
```python
def make_loop_test():

    def _cond(i, *_):
        return i < 3

    def _body(i, var, var_hist):
        # write current element
        var_hist = var_hist.write(i, var)

        # retrieve all current previous elements as well as the one appended just now, and compute the sum
        util = tf.reduce_sum(var_hist.gather(tf.range(0, i+1))) * 2.0 + 1.0

        # take gradient, where I think the problem comes from
        grad = tf.gradients(util, [var])[0]

        return i + 1, var - grad * 0.1, var_hist

    _init_state = (0, 2e3, tf.TensorArray(dtype=tf.float32, size=3, clear_after_read=False))

    loop_i, loop_var, loop_var_hist = tf.while_loop(_cond, _body, _init_state, parallel_iterations=1)

    return loop_i, loop_var, loop_var_hist.stack()

with tf.Session() as sess:
    print(sess.run(make_loop_test()))
```

I used to add a bunch of tf.Print statements and found the error was coming from gradient statement in the second iteration. The error message looks weird to me since I am not writing to index 0 at that time.


### Complete logs
```
File ""<ipython-input-132-3da3dc3dd8f4>"", line 18, in <module>
  print(sess.run(make_loop_test()))
File ""<ipython-input-132-3da3dc3dd8f4>"", line 13, in make_loop_test
  loop_i, loop_var, loop_var_hist = tf.while_loop(_cond, _body, _init_state, parallel_iterations=1)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2775, in while_loop
  result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2604, in BuildLoop
  pred, body, original_loop_vars, loop_vars, shape_invariants)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2554, in _BuildLoop
  body_result = body(*packed_vars_for_body)
File ""<ipython-input-132-3da3dc3dd8f4>"", line 8, in _body
  grad = tf.gradients(util, [var])[0]
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py"", line 542, in gradients
  grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py"", line 348, in _MaybeCompile
  return grad_fn()  # Exit early
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py"", line 542, in <lambda>
  grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/tensor_array_grad.py"", line 162, in _TensorArrayGatherGrad
  u_g = g.scatter(indices, grad)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py"", line 175, in wrapped
  return _add_should_use_warning(fn(*args, **kwargs))
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 441, in scatter
  name=name)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 2649, in _tensor_array_scatter_v3
  name=name)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
  op_def=op_def)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
  original_op=self._default_original_op, op_def=op_def)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
  self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
...which was originally created as op 'while_62/TensorArrayGatherV3', defined at:
File ""/home/ecsark/envs/conda/lib/python3.5/runpy.py"", line 193, in _run_module_as_main
  ""__main__"", mod_spec)
[elided 23 identical lines from previous traceback]
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2554, in _BuildLoop
  body_result = body(*packed_vars_for_body)
File ""<ipython-input-132-3da3dc3dd8f4>"", line 7, in _body
  util = tf.reduce_sum(var_hist.gather(tf.range(0, i+1))) * 2.0 + 1.0
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py"", line 93, in fn
  return method(self, *args, **kwargs)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 360, in gather
  element_shape=element_shape)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 2401, in _tensor_array_gather_v3
  element_shape=element_shape, name=name)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
  op_def=op_def)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
  original_op=self._default_original_op, op_def=op_def)
File ""/home/ecsark/envs/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
  self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
InvalidArgumentError (see above for traceback): TensorArray TensorArray_3_20@while_62/gradients: Could not write to TensorArray index 0 because it has already been read.
 [[Node: while_62/gradients/while_62/TensorArrayGatherV3_grad/TensorArrayScatter/TensorArrayScatterV3 = TensorArrayScatterV3[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](while_62/gradients/while_62/TensorArrayGatherV3_grad/TensorArrayGrad/TensorArrayGradV3, while_62/range, while_62/gradients/while_62/Sum_grad/Tile, while_62/gradients/while_62/TensorArrayGatherV3_grad/TensorArrayGrad/gradient_flow)]]
```

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 7.11 (wheezy)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.3.1-0-g48c54ee 1.3.1 
- **Python version**:  3.5.4
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA",1,,4,2017-10-25T21:32:30Z,NONE
13982,Feature Request: C++ gradient for Floor,,"Implement the gradient for Floor in c++ so that it is available for TF_AddGradients

@suharshs I will implement this one with some guidance from @bpiel 

I believe this is the python code I'll be porting over:
https://github.com/tensorflow/tensorflow/blob/962ed613cf1087637848d3e2b23f5b01d93c7eda/tensorflow/python/ops/math_grad.py#L1004-L1006
",1,,20,2017-10-25T20:23:45Z,CONTRIBUTOR
13980,NadamOptimizer throws InvalidArgumentError (incompatible shapes),stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, but this issue can be replicated by changing one line in the example script `word2vec_basic.py`
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7, MacOS High Sierra 
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.4.0-rc0-21-g1e25994', '1.4.0-rc1'). I also know someone who encountered this in the 1.3 release.
- **Python version**: 2.7.10, 2.7.14
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 8.0 / 6.0
- **GPU model and memory**: Titan X 12gb
- **Exact command to reproduce**:
Change line 190 in `tensorflow/examples/tutorials/word2vec/word2vec_basic.py` to:
`optimizer = tf.contrib.opt.NadamOptimizer(1.0).minimize(loss)`. 
Run.

### Describe the problem
When I attempt to train a model with `tf.controb.opt.NadamOptimizer`, TensorFlow crashes with an InvalidArgumentError (Incompatible shapes: [105] vs. [50000]), which is thrown from the optimizer (in my code it's when trying to apply updates to the word embedding table.) It looks like it's trying to apply sparse updates to the embeddings using dense operations, causing a shape mismatch, or something along those lines. `AdamOptimizer` and `LazyAdamOptimizer` work fine.

### Source code / logs
Traceback can be found [here](https://gist.github.com/strubell/37897084888252989750b58260f76ff5).
The error is easily replicable in the example script `word2vec_basic.py`.
",0,,5,2017-10-25T19:33:57Z,NONE
13963,Tensorflow crashes when importing certain modules before tensorflow,stat:community support,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
binary both from conda-forge and from pip install using the tfBinaryURL

- **TensorFlow version (use command below)**:
1.3.0

- **Python version**:
3.6.2 from Anaconda

- **CUDA/cuDNN version**:
CUDA 8.0 cuDNN 6.0

- **GPU model and memory**:
GTX 1060 6 GB RAM

- **Exact command to reproduce**:
```python
import psi4
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))
```

### Describe the problem
Running the above code produces the following error

```
2017-10-24 22:17:35.570620: F tensorflow/core/framework/op.cc:165] Non-OK-status: RegisterAlreadyLocked(deferred_[i]) status: Invalid argument: Could not parse default value '4000' from Attr(""upper_frequency_limit: float = 4000"") for Op Mfcc
Could not parse default value '20' from Attr(""lower_frequency_limit: float = 20"") for Op Mfcc
forrtl: error (76): Abort trap signal
```

Strangely if tensorflow is imported before psi4 then the same error does not occur. Also, the error seems to be related to one of the Ops in tensorflow/tensorflow/core/kernels/mfcc.h which as far as I can tell is not an Op that I'm even using.

This issue occurs with at least two different python modules that I know of, psi4 as I have run into, and lycon which has their own issue open regarding this same error ethereon/lycon#3. In the linked issue it seems that this error occurs for others on python 2 and 3.5 with Ubuntu 16.04 both with and without GPU support for tensorflow, but another user states that this did not occur for him on Ubuntu 14.04 or on macOS 10.13. It seems like this may be an issue specific to at least Ubuntu 16.04 then.

### Source code / logs
Full output from the error

```
2017-10-24 22:17:35.570620: F tensorflow/core/framework/op.cc:165] Non-OK-status: RegisterAlreadyLocked(deferred_[i]) status: Invalid argument: Could not parse default value '4000' from Attr(""upper_frequency_limit: float = 4000"") for Op Mfcc
Could not parse default value '20' from Attr(""lower_frequency_limit: float = 20"") for Op Mfcc
forrtl: error (76): Abort trap signal
Image              PC                Routine            Line        Source             
libpcm.so.1        00007FCA4B14A725  Unknown               Unknown  Unknown
libpcm.so.1        00007FCA4B148347  Unknown               Unknown  Unknown
libpcm.so.1        00007FCA4B05FAA2  Unknown               Unknown  Unknown
libpcm.so.1        00007FCA4B05F8F6  Unknown               Unknown  Unknown
libpcm.so.1        00007FCA4B02DEFD  Unknown               Unknown  Unknown
libpcm.so.1        00007FCA4B031ABF  Unknown               Unknown  Unknown
libpthread.so.0    00007FCA5609F390  Unknown               Unknown  Unknown
libc.so.6          00007FCA55CF9428  Unknown               Unknown  Unknown
libc.so.6          00007FCA55CFB02A  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0DA71B94  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D94AAFE  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D94B21A  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D924199  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D946EFE  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D934760  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D68F8D7  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D62136E  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D621488  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0D621876  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0B615970  Unknown               Unknown  Unknown
_pywrap_tensorflo  00007FCA0B434177  Unknown               Unknown  Unknown
python             000055BE1E6850C6  Unknown               Unknown  Unknown
python             000055BE1E7181DC  Unknown               Unknown  Unknown
python             000055BE1E7398BA  Unknown               Unknown  Unknown
python             000055BE1E711FEB  Unknown               Unknown  Unknown
python             000055BE1E7182B5  Unknown               Unknown  Unknown
python             000055BE1E7398BA  Unknown               Unknown  Unknown
python             000055BE1E713116  Unknown               Unknown  Unknown
python             000055BE1E713B84  Unknown               Unknown  Unknown
python             000055BE1E684F8E  Unknown               Unknown  Unknown
python             000055BE1E73AF74  Unknown               Unknown  Unknown
python             000055BE1E711334  Unknown               Unknown  Unknown
python             000055BE1E712221  Unknown               Unknown  Unknown
python             000055BE1E7182B5  Unknown               Unknown  Unknown
python             000055BE1E7398BA  Unknown               Unknown  Unknown
python             000055BE1E711908  Unknown               Unknown  Unknown
python             000055BE1E712221  Unknown               Unknown  Unknown
python             000055BE1E7182B5  Unknown               Unknown  Unknown
python             000055BE1E7398BA  Unknown               Unknown  Unknown
python             000055BE1E711FEB  Unknown               Unknown  Unknown
python             000055BE1E7182B5  Unknown               Unknown  Unknown
python             000055BE1E7398BA  Unknown               Unknown  Unknown
python             000055BE1E711334  Unknown               Unknown  Unknown
python             000055BE1E712221  Unknown               Unknown  Unknown
python             000055BE1E7182B5  Unknown               Unknown  Unknown
python             000055BE1E7398BA  Unknown               Unknown  Unknown
python             000055BE1E712D58  Unknown               Unknown  Unknown
python             000055BE1E713B0C  Unknown               Unknown  Unknown
python             000055BE1E78DF04  Unknown               Unknown  Unknown
python             000055BE1E65475A  Unknown               Unknown  Unknown
python             000055BE1E6548FD  Unknown               Unknown  Unknown
python             000055BE1E65495E  Unknown               Unknown  Unknown
python             000055BE1E656B65  Unknown               Unknown  Unknown
python             000055BE1E65951E  Unknown               Unknown  Unknown
libc.so.6          00007FCA55CE4830  Unknown               Unknown  Unknown
python             000055BE1E7403D9  Unknown               Unknown  Unknown
Aborted (core dumped)
```
",0,,10,2017-10-25T02:53:56Z,NONE
13954,"make ""smart_cond"" api public and reusable","awaiting review,cla: yes,stat:awaiting tensorflower","Fix #13903 

Move the implementation of ""smart_cond"" and ""constant_value"" from tensorflow/python/layers/utils to tensorflow/python/ops/control_flow_ops and add corresponding test and expose smart_cond to tensorflow/python/ops/standard_ops.

@martinwicke should I implement the API in this way or not? As I think ops should be lower level API than layers and smart_cond should be a kind of ops. It's my first time to contribute to TensorFlow. Please feel free to correct me if there's any problem with the design and codes.

Tips, I closed the former PR #13938 and create a new since there's some signature/info problem with that PR.",1,,16,2017-10-24T19:07:15Z,NONE
13947,Tensorflow import fails with Segmentation fault error,stat:community support,"Hello

I have pip3 installed tensorflow CPU only
Python version:  3.5.2
OS:LSB Version:    :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch
Distributor ID: RedHatEnterpriseServer
Description:    Red Hat Enterprise Linux Server release 6.8 (Santiago)
Release:        6.8
Codename:       Santiago

Install command: pip3 install tensorflow

echo $LD_LIBRARY_PATH
:/usr/local/lib:/grapps/hadoop/instantclient/instantclient_11_2:/usr/local/lib:/opt/glibc-2.14/lib


Python 3.5.2 (default, Mar 23 2017, 07:51:35)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-17)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>>
>>> import tensorflow
Segmentation fault


Also tried to import scipy,numpy and matplotlib before importing tensorflow as per suggestion seens in some other cases https://github.com/tensorflow/tensorflow/issues/2034. 

But nothing solved the issue. 

Thanks for the advice 

Abraham 



",0,,1,2017-10-24T12:50:14Z,NONE
13939,Quantization make graph slower during inference.,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: using TF source code (GPU build), can provide docker to reproduce environment conditions if necessary
- **TensorFlow version**: using r1.3 branch, version 1.3.1
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.6.1
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: GeForce GTX 1080 Ti, 11170 MB
- **Exact command to reproduce**: 
/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph  --in_graph=/quantization/VGG16/frozen_model.pb   --outputs=""Validation_segmentation/Validation/decoder/Softmax"" --out_graph=/quantization/VGG16/optimized_model.pb   --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""384,1248,3"") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes'


### Describe the problem
Hi, I compressed a graph using transform_graph tool but the resulting graph is actually slower during inference. I am compressing a graph similar to the one presented in this article: https://arxiv.org/pdf/1612.07695.pdf, which has VGG16 as an encoder in input and a classification decoder with a Softmax in output. Inference uses same python script for both graph (original and quantized) and make an average of 100 inferences. Original graph takes ~0.1s for inference, quantized graph takes 70s! If I perform quantization without quantize_nodes, inference takes ~0.3s.

I understand that this quantization is still in a work in progress and maybe was more aimed at improving inference on mobile devices, but I'm surprised that it is actually so much slower, so that's why I'm logging it as a bug here. (I posted this on stackoverflow but didn't get any answer...)

The graph takes ~500Mb, let me know if I should attach it to this ticket (or include an external link?)

### Source code / logs
[quantization_logs.txt](https://github.com/tensorflow/tensorflow/files/1409825/quantization_logs.txt)
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1409824/tf_env.txt)
[inference.py.txt](https://github.com/tensorflow/tensorflow/files/1409864/inference.py.txt)

",1,,5,2017-10-24T07:19:04Z,NONE
13931,TF 1.4 (CUDA 9/CUDNN7) Chrome Tracing Timeline broken,,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow


------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ArchLinux Latest
- **TensorFlow installed from (source or binary)**:Source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.7
- **CUDA/cuDNN version**: 9 /7
- **GPU model and memory**: 2* Nvidia1080ti (11GB)
- **Exact command to reproduce**: 
run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
run_metadata = tf.RunMetadata()
training_loss_, _ = sess.run(op_list,                                          
      feed_dict=feed_dict,
      options=run_options,run_metadata=run_metadata)
tl=timeline.Timeline(run_metadata.step_stats)
chrome_trace = tl.generate_chrome_trace_format()
with open(filename, 'w') as f:
              f.write(chrome_trace)


### Describe the problem
After switching to TF 1.4 compiled with CUDA 9 /CUDNN7 from TF 1.3 with CUDA 8 and CUDNN 6, chrome trace timeline stopped working, otherwise the code runs as before. See the attached screenshots (TF1.4 / TF1.3).

### Source code / logs
![image](https://user-images.githubusercontent.com/24719485/31917426-7a1b3828-b84f-11e7-8352-b82088b353bb.png)
![image](https://user-images.githubusercontent.com/24719485/31917461-9f9dd3d0-b84f-11e7-874d-c9c6dadf3bc8.png)
",1,,3,2017-10-23T23:29:50Z,NONE
13926,Build from source issue (CUDA 7.5),stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4 RC0
- **Python version**: 3.4.3
- **Bazel version (if compiling from source)**: 0.7
- **CUDA/cuDNN version**: CUDA7.5 , cudnn v5.1
- **GPU model and memory**: GeForce GTX TITAN 
- **Exact command to reproduce**: `bazel build --config opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`

### Describe the problem
I am trying to build tensorflow 1.4 RC0 from source, getting compilation error that 'cusolverEigMode_t' has not been declared.

Looks like this is the commit where this code was added:
https://github.com/tensorflow/tensorflow/commit/e3413de529c3f762885efd62932f76445ed22653#diff-e4b1fa736000720d06dab76006540ec4R467

I tried grepping for `cusolverEigMode_t`in my `/usr/local/cuda/` but could not find any reference, is it possible that `cusolverEigMode_t` is not supported in CUDA 7.5? 
In that case, it should be noted that 1.4 is only supported for CUDA 8.0 and above

### Source code / logs
```
ERROR: /home/xxxxx/downloads/tensorflow/tensorflow/core/kernels/BUILD:839:1: C++ compilation of rule '//tensorflow/core/kernels:where_op' failed (Exit 1).
In file included from tensorflow/core/kernels/where_op.cc:42:0:
./tensorflow/core/kernels/cuda_solvers.h:299:16: error: 'cusolverEigMode_t' has not been declared
   Status Heevd(cusolverEigMode_t jobz, cublasFillMode_t uplo, int n,
                ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```
",0,,15,2017-10-23T21:08:31Z,NONE
13912,tensorflow is not importing even after successful installation ,stat:awaiting response,"in Centos 6.9 i am unable to import tensorflow-1.3.0 in any anaconda (2,3) and getting this error please resolve this issue ..




![screenshot-7](https://user-images.githubusercontent.com/24870531/31872238-d008d862-b7d7-11e7-8f4a-0f2ad9b159a1.png)
![screenshot-6](https://user-images.githubusercontent.com/24870531/31872240-d04142c4-b7d7-11e7-8cab-9bd5b2f931c7.png)
",0,,4,2017-10-23T04:22:08Z,NONE
13903,Feature request: make `smart_cond` public API,"stat:contributions welcome,type:feature","------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.3.0-24-g658866597
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: None

### Describe the problem

Currently `tf.cond` does not work if predicate is a Python boolean. As a result, people frequently have to write conditional statements twice, one with `if` statement, and one with `tf.cond` call. There is a `smart_cond` in `tensorflow/python/layers/utils.py`, but it is not in the public API or searchable in documentation. Petition to make it public or just integrate the smartness in `tf.cond` altogether. It is not a big change and will not impact backwards compatibility.",1,,4,2017-10-22T15:04:55Z,NONE
13890,tf.image.crop_and_resize() return 0 values when assigned to GPU on  the Jetson TX2 ,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.LTS
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.5.2
- **CUDA/cuDNN version**: 8.0/6.0.21
- **GPU model and memory**: Nvidia Tegra X2
- **Exact command to reproduce**:`tf.image.crop_and_resize(raw_sample, boxes, box_ind)`

### Describe the problem
I'm getting completly different results from tensorflow's function `tf.image.crop_and_resize(...)` when assigned it to gpu and cpu.
In other words:
  -when I run this ops on CPU, I get correct results( I mean, the  right crops)
  -when I put it on the GPU device I get crops fulled with 0 values.

### Source code / logs
Here, you can see a simple use case:
```
import tensorflow as tf 
import numpy as np
import cv2 #Just importing cv2 to read  image, you use PIL or anything else to load it

device='gpu' 

def img2batch_crops(input_image):
    raw_sample_tensor_4d=tf.expand_dims(input_image, 0)
    
    #Setting the size to crop and the final size of cropped images
    patches_top=[0,0.5]
    patches_bottom =[0.5,0.5]
    crop_size = [100,100]
    boxes=tf.stack([patches_top, patches_top, patches_bottom, patches_bottom], axis=1)
    
    ##Here is the bug:
        #When device == 'cpu', I got  results 
        #When device == 'gpu', I got  black cropped images( 0 values)
    with tf.device('/'+device+':0'):  
        crops=tf.image.crop_and_resize(raw_sample_tensor_4d, boxes, box_ind=tf.zeros_like(patches_top, dtype=tf.int32), crop_size=crop_size, name=""croper"")

    return crops


def main():

	img_data = cv2.imread('image.jpg') #Just loading the image,

	print(""Shape and type of image input "",img_data.shape, img_data.dtype) #Print the shape and the type of the image, supposed to be a numpy array

	raw_image = tf.placeholder(dtype=tf.float32, shape=img_data.shape, name='input_image')
     
       crops = img2batch_crops(raw_image) # Adding ops to the graph

	with tf.Session() as sess:
	    myBatchedImages = sess.run(crops, feed_dict={raw_image:img_data})
	    cv2.imwrite('result_'+device+'.jpg',myBatchedImages[0])   ## Savej just one cropped image to see how it looks like

main()
```
",0,,4,2017-10-21T21:31:45Z,NONE
13888,InvalidArgumentError: No OpKernel was registered to support Op 'Resampler' with these attrs. ,stat:contributions welcome,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: Python 3.6.2 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 8/ CUDNN 6
- **GPU model and memory**: GeForce 940MX
- **Exact command to reproduce**: tf.contrib.resampler.resampler(inp,warp)

### Describe the problem
No registered kernels for the resampler operation. The code is as follows
`import tensorflow as tf`
`inp = tf.ones([1,4,4,3],dtype=tf.float32)`
`warp = tf.zeros([1,4,4,2],dtype=tf.float32)`
`out = tf.contrib.resampler.resampler(inp,warp)`
`print(out)`
`sess = tf.Session()`
`print(sess.run(out))`

### Source code / logs
I get the following output and error, traceback

Tensor(""resampler_1/Resampler:0"", shape=(1, 4, 4, 3), dtype=float32)

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1326     try:
-> 1327       return fn(*args)
   1328     except errors.OpError as e:

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\client\session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1296       # Ensure any changes to the graph are reflected in the runtime.
-> 1297       self._extend_graph()
   1298       with errors.raise_exception_on_not_ok_status() as status:

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\client\session.py in _extend_graph(self)
   1357           tf_session.TF_ExtendGraph(
-> 1358               self._session, graph_def.SerializeToString(), status)
   1359         self._opened = True

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\contextlib.py in __exit__(self, type, value, traceback)
     87             try:
---> 88                 next(self.gen)
     89             except StopIteration:

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\errors_impl.py in raise_exception_on_not_ok_status()
    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 466           pywrap_tensorflow.TF_GetCode(status))
    467   finally:

InvalidArgumentError: No OpKernel was registered to support Op 'Resampler' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
 &lt;no registered kernels&gt;

	 [[Node: resampler_1/Resampler = Resampler[T=DT_FLOAT](ones_2, zeros_2)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-3-0ff9594126bf> in <module>()
      5 print(out)
      6 sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
----> 7 print(sess.run(out))

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    893     try:
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--> 895                          run_metadata_ptr)
    896       if run_metadata:
    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1122     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1123       results = self._do_run(handle, final_targets, final_fetches,
-> 1124                              feed_dict_tensor, options, run_metadata)
   1125     else:
   1126       results = []

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\client\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1319     if handle is None:
   1320       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1321                            options, run_metadata)
   1322     else:
   1323       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1338         except KeyError:
   1339           pass
-> 1340       raise type(e)(node_def, op, message)
   1341 
   1342   def _extend_graph(self):

InvalidArgumentError: No OpKernel was registered to support Op 'Resampler' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
 &lt;no registered kernels&gt;

	 [[Node: resampler_1/Resampler = Resampler[T=DT_FLOAT](ones_2, zeros_2)]]

Caused by op 'resampler_1/Resampler', defined at:
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\traitlets\config\application.py"", line 658, in launch_instance
    app.start()
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\ipykernel\kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\zmq\eventloop\ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tornado\ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\zmq\eventloop\zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\zmq\eventloop\zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\zmq\eventloop\zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\ipykernel\kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\ipykernel\kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\ipykernel\kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\ipykernel\ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\ipykernel\zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 2698, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 2802, in run_ast_nodes
    if self.run_code(code, result):
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 2862, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-3-0ff9594126bf>"", line 4, in <module>
    out = tf.contrib.resampler.resampler(inp,warp)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\contrib\resampler\python\ops\resampler_ops.py"", line 59, in resampler
    return gen_resampler_ops.resampler(data_tensor, warp_tensor)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\contrib\resampler\ops\gen_resampler_ops.py"", line 28, in resampler
    result = _op_def_lib.apply_op(""Resampler"", data=data, warp=warp, name=name)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""F:\Sharath\Anaconda\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'Resampler' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  &lt;no registered kernels&gt;

	 [[Node: resampler_1/Resampler = Resampler[T=DT_FLOAT](ones_2, zeros_2)]]
",0,,6,2017-10-21T20:07:14Z,NONE
13876,Should we provide parameters for 'data_dir' or 'untar' to cifar10.load_data?,stat:contributions welcome,"https://github.com/tensorflow/tensorflow/blob/d7409d32bba5ffa89141ec5427780f68a3b6942d/tensorflow/python/keras/_impl/keras/datasets/cifar10.py#L30

This is maybe really a trivial issue for such a brilliant framework,
but it would be great more friendly to add this flexibility to load data from somewhere that I already have it and unpacked. Or it will fixed me to dig into the source to find where and in which format should this data be stored.

Hope that make sense.

Thanks a lot for you time.",0,,5,2017-10-21T04:40:57Z,NONE
13869,"conv2d_transpose crashing, ""NotFoundError: No algorithm worked!"", only with batch size >=2^16","stat:community support,type:bug/performance","I'm getting a crash running a simple autoencoder network, stack trace below. Interestingly if I trim the batch size of the input (validate_vecs_normed) to 65535, everything is fine. E.g.
`validate_vecs_normed.shape (65536, 75)` crashes, `validate_vecs_normed.shape (65536, 75)` does not. The size of input is less than 20 MB so should be plenty of room with a 12GB card.

```
Traceback (most recent call last):
  [...snip...] 
    recon, batch_cost = sess.run([decoded, cost], feed_dict={x_in_unrav: validate_vecs_normed})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: No algorithm worked!
	 [[Node: conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NHWC"", padding=""VALID"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](stack, W_0/read, enc_output_0)]]
	 [[Node: cost/_25 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_47_cost"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'conv2d_transpose', defined at:
  [...snip...]
    saver = tf.train.import_meta_graph(os.path.join(model_dir, model_meta_format.format(fold_ind)))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1698, in import_meta_graph
    **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.py"", line 656, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 313, in import_graph_def
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): No algorithm worked!
	 [[Node: conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NHWC"", padding=""VALID"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](stack, W_0/read, enc_output_0)]]
	 [[Node: cost/_25 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_47_cost"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```
Possibly related to #11327 or #9576 but not sure. One other thing, when running same code on tensorflow 1.0.1, there was no crash, but the return value ""decoded"" was all zeros when running a large batch size, and normal with smaller. I'm not sure if it's the same 65535/65536 threshold, I hadn't found it at that point.

Just for fun I ran with `TF_USE_CUDNN=0` but that crashes with `UnimplementedError (see above for traceback): Conv2D for GPU is not currently supported without cudnn`

OS: Ubuntu 16.04. 
Running docker image based on tensorflow/tensorflow:1.3.0-devel-gpu (so python 2.7.12, CUDA v8.0, cuDNN v6.0), with nvidia-docker 17.05.0-ce. 
Docker image tensorflow/tensorflow:1.0.1-gpu returns all zeros instead of crashing.
GPUs: 2x Titan X (Pascal).






",0,,4,2017-10-20T21:46:31Z,NONE
13868,speech_commands svdf model does not work in android demo app.,,"== cat /etc/issue ===============================================
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.0.0 (clang-900.0.37)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.4.0rc1)

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc1-3261-g934662e7b
tf.COMPILER_VERSION = v1.3.0-rc1-3261-g934662e7b
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
/var/tmp/collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================


### Describe the problem
under tensorflow/examples/speech_commands, there are three models for speech commands. The 
default one(conv) and low-latency-conv works when I install them to android demo app(tensorflow/examples/android). 

low-latency-svdf does not work in the android app, it works on pc though.

If i copy the svdf model into the app, app crashes when startup reporting model file error like this:

`Not a valid TensorFlow Graph serialization: Value for attr 'T' of int64 is not in the list of allowed values: float, int32, qint8, quint8, qint32
; NodeDef: count_nonzero/Sum = Sum[T=DT_INT64, Tidx=DT_INT32, keep_dims=false](count_nonzero/ToInt64, count_nonzero/Const); Op<name=Sum; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_INT32, DT_QINT8, DT_QUINT8, DT_QINT32]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>`

### Source code / logs

> 10-20 17:08:30.889 23598-23598/org.tensorflow.demo.svdf D/AndroidRuntime: Shutting down VM
10-20 17:08:30.894 23598-23598/org.tensorflow.demo.svdf E/AndroidRuntime: FATAL EXCEPTION: main
                                                                          Process: org.tensorflow.demo.svdf, PID: 23598
                                                                          java.lang.RuntimeException: Unable to start activity ComponentInfo{org.tensorflow.demo.svdf/org.tensorflow.demo.SpeechActivity}: java.lang.RuntimeException: Failed to load model from 'file:///android_asset/marvin_sheila_ll_svdf_graph.pb'
                                                                              at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2817)
                                                                              at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2892)
                                                                              at android.app.ActivityThread.-wrap11(Unknown Source:0)
                                                                              at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1593)
                                                                              at android.os.Handler.dispatchMessage(Handler.java:105)
                                                                              at android.os.Looper.loop(Looper.java:164)
                                                                              at android.app.ActivityThread.main(ActivityThread.java:6541)
                                                                              at java.lang.reflect.Method.invoke(Native Method)
                                                                              at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240)
                                                                              at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)
                                                                           Caused by: java.lang.RuntimeException: Failed to load model from 'file:///android_asset/marvin_sheila_ll_svdf_graph.pb'
                                                                              at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:113)
                                                                              at org.tensorflow.demo.SpeechActivity.onCreate(SpeechActivity.java:151)
                                                                              at android.app.Activity.performCreate(Activity.java:6975)
                                                                              at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1213)
                                                                              at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2770)
                                                                              at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2892) 
                                                                              at android.app.ActivityThread.-wrap11(Unknown Source:0) 
                                                                              at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1593) 
                                                                              at android.os.Handler.dispatchMessage(Handler.java:105) 
                                                                              at android.os.Looper.loop(Looper.java:164) 
                                                                              at android.app.ActivityThread.main(ActivityThread.java:6541) 
                                                                              at java.lang.reflect.Method.invoke(Native Method) 
                                                                              at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240) 
                                                                              at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767) 
                                                                           Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Value for attr 'T' of int64 is not in the list of allowed values: float, int32, qint8, quint8, qint32
                                                                          	; NodeDef: count_nonzero/Sum = Sum[T=DT_INT64, Tidx=DT_INT32, keep_dims=false](count_nonzero/ToInt64, count_nonzero/Const); Op<name=Sum; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_INT32, DT_QINT8, DT_QUINT8, DT_QINT32]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>
                                                                              at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)
                                                                              at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:105)
                                                                              	... 13 more
",1,,5,2017-10-20T21:12:26Z,NONE
13857,Trying to import tensorflow but im getting this im using the cuda 9 and cudnn 7,stat:community support,"Traceback (most recent call last):
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/mohammad/.conda/envs/my_root/lib/python3.6/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/mohammad/.conda/envs/my_root/lib/python3.6/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/mohammad/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/mohammad/.conda/envs/my_root/lib/python3.6/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/mohammad/.conda/envs/my_root/lib/python3.6/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.
",0,,4,2017-10-20T16:46:32Z,NONE
13851,Fail in configuration due to different CUDA libraries path,"stat:contributions welcome,type:build/install","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 49f9c6f890c938955fa2d448ac5b556b9a6d9aa0
- **Python version**: Python 3.5.3
- **Bazel version (if compiling from source)**: bazel release 0.6.1
- **CUDA/cuDNN version**: CUDA 8, cuDNN 7
- **GPU model and memory**: GeForce GTX 1080 

### Describe the problem
As for now, TF assumes that CUDA liibs are located at `CUDA_PATH/lib64/`, however Ubuntu installs CUDA to `/usr/lib/x86_64-linux-gnu/`, which makes configuration impossible: I can't specify cuda path such that it'll find `/usr/lib/x86_64-linux-gnu/libcudart.so.8.0`
",0,,14,2017-10-20T07:52:18Z,NONE
13848,can not compile android demo for x86,stat:awaiting response,"I tried to use the following commands to build android demo for x86
bazel build //tensorflow/examples/android:tensorflow_demo --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain  --force_pic --cpu=x86_64 --config=android_x86

I always get the tensorflow_demo.apk for ARM device.
Is there anything wrong?",0,,5,2017-10-20T06:19:48Z,NONE
13844,Saving large graphs to S3 fails with InternalError: : Unable to connect to endpoint,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes; modified Tensorflow [save/load example code](https://www.tensorflow.org/programmers_guide/saved_model) to save a few large tensors to S3
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version**:
Git version: `v1.3.0-rc1-3504-g27767d8`
Tensorflow version: `1.4.0-rc1`
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Nvidia Tesla K80 (12 GiB RAM)
- **Exact command to reproduce**: Run the code in [this gist](https://gist.github.com/smurching/8766a9d91c148ef7d89292b6dd4da5b8) in a Python shell. You'll need access to an S3 bucket for which you have write permissions.

### Describe the problem
I'm trying to save a large (~380 MB) graph to S3, but my call to `tf.Saver.save()` crashes after ~1 min with what appears to be an AWS SDK error (`InternalError: : Unable to connect to endpoint`).

If the error is indeed AWS related, it'd be helpful to wrap it in something to indicate that the error isn't coming from tensorflow. Here's the stacktrace:

```
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
<command-5036518> in <module>()
----> 1 test_save(num_tensors=10, tensor_size=10000000, save_path=""s3://<redacted_s3_bucket_name>/model.ckpt"")

<command-5036204> in test_save(num_tensors, tensor_size, save_path)
     18     sess.run(init_op)
     19     # Save the variables to disk.
---> 20     save_path = saver.save(sess, save_path)
     21     print(""Model saved in file: %s"" % save_path)

/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)
   1571           model_checkpoint_path = sess.run(
   1572               self.saver_def.save_tensor_name,
-> 1573               {self.saver_def.filename_tensor_name: checkpoint_file})
   1574         else:
   1575           self._build_eager(

/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    887     try:
    888       result = self._run(None, fetches, feed_dict, options_ptr,
--> 889                          run_metadata_ptr)
    890       if run_metadata:
    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1119       results = self._do_run(handle, final_targets, final_fetches,
-> 1120                              feed_dict_tensor, options, run_metadata)
   1121     else:
   1122       results = []

/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1315     if handle is None:
   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1317                            options, run_metadata)
   1318     else:
   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1334         except KeyError:
   1335           pass
-> 1336       raise type(e)(node_def, op, message)
   1337 
   1338   def _extend_graph(self):

InternalError: : Unable to connect to endpoint
	 [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]

Caused by op u'save/SaveV2', defined at:
  File ""/tmp/1509404428358-0/PythonShell.py"", line 990, in <module>
    launch_process()
  File ""/tmp/1509404428358-0/PythonShell.py"", line 986, in launch_process
    shell.executor.run()
  File ""/tmp/1509404428358-0/PythonShell.py"", line 263, in run
    self.shell.shell.run_cell(command_id, cmd, store_history=True)
  File ""/tmp/1509404428358-0/PythonShell.py"", line 572, in run_cell
    super(IPythonShell, self).run_cell(raw_cell, store_history, silent, shell_futures)
  File ""/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2741, in run_cell
    interactivity=interactivity, compiler=compiler)
  File ""/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2833, in run_ast_nodes
    if self.run_code(code):
  File ""/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2883, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<command-5036518>"", line 1, in <module>
    test_save(num_tensors=10, tensor_size=10000000, save_path=""s3://databricks-mllib/tmp/s3-save-failure/model.ckpt"")
  File ""<command-5036204>"", line 13, in test_save
    saver = tf.train.Saver()
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1218, in __init__
    self.build()
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1227, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1263, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 748, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 296, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 239, in save_op
    tensors)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1163, in save_v2
    shape_and_slices=shape_and_slices, tensors=tensors, name=name)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InternalError (see above for traceback): : Unable to connect to endpoint
	 [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]
```

If I run the same code but checkpoint to my local filesystem the save op runs without error.
The error also only seems to occur for large graphs (running the [linked gist](https://gist.github.com/smurching/8766a9d91c148ef7d89292b6dd4da5b8) with smaller/fewer tensors works)



",0,,9,2017-10-20T01:24:35Z,NONE
13838,optimize_for_inference - KeyError,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yUP.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Elementary OS 0.4 Loki
- **TensorFlow installed from (source or binary)**: ```pip install tensorflow```
- **TensorFlow version (use command below)**: ```('v1.3.0-rc2-20-g0787eee', '1.3.0')```
- **Python version**: 2.7.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.5
- **GPU model and memory**: NVIDIA GTX 1060 - 6GB 
- **Exact command to reproduce**:

### Describe the problem

Experiencing a strange KeyError whilst attempting to optimize graph.

```
Traceback (most recent call last):
  File ""/home/keo7/Projects/AgriDoctorAlpha/model/keras/main.py"", line 126, in <module>
    export_model(tf.train.Saver(), model, [""input_1""], ""dense_3/kernel"")
  File ""/home/keo7/Projects/AgriDoctorAlpha/model/keras/main.py"", line 115, in export_model
    tf.float32.as_datatype_enum)
  File ""/home/keo7/.virtualenvs/deeplearning/local/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py"", line 109, in optimize_for_inference
    placeholder_type_enum)
  File ""/home/keo7/.virtualenvs/deeplearning/local/lib/python2.7/site-packages/tensorflow/python/tools/strip_unused_lib.py"", line 83, in strip_unused
    raise KeyError(""The following input nodes were not found: %s\n"" % not_found)
KeyError: ""The following input nodes were not found: set(['input_1'])\n""
```

### Source code / logs

```python
output_graph_def = optimize_for_inference_lib.optimize_for_inference(
            input_graph_def, [""input_1""], [""dense_3/kernel""]
            tf.float32.as_datatype_enum)
```

Graph:

```
node {
  name: ""input_1""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: -1
        }
        dim {
          size: 48
        }
        dim {
          size: 48
        }
        dim {
          size: 3
        }
      }
    }
  }
}
node {
  name: ""block1_conv1/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\003\000\000\000@\000\000\000""
      }
    }
  }
}
node {
  name: ""block1_conv1/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0997509360313
      }
    }
  }
}
node {
  name: ""block1_conv1/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0997509360313
      }
    }
  }
}
node {
  name: ""block1_conv1/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block1_conv1/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 4107740
    }
  }
}
node {
  name: ""block1_conv1/random_uniform/sub""
  op: ""Sub""
  input: ""block1_conv1/random_uniform/max""
  input: ""block1_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_conv1/random_uniform/mul""
  op: ""Mul""
  input: ""block1_conv1/random_uniform/RandomUniform""
  input: ""block1_conv1/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_conv1/random_uniform""
  op: ""Add""
  input: ""block1_conv1/random_uniform/mul""
  input: ""block1_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_conv1/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 64
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block1_conv1/kernel/Assign""
  op: ""Assign""
  input: ""block1_conv1/kernel""
  input: ""block1_conv1/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block1_conv1/kernel/read""
  op: ""Identity""
  input: ""block1_conv1/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/kernel""
      }
    }
  }
}
node {
  name: ""block1_conv1/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 64
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block1_conv1/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 64
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block1_conv1/bias/Assign""
  op: ""Assign""
  input: ""block1_conv1/bias""
  input: ""block1_conv1/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block1_conv1/bias/read""
  op: ""Identity""
  input: ""block1_conv1/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/bias""
      }
    }
  }
}
node {
  name: ""block1_conv1/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\003\000\000\000@\000\000\000""
      }
    }
  }
}
node {
  name: ""block1_conv1/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block1_conv1/convolution""
  op: ""Conv2D""
  input: ""input_1""
  input: ""block1_conv1/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block1_conv1/BiasAdd""
  op: ""BiasAdd""
  input: ""block1_conv1/convolution""
  input: ""block1_conv1/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block1_conv1/Relu""
  op: ""Relu""
  input: ""block1_conv1/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_conv2/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000@\000\000\000@\000\000\000""
      }
    }
  }
}
node {
  name: ""block1_conv2/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0721687823534
      }
    }
  }
}
node {
  name: ""block1_conv2/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0721687823534
      }
    }
  }
}
node {
  name: ""block1_conv2/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block1_conv2/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 9992257
    }
  }
}
node {
  name: ""block1_conv2/random_uniform/sub""
  op: ""Sub""
  input: ""block1_conv2/random_uniform/max""
  input: ""block1_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_conv2/random_uniform/mul""
  op: ""Mul""
  input: ""block1_conv2/random_uniform/RandomUniform""
  input: ""block1_conv2/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_conv2/random_uniform""
  op: ""Add""
  input: ""block1_conv2/random_uniform/mul""
  input: ""block1_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_conv2/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 64
        }
        dim {
          size: 64
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block1_conv2/kernel/Assign""
  op: ""Assign""
  input: ""block1_conv2/kernel""
  input: ""block1_conv2/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block1_conv2/kernel/read""
  op: ""Identity""
  input: ""block1_conv2/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/kernel""
      }
    }
  }
}
node {
  name: ""block1_conv2/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 64
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block1_conv2/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 64
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block1_conv2/bias/Assign""
  op: ""Assign""
  input: ""block1_conv2/bias""
  input: ""block1_conv2/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block1_conv2/bias/read""
  op: ""Identity""
  input: ""block1_conv2/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/bias""
      }
    }
  }
}
node {
  name: ""block1_conv2/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000@\000\000\000@\000\000\000""
      }
    }
  }
}
node {
  name: ""block1_conv2/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block1_conv2/convolution""
  op: ""Conv2D""
  input: ""block1_conv1/Relu""
  input: ""block1_conv2/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block1_conv2/BiasAdd""
  op: ""BiasAdd""
  input: ""block1_conv2/convolution""
  input: ""block1_conv2/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block1_conv2/Relu""
  op: ""Relu""
  input: ""block1_conv2/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block1_pool/MaxPool""
  op: ""MaxPool""
  input: ""block1_conv2/Relu""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""ksize""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""VALID""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
}
node {
  name: ""block2_conv1/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000@\000\000\000\200\000\000\000""
      }
    }
  }
}
node {
  name: ""block2_conv1/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0589255653322
      }
    }
  }
}
node {
  name: ""block2_conv1/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0589255653322
      }
    }
  }
}
node {
  name: ""block2_conv1/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block2_conv1/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 6910695
    }
  }
}
node {
  name: ""block2_conv1/random_uniform/sub""
  op: ""Sub""
  input: ""block2_conv1/random_uniform/max""
  input: ""block2_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_conv1/random_uniform/mul""
  op: ""Mul""
  input: ""block2_conv1/random_uniform/RandomUniform""
  input: ""block2_conv1/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_conv1/random_uniform""
  op: ""Add""
  input: ""block2_conv1/random_uniform/mul""
  input: ""block2_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_conv1/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 64
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block2_conv1/kernel/Assign""
  op: ""Assign""
  input: ""block2_conv1/kernel""
  input: ""block2_conv1/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block2_conv1/kernel/read""
  op: ""Identity""
  input: ""block2_conv1/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/kernel""
      }
    }
  }
}
node {
  name: ""block2_conv1/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block2_conv1/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block2_conv1/bias/Assign""
  op: ""Assign""
  input: ""block2_conv1/bias""
  input: ""block2_conv1/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block2_conv1/bias/read""
  op: ""Identity""
  input: ""block2_conv1/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/bias""
      }
    }
  }
}
node {
  name: ""block2_conv1/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000@\000\000\000\200\000\000\000""
      }
    }
  }
}
node {
  name: ""block2_conv1/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block2_conv1/convolution""
  op: ""Conv2D""
  input: ""block1_pool/MaxPool""
  input: ""block2_conv1/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block2_conv1/BiasAdd""
  op: ""BiasAdd""
  input: ""block2_conv1/convolution""
  input: ""block2_conv1/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block2_conv1/Relu""
  op: ""Relu""
  input: ""block2_conv1/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_conv2/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\200\000\000\000\200\000\000\000""
      }
    }
  }
}
node {
  name: ""block2_conv2/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0510310381651
      }
    }
  }
}
node {
  name: ""block2_conv2/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0510310381651
      }
    }
  }
}
node {
  name: ""block2_conv2/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block2_conv2/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 7708517
    }
  }
}
node {
  name: ""block2_conv2/random_uniform/sub""
  op: ""Sub""
  input: ""block2_conv2/random_uniform/max""
  input: ""block2_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_conv2/random_uniform/mul""
  op: ""Mul""
  input: ""block2_conv2/random_uniform/RandomUniform""
  input: ""block2_conv2/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_conv2/random_uniform""
  op: ""Add""
  input: ""block2_conv2/random_uniform/mul""
  input: ""block2_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_conv2/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block2_conv2/kernel/Assign""
  op: ""Assign""
  input: ""block2_conv2/kernel""
  input: ""block2_conv2/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block2_conv2/kernel/read""
  op: ""Identity""
  input: ""block2_conv2/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/kernel""
      }
    }
  }
}
node {
  name: ""block2_conv2/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 128
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block2_conv2/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block2_conv2/bias/Assign""
  op: ""Assign""
  input: ""block2_conv2/bias""
  input: ""block2_conv2/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block2_conv2/bias/read""
  op: ""Identity""
  input: ""block2_conv2/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/bias""
      }
    }
  }
}
node {
  name: ""block2_conv2/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\200\000\000\000\200\000\000\000""
      }
    }
  }
}
node {
  name: ""block2_conv2/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block2_conv2/convolution""
  op: ""Conv2D""
  input: ""block2_conv1/Relu""
  input: ""block2_conv2/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block2_conv2/BiasAdd""
  op: ""BiasAdd""
  input: ""block2_conv2/convolution""
  input: ""block2_conv2/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block2_conv2/Relu""
  op: ""Relu""
  input: ""block2_conv2/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block2_pool/MaxPool""
  op: ""MaxPool""
  input: ""block2_conv2/Relu""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""ksize""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""VALID""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
}
node {
  name: ""block3_conv1/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\200\000\000\000\000\001\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv1/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0416666679084
      }
    }
  }
}
node {
  name: ""block3_conv1/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0416666679084
      }
    }
  }
}
node {
  name: ""block3_conv1/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block3_conv1/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 8232814
    }
  }
}
node {
  name: ""block3_conv1/random_uniform/sub""
  op: ""Sub""
  input: ""block3_conv1/random_uniform/max""
  input: ""block3_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv1/random_uniform/mul""
  op: ""Mul""
  input: ""block3_conv1/random_uniform/RandomUniform""
  input: ""block3_conv1/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv1/random_uniform""
  op: ""Add""
  input: ""block3_conv1/random_uniform/mul""
  input: ""block3_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv1/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 128
        }
        dim {
          size: 256
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block3_conv1/kernel/Assign""
  op: ""Assign""
  input: ""block3_conv1/kernel""
  input: ""block3_conv1/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv1/kernel/read""
  op: ""Identity""
  input: ""block3_conv1/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/kernel""
      }
    }
  }
}
node {
  name: ""block3_conv1/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 256
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block3_conv1/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 256
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block3_conv1/bias/Assign""
  op: ""Assign""
  input: ""block3_conv1/bias""
  input: ""block3_conv1/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv1/bias/read""
  op: ""Identity""
  input: ""block3_conv1/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/bias""
      }
    }
  }
}
node {
  name: ""block3_conv1/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\200\000\000\000\000\001\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv1/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv1/convolution""
  op: ""Conv2D""
  input: ""block2_pool/MaxPool""
  input: ""block3_conv1/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv1/BiasAdd""
  op: ""BiasAdd""
  input: ""block3_conv1/convolution""
  input: ""block3_conv1/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block3_conv1/Relu""
  op: ""Relu""
  input: ""block3_conv1/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv2/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\001\000\000\000\001\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv2/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0360843911767
      }
    }
  }
}
node {
  name: ""block3_conv2/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0360843911767
      }
    }
  }
}
node {
  name: ""block3_conv2/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block3_conv2/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 7964615
    }
  }
}
node {
  name: ""block3_conv2/random_uniform/sub""
  op: ""Sub""
  input: ""block3_conv2/random_uniform/max""
  input: ""block3_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv2/random_uniform/mul""
  op: ""Mul""
  input: ""block3_conv2/random_uniform/RandomUniform""
  input: ""block3_conv2/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv2/random_uniform""
  op: ""Add""
  input: ""block3_conv2/random_uniform/mul""
  input: ""block3_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv2/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 256
        }
        dim {
          size: 256
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block3_conv2/kernel/Assign""
  op: ""Assign""
  input: ""block3_conv2/kernel""
  input: ""block3_conv2/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv2/kernel/read""
  op: ""Identity""
  input: ""block3_conv2/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/kernel""
      }
    }
  }
}
node {
  name: ""block3_conv2/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 256
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block3_conv2/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 256
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block3_conv2/bias/Assign""
  op: ""Assign""
  input: ""block3_conv2/bias""
  input: ""block3_conv2/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv2/bias/read""
  op: ""Identity""
  input: ""block3_conv2/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/bias""
      }
    }
  }
}
node {
  name: ""block3_conv2/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\001\000\000\000\001\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv2/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv2/convolution""
  op: ""Conv2D""
  input: ""block3_conv1/Relu""
  input: ""block3_conv2/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv2/BiasAdd""
  op: ""BiasAdd""
  input: ""block3_conv2/convolution""
  input: ""block3_conv2/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block3_conv2/Relu""
  op: ""Relu""
  input: ""block3_conv2/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv3/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\001\000\000\000\001\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv3/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0360843911767
      }
    }
  }
}
node {
  name: ""block3_conv3/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0360843911767
      }
    }
  }
}
node {
  name: ""block3_conv3/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block3_conv3/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 6435287
    }
  }
}
node {
  name: ""block3_conv3/random_uniform/sub""
  op: ""Sub""
  input: ""block3_conv3/random_uniform/max""
  input: ""block3_conv3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv3/random_uniform/mul""
  op: ""Mul""
  input: ""block3_conv3/random_uniform/RandomUniform""
  input: ""block3_conv3/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv3/random_uniform""
  op: ""Add""
  input: ""block3_conv3/random_uniform/mul""
  input: ""block3_conv3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_conv3/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 256
        }
        dim {
          size: 256
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block3_conv3/kernel/Assign""
  op: ""Assign""
  input: ""block3_conv3/kernel""
  input: ""block3_conv3/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv3/kernel/read""
  op: ""Identity""
  input: ""block3_conv3/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/kernel""
      }
    }
  }
}
node {
  name: ""block3_conv3/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 256
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block3_conv3/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 256
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block3_conv3/bias/Assign""
  op: ""Assign""
  input: ""block3_conv3/bias""
  input: ""block3_conv3/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv3/bias/read""
  op: ""Identity""
  input: ""block3_conv3/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/bias""
      }
    }
  }
}
node {
  name: ""block3_conv3/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\001\000\000\000\001\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv3/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block3_conv3/convolution""
  op: ""Conv2D""
  input: ""block3_conv2/Relu""
  input: ""block3_conv3/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block3_conv3/BiasAdd""
  op: ""BiasAdd""
  input: ""block3_conv3/convolution""
  input: ""block3_conv3/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block3_conv3/Relu""
  op: ""Relu""
  input: ""block3_conv3/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block3_pool/MaxPool""
  op: ""MaxPool""
  input: ""block3_conv3/Relu""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""ksize""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""VALID""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
}
node {
  name: ""block4_conv1/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\001\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv1/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0294627826661
      }
    }
  }
}
node {
  name: ""block4_conv1/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0294627826661
      }
    }
  }
}
node {
  name: ""block4_conv1/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block4_conv1/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 215528
    }
  }
}
node {
  name: ""block4_conv1/random_uniform/sub""
  op: ""Sub""
  input: ""block4_conv1/random_uniform/max""
  input: ""block4_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv1/random_uniform/mul""
  op: ""Mul""
  input: ""block4_conv1/random_uniform/RandomUniform""
  input: ""block4_conv1/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv1/random_uniform""
  op: ""Add""
  input: ""block4_conv1/random_uniform/mul""
  input: ""block4_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv1/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 256
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block4_conv1/kernel/Assign""
  op: ""Assign""
  input: ""block4_conv1/kernel""
  input: ""block4_conv1/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv1/kernel/read""
  op: ""Identity""
  input: ""block4_conv1/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/kernel""
      }
    }
  }
}
node {
  name: ""block4_conv1/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block4_conv1/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block4_conv1/bias/Assign""
  op: ""Assign""
  input: ""block4_conv1/bias""
  input: ""block4_conv1/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv1/bias/read""
  op: ""Identity""
  input: ""block4_conv1/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/bias""
      }
    }
  }
}
node {
  name: ""block4_conv1/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\001\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv1/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv1/convolution""
  op: ""Conv2D""
  input: ""block3_pool/MaxPool""
  input: ""block4_conv1/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv1/BiasAdd""
  op: ""BiasAdd""
  input: ""block4_conv1/convolution""
  input: ""block4_conv1/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block4_conv1/Relu""
  op: ""Relu""
  input: ""block4_conv1/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv2/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv2/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0255155190825
      }
    }
  }
}
node {
  name: ""block4_conv2/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0255155190825
      }
    }
  }
}
node {
  name: ""block4_conv2/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block4_conv2/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 5791903
    }
  }
}
node {
  name: ""block4_conv2/random_uniform/sub""
  op: ""Sub""
  input: ""block4_conv2/random_uniform/max""
  input: ""block4_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv2/random_uniform/mul""
  op: ""Mul""
  input: ""block4_conv2/random_uniform/RandomUniform""
  input: ""block4_conv2/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv2/random_uniform""
  op: ""Add""
  input: ""block4_conv2/random_uniform/mul""
  input: ""block4_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv2/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block4_conv2/kernel/Assign""
  op: ""Assign""
  input: ""block4_conv2/kernel""
  input: ""block4_conv2/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv2/kernel/read""
  op: ""Identity""
  input: ""block4_conv2/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/kernel""
      }
    }
  }
}
node {
  name: ""block4_conv2/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block4_conv2/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block4_conv2/bias/Assign""
  op: ""Assign""
  input: ""block4_conv2/bias""
  input: ""block4_conv2/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv2/bias/read""
  op: ""Identity""
  input: ""block4_conv2/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/bias""
      }
    }
  }
}
node {
  name: ""block4_conv2/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv2/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv2/convolution""
  op: ""Conv2D""
  input: ""block4_conv1/Relu""
  input: ""block4_conv2/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv2/BiasAdd""
  op: ""BiasAdd""
  input: ""block4_conv2/convolution""
  input: ""block4_conv2/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block4_conv2/Relu""
  op: ""Relu""
  input: ""block4_conv2/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv3/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv3/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0255155190825
      }
    }
  }
}
node {
  name: ""block4_conv3/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0255155190825
      }
    }
  }
}
node {
  name: ""block4_conv3/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block4_conv3/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 6240709
    }
  }
}
node {
  name: ""block4_conv3/random_uniform/sub""
  op: ""Sub""
  input: ""block4_conv3/random_uniform/max""
  input: ""block4_conv3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv3/random_uniform/mul""
  op: ""Mul""
  input: ""block4_conv3/random_uniform/RandomUniform""
  input: ""block4_conv3/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv3/random_uniform""
  op: ""Add""
  input: ""block4_conv3/random_uniform/mul""
  input: ""block4_conv3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_conv3/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block4_conv3/kernel/Assign""
  op: ""Assign""
  input: ""block4_conv3/kernel""
  input: ""block4_conv3/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv3/kernel/read""
  op: ""Identity""
  input: ""block4_conv3/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/kernel""
      }
    }
  }
}
node {
  name: ""block4_conv3/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block4_conv3/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block4_conv3/bias/Assign""
  op: ""Assign""
  input: ""block4_conv3/bias""
  input: ""block4_conv3/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv3/bias/read""
  op: ""Identity""
  input: ""block4_conv3/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/bias""
      }
    }
  }
}
node {
  name: ""block4_conv3/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv3/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block4_conv3/convolution""
  op: ""Conv2D""
  input: ""block4_conv2/Relu""
  input: ""block4_conv3/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block4_conv3/BiasAdd""
  op: ""BiasAdd""
  input: ""block4_conv3/convolution""
  input: ""block4_conv3/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block4_conv3/Relu""
  op: ""Relu""
  input: ""block4_conv3/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block4_pool/MaxPool""
  op: ""MaxPool""
  input: ""block4_conv3/Relu""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""ksize""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""VALID""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
}
node {
  name: ""block5_conv1/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv1/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0255155190825
      }
    }
  }
}
node {
  name: ""block5_conv1/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0255155190825
      }
    }
  }
}
node {
  name: ""block5_conv1/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block5_conv1/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 7151531
    }
  }
}
node {
  name: ""block5_conv1/random_uniform/sub""
  op: ""Sub""
  input: ""block5_conv1/random_uniform/max""
  input: ""block5_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv1/random_uniform/mul""
  op: ""Mul""
  input: ""block5_conv1/random_uniform/RandomUniform""
  input: ""block5_conv1/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv1/random_uniform""
  op: ""Add""
  input: ""block5_conv1/random_uniform/mul""
  input: ""block5_conv1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv1/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block5_conv1/kernel/Assign""
  op: ""Assign""
  input: ""block5_conv1/kernel""
  input: ""block5_conv1/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv1/kernel/read""
  op: ""Identity""
  input: ""block5_conv1/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/kernel""
      }
    }
  }
}
node {
  name: ""block5_conv1/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block5_conv1/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block5_conv1/bias/Assign""
  op: ""Assign""
  input: ""block5_conv1/bias""
  input: ""block5_conv1/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv1/bias/read""
  op: ""Identity""
  input: ""block5_conv1/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/bias""
      }
    }
  }
}
node {
  name: ""block5_conv1/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv1/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv1/convolution""
  op: ""Conv2D""
  input: ""block4_pool/MaxPool""
  input: ""block5_conv1/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv1/BiasAdd""
  op: ""BiasAdd""
  input: ""block5_conv1/convolution""
  input: ""block5_conv1/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block5_conv1/Relu""
  op: ""Relu""
  input: ""block5_conv1/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv2/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv2/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0255155190825
      }
    }
  }
}
node {
  name: ""block5_conv2/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0255155190825
      }
    }
  }
}
node {
  name: ""block5_conv2/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block5_conv2/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 4344407
    }
  }
}
node {
  name: ""block5_conv2/random_uniform/sub""
  op: ""Sub""
  input: ""block5_conv2/random_uniform/max""
  input: ""block5_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv2/random_uniform/mul""
  op: ""Mul""
  input: ""block5_conv2/random_uniform/RandomUniform""
  input: ""block5_conv2/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv2/random_uniform""
  op: ""Add""
  input: ""block5_conv2/random_uniform/mul""
  input: ""block5_conv2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv2/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block5_conv2/kernel/Assign""
  op: ""Assign""
  input: ""block5_conv2/kernel""
  input: ""block5_conv2/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv2/kernel/read""
  op: ""Identity""
  input: ""block5_conv2/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/kernel""
      }
    }
  }
}
node {
  name: ""block5_conv2/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block5_conv2/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block5_conv2/bias/Assign""
  op: ""Assign""
  input: ""block5_conv2/bias""
  input: ""block5_conv2/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv2/bias/read""
  op: ""Identity""
  input: ""block5_conv2/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/bias""
      }
    }
  }
}
node {
  name: ""block5_conv2/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv2/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv2/convolution""
  op: ""Conv2D""
  input: ""block5_conv1/Relu""
  input: ""block5_conv2/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv2/BiasAdd""
  op: ""BiasAdd""
  input: ""block5_conv2/convolution""
  input: ""block5_conv2/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block5_conv2/Relu""
  op: ""Relu""
  input: ""block5_conv2/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv3/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv3/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0255155190825
      }
    }
  }
}
node {
  name: ""block5_conv3/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0255155190825
      }
    }
  }
}
node {
  name: ""block5_conv3/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""block5_conv3/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 3686380
    }
  }
}
node {
  name: ""block5_conv3/random_uniform/sub""
  op: ""Sub""
  input: ""block5_conv3/random_uniform/max""
  input: ""block5_conv3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv3/random_uniform/mul""
  op: ""Mul""
  input: ""block5_conv3/random_uniform/RandomUniform""
  input: ""block5_conv3/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv3/random_uniform""
  op: ""Add""
  input: ""block5_conv3/random_uniform/mul""
  input: ""block5_conv3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_conv3/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block5_conv3/kernel/Assign""
  op: ""Assign""
  input: ""block5_conv3/kernel""
  input: ""block5_conv3/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv3/kernel/read""
  op: ""Identity""
  input: ""block5_conv3/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/kernel""
      }
    }
  }
}
node {
  name: ""block5_conv3/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 512
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""block5_conv3/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""block5_conv3/bias/Assign""
  op: ""Assign""
  input: ""block5_conv3/bias""
  input: ""block5_conv3/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv3/bias/read""
  op: ""Identity""
  input: ""block5_conv3/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/bias""
      }
    }
  }
}
node {
  name: ""block5_conv3/convolution/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: ""\003\000\000\000\003\000\000\000\000\002\000\000\000\002\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv3/convolution/dilation_rate""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\001\000\000\000\001\000\000\000""
      }
    }
  }
}
node {
  name: ""block5_conv3/convolution""
  op: ""Conv2D""
  input: ""block5_conv2/Relu""
  input: ""block5_conv3/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""SAME""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: ""use_cudnn_on_gpu""
    value {
      b: true
    }
  }
}
node {
  name: ""block5_conv3/BiasAdd""
  op: ""BiasAdd""
  input: ""block5_conv3/convolution""
  input: ""block5_conv3/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""block5_conv3/Relu""
  op: ""Relu""
  input: ""block5_conv3/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""block5_pool/MaxPool""
  op: ""MaxPool""
  input: ""block5_conv3/Relu""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
  attr {
    key: ""ksize""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
  attr {
    key: ""padding""
    value {
      s: ""VALID""
    }
  }
  attr {
    key: ""strides""
    value {
      list {
        i: 1
        i: 2
        i: 2
        i: 1
      }
    }
  }
}
node {
  name: ""Placeholder""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 64
        }
      }
    }
  }
}
node {
  name: ""Assign""
  op: ""Assign""
  input: ""block1_conv1/kernel""
  input: ""Placeholder""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_1""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 64
        }
      }
    }
  }
}
node {
  name: ""Assign_1""
  op: ""Assign""
  input: ""block1_conv1/bias""
  input: ""Placeholder_1""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_2""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 64
        }
        dim {
          size: 64
        }
      }
    }
  }
}
node {
  name: ""Assign_2""
  op: ""Assign""
  input: ""block1_conv2/kernel""
  input: ""Placeholder_2""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_3""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 64
        }
      }
    }
  }
}
node {
  name: ""Assign_3""
  op: ""Assign""
  input: ""block1_conv2/bias""
  input: ""Placeholder_3""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_4""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 64
        }
        dim {
          size: 128
        }
      }
    }
  }
}
node {
  name: ""Assign_4""
  op: ""Assign""
  input: ""block2_conv1/kernel""
  input: ""Placeholder_4""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_5""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
}
node {
  name: ""Assign_5""
  op: ""Assign""
  input: ""block2_conv1/bias""
  input: ""Placeholder_5""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_6""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 128
        }
        dim {
          size: 128
        }
      }
    }
  }
}
node {
  name: ""Assign_6""
  op: ""Assign""
  input: ""block2_conv2/kernel""
  input: ""Placeholder_6""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_7""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 128
        }
      }
    }
  }
}
node {
  name: ""Assign_7""
  op: ""Assign""
  input: ""block2_conv2/bias""
  input: ""Placeholder_7""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_8""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 128
        }
        dim {
          size: 256
        }
      }
    }
  }
}
node {
  name: ""Assign_8""
  op: ""Assign""
  input: ""block3_conv1/kernel""
  input: ""Placeholder_8""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_9""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 256
        }
      }
    }
  }
}
node {
  name: ""Assign_9""
  op: ""Assign""
  input: ""block3_conv1/bias""
  input: ""Placeholder_9""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_10""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 256
        }
        dim {
          size: 256
        }
      }
    }
  }
}
node {
  name: ""Assign_10""
  op: ""Assign""
  input: ""block3_conv2/kernel""
  input: ""Placeholder_10""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_11""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 256
        }
      }
    }
  }
}
node {
  name: ""Assign_11""
  op: ""Assign""
  input: ""block3_conv2/bias""
  input: ""Placeholder_11""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_12""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 256
        }
        dim {
          size: 256
        }
      }
    }
  }
}
node {
  name: ""Assign_12""
  op: ""Assign""
  input: ""block3_conv3/kernel""
  input: ""Placeholder_12""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_13""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 256
        }
      }
    }
  }
}
node {
  name: ""Assign_13""
  op: ""Assign""
  input: ""block3_conv3/bias""
  input: ""Placeholder_13""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_14""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 256
        }
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_14""
  op: ""Assign""
  input: ""block4_conv1/kernel""
  input: ""Placeholder_14""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_15""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_15""
  op: ""Assign""
  input: ""block4_conv1/bias""
  input: ""Placeholder_15""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_16""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_16""
  op: ""Assign""
  input: ""block4_conv2/kernel""
  input: ""Placeholder_16""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_17""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_17""
  op: ""Assign""
  input: ""block4_conv2/bias""
  input: ""Placeholder_17""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_18""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_18""
  op: ""Assign""
  input: ""block4_conv3/kernel""
  input: ""Placeholder_18""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_19""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_19""
  op: ""Assign""
  input: ""block4_conv3/bias""
  input: ""Placeholder_19""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_20""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_20""
  op: ""Assign""
  input: ""block5_conv1/kernel""
  input: ""Placeholder_20""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_21""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_21""
  op: ""Assign""
  input: ""block5_conv1/bias""
  input: ""Placeholder_21""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_22""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_22""
  op: ""Assign""
  input: ""block5_conv2/kernel""
  input: ""Placeholder_22""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_23""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_23""
  op: ""Assign""
  input: ""block5_conv2/bias""
  input: ""Placeholder_23""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_24""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 3
        }
        dim {
          size: 3
        }
        dim {
          size: 512
        }
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_24""
  op: ""Assign""
  input: ""block5_conv3/kernel""
  input: ""Placeholder_24""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""Placeholder_25""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
      }
    }
  }
}
node {
  name: ""Assign_25""
  op: ""Assign""
  input: ""block5_conv3/bias""
  input: ""Placeholder_25""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: false
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""init""
  op: ""NoOp""
  input: ""^block1_conv1/kernel/Assign""
  input: ""^block1_conv1/bias/Assign""
  input: ""^block1_conv2/kernel/Assign""
  input: ""^block1_conv2/bias/Assign""
  input: ""^block2_conv1/kernel/Assign""
  input: ""^block2_conv1/bias/Assign""
  input: ""^block2_conv2/kernel/Assign""
  input: ""^block2_conv2/bias/Assign""
  input: ""^block3_conv1/kernel/Assign""
  input: ""^block3_conv1/bias/Assign""
  input: ""^block3_conv2/kernel/Assign""
  input: ""^block3_conv2/bias/Assign""
  input: ""^block3_conv3/kernel/Assign""
  input: ""^block3_conv3/bias/Assign""
  input: ""^block4_conv1/kernel/Assign""
  input: ""^block4_conv1/bias/Assign""
  input: ""^block4_conv2/kernel/Assign""
  input: ""^block4_conv2/bias/Assign""
  input: ""^block4_conv3/kernel/Assign""
  input: ""^block4_conv3/bias/Assign""
  input: ""^block5_conv1/kernel/Assign""
  input: ""^block5_conv1/bias/Assign""
  input: ""^block5_conv2/kernel/Assign""
  input: ""^block5_conv2/bias/Assign""
  input: ""^block5_conv3/kernel/Assign""
  input: ""^block5_conv3/bias/Assign""
}
node {
  name: ""flatten_1/Shape""
  op: ""Shape""
  input: ""block5_pool/MaxPool""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""out_type""
    value {
      type: DT_INT32
    }
  }
}
node {
  name: ""flatten_1/strided_slice/stack""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: ""flatten_1/strided_slice/stack_1""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: ""flatten_1/strided_slice/stack_2""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: ""flatten_1/strided_slice""
  op: ""StridedSlice""
  input: ""flatten_1/Shape""
  input: ""flatten_1/strided_slice/stack""
  input: ""flatten_1/strided_slice/stack_1""
  input: ""flatten_1/strided_slice/stack_2""
  attr {
    key: ""Index""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""begin_mask""
    value {
      i: 0
    }
  }
  attr {
    key: ""ellipsis_mask""
    value {
      i: 0
    }
  }
  attr {
    key: ""end_mask""
    value {
      i: 1
    }
  }
  attr {
    key: ""new_axis_mask""
    value {
      i: 0
    }
  }
  attr {
    key: ""shrink_axis_mask""
    value {
      i: 0
    }
  }
}
node {
  name: ""flatten_1/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: ""flatten_1/Prod""
  op: ""Prod""
  input: ""flatten_1/strided_slice""
  input: ""flatten_1/Const""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""keep_dims""
    value {
      b: false
    }
  }
}
node {
  name: ""flatten_1/stack/0""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: ""flatten_1/stack""
  op: ""Pack""
  input: ""flatten_1/stack/0""
  input: ""flatten_1/Prod""
  attr {
    key: ""N""
    value {
      i: 2
    }
  }
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""axis""
    value {
      i: 0
    }
  }
}
node {
  name: ""flatten_1/Reshape""
  op: ""Reshape""
  input: ""block5_pool/MaxPool""
  input: ""flatten_1/stack""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tshape""
    value {
      type: DT_INT32
    }
  }
}
node {
  name: ""dense_1/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\000\002\000\000\000\004\000\000""
      }
    }
  }
}
node {
  name: ""dense_1/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0625
      }
    }
  }
}
node {
  name: ""dense_1/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0625
      }
    }
  }
}
node {
  name: ""dense_1/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""dense_1/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 9805962
    }
  }
}
node {
  name: ""dense_1/random_uniform/sub""
  op: ""Sub""
  input: ""dense_1/random_uniform/max""
  input: ""dense_1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_1/random_uniform/mul""
  op: ""Mul""
  input: ""dense_1/random_uniform/RandomUniform""
  input: ""dense_1/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_1/random_uniform""
  op: ""Add""
  input: ""dense_1/random_uniform/mul""
  input: ""dense_1/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_1/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 512
        }
        dim {
          size: 1024
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""dense_1/kernel/Assign""
  op: ""Assign""
  input: ""dense_1/kernel""
  input: ""dense_1/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""dense_1/kernel/read""
  op: ""Identity""
  input: ""dense_1/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/kernel""
      }
    }
  }
}
node {
  name: ""dense_1/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 1024
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""dense_1/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 1024
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""dense_1/bias/Assign""
  op: ""Assign""
  input: ""dense_1/bias""
  input: ""dense_1/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""dense_1/bias/read""
  op: ""Identity""
  input: ""dense_1/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/bias""
      }
    }
  }
}
node {
  name: ""dense_1/MatMul""
  op: ""MatMul""
  input: ""flatten_1/Reshape""
  input: ""dense_1/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""transpose_a""
    value {
      b: false
    }
  }
  attr {
    key: ""transpose_b""
    value {
      b: false
    }
  }
}
node {
  name: ""dense_1/BiasAdd""
  op: ""BiasAdd""
  input: ""dense_1/MatMul""
  input: ""dense_1/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""dense_1/Relu""
  op: ""Relu""
  input: ""dense_1/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/keras_learning_phase""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_BOOL
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        unknown_rank: true
      }
    }
  }
}
node {
  name: ""dropout_1/cond/Switch""
  op: ""Switch""
  input: ""dropout_1/keras_learning_phase""
  input: ""dropout_1/keras_learning_phase""
  attr {
    key: ""T""
    value {
      type: DT_BOOL
    }
  }
}
node {
  name: ""dropout_1/cond/switch_t""
  op: ""Identity""
  input: ""dropout_1/cond/Switch:1""
  attr {
    key: ""T""
    value {
      type: DT_BOOL
    }
  }
}
node {
  name: ""dropout_1/cond/switch_f""
  op: ""Identity""
  input: ""dropout_1/cond/Switch""
  attr {
    key: ""T""
    value {
      type: DT_BOOL
    }
  }
}
node {
  name: ""dropout_1/cond/pred_id""
  op: ""Identity""
  input: ""dropout_1/keras_learning_phase""
  attr {
    key: ""T""
    value {
      type: DT_BOOL
    }
  }
}
node {
  name: ""dropout_1/cond/mul/y""
  op: ""Const""
  input: ""^dropout_1/cond/switch_t""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: ""dropout_1/cond/mul/Switch""
  op: ""Switch""
  input: ""dense_1/Relu""
  input: ""dropout_1/cond/pred_id""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/Relu""
      }
    }
  }
}
node {
  name: ""dropout_1/cond/mul""
  op: ""Mul""
  input: ""dropout_1/cond/mul/Switch:1""
  input: ""dropout_1/cond/mul/y""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/keep_prob""
  op: ""Const""
  input: ""^dropout_1/cond/switch_t""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.5
      }
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/Shape""
  op: ""Shape""
  input: ""dropout_1/cond/mul""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""out_type""
    value {
      type: DT_INT32
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/random_uniform/min""
  op: ""Const""
  input: ""^dropout_1/cond/switch_t""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/random_uniform/max""
  op: ""Const""
  input: ""^dropout_1/cond/switch_t""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""dropout_1/cond/dropout/Shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 4883238
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/random_uniform/sub""
  op: ""Sub""
  input: ""dropout_1/cond/dropout/random_uniform/max""
  input: ""dropout_1/cond/dropout/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/random_uniform/mul""
  op: ""Mul""
  input: ""dropout_1/cond/dropout/random_uniform/RandomUniform""
  input: ""dropout_1/cond/dropout/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/random_uniform""
  op: ""Add""
  input: ""dropout_1/cond/dropout/random_uniform/mul""
  input: ""dropout_1/cond/dropout/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/add""
  op: ""Add""
  input: ""dropout_1/cond/dropout/keep_prob""
  input: ""dropout_1/cond/dropout/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/Floor""
  op: ""Floor""
  input: ""dropout_1/cond/dropout/add""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/div""
  op: ""RealDiv""
  input: ""dropout_1/cond/mul""
  input: ""dropout_1/cond/dropout/keep_prob""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/dropout/mul""
  op: ""Mul""
  input: ""dropout_1/cond/dropout/div""
  input: ""dropout_1/cond/dropout/Floor""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dropout_1/cond/Switch_1""
  op: ""Switch""
  input: ""dense_1/Relu""
  input: ""dropout_1/cond/pred_id""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/Relu""
      }
    }
  }
}
node {
  name: ""dropout_1/cond/Merge""
  op: ""Merge""
  input: ""dropout_1/cond/Switch_1""
  input: ""dropout_1/cond/dropout/mul""
  attr {
    key: ""N""
    value {
      i: 2
    }
  }
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_2/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\000\004\000\000\000\004\000\000""
      }
    }
  }
}
node {
  name: ""dense_2/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0541265867651
      }
    }
  }
}
node {
  name: ""dense_2/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0541265867651
      }
    }
  }
}
node {
  name: ""dense_2/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""dense_2/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 3506239
    }
  }
}
node {
  name: ""dense_2/random_uniform/sub""
  op: ""Sub""
  input: ""dense_2/random_uniform/max""
  input: ""dense_2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_2/random_uniform/mul""
  op: ""Mul""
  input: ""dense_2/random_uniform/RandomUniform""
  input: ""dense_2/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_2/random_uniform""
  op: ""Add""
  input: ""dense_2/random_uniform/mul""
  input: ""dense_2/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_2/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 1024
        }
        dim {
          size: 1024
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""dense_2/kernel/Assign""
  op: ""Assign""
  input: ""dense_2/kernel""
  input: ""dense_2/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""dense_2/kernel/read""
  op: ""Identity""
  input: ""dense_2/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_2/kernel""
      }
    }
  }
}
node {
  name: ""dense_2/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 1024
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""dense_2/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 1024
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""dense_2/bias/Assign""
  op: ""Assign""
  input: ""dense_2/bias""
  input: ""dense_2/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""dense_2/bias/read""
  op: ""Identity""
  input: ""dense_2/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_2/bias""
      }
    }
  }
}
node {
  name: ""dense_2/MatMul""
  op: ""MatMul""
  input: ""dropout_1/cond/Merge""
  input: ""dense_2/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""transpose_a""
    value {
      b: false
    }
  }
  attr {
    key: ""transpose_b""
    value {
      b: false
    }
  }
}
node {
  name: ""dense_2/BiasAdd""
  op: ""BiasAdd""
  input: ""dense_2/MatMul""
  input: ""dense_2/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""dense_2/Relu""
  op: ""Relu""
  input: ""dense_2/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_3/random_uniform/shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\000\004\000\000\n\000\000\000""
      }
    }
  }
}
node {
  name: ""dense_3/random_uniform/min""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.0761755108833
      }
    }
  }
}
node {
  name: ""dense_3/random_uniform/max""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0761755108833
      }
    }
  }
}
node {
  name: ""dense_3/random_uniform/RandomUniform""
  op: ""RandomUniform""
  input: ""dense_3/random_uniform/shape""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""seed""
    value {
      i: 87654321
    }
  }
  attr {
    key: ""seed2""
    value {
      i: 1428162
    }
  }
}
node {
  name: ""dense_3/random_uniform/sub""
  op: ""Sub""
  input: ""dense_3/random_uniform/max""
  input: ""dense_3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_3/random_uniform/mul""
  op: ""Mul""
  input: ""dense_3/random_uniform/RandomUniform""
  input: ""dense_3/random_uniform/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_3/random_uniform""
  op: ""Add""
  input: ""dense_3/random_uniform/mul""
  input: ""dense_3/random_uniform/min""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""dense_3/kernel""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 1024
        }
        dim {
          size: 10
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""dense_3/kernel/Assign""
  op: ""Assign""
  input: ""dense_3/kernel""
  input: ""dense_3/random_uniform""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""dense_3/kernel/read""
  op: ""Identity""
  input: ""dense_3/kernel""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_3/kernel""
      }
    }
  }
}
node {
  name: ""dense_3/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 10
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""dense_3/bias""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 10
        }
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""dense_3/bias/Assign""
  op: ""Assign""
  input: ""dense_3/bias""
  input: ""dense_3/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""dense_3/bias/read""
  op: ""Identity""
  input: ""dense_3/bias""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_3/bias""
      }
    }
  }
}
node {
  name: ""dense_3/MatMul""
  op: ""MatMul""
  input: ""dense_2/Relu""
  input: ""dense_3/kernel/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""transpose_a""
    value {
      b: false
    }
  }
  attr {
    key: ""transpose_b""
    value {
      b: false
    }
  }
}
node {
  name: ""dense_3/BiasAdd""
  op: ""BiasAdd""
  input: ""dense_3/MatMul""
  input: ""dense_3/bias/read""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""data_format""
    value {
      s: ""NHWC""
    }
  }
}
node {
  name: ""dense_3/Softmax""
  op: ""Softmax""
  input: ""dense_3/BiasAdd""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""SGD/iterations/initial_value""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT64
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
        }
        int64_val: 0
      }
    }
  }
}
node {
  name: ""SGD/iterations""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_INT64
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""SGD/iterations/Assign""
  op: ""Assign""
  input: ""SGD/iterations""
  input: ""SGD/iterations/initial_value""
  attr {
    key: ""T""
    value {
      type: DT_INT64
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/iterations""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""SGD/iterations/read""
  op: ""Identity""
  input: ""SGD/iterations""
  attr {
    key: ""T""
    value {
      type: DT_INT64
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/iterations""
      }
    }
  }
}
node {
  name: ""SGD/lr/initial_value""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 9.99999974738e-05
      }
    }
  }
}
node {
  name: ""SGD/lr""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""SGD/lr/Assign""
  op: ""Assign""
  input: ""SGD/lr""
  input: ""SGD/lr/initial_value""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/lr""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""SGD/lr/read""
  op: ""Identity""
  input: ""SGD/lr""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/lr""
      }
    }
  }
}
node {
  name: ""SGD/momentum/initial_value""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.899999976158
      }
    }
  }
}
node {
  name: ""SGD/momentum""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""SGD/momentum/Assign""
  op: ""Assign""
  input: ""SGD/momentum""
  input: ""SGD/momentum/initial_value""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/momentum""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""SGD/momentum/read""
  op: ""Identity""
  input: ""SGD/momentum""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/momentum""
      }
    }
  }
}
node {
  name: ""SGD/decay/initial_value""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""SGD/decay""
  op: ""VariableV2""
  attr {
    key: ""container""
    value {
      s: """"
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
      }
    }
  }
  attr {
    key: ""shared_name""
    value {
      s: """"
    }
  }
}
node {
  name: ""SGD/decay/Assign""
  op: ""Assign""
  input: ""SGD/decay""
  input: ""SGD/decay/initial_value""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/decay""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""SGD/decay/read""
  op: ""Identity""
  input: ""SGD/decay""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/decay""
      }
    }
  }
}
node {
  name: ""dense_3_target""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: -1
        }
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: ""dense_3_sample_weights""
  op: ""Placeholder""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/Sum/reduction_indices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/Sum""
  op: ""Sum""
  input: ""dense_3/Softmax""
  input: ""loss/dense_3_loss/Sum/reduction_indices""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""keep_dims""
    value {
      b: true
    }
  }
}
node {
  name: ""loss/dense_3_loss/div""
  op: ""RealDiv""
  input: ""dense_3/Softmax""
  input: ""loss/dense_3_loss/Sum""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.00000001169e-07
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/sub/x""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/sub""
  op: ""Sub""
  input: ""loss/dense_3_loss/sub/x""
  input: ""loss/dense_3_loss/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/clip_by_value/Minimum""
  op: ""Minimum""
  input: ""loss/dense_3_loss/div""
  input: ""loss/dense_3_loss/sub""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/clip_by_value""
  op: ""Maximum""
  input: ""loss/dense_3_loss/clip_by_value/Minimum""
  input: ""loss/dense_3_loss/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/Log""
  op: ""Log""
  input: ""loss/dense_3_loss/clip_by_value""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/mul""
  op: ""Mul""
  input: ""dense_3_target""
  input: ""loss/dense_3_loss/Log""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/Sum_1/reduction_indices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/Sum_1""
  op: ""Sum""
  input: ""loss/dense_3_loss/mul""
  input: ""loss/dense_3_loss/Sum_1/reduction_indices""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""keep_dims""
    value {
      b: false
    }
  }
}
node {
  name: ""loss/dense_3_loss/Neg""
  op: ""Neg""
  input: ""loss/dense_3_loss/Sum_1""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/Mean/reduction_indices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/Mean""
  op: ""Mean""
  input: ""loss/dense_3_loss/Neg""
  input: ""loss/dense_3_loss/Mean/reduction_indices""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""keep_dims""
    value {
      b: false
    }
  }
}
node {
  name: ""loss/dense_3_loss/mul_1""
  op: ""Mul""
  input: ""loss/dense_3_loss/Mean""
  input: ""dense_3_sample_weights""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/NotEqual/y""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/NotEqual""
  op: ""NotEqual""
  input: ""dense_3_sample_weights""
  input: ""loss/dense_3_loss/NotEqual/y""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/Cast""
  op: ""Cast""
  input: ""loss/dense_3_loss/NotEqual""
  attr {
    key: ""DstT""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""SrcT""
    value {
      type: DT_BOOL
    }
  }
}
node {
  name: ""loss/dense_3_loss/Const_1""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/Mean_1""
  op: ""Mean""
  input: ""loss/dense_3_loss/Cast""
  input: ""loss/dense_3_loss/Const_1""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""keep_dims""
    value {
      b: false
    }
  }
}
node {
  name: ""loss/dense_3_loss/div_1""
  op: ""RealDiv""
  input: ""loss/dense_3_loss/mul_1""
  input: ""loss/dense_3_loss/Mean_1""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""loss/dense_3_loss/Const_2""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: ""loss/dense_3_loss/Mean_2""
  op: ""Mean""
  input: ""loss/dense_3_loss/div_1""
  input: ""loss/dense_3_loss/Const_2""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""keep_dims""
    value {
      b: false
    }
  }
}
node {
  name: ""loss/mul/x""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: ""loss/mul""
  op: ""Mul""
  input: ""loss/mul/x""
  input: ""loss/dense_3_loss/Mean_2""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: ""metrics/acc/ArgMax/dimension""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: ""metrics/acc/ArgMax""
  op: ""ArgMax""
  input: ""dense_3_target""
  input: ""metrics/acc/ArgMax/dimension""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""output_type""
    value {
      type: DT_INT64
    }
  }
}
node {
  name: ""metrics/acc/ArgMax_1/dimension""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: ""metrics/acc/ArgMax_1""
  op: ""ArgMax""
  input: ""dense_3/Softmax""
  input: ""metrics/acc/ArgMax_1/dimension""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""output_type""
    value {
      type: DT_INT64
    }
  }
}
node {
  name: ""metrics/acc/Equal""
  op: ""Equal""
  input: ""metrics/acc/ArgMax""
  input: ""metrics/acc/ArgMax_1""
  attr {
    key: ""T""
    value {
      type: DT_INT64
    }
  }
}
node {
  name: ""metrics/acc/Cast""
  op: ""Cast""
  input: ""metrics/acc/Equal""
  attr {
    key: ""DstT""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""SrcT""
    value {
      type: DT_BOOL
    }
  }
}
node {
  name: ""metrics/acc/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: ""metrics/acc/Mean""
  op: ""Mean""
  input: ""metrics/acc/Cast""
  input: ""metrics/acc/Const""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""Tidx""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""keep_dims""
    value {
      b: false
    }
  }
}
node {
  name: ""save/Const""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""model""
      }
    }
  }
}
node {
  name: ""save/SaveV2/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 36
          }
        }
        string_val: ""SGD/decay""
        string_val: ""SGD/iterations""
        string_val: ""SGD/lr""
        string_val: ""SGD/momentum""
        string_val: ""block1_conv1/bias""
        string_val: ""block1_conv1/kernel""
        string_val: ""block1_conv2/bias""
        string_val: ""block1_conv2/kernel""
        string_val: ""block2_conv1/bias""
        string_val: ""block2_conv1/kernel""
        string_val: ""block2_conv2/bias""
        string_val: ""block2_conv2/kernel""
        string_val: ""block3_conv1/bias""
        string_val: ""block3_conv1/kernel""
        string_val: ""block3_conv2/bias""
        string_val: ""block3_conv2/kernel""
        string_val: ""block3_conv3/bias""
        string_val: ""block3_conv3/kernel""
        string_val: ""block4_conv1/bias""
        string_val: ""block4_conv1/kernel""
        string_val: ""block4_conv2/bias""
        string_val: ""block4_conv2/kernel""
        string_val: ""block4_conv3/bias""
        string_val: ""block4_conv3/kernel""
        string_val: ""block5_conv1/bias""
        string_val: ""block5_conv1/kernel""
        string_val: ""block5_conv2/bias""
        string_val: ""block5_conv2/kernel""
        string_val: ""block5_conv3/bias""
        string_val: ""block5_conv3/kernel""
        string_val: ""dense_1/bias""
        string_val: ""dense_1/kernel""
        string_val: ""dense_2/bias""
        string_val: ""dense_2/kernel""
        string_val: ""dense_3/bias""
        string_val: ""dense_3/kernel""
      }
    }
  }
}
node {
  name: ""save/SaveV2/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 36
          }
        }
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/SaveV2""
  op: ""SaveV2""
  input: ""save/Const""
  input: ""save/SaveV2/tensor_names""
  input: ""save/SaveV2/shape_and_slices""
  input: ""SGD/decay""
  input: ""SGD/iterations""
  input: ""SGD/lr""
  input: ""SGD/momentum""
  input: ""block1_conv1/bias""
  input: ""block1_conv1/kernel""
  input: ""block1_conv2/bias""
  input: ""block1_conv2/kernel""
  input: ""block2_conv1/bias""
  input: ""block2_conv1/kernel""
  input: ""block2_conv2/bias""
  input: ""block2_conv2/kernel""
  input: ""block3_conv1/bias""
  input: ""block3_conv1/kernel""
  input: ""block3_conv2/bias""
  input: ""block3_conv2/kernel""
  input: ""block3_conv3/bias""
  input: ""block3_conv3/kernel""
  input: ""block4_conv1/bias""
  input: ""block4_conv1/kernel""
  input: ""block4_conv2/bias""
  input: ""block4_conv2/kernel""
  input: ""block4_conv3/bias""
  input: ""block4_conv3/kernel""
  input: ""block5_conv1/bias""
  input: ""block5_conv1/kernel""
  input: ""block5_conv2/bias""
  input: ""block5_conv2/kernel""
  input: ""block5_conv3/bias""
  input: ""block5_conv3/kernel""
  input: ""dense_1/bias""
  input: ""dense_1/kernel""
  input: ""dense_2/bias""
  input: ""dense_2/kernel""
  input: ""dense_3/bias""
  input: ""dense_3/kernel""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
        type: DT_INT64
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/control_dependency""
  op: ""Identity""
  input: ""save/Const""
  input: ""^save/SaveV2""
  attr {
    key: ""T""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@save/Const""
      }
    }
  }
}
node {
  name: ""save/RestoreV2/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""SGD/decay""
      }
    }
  }
}
node {
  name: ""save/RestoreV2/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2/tensor_names""
  input: ""save/RestoreV2/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign""
  op: ""Assign""
  input: ""SGD/decay""
  input: ""save/RestoreV2""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/decay""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_1/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""SGD/iterations""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_1/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_1""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_1/tensor_names""
  input: ""save/RestoreV2_1/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_INT64
      }
    }
  }
}
node {
  name: ""save/Assign_1""
  op: ""Assign""
  input: ""SGD/iterations""
  input: ""save/RestoreV2_1""
  attr {
    key: ""T""
    value {
      type: DT_INT64
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/iterations""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_2/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""SGD/lr""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_2/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_2""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_2/tensor_names""
  input: ""save/RestoreV2_2/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_2""
  op: ""Assign""
  input: ""SGD/lr""
  input: ""save/RestoreV2_2""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/lr""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_3/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""SGD/momentum""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_3/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_3""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_3/tensor_names""
  input: ""save/RestoreV2_3/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_3""
  op: ""Assign""
  input: ""SGD/momentum""
  input: ""save/RestoreV2_3""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@SGD/momentum""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_4/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block1_conv1/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_4/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_4""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_4/tensor_names""
  input: ""save/RestoreV2_4/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_4""
  op: ""Assign""
  input: ""block1_conv1/bias""
  input: ""save/RestoreV2_4""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_5/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block1_conv1/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_5/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_5""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_5/tensor_names""
  input: ""save/RestoreV2_5/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_5""
  op: ""Assign""
  input: ""block1_conv1/kernel""
  input: ""save/RestoreV2_5""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_6/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block1_conv2/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_6/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_6""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_6/tensor_names""
  input: ""save/RestoreV2_6/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_6""
  op: ""Assign""
  input: ""block1_conv2/bias""
  input: ""save/RestoreV2_6""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_7/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block1_conv2/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_7/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_7""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_7/tensor_names""
  input: ""save/RestoreV2_7/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_7""
  op: ""Assign""
  input: ""block1_conv2/kernel""
  input: ""save/RestoreV2_7""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block1_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_8/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block2_conv1/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_8/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_8""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_8/tensor_names""
  input: ""save/RestoreV2_8/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_8""
  op: ""Assign""
  input: ""block2_conv1/bias""
  input: ""save/RestoreV2_8""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_9/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block2_conv1/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_9/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_9""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_9/tensor_names""
  input: ""save/RestoreV2_9/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_9""
  op: ""Assign""
  input: ""block2_conv1/kernel""
  input: ""save/RestoreV2_9""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_10/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block2_conv2/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_10/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_10""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_10/tensor_names""
  input: ""save/RestoreV2_10/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_10""
  op: ""Assign""
  input: ""block2_conv2/bias""
  input: ""save/RestoreV2_10""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_11/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block2_conv2/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_11/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_11""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_11/tensor_names""
  input: ""save/RestoreV2_11/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_11""
  op: ""Assign""
  input: ""block2_conv2/kernel""
  input: ""save/RestoreV2_11""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block2_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_12/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block3_conv1/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_12/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_12""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_12/tensor_names""
  input: ""save/RestoreV2_12/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_12""
  op: ""Assign""
  input: ""block3_conv1/bias""
  input: ""save/RestoreV2_12""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_13/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block3_conv1/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_13/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_13""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_13/tensor_names""
  input: ""save/RestoreV2_13/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_13""
  op: ""Assign""
  input: ""block3_conv1/kernel""
  input: ""save/RestoreV2_13""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_14/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block3_conv2/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_14/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_14""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_14/tensor_names""
  input: ""save/RestoreV2_14/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_14""
  op: ""Assign""
  input: ""block3_conv2/bias""
  input: ""save/RestoreV2_14""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_15/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block3_conv2/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_15/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_15""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_15/tensor_names""
  input: ""save/RestoreV2_15/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_15""
  op: ""Assign""
  input: ""block3_conv2/kernel""
  input: ""save/RestoreV2_15""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_16/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block3_conv3/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_16/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_16""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_16/tensor_names""
  input: ""save/RestoreV2_16/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_16""
  op: ""Assign""
  input: ""block3_conv3/bias""
  input: ""save/RestoreV2_16""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_17/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block3_conv3/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_17/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_17""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_17/tensor_names""
  input: ""save/RestoreV2_17/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_17""
  op: ""Assign""
  input: ""block3_conv3/kernel""
  input: ""save/RestoreV2_17""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block3_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_18/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block4_conv1/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_18/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_18""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_18/tensor_names""
  input: ""save/RestoreV2_18/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_18""
  op: ""Assign""
  input: ""block4_conv1/bias""
  input: ""save/RestoreV2_18""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_19/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block4_conv1/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_19/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_19""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_19/tensor_names""
  input: ""save/RestoreV2_19/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_19""
  op: ""Assign""
  input: ""block4_conv1/kernel""
  input: ""save/RestoreV2_19""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_20/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block4_conv2/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_20/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_20""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_20/tensor_names""
  input: ""save/RestoreV2_20/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_20""
  op: ""Assign""
  input: ""block4_conv2/bias""
  input: ""save/RestoreV2_20""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_21/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block4_conv2/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_21/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_21""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_21/tensor_names""
  input: ""save/RestoreV2_21/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_21""
  op: ""Assign""
  input: ""block4_conv2/kernel""
  input: ""save/RestoreV2_21""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_22/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block4_conv3/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_22/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_22""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_22/tensor_names""
  input: ""save/RestoreV2_22/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_22""
  op: ""Assign""
  input: ""block4_conv3/bias""
  input: ""save/RestoreV2_22""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_23/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block4_conv3/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_23/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_23""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_23/tensor_names""
  input: ""save/RestoreV2_23/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_23""
  op: ""Assign""
  input: ""block4_conv3/kernel""
  input: ""save/RestoreV2_23""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block4_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_24/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block5_conv1/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_24/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_24""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_24/tensor_names""
  input: ""save/RestoreV2_24/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_24""
  op: ""Assign""
  input: ""block5_conv1/bias""
  input: ""save/RestoreV2_24""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_25/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block5_conv1/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_25/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_25""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_25/tensor_names""
  input: ""save/RestoreV2_25/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_25""
  op: ""Assign""
  input: ""block5_conv1/kernel""
  input: ""save/RestoreV2_25""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_26/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block5_conv2/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_26/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_26""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_26/tensor_names""
  input: ""save/RestoreV2_26/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_26""
  op: ""Assign""
  input: ""block5_conv2/bias""
  input: ""save/RestoreV2_26""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_27/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block5_conv2/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_27/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_27""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_27/tensor_names""
  input: ""save/RestoreV2_27/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_27""
  op: ""Assign""
  input: ""block5_conv2/kernel""
  input: ""save/RestoreV2_27""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_28/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block5_conv3/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_28/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_28""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_28/tensor_names""
  input: ""save/RestoreV2_28/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_28""
  op: ""Assign""
  input: ""block5_conv3/bias""
  input: ""save/RestoreV2_28""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_29/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""block5_conv3/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_29/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_29""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_29/tensor_names""
  input: ""save/RestoreV2_29/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_29""
  op: ""Assign""
  input: ""block5_conv3/kernel""
  input: ""save/RestoreV2_29""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@block5_conv3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_30/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""dense_1/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_30/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_30""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_30/tensor_names""
  input: ""save/RestoreV2_30/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_30""
  op: ""Assign""
  input: ""dense_1/bias""
  input: ""save/RestoreV2_30""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_31/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""dense_1/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_31/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_31""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_31/tensor_names""
  input: ""save/RestoreV2_31/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_31""
  op: ""Assign""
  input: ""dense_1/kernel""
  input: ""save/RestoreV2_31""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_1/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_32/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""dense_2/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_32/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_32""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_32/tensor_names""
  input: ""save/RestoreV2_32/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_32""
  op: ""Assign""
  input: ""dense_2/bias""
  input: ""save/RestoreV2_32""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_2/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_33/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""dense_2/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_33/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_33""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_33/tensor_names""
  input: ""save/RestoreV2_33/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_33""
  op: ""Assign""
  input: ""dense_2/kernel""
  input: ""save/RestoreV2_33""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_2/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_34/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""dense_3/bias""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_34/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_34""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_34/tensor_names""
  input: ""save/RestoreV2_34/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_34""
  op: ""Assign""
  input: ""dense_3/bias""
  input: ""save/RestoreV2_34""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_3/bias""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/RestoreV2_35/tensor_names""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""dense_3/kernel""
      }
    }
  }
}
node {
  name: ""save/RestoreV2_35/shape_and_slices""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_STRING
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: """"
      }
    }
  }
}
node {
  name: ""save/RestoreV2_35""
  op: ""RestoreV2""
  input: ""save/Const""
  input: ""save/RestoreV2_35/tensor_names""
  input: ""save/RestoreV2_35/shape_and_slices""
  attr {
    key: ""dtypes""
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: ""save/Assign_35""
  op: ""Assign""
  input: ""dense_3/kernel""
  input: ""save/RestoreV2_35""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@dense_3/kernel""
      }
    }
  }
  attr {
    key: ""use_locking""
    value {
      b: true
    }
  }
  attr {
    key: ""validate_shape""
    value {
      b: true
    }
  }
}
node {
  name: ""save/restore_all""
  op: ""NoOp""
  input: ""^save/Assign""
  input: ""^save/Assign_1""
  input: ""^save/Assign_2""
  input: ""^save/Assign_3""
  input: ""^save/Assign_4""
  input: ""^save/Assign_5""
  input: ""^save/Assign_6""
  input: ""^save/Assign_7""
  input: ""^save/Assign_8""
  input: ""^save/Assign_9""
  input: ""^save/Assign_10""
  input: ""^save/Assign_11""
  input: ""^save/Assign_12""
  input: ""^save/Assign_13""
  input: ""^save/Assign_14""
  input: ""^save/Assign_15""
  input: ""^save/Assign_16""
  input: ""^save/Assign_17""
  input: ""^save/Assign_18""
  input: ""^save/Assign_19""
  input: ""^save/Assign_20""
  input: ""^save/Assign_21""
  input: ""^save/Assign_22""
  input: ""^save/Assign_23""
  input: ""^save/Assign_24""
  input: ""^save/Assign_25""
  input: ""^save/Assign_26""
  input: ""^save/Assign_27""
  input: ""^save/Assign_28""
  input: ""^save/Assign_29""
  input: ""^save/Assign_30""
  input: ""^save/Assign_31""
  input: ""^save/Assign_32""
  input: ""^save/Assign_33""
  input: ""^save/Assign_34""
  input: ""^save/Assign_35""
}
node {
  name: ""init_1""
  op: ""NoOp""
  input: ""^dense_1/kernel/Assign""
  input: ""^dense_1/bias/Assign""
  input: ""^dense_2/kernel/Assign""
  input: ""^dense_2/bias/Assign""
  input: ""^dense_3/kernel/Assign""
  input: ""^dense_3/bias/Assign""
  input: ""^SGD/iterations/Assign""
  input: ""^SGD/lr/Assign""
  input: ""^SGD/momentum/Assign""
  input: ""^SGD/decay/Assign""
}
versions {
  producer: 24
}

```",1,,8,2017-10-19T20:15:42Z,NONE
13818,"Feature request: C API ""TF_FinishWhile"" should create a ""WhileContextDef""",type:feature,"Thanks @skye et al for getting while loops into the C API!

I'd like to request that `TF_FinishWhile` generate a `WhileContextDef` protobuf object. That way, non-Python TensorFlow clients can create metagraphs involving while loops which the Python client can then import and take gradients of. Ideally, you could gradients of while loops directly in the C API, but I think just creating the while context should be much easier and is a good stop gap on the way there. 
",1,,8,2017-10-18T20:43:04Z,CONTRIBUTOR
13817,allow to run configure from a parent workspace,cla: yes,"With this patch you can configure tensorflow directly using bazel.

see issue #12761 

```
export TF_NEED_CUDA=1
export TF_CUDA_VERSION=8.0
export TF_CUDA_COMPUTE_CAPABILITIES=6.0
export TF_CUDNN_VERSION=6
export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu
export PYTHON_BIN_PATH=`which python2`
export TF_NEED_GCP=1
export TF_NEED_HDFS=0
export TF_ENABLE_XLA=1
export TF_NEED_VERBS=1
export CC_OPT_FLAGS=""-mavx -msse4.2 -mfpmath=both -DEIGEN_USE_VML""
export TF_NEED_MKL=1
export TF_DOWNLOAD_MKL=1
bazel run @org_tensorflow//:configure -- --tf_workspace= $(bazel info output_base)/external/org_tensorflow`"" --workspace=$(PWD)
```",1,,13,2017-10-18T18:53:10Z,CONTRIBUTOR
13810,tf.nn.max_pool memory leak?,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 5.
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I'm using a tensorflow graph for offline preprocessing, and I believe I've stumbled onto a memory leak problem with tf.nn.maxpool. After certain amount of feed-forward operations (only inference, no training), I get a `Allocator (cuda_host_bfc) ran out of memory trying to allocate ...` error. This happens consistently after a number of data*points* fed through the graph, independtly on how those datapoints are spread over batches. e.g. with batchsize 4 I get this after 64 iterations, with batchsize 2 I get this error after 128 iterations.
The following rough code should reproduce this issue on a Titan XP with 12gb memory, didn't test this due to time constraints.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
import tensorflow as tf
from keras import Input
from keras.layers import AvgPool2D, MaxPool2D, Lambda, Concatenate
from keras.engine import Model
import numpy as np

thumb_dim = 8192
strides = 1
pooling = 22
inputs, outputs = [], []
slide = Input([thumb_dim, thumb_dim, 3])
mask = Input([thumb_dim, thumb_dim, 1])
inputs.append(slide)
inputs.append(mask)

hsv_slide = Lambda(lambda x: tf.image.rgb_to_hsv(x))(slide)
heatmap = Lambda(
    lambda x: x[..., 1:2] * tf.cast(x[..., 2:3] > 0.3, 'float32'))(
    hsv_slide)
# heatmap = AvgPool2D(4, strides=1, padding='same')(heatmap)

to_pool = Concatenate(axis=-1)([heatmap, mask])
concat = Lambda(lambda x: tf.stop_gradient(tf.nn.max_pool(x, ksize=(1, pooling, pooling, 1),
                                                          strides=(1, strides, strides, 1), padding='VALID')))(to_pool)

outputs.append(concat)
rpn = Model(inputs, outputs)
rpn.predict_generator(([
    np.random.random((2, thumb_dim, thumb_dim, 3)),
    np.random.random((2, thumb_dim, thumb_dim, 1))] for _ in range(200)))
```",0,,5,2017-10-18T16:05:12Z,CONTRIBUTOR
13805,Tensorflow serving API does not support python3.5 ,"stat:contributions welcome,type:feature",Tensorflow serving API only supports python2.7.   It is not work for python3 .5,0,,7,2017-10-18T13:19:18Z,NONE
13796,Feature Request: use S3 for checkpoint loading/saving,stat:contributions welcome,EFS is not available in most AWS regions. For distributed TensorFlow in those regions one would have to rely on S3 to save/restore checkpoints,0,,4,2017-10-18T02:51:38Z,CONTRIBUTOR
13775,Installed Tensorflow-gpu but i cant import it it gives me this error,stat:community support,"Traceback (most recent call last):
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Mohammad Reza\AppData\Local\conda\conda\envs\my_root\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.",0,,2,2017-10-17T09:05:09Z,NONE
13740,AV in nvcuda on Win10 amd64,stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: example script startup
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10 amd64 10.0.16291.0
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: b'unknown' 1.3.0
- **Python version**:  3.6.3
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0.61.2/6.0
- **GPU model and memory**: nVidia 1080Ti
- **Exact command to reproduce**:

```
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
```

### Describe the problem

Access violation in nvcuda

### Source code / logs

```
2017-10-15 22:51:24.306411: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-15 22:51:24.306463: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
```

```
0:000> kn
 # Child-SP          RetAddr           Call Site
00 000000c2`28be6150 00007fff`ace93028 nvcuda!cuTexRefSetAddress+0x309622
01 000000c2`28be6180 00007fff`ace92ac2 nvcuda!cuTexRefSetAddress+0x1759ea
02 000000c2`28be61b0 00007fff`ad02abf2 nvcuda!cuTexRefSetAddress+0x175484
03 000000c2`28be6250 00007fff`ace950d6 nvcuda!cuTexRefSetAddress+0x30d5b4
04 000000c2`28beddd0 00007fff`ace5c2e0 nvcuda!cuTexRefSetAddress+0x177a98
05 000000c2`28bedee0 00007fff`ace5acfe nvcuda!cuTexRefSetAddress+0x13eca2
06 000000c2`28bedf10 00007fff`ace5aa77 nvcuda!cuTexRefSetAddress+0x13d6c0
07 000000c2`28bedf50 00007fff`acec6617 nvcuda!cuTexRefSetAddress+0x13d439
*** WARNING: Unable to verify checksum for C:\Python36\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd
*** ERROR: Symbol file could not be found.  Defaulted to export symbols for C:\Python36\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd - 
08 000000c2`28bedf80 00007fff`8d0e1b50 nvcuda!cuTexRefSetAddress+0x1a8fd9
09 000000c2`28bee040 00007fff`8d0e185e _pywrap_tensorflow_internal!perftools::gputools::port::InternalError+0xe0
0a 000000c2`28bee250 00007fff`8d0eebd4 _pywrap_tensorflow_internal!perftools::gputools::cuda::CUDADriver::Init+0x10e
0b 000000c2`28bee2a0 00007fff`8b6225d0 _pywrap_tensorflow_internal!perftools::gputools::cuda::CudaPlatform::VisibleDeviceCount+0x14
0c 000000c2`28bee2d0 00007fff`8b62043b _pywrap_tensorflow_internal!tensorflow::BaseGPUDeviceFactory::GetValidDeviceIds+0x120
0d 000000c2`28bee5f0 00007fff`8b51dd9c _pywrap_tensorflow_internal!tensorflow::BaseGPUDeviceFactory::CreateDevices+0x25b
0e 000000c2`28bee7a0 00007fff`8b8e96ee _pywrap_tensorflow_internal!tensorflow::DeviceFactory::AddDevices+0x24c
0f 000000c2`28bee880 00007fff`8b71742c _pywrap_tensorflow_internal!tensorflow::DirectSessionFactory::NewSession+0xae
10 000000c2`28beea30 00007fff`8b4c6d9f _pywrap_tensorflow_internal!tensorflow::NewSession+0x12c
11 000000c2`28beeb90 00007fff`8b4aa72b _pywrap_tensorflow_internal!TF_NewDeprecatedSession+0x1f
*** ERROR: Symbol file could not be found.  Defaulted to export symbols for C:\Python36\python36.dll - 
12 000000c2`28beebc0 00000000`604aad02 _pywrap_tensorflow_internal!tensorflow::Scope::status+0x138ab
13 000000c2`28beec10 00000000`604aa413 python36!PyCFunction_FastCallDict+0x182
14 000000c2`28beec90 00000000`604888d8 python36!PyObject_CallFunctionObjArgs+0x383
15 000000c2`28beed70 00000000`604ab284 python36!PyEval_EvalFrameDefault+0x3c8
16 000000c2`28beef00 00000000`604aa87f python36!Py_CheckFunctionResult+0x314
17 000000c2`28beefb0 00000000`6048a03c python36!PyObject_CallFunctionObjArgs+0x7ef
18 000000c2`28bef090 00000000`604ab284 python36!PyEval_EvalFrameDefault+0x1b2c
19 000000c2`28bef220 00000000`604a9f98 python36!Py_CheckFunctionResult+0x314
1a 000000c2`28bef2d0 00000000`604a9d65 python36!PyFunction_FastCallDict+0x1b8
1b 000000c2`28bef3a0 00000000`604ad33c python36!PyUnicode_Partition+0x745
1c 000000c2`28bef450 00000000`604ab067 python36!PyType_GenericAlloc+0x72c
1d 000000c2`28bef4d0 00000000`604aa76f python36!Py_CheckFunctionResult+0xf7
1e 000000c2`28bef500 00000000`604888d8 python36!PyObject_CallFunctionObjArgs+0x6df
1f 000000c2`28bef5e0 00000000`604ab284 python36!PyEval_EvalFrameDefault+0x3c8
20 000000c2`28bef770 00000000`604b5ee3 python36!Py_CheckFunctionResult+0x314
21 000000c2`28bef820 00000000`604b5e41 python36!PyEval_EvalCodeEx+0x9b
22 000000c2`28bef8b0 00000000`604b5deb python36!PyEval_EvalCode+0x2d
23 000000c2`28bef920 00000000`6060a864 python36!PyArena_Free+0xa7
24 000000c2`28bef960 00000000`6060a514 python36!PyRun_InteractiveOneObject+0x2b8
25 000000c2`28befa00 00000000`6060a279 python36!PyRun_InteractiveLoopFlags+0xe8
26 000000c2`28befa30 00000000`6055b0b0 python36!PyRun_AnyFileExFlags+0x45
27 000000c2`28befa60 00000000`604f9ea8 python36!Py_hashtable_size+0x5140
*** ERROR: Module load completed but symbols could not be loaded for C:\Python36\python.exe
28 000000c2`28befaa0 00000000`1cf8126d python36!Py_FatalError+0x2cb48
29 000000c2`28befba0 00007fff`fab71fe4 python+0x126d
2a 000000c2`28befbe0 00007fff`fc451eb1 KERNEL32!BaseThreadInitThunk+0x14
2b 000000c2`28befc10 00000000`00000000 ntdll!RtlUserThreadStart+0x21
```

```
0:000> r
rax=0000000000000000 rbx=00000223d1788910 rcx=00000223d1788910
rdx=0000000000000064 rsi=000000c228be61e8 rdi=00000000000003e7
rip=00007fffad026c60 rsp=000000c228be6150 rbp=0000000000000000
 r8=00000223be8a0f00  r9=0000000000008000 r10=00000223d04c0030
r11=0000000000000246 r12=0000000000000001 r13=000000005c000001
r14=000000c228be62e0 r15=0000000000000000
iopl=0         nv up ei pl nz na po nc
cs=0033  ss=002b  ds=002b  es=002b  fs=0053  gs=002b             efl=00010206
nvcuda!cuTexRefSetAddress+0x309622:
00007fff`ad026c60 488b5010        mov     rdx,qword ptr [rax+10h] ds:00000000`00000010=????????????????
0:000> ub
nvcuda!cuTexRefSetAddress+0x30960e:
00007fff`ad026c4c cc              int     3
00007fff`ad026c4d cc              int     3
00007fff`ad026c4e cc              int     3
00007fff`ad026c4f cc              int     3
00007fff`ad026c50 4053            push    rbx
00007fff`ad026c52 4883ec20        sub     rsp,20h
00007fff`ad026c56 488b81d81b0000  mov     rax,qword ptr [rcx+1BD8h]
00007fff`ad026c5d 488bd9          mov     rbx,rcx
0:000> u
nvcuda!cuTexRefSetAddress+0x309622:
00007fff`ad026c60 488b5010        mov     rdx,qword ptr [rax+10h]
00007fff`ad026c64 817a04d0070000  cmp     dword ptr [rdx+4],7D0h
00007fff`ad026c6b 7c11            jl      nvcuda!cuTexRefSetAddress+0x309640 (00007fff`ad026c7e)
00007fff`ad026c6d e89ec5ceff      call    nvcuda!cuTexRefDestroy+0x113 (00007fff`acd13210)
00007fff`ad026c72 84c0            test    al,al
00007fff`ad026c74 7408            je      nvcuda!cuTexRefSetAddress+0x309640 (00007fff`ad026c7e)
00007fff`ad026c76 488bcb          mov     rcx,rbx
00007fff`ad026c79 e837dfceff      call    nvcuda!cuTexRefSetFlags+0xc8 (00007fff`acd14bb5)
0:000> u
nvcuda!cuTexRefSetAddress+0x309640:
00007fff`ad026c7e 33c0            xor     eax,eax
00007fff`ad026c80 4883c420        add     rsp,20h
00007fff`ad026c84 5b              pop     rbx
00007fff`ad026c85 c3              ret
00007fff`ad026c86 cc              int     3
00007fff`ad026c87 cc              int     3
00007fff`ad026c88 cc              int     3
00007fff`ad026c89 cc              int     3
```",0,,3,2017-10-16T05:53:09Z,NONE
13725, Build tensorflow 1.0.1 for bug on jetson TX2,"stat:community support,type:build/install","Hi,
Build tensorflow 1.0.1 for bug on jetson TX2
$ ./cloneTensorFlow.sh$ 
$./setTensorFlowEV.sh
$ ./buildTensorFlow.sh


ERROR: /home/nvidia/tensorflow/tensorflow/core/kernels/BUILD:685:1: output 'tensorflow/core/kernels/_objs/tile_ops_gpu/tensorflow/core/kernels/tile_ops_gpu.cu.pic.o' was not created.
ERROR: /home/nvidia/tensorflow/tensorflow/core/kernels/BUILD:685:1: not all outputs were created or valid.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 3022.881s, Critical Path: 2684.15s

Thank you for your help",0,,2,2017-10-14T23:56:16Z,NONE
13718,fatal error: third_party/eigen3/Eigen/Core: No such file or directory,stat:awaiting tensorflower,"Hi,
I have followed below mentioned steps on my raspberry PI device to enable tensorflow support, but stuck with this issue when executed ""**make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=""-Os"" CXX=g++-4.8** "" command -

Error description - 

```
 fatal error: third_party/eigen3/Eigen/Core: No such file or directory
 #include ""third_party/eigen3/Eigen/Core""                                         ^
compilation terminated.
tensorflow/contrib/makefile/Makefile:617: recipe for target '/home/pi/tensorflow                                                                                                             /contrib/makefile/gen/host_obj/tensorflow/core/platform/denormal.o' failed
make: *** [/home/pi/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/pla                                                                                                             tform/denormal.o] Error 1
```

Steps executed on raspberry pi; steps a to k are successful, getting error at step l- 
a) tensorflow/contrib/makefile/download_dependencies.sh
b) sudo apt-get install -y autoconf automake libtool gcc-4.8 g++-4.8
c ) cd tensorflow/contrib/makefile/downloads/protobuf/
d) ./autogen.sh
e) ./configure
f) make
g) sudo make install
h) sudo ldconfig  # refresh shared library cache
i) cd ../../../../..
j) export HOST_NSYNC_LIB=`tensorflow/contrib/makefile/compile_nsync.sh`
k) export TARGET_NSYNC_LIB=""$HOST_NSYNC_LIB""
**l) make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=""-Os"" CXX=g++-4.8**

Not sure, what am i missing? Please provide suggestions to resolve this issue. Thanks!

Thanks
Amit Srivastava
",0,,4,2017-10-14T16:46:57Z,NONE
13705,While compiling external app -> fatal error: unsupported/Eigen/CXX11/Tensor: No such file or directory,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: It's a C++ code from [this tutorial](https://tebesu.github.io/posts/Training-a-TensorFlow-graph-in-C++-API)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Release 1.4.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.6.1
- **CUDA/cuDNN version**: no CUDA
- **GPU model and memory**: no GPU
- **Exact command to reproduce**: `g++ -I /opt/tensorflow -I /opt/tensorflow/bazel-genfiles loader.cpp`

### Describe the problem
I have a problem while trying to use tensorflow in external app. I took the code from the tutorial above, built tensorflow with following command: `bazel build //tensorflow:libtensorflow_cc.so`. Now, I want to build my external application with tensorflow. While compiling with given command, I receive an error. I also tried compiling with `cmake` and proper `include_directories` directive, but to no avail.

### Source code / logs

The problematic line of code is:
`#include ""tensorflow/core/public/session.h""`<br>
Compiling with command: `g++ -I /opt/tensorflow -I /opt/tensorflow/bazel-genfiles loader.cpp` generates error:

```
In file included from /opt/tensorflow/tensorflow/core/framework/tensor.h:19:0,
                 from /opt/tensorflow/tensorflow/core/public/session.h:24,
                 from loader.cpp:1:
/opt/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:42: fatal error: unsupported/Eigen/CXX11/Tensor: No such file or directory
compilation terminated.
```
Whole code snippet can be seen in the tutorial link above

### Remarks
A similar issue is #4680 but:
1. It is closed without specific information, if it's resolved or not.
2. There is a comment, which states, that if similar issue happens in future, it should be opened as new issue
3. The use case there was not precisely using external app on Ubuntu, but on RaspberryPi instead.
Thus, I'm submitting new issue for this case.",1,,14,2017-10-14T02:18:00Z,NONE
13694,Module not found: tensorflow  Running Docker Jupyter OSX,stat:awaiting tensorflower,"

 After installing docker, I attempted to run tensorflow in Jupyter. My run command was
`LewIss-MacBook-Pro:MyTensorFlow` lewleib$  docker run -it -p 8888:8888 -p 6006:6006 -v ~/Users/lewleib/MyTensorFlow:/notebooks tensorflow/tensorflow`

In the Jupyter notebook I ran  
 ```
import tensorflow as tf     
hello = tf.constant('Hello, TensorFlow!')     
sess = tf.Session()     
print(sess.run(hello) 
```

This resulted in
`ModuleNotFoundError: No module named 'tensorflow'`

I have tried starting in different directories and added prefix gcr.io with the same results. Thanks
-- | --



",0,,4,2017-10-13T16:17:28Z,NONE
13649,LSTMBlockFusedCell  does not support using  DropoutWrapper ,stat:awaiting response,"I am trying to use DropoutWrapper with LSTMBlockFusedCell as follows:

```
cell = tf.contrib.rnn.LSTMBlockFusedCell(num_units,forget_bias) 
cell = tf.contrib.rnn.DropoutWrapper(cell,dropout)
```
 I get an exception that the LSTMBlockFusedCell is not an RNNCell
Message: The parameter cell is not a RNNCell. Which is raised form _like_rnncell during DropoutWrapper initialization. 

It is checking for those proprieties on the cell:
""""Checks that a given object is an RNNCell by using duck typing.""""""
   conditions = [hasattr(cell, ""output_size""), hasattr(cell, ""state_size""),                 hasattr(cell, ""zero_state""), callable(cell)]  LSTMBlockFusedCell does not have output_size , state_size or zero_state properties. 

Should LSTMBlockFusedCell  act like RNNCell to allow using various wrappers?

https://stackoverflow.com/questions/46699985/using-tensorflow-dropoutwrapper-with-lstmblockfusedcell",0,,10,2017-10-12T01:33:52Z,NONE
13644,Add support for Mel Generalized Cepstrum Analysis to tf.contrib.signal.,stat:contributions welcome,"Requested via discuss@
https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/k6EI-BxbCMg

Please :+1: if you would like to see this feature in tf.contrib.signal.",0,,0,2017-10-11T20:45:54Z,MEMBER
13641,Extend SVD gradient to support backpropagating through complex and (strongly) rectangular U and V,stat:contributions welcome,"This initial version of SVD gradients has the following restrictions:
  Only supports statically known inner matrix dimensions m and n.

Backpropagating through U and V (i.e. backpropagating through SVD nodes with compute_uv=True) has further restrictions:
  a) Only supports real tensors.
  b) Only supports square and ""almost square"" matrices where the number of rows and columns differ by at most 1.
  c) full_matrices must be true also. This does not currently have severe implications, given the restriction in b).

Support for dynamic shapes and a) (I think) is straightforward to fix.  But b) is probably a deeper issue having to do with the (lack of) uniqueness of the decomposition, and will require some analysis. I think that if we understand b), we can get around the restriction in c) as well.

I'm marking this as contributions welcome, in the hope that somebody with better math skills than myself will help out :-)",1,,10,2017-10-11T17:18:44Z,MEMBER
13639,Invoke get_shape() on sparse_tensor leads to feeding error,,"If I invoke get_shape method on sparse_tensor, the shape tensor will be added into the _unfeedable_tensors set of the current graph. Then when I feed the sparse tensor, an error occurs.

The codes below show this error

```python
import tensorflow as tf
import numpy as np

shape = np.array([7, 9, 2], dtype=np.int64)
indices = np.array([[3, 2, 0], [4, 5, 1]], dtype=np.int64)
values = np.array([1.0, 2.0], dtype=np.float32)
x = tf.sparse_placeholder(tf.float32, shape=shape)

with tf.Session() as sess:
    x.get_shape() # <-- Troublemaker
    # This line leads to the exception:
    # 	   Tensor Tensor(""Const:0"", shape=(3,), dtype=int64) may not be fed.
    # The side effection of this line is that 
    # it adds the 'shape' tensor into Graph._unfeedable_tensors, 

    print(sess.run(x, feed_dict={
    	x: tf.SparseTensorValue(indices, values, shape)}))
```

The stacktrace
```
ValueError                                Traceback (most recent call last)
<ipython-input-1-baac6f49a954> in <module>()
     10     x.get_shape()
     11     print(sess.run(x, feed_dict={
---> 12     	x: tf.SparseTensorValue(indices, values, shape)}))

/Users/liqimai/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    765     try:
    766       result = self._run(None, fetches, feed_dict, options_ptr,
--> 767                          run_metadata_ptr)
    768       if run_metadata:
    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/Users/liqimai/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    944                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
    945           if not self.graph.is_feedable(subfeed_t):
--> 946             raise ValueError('Tensor %s may not be fed.' % subfeed_t)
    947           subfeed_name = compat.as_bytes(subfeed_t.name)
    948           feed_dict_string[subfeed_name] = np_val

ValueError: Tensor Tensor(""Const:0"", shape=(3,), dtype=int64) may not be fed.
```
------------------------

### System information
I do not think this bug is related to my environment.
== cat /etc/issue ===============================================
Darwin liqimaideMacBook-Pro.local 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.0.0 (clang-900.0.37)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin MacBook-Pro.local 16.7.0 Darwin Kernel Version 16.7.0: Thu Jun 15 17:36:27 PDT 2017; root:xnu-3789.70.16~2/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.11.3)
protobuf (3.2.0)
tensorflow (1.0.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.0.0
tf.GIT_VERSION = v1.0.0-rc2-15-g47bba63-dirty
tf.COMPILER_VERSION = v1.0.0-rc2-15-g47bba63-dirty
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================",1,,7,2017-10-11T16:56:27Z,NONE
13627,HDFS user impersonation,"stat:contributions welcome,type:feature","TensorFlow  does support HDFS filesystem but there is no way to specify as which user to access the filesystem.

The native hdfs library provides a function to set the user name, hdfsBuilderSetUserName() similar to hdfsBuilderSetNameNode(). There is also hdfsConnectAsUser() where you can specify the user, builds the hdfsBuilder struct, set the username among other arguments and return the FileSystem handle.

Currently I don't see any way to provide a username in TensorFlow and more specifically in tensorflow/core/platform/hadoop/hadoop_file_system.cc

I suppose that something like the following would be sufficient.
https://github.com/kouzant/tensorflow/commit/eacef5cb81d09d0490403fde33de8e5526f212ad",0,,3,2017-10-11T09:56:23Z,NONE
13622,CudnnLSTM returns all Ones(1) after the 10th sequence ,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: v1.3.0-rc1-1486-g752dcb6 1.3.0
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: GTX1050Ti
- **Exact command to reproduce**:


### Describe the problem
I tried to use CudnnLSTM to speed up the training, but found it only returns one after the 10th step, following code generate the output.

### Source code / logs
    import tensorflow as tf
    from tensorflow.contrib.cudnn_rnn import CudnnLSTM
    import numpy as np


    np.set_printoptions(linewidth=240, edgeitems=6)
    # Reset default graph
    tf.reset_default_graph()

    num_layer = 5
    num_unit = 256
    input_size = 400
    seq_lenght = 20

    with tf.device('/gpu:0'):
        x = tf.random_uniform([seq_lenght, input_size], maxval=1, dtype=tf.float32)
        x1 = tf.expand_dims(x, 1)
        lstm = CudnnLSTM(num_layers=num_layer, num_units=num_unit, input_size=input_size,
                     input_mode='linear_input',
                     direction='unidirectional')

        # CudnnLSTM parameter
        lstm_para_size = lstm.params_size()
        lstm_para = tf.Variable(tf.random_uniform([lstm_para_size]), validate_shape=False, name='lstm_para')

        state_c = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)
        state_h = tf.Variable(tf.zeros(shape=[num_layer, 1, num_unit]), trainable=False)

        lstm_output, lstm_h, lstm_c = lstm(input_data=x1, input_h=state_h, input_c=state_c, params=lstm_para)

    # Variable initializing op
    init = tf.global_variables_initializer()

    with tf.Session() as sess:
        sess.run(init)
    cudnn_output = sess.run(lstm_output)
    print(cudnn_output)

###LSTM output
[[[ 0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418 ...,  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418  0.76159418]]

 [[ 0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758 ...,  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758  0.96402758]]

 [[ 0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478 ...,  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478  0.99505478]]

 [[ 0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933 ...,  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933  0.99932933]]

 [[ 0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922 ...,  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922  0.99990922]]

 [[ 0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772 ...,  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772  0.99998772]]

 ..., 
 [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]

 [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]

 [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]

 [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]

 [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]

 [[ 1.          1.          1.          1.          1.          1.         ...,  1.          1.          1.          1.          1.          1.        ]]]",1,,7,2017-10-11T07:30:44Z,NONE
13620,Erase Operation on tf.contrib.lookup.MutableHashTable,stat:awaiting tensorflower,"### System information
- TensorFlow r1.3

### Describe the problem

The `tf.contrib.lookup` package has `MutableHashTable` class which wraps the C++11 std::unordered_map class. However, the erase method of unordered_map is not exposed. 

Is there some existing way to erase keys from the lookup table? 

If not I can create a patch with a new kernel/op on the MutableHashTable classes, and also add a method to the Python API.

Thanks",0,,4,2017-10-11T04:05:05Z,NONE
13618,question in image_ops_impl.py,stat:awaiting tensorflower,"I am confused about the code line 827 in image_ops_impl.py .It should be 
variance = (math_ops.reduce_mean(math_ops.square(image-image_mean))

or some reason for the equation?
",0,,4,2017-10-11T02:34:12Z,NONE
13610,Can we run Dataset API on GPU?,type:feature,"I am running binary TF 1.3.0 on Ubuntu 16.04.

Python Version: 3.5.3

I have Nvidia TITAN Xp installed.

I use Dataset API to build input pipeline. What I want is to extract image features using CNN layers 
in the input pipeline. The code looks like this:

```
    def extract_feats(image):
      with tf.device(""/gpu:0""):
        _, end_points = vgg.vgg_16(tf.expand_dims(image, 0),
                                   is_training=(mode == ModeKeys.TRAIN),
                                   spatial_squeeze=False)
        final_conv_layer = end_points['vgg_16/conv5/conv5_3']
        feats = spatial_pyramid_pooling(final_conv_layer, [bin_size], mode='avg')
      return tf.reshape(feats, shape=(bin_size * bin_size, tf.shape(final_conv_layer)[-1]))

    features = features.map(extract_feats)
```

When running the code, my CPU usage is more than 1000% (I have an 6 cores/12 threads CPU), while the GPU usage is 0%. I suspect that the input pipeline built from Dataset API are forced to run on CPU. I tried to set `log_device_placement=True` and I can see that the operation is placed on GPU.

Since I want to extract vectors with same length from variable-sized images using SPP pooling, I have to process these images one by one using `Dataset.map` before calling `Dataset.batch`. So I hope the operations inside `Dataset` could be run on GPU.
",1,,10,2017-10-10T18:02:18Z,NONE
13580,Equeued values to Queue get chopped-off if the Queue isn't instantiated properly.,stat:awaiting response,"### Describe the problem

In QueueBase._check_enqueue_dtypes, the following code is run:
`tensors = []
    for i, (val, dtype) in enumerate(zip(vals, self._dtypes)):
      tensors.append(ops.convert_to_tensor(val, dtype=dtype,
          name=""component_%d"" % i))`

The problem is if the user feeds a list of tensors as `val` (the input) which is longer than the `_dtypes`-construction argument of QueueBase. 

If the user hasn't specified a length of `_dtypes`, e.g if he constructs a Queue like this:
`tf.FIFOQueue(100,dtypes=tf.int64)`
The FIFOQueue will have a default length 1. This means that the zip-function in the code above will essentialy **cut-off** any data that is longer than 1 (or whatever length `_dtypes` is).

I think an exception should be thrown if the user tries to enqueue a list of tensors that is of unexpected length.




### Source code / logs
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/data_flow_ops.py
Line 270, 271, 272 and 273
",0,,6,2017-10-09T12:51:33Z,NONE
13568,batch_flatten gives unpredictable results when batch_size is 1,stat:awaiting tensorflower,"## Problem

When I attempt to use `tf.contrib.keras.backend.batch_flatten` or more readily `keras.backend.batch_flatten` on a Tensor of shape (1, a, b) it produces a Tensor with shape (None, None).

## MCVE

Note, I'll use keras tensorflow backend because that is how I noticed it. 

```
t = K.zeros((1,2,2))
print(K.int_shape(K.reshape(t,(-1,2*2))))
print(K.int_shape(K.batch_flatten(t)))
```
prints out `(1,4)` and `(None, None)`.
If you replace the first dimension to 2 or more it works as expected.

## System

tensorflow 1.2.0 
keras 2.0.8 python 3.6 installed from git repo




",0,,6,2017-10-08T14:35:42Z,NONE
13565,Bug in Estimator tutorial?,type:docs,"This is the tutorial for the Estimator-class:

https://www.tensorflow.org/extend/estimators

You have the following code:

    my_nn = tf.estimator.DNNClassifier(feature_columns=[age, height, weight],
                                       hidden_units=[10, 10, 10],
                                       activation_fn=tf.nn.relu,
                                       dropout=0.2,
                                       n_classes=3,
                                       optimizer=""Adam"")

and the following:

    input_layer = tf.feature_column.input_layer(
        features=features, feature_columns=[age, height, weight])

If I understand correctly, the feature-columns use the __variables__ `age`, `height` and `weight`. However, these __variables__ are not defined anywhere in the source-code for the tutorial.

The complete source-code is available in `abalone.py` as well:

https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/examples/tutorials/estimators/abalone.py

But here you no longer have the `input_layer` that uses the feature-columns. Instead you have the following which pulls out `""x""` from the `features`-dict:

    # Connect the first hidden layer to input layer
    # (features[""x""]) with relu activation
    first_hidden_layer = tf.layers.dense(features[""x""], 10, activation=tf.nn.relu)

So I'm a bit confused how this is supposed to work?

In general, why don't you make the tutorials as Jupyter Notebooks instead? It would be immensely more helpful than your current tutorial style which is very confusing.

And please remember, that for each hour you spend polishing the code, you will likely save several hours of head-aches for each person trying to understand your code. Multiplied by the many thousands of TensorFlow users, this is a tremendous amount of work-hours that is freed up for the community!
",1,,9,2017-10-08T12:47:44Z,CONTRIBUTOR
13557,Fix the gradient computation of dynamic stitch.,"awaiting review,cla: yes,stat:awaiting tensorflower","Currently the gradient of tf.dynamic_stitch is not correct for duplicated indices. This is
issue #7397. @drasmuss submitted a pull request for this issue, but it was ultimately not merged
due to a performance drop.

While working on this, I realised that the problem is more complicated than what follows
from the discussion in #7487. In fact, the solution proposed in #7487 is not correct, because
one can have duplicated indices in the same input tensor. The following example shows this:

```
import tensorflow as tf

x = tf.zeros((3,))
y = tf.dynamic_stitch([[0, 1, 0]], [x])

with tf.Session() as sess:
    print(""y"")
    print(sess.run(y))

    analytic, numeric = tf.test.compute_gradient(x, (3,), y, (2,))
    print(""analytic"")
    print(analytic)
    print(""numeric"")
    print(numeric)
```

The output (even with #7487) is

```
y
[ 0.  0.]
analytic
[[ 1.  0.]
 [ 0.  1.]
 [ 1.  0.]]
numeric
[[ 0.          0.        ]
 [ 0.          0.99998707]
 [ 0.99998707  0.        ]]
```

My fix is to add a new kernel op `GatherDisjoint`, that can handle all the inputs together.
This replaces the `n` calls to `gather` in `data_flow_grad._DynamicStitchGrads` with a
single `gather_disjoint`.

The implementation is very similar to `gather`, I just zero out duplicated slices at the end.
I've put this op in core/, if you would like I can move it to contrib/, just let me know where.

I've also added tests for the op and new tests for the gradient of dynamic stitch. Here
I inspired myself from @drasmuss pull request.

I've run the script by @drasmuss again:

```
import time

import numpy as np
import tensorflow as tf

stitch_size = 1000
n_inputs = 10
input_shape = (100, 50, 50)
reps = 10

with tf.device(""cpu:0""):
    idxs = [tf.constant(np.random.randint(stitch_size, size=input_shape[0]), dtype=tf.int32)
            for _ in range(n_inputs)]
    vals = [tf.constant(np.random.uniform(-1, 1, size=input_shape), dtype=tf.float32)
            for _ in range(n_inputs)]
    y = tf.dynamic_stitch(idxs, vals)
    grad = tf.gradients(y, vals)

total_time = 0.0
for _ in range(reps):
    with tf.Session() as sess:
        start = time.time()
        sess.run(grad)
        total_time += time.time() - start

print(total_time / reps)
```

The results are as follows:
with my fix:
CPU - 0.09455678462982178
GPU - 0.09739606380462647
without my fix:
CPU - 0.11728813648223876
GPU - 0.11805038452148438

So with the fix it runs faster. On GPU the slowdown is due to the memory copies from host to device
and back, for input and output (I've checked with nvprof), and not because of my fix.

I've run this script using local builds of the same master branch, with and without my patch.

Let me know if the op should be moved somewhere else, or it should be made hidden.",1,,9,2017-10-07T20:50:05Z,CONTRIBUTOR
13549,const_op.h missing from C++ API documentation,type:docs,"I could not find the documentation for tensorflow::ops::Const starting from the C++ API documentation. I figured out it is declared in ops/const_op.h, but there is no link from the main C++ docs:
https://www.tensorflow.org/api_docs/cc/

A search returns this, but it looks orphaned:
https://www.tensorflow.org/api_docs/cc/group/const-op

So I guess there is something wrong in the docs.",1,,10,2017-10-07T09:37:48Z,NONE
13537,Feature Request: tf.assign() support tuples,type:bug/performance,"I have recently updated to V1.3 of Tensorflow.  I have some code that I use for dynamic_rnn which copies the STATE of the cell so it persists to the next .run(), I can also INIT that value as well.  Since the update, I am getting a ""WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f278c196940>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True."".  I have tried to enable state_is_tuple but then the assign() commands fail as they don't support the tuple structures.

I have an open StackOverflow question with the details:
https://stackoverflow.com/questions/46576194/how-do-i-assign-a-lstmstatetuple-using-tf-assign

Since it seems like the RNN core is moving in the direction of the tuple for the state, it would be nice if the .assign() can handle this transparently.
",1,,20,2017-10-06T21:13:57Z,CONTRIBUTOR
13530,"Pandas_input_fn slow, starving CPU/GPU",type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: It is a customized version of the Deep & Wide example code. Fairly close to original code.
- **OS Platform and Distribution: Windows Server 2012 R2
- **TensorFlow installed from: nightly build WHL through pip (this was tried after numerous other versions, including install through pip)
- **TensorFlow version (use command below)**: b'unknown' 1.4.0-dev20170926
- **Python version**: 3.5 and 3.6
- **Bazel version (if compiling from source)**: Not compiling
- **CUDA/cuDNN version**: CUDA 8, CUDnn 6.1
- **GPU model and memory**: Tesla M60 GPU 8GB
- **Exact command to reproduce**:  See attached Script.
-For the record, the server vm has 8 xeon physical cores and 240 gb ram allocated. The CPU only machine is a new skylake i7 with 32gb ram.

### Describe the problem
To start, I submitted to stack overflow (https://stackoverflow.com/questions/46457476/tensorflow-pandas-input-fn-slow-starving-cpu-gpu) and have not been able to garner assistance after multiple edits to make sure it was framed correctly. I truly believe this is a bug since I am sticking so close to the example code, but if I have made a mistake I am deeply sorry to all of you.

I am working on a wide and deep model following the framework in the Tensorflow Wide and Deep tutorial (https://www.tensorflow.org/tutorials/wide_and_deep). Model works fine when built the old way (load entire dataset from pandas, convert to tensors, feed in input_fn) which is ok for running on a CPU. 

However, to make it work on the GPU the dataset is too large to fit into GPU memory, so batching is necessary. I tried using the pandas_input_fn to batch data to the video card and noticed I get spikes of activity followed by long lulls while the next batch is prepared. The odd thing is, this happens even if I run it on a machine with CPU only. The lulls are almost the exact same length, so it isn't simply the video card crushing through a simple model faster than the proc can deliver it. It seems like it is always waiting to begin loading the next batch until the last one is done training. 

(If this function simply cannot be used in this way, can we get an example of Deep and Wide using the dataset API? or a manual build of deep and wide using layers and queues? At the moment, the example code for the dataset api using make_one_shot_iterator for canned estimators doesn't run.)

I increased the complexity of the model to make sure it wasn't too easy to compute and still have the same issue. I have tried increasing the number of threads allocated to pandas_input_fn, I have tried increasing the queue size to far larger than seems reasonable (10x dataset size) which helps a bit, but not much. I am not sure if the slowdown is when it is queueing or de-queueing, but I have been unable to solve the issue after two weeks of troubleshooting. The data I am working with is 117 columns, 400k rows.

I have created a generic script that generates fake values to simulate the problem. However, there are far fewer fake columns than real ones, so the gap between steps is not nearly as long, but still noticeable. Code attached.


--

### Source code / logs
attached
[pandas_input_example.txt](https://github.com/tensorflow/tensorflow/files/1363335/pandas_input_example.txt)
",1,,11,2017-10-06T16:54:00Z,NONE
13521,complex gradient update in optimization,"stat:contributions welcome,type:feature","Is there a plan to allow complex optimization in Tensorflow in the future?

When you try to do it with version 1.3, you can calculate and evaluate gradients, but you cannot apply them with opt.apply_gradients(grds_and_vars). The error message you get is: 

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'ApplyAdadelta' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution 
Distributor ID: Debian
Description:    Debian GNU/Linux 8.9 (jessie)
Release:        8.9

- **TensorFlow installed from (source or binary)**:
using pip install in a virtual conda environment

- **TensorFlow version (use command below)**:
1.3

- **Python version**: 
Python 3.5.2 |Anaconda 4.3.0 (64-bit)| (default, Jul  2 2016, 17:53:06) 

- **Bazel version (if compiling from source)**:
not applicable

- **CUDA/cuDNN version**:
8.0/6.0

- **GPU model and memory**:
Tesla K40c, 11439MiB

- **Exact command to reproduce**:
not necessary, since feature request/question

### Describe the problem
problem description above

### Source code / logs
not applicable
",0,,5,2017-10-06T10:19:19Z,NONE
13520,issue installing Tensorflow on NVIDIA Jetson TX2,stat:community support,"Hello

I am following this tutorial from Jetsonhacks to install Tensorflow on my NVIDIA Jetson TX2 board: http://www.jetsonhacks.com/2017/04/02/tensorflow-on-nvidia-jetson-tx2-development-kit/ 

The situation: 

I ran a couple of provided scripts and seems like I ran into a bug, based on the error message I got. 

    - I haven't set up any swap memory
    - normally CUDNN and CUDA should be properly installed, I installed them remotely via Jetpack
    - df -h returns:


    $ df -h
    Filesystem      Size  Used Avail Use% Mounted on
    /dev/mmcblk0p1   28G   19G  7.6G  71% /
    none            7.0G     0  7.0G   0% /dev
    tmpfs           7.7G  264K  7.7G   1% /dev/shm
    tmpfs           7.7G   14M  7.7G   1% /run
    tmpfs           5.0M  4.0K  5.0M   1% /run/lock
    tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup
    tmpfs           786M   72K  786M   1% /run/user/1001



The issue:

When running the script provided by jetsonhacks: $ ./buildTensorFlow.sh
I get this error message:

    ERROR: /home/nvidia/tensorflow/tensorflow/core/kernels/BUILD:2183:1: C++ compilation of rule '//tensorflow/core/kernels:svd_op'     failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
      (cd /home/nvidia/.cache/bazel/_bazel_nvidia/d2751a49dacf4cb14a513ec663770624/execroot/org_tensorflow && \
      exec env - \
        CUDA_TOOLKIT_PATH=/usr/local/cuda \
        CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \
        GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
        LD_LIBRARY_PATH=/home/nvidia/torch/install/lib:/home/nvidia/torch/install/lib: \
        PATH=/home/nvidia/torch/install/bin:/home/nvidia/torch/install/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
        PWD=/proc/self/cwd \
        PYTHON_BIN_PATH=/usr/bin/python \
        PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
        TF_CUDA_CLANG=0 \
        TF_CUDA_COMPUTE_CAPABILITIES=6.2 \
        TF_CUDA_VERSION=8.0 \
        TF_CUDNN_VERSION=5.1.10 \
        TF_NEED_CUDA=1 \
        TF_NEED_OPENCL=0 \

      external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE         '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-    frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/local_linux-opt/bin    /tensorflow/core/kernels/_objs/svd_op/tensorflow/core/kernels/svd_op_complex64.pic.d '-frandom-seed=bazel-out/local_linux-    opt/bin/tensorflow/core/kernels/_objs/svd_op/tensorflow/core/kernels/svd_op_complex64.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DSNAPPY -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-    opt/genfiles/external/bazel_tools -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local_linux-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local_linux-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local_linux-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local_linux-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local_linux-opt/genfiles/external/snappy -iquote external/local_config_cuda -iquote bazel-out/local_linux-opt/genfiles/external/local_config_cuda -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/eigen_archive -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local_linux-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda/cuda/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-DGOOGLE_CUDA=1' -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined         '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c     tensorflow/core/kernels/svd_op_complex64.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/svd_op/tensorflow/core/kernels/svd_op_complex64.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
    gcc: internal compiler error: Killed (program cc1plus)
    Please submit a full bug report,
    with preprocessed source if appropriate.
    See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.
    Target //tensorflow/tools/pip_package:build_pip_package failed to build
    INFO: Elapsed time: 5924.737s, Critical Path: 813.48s[/code]
    

after this error message I can't run this script: 

    $ ./packageTensorFlow.sh
    ./packageTensorFlow.sh: line 3: cd: /home/nvidia/tensorflow: No such file or directory
    ./packageTensorFlow.sh: line 4: bazel-bin/tensorflow/tools/pip_package/build_pip_package: No such file or directory
    mv: cannot stat '/tmp/tensorflow_pkg/tensorflow-*.whl': No such file or directory


What can I do to solve this issue so I can install Tensorflow as shown in this tutorial?

",0,,1,2017-10-06T09:52:41Z,NONE
13519,"Documentation mentions FeatureValueToId, but it's not found anywhere on the site.","stat:awaiting tensorflower,type:docs","The latest documentation on tensorflow.org expains that for embedding_lookup* functions ids are obtained typically from FeatureValueTold. The last term is not found anywhere else on the site. Probably some remnant from ancient functions.

It should probably be replaced with index_table_from* or something similar.
",0,,8,2017-10-06T09:48:55Z,NONE
13499,Using third party library in custom op implementation with GPU memory manipulation,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 14.04.5
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:1.2.0
- **Python version**: 2.7.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA 8.0
- **GPU model and memory**:GeForce GTX 1080 8G
- **Exact command to reproduce**:


### Describe the problem

To speed up the model's training and evaluating process, and to make the model more flexible, people would like to use some third party libraries for their customized ops. For example, CUDPP, http://cudpp.github.io/, allows people to build a hash table on GPU.

However, I find that TensorFlow does not allow people to manipulate GPU memory by themselves, but only to use allocate_temp in the compute function, which is very inconvenient and inflexible. And these good third party libraries involve many GPU memory manipulations. I cannot find much information about this, but I met some errors in allocating memories.

* What's the reason behind this prohibition?
* Is there some method to allow us manipulate GPU by ourselves? (some switches, some options)
* If we cannot manipulate GPU memory, then how can we use/adapt these third party GPU libraries for the customized ops? What's the good programming practice?

More specifically, the problem I met is that I implemented a customized op on GPU, using the multivalue hash table from the CUDPP library. For very small-scale data, the customized op passed the test. But when I use larger data, and incorporate the customized op into a larger model, then I cannot allocate the memory on CUDA. https://stackoverflow.com/questions/40183189/trouble-compiling-with-custom-tensorflow-gpu-op, this expalins something. I can avoid manipulating GPU memory myself, but the CUDPP library needs to manipulate GPU memory.



### Source code / logs
The cudpp git repo: https://github.com/cudpp/cudpp/compare?expand=1.

My OpKernel:
```C++
void querySquarePointLauncher(int b, int n, int m, float grid_size, int nsample, const float *all_xyz, const float *centroids_xyz, const float *limits, const int *sizes, int *idx, int *pts_cnt, unsigned int *d_keys, unsigned int *d_vals, unsigned int *d_queries, uint2 *d_vals_multivalue);
class QuerySquarePointGpuOp : public OpKernel {
    public:
        explicit QuerySquarePointGpuOp(OpKernelConstruction* context) : OpKernel(context) {
            OP_REQUIRES_OK(context, context->GetAttr(""grid_size"", &grid_size_));
            OP_REQUIRES(context, grid_size_ > 0, errors::InvalidArgument(""QuerySquarePoint expects positive grid size""));

            OP_REQUIRES_OK(context, context->GetAttr(""nsample"", &nsample_));
            OP_REQUIRES(context, nsample_ > 0, errors::InvalidArgument(""QuerySquarePoint expects positive nsample""));
        }

        void Compute(OpKernelContext* context) override {
            const Tensor& all_xyz_tensor = context->input(0);
            OP_REQUIRES(context, all_xyz_tensor.dims()==3 && all_xyz_tensor.shape().dim_size(2)==3, errors::InvalidArgument(""QuerySquarePoint expects (batch_size, ndataset, 3) all_xyz_tensor shape.""));
            int b = all_xyz_tensor.shape().dim_size(0);
            int n = all_xyz_tensor.shape().dim_size(1);

            const Tensor& centroids_xyz_tensor = context->input(1);
            OP_REQUIRES(context, centroids_xyz_tensor.dims()==3 && centroids_xyz_tensor.shape().dim_size(2)==3, errors::InvalidArgument(""QuerySquarePoint expects (batch_size, npoint, 3) centroids_xyz shape.""));
            int m = centroids_xyz_tensor.shape().dim_size(1);
            
            const Tensor& limits_tensor = context->input(2);
            OP_REQUIRES(context, limits_tensor.dims()==1 && limits_tensor.shape().dim_size(0)==6, errors::InvalidArgument(""QuerySquarePoint expects (6) limits shape.""))
            
            const Tensor& sizes_tensor = context->input(3);
            OP_REQUIRES(context, sizes_tensor.dims()==1 && sizes_tensor.shape().dim_size(0) == 3, errors::InvalidArgument(""QuerySquarePoint expects (3) sizes shape.""))

            Tensor *idx_tensor = nullptr;
            OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape{b,m,nsample_}, &idx_tensor));
            Tensor *pts_cnt_tensor = nullptr;
            OP_REQUIRES_OK(context, context->allocate_output(1, TensorShape{b,m}, &pts_cnt_tensor));
            
            Tensor keys_tensor;
            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*n}), &keys_tensor));
            
            Tensor vals_tensor;
            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*n}), &vals_tensor));
            
            Tensor vals_multivalue_tensor;
            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*m*27*2}), &vals_multivalue_tensor));
            
            Tensor queries_tensor;
            OP_REQUIRES_OK(context, context->allocate_temp(DT_INT32, TensorShape({b*m*27}), &queries_tensor));
            

            auto all_xyz_flat = all_xyz_tensor.flat<float>();
            const float *all_xyz = &(all_xyz_flat(0));
            
            auto centroids_xyz_flat = centroids_xyz_tensor.flat<float>();
            const float *centroids_xyz = &(centroids_xyz_flat(0));
            
            auto limits_flat = limits_tensor.flat<float>();
            const float *limits = &(limits_flat(0));
            
            auto sizes_flat = sizes_tensor.flat<int>();
            const int *sizes = &(sizes_flat(0));
            
            auto idx_flat = idx_tensor->flat<int>();
            int *idx = &(idx_flat(0));
            auto pts_cnt_flat = pts_cnt_tensor->flat<int>();
            int *pts_cnt = &(pts_cnt_flat(0));
            
            auto keys_flat = keys_tensor.flat<int>();
            unsigned int *keys = (unsigned int *)&(keys_flat(0));
            
            auto vals_flat = vals_tensor.flat<int>();
            unsigned int *vals = (unsigned int *)&(vals_flat(0));
            
            auto queries_flat = queries_tensor.flat<int>();
            unsigned int *queries = (unsigned int *)&(queries_flat(0));
            
            auto vals_multivalue_flat = vals_multivalue_tensor.flat<int>();
            uint2 *vals_multivalue = reinterpret_cast<uint2*> (&(vals_multivalue_flat(0)));
            
            printf(""Before launcher in cpp\n"");
            
            querySquarePointLauncher(b, n, m, grid_size_, nsample_, all_xyz, centroids_xyz, limits, sizes, idx, pts_cnt, keys, vals, queries, vals_multivalue);         
        }
    private:
        float grid_size_;
        int nsample_;
};
REGISTER_KERNEL_BUILDER(Name(""QuerySquarePoint"").Device(DEVICE_GPU), QuerySquarePointGpuOp);
```

The CUDA implementation:
```C++
__global__ void compose_insert_items(int b, int n, float grid_size, const float *all_xyz, const float *limits, const int *sizes, unsigned int *d_keys, unsigned int *d_vals){
    int index = threadIdx.x;
   
    if(index < n){
        int batch_index = blockIdx.x;
        all_xyz += batch_index * n * 3;
        unsigned int *tmp_d_keys = d_keys + batch_index * n;
        unsigned int *tmp_d_vals = d_vals + batch_index * n;
        int stride = blockDim.x;
        
        for(int point_idx = index; point_idx < n; point_idx += stride){
            unsigned int x_idx = __float2uint_rd((all_xyz[point_idx*3] - limits[0]) / grid_size) + 1;
            unsigned int y_idx = __float2uint_rd((all_xyz[point_idx*3+1] - limits[2]) / grid_size) + 1;
            unsigned int z_idx = __float2uint_rd((all_xyz[point_idx*3+2] - limits[4]) / grid_size) + 1;
            
            tmp_d_keys[point_idx] = z_idx + sizes[2] * (y_idx + sizes[1] * (x_idx + batch_index * sizes[0]));
            tmp_d_vals[point_idx] = point_idx;
        }
    }
}
//compose_queries<<<b,256>>>(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);
__global__ void compose_queries(int b, int m, float grid_size, const float *centroids_xyz, const float *limits, const int *sizes, unsigned int *d_queries){

    int index = threadIdx.x;
    
    if(index < m){
        int stride = blockDim.x;
        int batch_index = blockIdx.x;
        centroids_xyz += batch_index * m * 3;
        unsigned int *tmp_d_queries = d_queries + batch_index * m * 27;
        
        unsigned int x_idx = __float2uint_rd((centroids_xyz[index*3] - limits[0]) / grid_size);
        unsigned int y_idx = __float2uint_rd((centroids_xyz[index*3+1] - limits[2]) / grid_size);
        unsigned int z_idx = __float2uint_rd((centroids_xyz[index*3+2] - limits[4]) / grid_size);
        
        int cnt = 0;
        for(int x_offset = 0; x_offset < 3; x_offset++){
            for(int y_offset = 0; y_offset < 3; y_offset++){
                for(int z_offset = 0; z_offset < 3; z_offset++){
                    tmp_d_queries[index*27+cnt] = z_idx + z_offset + sizes[2] * (y_idx + y_offset + sizes[1] * (x_idx + x_offset + batch_index * sizes[0]));  
                    cnt++;
                }
            }
        }

    }
}
__global__ void hash_square_idx_gpu(int b, int n, int m, int nsample, const uint2 *d_vals_multivalue, const unsigned int * d_all_values, int *idx, int *pts_cnt){
    int index = threadIdx.x;
    if(index < m){
        int stride = blockDim.x;
        int batch_index = blockIdx.x;
        unsigned int sorted_idx[27] = {13, 4,10,12,14,16,22, 1,3,5,7,9,11,15,17,19,21,23,25,  0,2,6,8,18,20,24,26};
                
        idx += batch_index * m * nsample;
        pts_cnt += batch_index * m;
        int query_idx_base = batch_index*m*27+index*27;
        
        int cnt = 0;
        for(int i = 0; i < 27; i++){
            int query_idx = query_idx_base + sorted_idx[i];
            unsigned int num_values = d_vals_multivalue[query_idx].y;
            if(num_values > 0){
                for(unsigned int j = 0; j < num_values && cnt < nsample; j++){
                    idx[index*nsample + cnt] = d_all_values[d_vals_multivalue[query_idx].x + j];
                    cnt++;
                }
            }
        }
        pts_cnt[index] = cnt;
        for(;cnt < nsample;cnt++){
            idx[index*nsample + cnt] = idx[index*nsample];
        }
    }
}

void querySquarePointLauncher(int b, int n, int m, float grid_size, int nsample, const float *all_xyz, const float *centroids_xyz, const float *limits, const int *sizes, int *idx, int *pts_cnt, unsigned int *d_keys, unsigned int *d_vals, unsigned int *d_queries, uint2 *d_vals_multivalue) {
    printf(""Start\n"");    
    unsigned int kInputSize = b * n;
    printf(""b %d, n %d, kInputSize: %u\n"", b, n, kInputSize);
    
    compose_insert_items<<<b,256>>>(b, n, grid_size, all_xyz, limits, sizes, d_keys, d_vals);
    cudaDeviceSynchronize();
    
    CUDPPHandle theCudpp;
    CUDPPResult result = cudppCreate(&theCudpp);
    if (result != CUDPP_SUCCESS){
        fprintf(stderr, ""Error initializing CUDPP Library.\n"");
        exit(-1);
    }

    CUDPPHashTableConfig config;
    config.type = CUDPP_MULTIVALUE_HASH_TABLE;
    config.kInputSize = kInputSize;
    config.space_usage = 2.0f;
    CUDPPHandle hash_table_handle;
    result = cudppHashTable(theCudpp, &hash_table_handle, &config);
    if (result != CUDPP_SUCCESS){
        fprintf(stderr, ""Error in cudppHashTable call in""
                ""testHashTable (make sure your device is at""
                ""least compute version 2.0\n"");
    }
    
    result = cudppHashInsert(hash_table_handle, d_keys,
                                d_vals, kInputSize);
    cudaThreadSynchronize();
    printf(""insert values\n"");
    if (result != CUDPP_SUCCESS){
        fprintf(stderr, ""Error in cudppHashInsert call in""
                ""testHashTable\n"");
    }
    
    unsigned int values_size;
    if (cudppMultivalueHashGetValuesSize(hash_table_handle,
                                    &values_size) !=
                                    CUDPP_SUCCESS){
        fprintf(stderr, ""Error: ""
                ""cudppMultivalueHashGetValuesSize()\n"");
    }
    
    unsigned int * d_all_values = NULL;
    if (cudppMultivalueHashGetAllValues(hash_table_handle,
                                        &d_all_values) !=
                                        CUDPP_SUCCESS){
        fprintf(stderr, ""Error: ""
                ""cudppMultivalueHashGetAllValues()\n"");
    }
    
    compose_queries<<<b,256>>>(b, m, grid_size, centroids_xyz, limits, sizes, d_queries);
    cudaDeviceSynchronize();
    
    result = cudppHashRetrieve(hash_table_handle,
                                d_queries,
                                d_vals_multivalue,
                                b * m * 27);
    cudaThreadSynchronize();
    printf(""retrieved values\n"");
    if (result != CUDPP_SUCCESS){
        fprintf(stderr, ""Error in cudppHashRetrieve call\n"");
    }

    hash_square_idx_gpu<<<b,256>>>(b, n, m, nsample, d_vals_multivalue, d_all_values, idx, pts_cnt);
    cudaDeviceSynchronize();
    printf(""obtain idx\n"");
    
    result = cudppDestroyHashTable(theCudpp, hash_table_handle);
    if (result != CUDPP_SUCCESS){
        fprintf(stderr, ""Error in cudppDestroyHashTable call in""
                ""testHashTable\n"");
    }

    result = cudppDestroy(theCudpp);
    if (result != CUDPP_SUCCESS){
        printf(""Error shutting down CUDPP Library.\n"");
    }
    printf(""Ends\n"");
}
```


",0,,10,2017-10-05T03:26:27Z,NONE
13491,Feature Request: support tf.diag on GPU,stat:contributions welcome,"This could be a good project for an external contributor, currently no GPU support for tf.diag so the following fails

```
import tensorflow as tf
with tf.device(""/gpu:0""):
  mat = tf.diag([1,1])
sess = tf.Session()
sess.run(mat)
```",0,,1,2017-10-04T16:54:05Z,CONTRIBUTOR
13462,Feature Request: recompute gradient with updated weights within a graph,stat:awaiting response,"Hi,

I wonder could there could be some new features to recompute gradients with updated weights within a graph or if there is any better way to do this. For example, for estimating hessian norm, we need to compute

delta ~ N(0, I)
hessian_norm = 1/M \sum_{1}^{M}  gradient(f(x+delta))- gradient(f(x-delta))/(2delta)

we need to gradient value on x+delta. Currently we will get None type if we use tf.gradient on var+delta directly. 

Thank you very much.",0,,6,2017-10-03T11:28:44Z,NONE
13460,Feature request: segment_argmax,stat:contributions welcome,"Currently trying to return argmax from a tensor for selected slices (segments)
slices do not have the same length, so reshaping can't be used.
was looking for a function similar to tf.segment_max, only with indices as the return value.

for e.g
a = [1, 2, 3, 4, 5, 6]
seg = [0, 0, 0, 1, 1, 2]
tf.segment_argmax  return value will be
[2, 4, 5]
",0,,4,2017-10-03T08:06:27Z,NONE
13439,Keras has much better gradients calculated than native TF,stat:awaiting response,"Hi,
I am not sure if this is a bug in some TF function or Keras has just some clever ways to pull things off.
I was prototyping a simple logistic regression model with Keras and trying to write the exact same model with TF to reproduce the result. However, there's something unexplainable to me that Keras always has much better gradients calculated than TF does when I use mini-batch SGD.

tensorflow==1.2.1
Keras==2.0.8
GPU: Tesla P40

Keras version:
```python
def custom_objective(y_true, y_pred):
    loss = tf.reduce_mean(-(y_true*tf.log(y_pred)+((1.0-y_true)*tf.log(1.0-y_pred))))
    return loss
model = Sequential()
model.add(Dense(1,input_dim=2440000, activation='sigmoid', bias_initializer='zeros', kernel_initializer='zeros'))
sgd = tf.train.GradientDescentOptimizer(0.5)
model.compile(loss=custom_objective, optimizer=sgd)
model.fit_generator(generator, steps_per_epoch=1, epochs=1, callbacks=[ival], max_queue_size=10, workers=1, use_multiprocessing=False, initial_epoch=0)
```
TF version:
```python
def linear(x, n_input, n_output, name=None):
    with tf.variable_scope(name or 'fc'):
        W = tf.get_variable(
            name = ""W"",
            # shape = [n_input, n_output],
            dtype=tf.float32,
            # initializer=tf.contrib.layers.xavier_initializer())
            initializer=tf.zeros(shape=[n_input,n_output]))
        b = tf.get_variable(
            name='bias',
            shape=[n_output],
            dtype=tf.float32,
            initializer=tf.constant_initializer(0.0))
        if not isinstance(x, tf.SparseTensor):
            h = tf.nn.bias_add(
                tf.matmul(x, W),
                b,
                name='h')
        else:
            h = tf.nn.bias_add(
                tf.sparse_tensor_dense_matmul(x, W),
                b,
                name='h')
    return h, W, b

tf.reset_default_graph()
X_shape = tf.placeholder(tf.int64, shape=[2], name=""X_shape"")
X_indices = tf.placeholder(tf.int64, name=""X_indices"")
X_values = tf.placeholder(tf.float32, shape=[None], name=""X_values"")
y = tf.placeholder(dtype=tf.float32, name=""y"")
H = tf.SparseTensor(indices=X_indices, values=X_values, dense_shape=X_shape)
logit, w, b = linear(H, 2440000, 1, name=""output_layer"")
y_pred = tf.nn.sigmoid(logit)
train_error = -(y*tf.log(y_pred) + ((1.0 - y) * tf.log(1.0-y_pred)))
loss = tf.reduce_mean(train_error)
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)
gvs = optimizer.compute_gradients(loss,[w,b])
train_op = optimizer.apply_gradients(gvs)
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True), graph=tf.get_default_graph())
sess.run(tf.global_variables_initializer())
```

TL;DR
Keras has better gradients calculated/updates than TF.

Both version implements a vanilla logistic regression, with **same native TF optimizer**, **same user defined cross entropy** and **same data generator**(except for Keras accepts a dense matrix and TF accepts sparse matrix.tocoo()), **same learning rate**, **same zero initializer for both w and b**.
Simple calculus can show that if the first batch contains all NEGATIVE examples, the gradient for b in the first update must be exactly 0.5.

If a batch has very few examples (e.g 1-9), both version produce an exact gradient of 0.5 for b.
When sample size goes above 9, Keras starts to have a way better gradients calculated for both b and w. For example, with sample size 10, Keras calculates 0.50000006 for b and TF gives 0.49999988. With sample size 12, Keras gives 0.49999994 but TF gives 0.50000012. Though both give wrong gradient, Keras is always better, not to mentions the weights gradients. Also trying casting the loss to float16, 32 or 64 won't make the gradient as good as Keras'.

The accumulated differences after 100 batches of training makes TF's model worse than Keras' in terms of AUC.

At this stage I am not sure where I should look for so I resort to the community to help me with this ""unexplainable"" phenomena. Any suggestion will be much appreciated.

Oscar
",0,,11,2017-10-02T07:09:27Z,CONTRIBUTOR
13437,Sin family identities for y=x yield bad gradients,"stat:contributions welcome,type:support","I'm writing a custom continuous piecewise function. At some point the function becomes an identity of f(x) = x, but while the loss decreases, the accuracy does not improve. Simply swapping in an ""x"" in the below code does cause everything to work smoothly.

Originally suspected tf.where as that has NaN gradient troubles, so I rewrote an equivalent function using boolean_mask. Still the same issue. I also attempted to trim values to prevent NaN propagation. A simplified version of the code is below (the troublesome statement in question being tf.cos(i*tf.acos(x)), which equals x):

    i = 1

    location_value = tf.stack([
        tf.less_equal(tf.abs(x), 1), # between_neg_1_and_1
        tf.greater(x, 1), # greater_than_1
        tf.less(x, -1), # less_than_neg_1
        tf.is_nan(x)] 
    , -1)

    res = tf.stack([
        tf.cos(i*tf.acos(tf.minimum(tf.maximum(x, -1), 1))),
        x,
        x,
        0*x]
    , -1)

    out_shape = x.get_shape().as_list()
    out_shape[0] = batch_size

    res = tf.reshape(tf.boolean_mask(res, location_value), out_shape)



------------------------

== cat /etc/issue ===============================================
Linux tyler-desktop 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""14.04.5 LTS, Trusty Tahr""
VERSION_ID=""14.04""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 4.8.5-2ubuntu1~14.04.1) 4.8.5
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux tyler-desktop 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.0)
protobuf (3.1.0.post1)
tensorflow-gpu (0.12.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 0.12.1
tf.GIT_VERSION = v0.12.0-10-g4d924e7-dirty
tf.COMPILER_VERSION = v0.12.0-10-g4d924e7-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally

== env ==========================================================
LD_LIBRARY_PATH /root/torch/install/lib:/root/torch/install/lib:/usr/local/cuda-8.0/lib64:/usr/lib:/usr/openwin/lib:/usr/dt/lib:/X11.6/lib:/X11.5/lib:/uva/lib:/gnu/lib:/usr/local/cuda/lib64:/usr/local/cuda:/usr/bin/g++
DYLD_LIBRARY_PATH /root/torch/install/lib:/root/torch/install/lib:

== nvidia-smi ===================================================
Sun Oct  1 18:05:01 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 0000:01:00.0      On |                  N/A |
|  0%   37C    P0    40W / 230W |    728MiB /  8110MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1137    G   /usr/bin/X                                     370MiB |
|    0      1761    G   compiz                                         243MiB |
|    0      2645    G   /usr/lib/firefox/firefox                         1MiB |
|    0      3024    G   ...ble-features=DocumentWriteEvaluator<Disal   111MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a
",0,,3,2017-10-01T23:07:50Z,NONE
13436,"""Variable rnn/basic_rnn_cell/kernel already exists, disallowed."" error while defining dynamic_rnn",stat:awaiting response,"I was writing a simple code to define an RNN and the code goes thus:

```
n_steps = 28
n_inputs = 28
n_neurons = 150
n_outputs = 10
n_epochs = 100
batch_sz = 150
l_rate = 0.001

X0 = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
Y0 = tf.placeholder(tf.int32, [None])
init_state = tf.zeros([n_steps, n_inputs])

basic_r_cell = rnn.BasicRNNCell(num_units = n_neurons)
ouputs, states = tf.nn.dynamic_rnn(basic_r_cell, X0, initial_state = init_state)

logits = layers.fully_connected(states, n_outputs, activation_fn = None)
```

Executing the above code gave the below error with traceback:

```
> ---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-67-05674d7f7864> in <module>()
     16 
     17 basic_r_cell = rnn.BasicRNNCell(num_units = n_neurons)
---> 18 ouputs, states = tf.nn.dynamic_rnn(basic_r_cell, X0, initial_state = init_state)
     19 
     20 logits = layers.fully_connected(states, n_outputs, activation_fn = None)

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in dynamic_rnn(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)
    572         swap_memory=swap_memory,
    573         sequence_length=sequence_length,
--> 574         dtype=dtype)
    575 
    576     # Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in _dynamic_rnn_loop(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)
    735       loop_vars=(time, output_ta, state),
    736       parallel_iterations=parallel_iterations,
--> 737       swap_memory=swap_memory)
    738 
    739   # Unpack final output if not using output tuples.

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)
   2768     context = WhileContext(parallel_iterations, back_prop, swap_memory, name)
   2769     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, context)
-> 2770     result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
   2771     return result
   2772 

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)
   2597       self.Enter()
   2598       original_body_result, exit_vars = self._BuildLoop(
-> 2599           pred, body, original_loop_vars, loop_vars, shape_invariants)
   2600     finally:
   2601       self.Exit()

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)
   2547         structure=original_loop_vars,
   2548         flat_sequence=vars_for_body_with_tensor_arrays)
-> 2549     body_result = body(*packed_vars_for_body)
   2550     if not nest.is_sequence(body_result):
   2551       body_result = [body_result]

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in _time_step(time, output_ta_t, state)
    720           skip_conditionals=True)
    721     else:
--> 722       (output, new_state) = call_cell()
    723 
    724     # Pack state if using state tuples

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in <lambda>()
    706 
    707     input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)
--> 708     call_cell = lambda: cell(input_t, state)
    709 
    710     if sequence_length is not None:

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in call(self, inputs, state)
    256   def call(self, inputs, state):
    257     """"""Most basic RNN: output = new_state = act(W * input + U * state + B).""""""
--> 258     output = self._activation(_linear([inputs, state], self._num_units, True))
    259     return output, output
    260 

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _linear(args, output_size, bias, bias_initializer, kernel_initializer)
   1015         _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size],
   1016         dtype=dtype,
-> 1017         initializer=kernel_initializer)
   1018     if len(args) == 1:
   1019       res = math_ops.matmul(args[0], weights)

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
   1063       collections=collections, caching_device=caching_device,
   1064       partitioner=partitioner, validate_shape=validate_shape,
-> 1065       use_resource=use_resource, custom_getter=custom_getter)
   1066 get_variable_or_local_docstring = (
   1067     """"""%s

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    960           collections=collections, caching_device=caching_device,
    961           partitioner=partitioner, validate_shape=validate_shape,
--> 962           use_resource=use_resource, custom_getter=custom_getter)
    963 
    964   def _get_partitioned_variable(self,

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    358           reuse=reuse, trainable=trainable, collections=collections,
    359           caching_device=caching_device, partitioner=partitioner,
--> 360           validate_shape=validate_shape, use_resource=use_resource)
    361     else:
    362       return _true_getter(

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)
    350           trainable=trainable, collections=collections,
    351           caching_device=caching_device, validate_shape=validate_shape,
--> 352           use_resource=use_resource)
    353 
    354     if custom_getter is not None:

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)
    662                          "" Did you mean to set reuse=True in VarScope? ""
    663                          ""Originally defined at:\n\n%s"" % (
--> 664                              name, """".join(traceback.format_list(tb))))
    665       found_var = self._vars[name]
    666       if not shape.is_compatible_with(found_var.get_shape()):

ValueError: Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:

  File ""c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()
  File ""c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
```",0,,4,2017-10-01T22:13:59Z,NONE
13433,Bug: tf.Variable uses always twice the memory (on the CPU),,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: tested on both
- **TensorFlow version (use command below)**: 1.3 for pip / 0cfb16e025b3d20e8c8aca431fc0887814817c44 for self-compiled
- **Python version**: Python 3.4.3 [GCC 4.9.2] on linux
- **Bazel version (if compiling from source)**: 0.5.4
- **CUDA/cuDNN version**: not used
- **GPU model and memory**: not used

### Describe the problem
Every tf.variable occupies always twice the necessary memory: 
Once for the tf.constant vector that is created for the initializer and once as the persistend storage.
Code to reproduce:
```
import os
os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '100' #print all
import tensorflow as tf

runs = 1
N = int(1024 * 1024 * 1.1)
M = int(1024 / 8)
print(""testing allocation of {:.2f} MB"".format(N*M*8. / 1024 / 1024))

#does not matter which version you use:
v = tf.Variable(tf.ones([M, N], tf.float64), name=""var1"")
#v = tf.get_variable(shape=(M,N), initializer=tf.ones_initializer, dtype=tf.float64, name='var1', trainable=False)

init = tf.global_variables_initializer()
for i in range(runs):
      print(""start session"")
      with tf.Session() as sess:
            print(""start init"")
            sess.run(init)
```

In my self-compiled version the output contains the following lines:
```
 tensorflow/core/common_runtime/bfc_allocator.cc:133] Extending allocation by 2.00GiB bytes.
 tensorflow/core/common_runtime/bfc_allocator.cc:137] Total allocated bytes: 4.00GiB
```
For the pip version, the current allocation is not displayed, but observing htop during the execution or using mprof reveals the same.

The issue seems to occur because assign does not reuse the memory of tf.ones but instead allocates additional memory. Related lines: [assign_op.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/assign_op.h#L79-L86)
context->forward_input returns null in this case, because the memory of tf.ones has a ref count of 2.
(I dont know why) see [op_kernel.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/op_kernel.cc#L455)
input->RefCountIsOne() is therefore false.

I tried to comment out the input->RefCountIsOne() check, but then it still doesn't work because of the 
output_attr.IsEqualOrLessRestrictiveThan() check.
If you remove this check too, the memory usage finaly drops to the expected value, the memory of tf.ones is reused.  
But this is not a real solution, because I don't know how this would effect other operations and it seems to break the memory freeing.

I think this bug is quiet serious, because it affects nearly all computations. 
Is this an already known bug?

",1,,15,2017-10-01T18:00:20Z,NONE
13426,//tensorflow/contrib/android:libtensorflow_inference.so build fails when compiling @protobuf//:protobuf,"stat:awaiting tensorflower,type:support","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Docker image gcr.io/tensorflow/tensorflow:1.3.0-devel
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**: 0.5.0

Output from `tf_env_collect.sh` is at the end of this report.

### Describe the problem
I'm trying to follow the instructions in [print_selective_registration_header.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/print_selective_registration_header.py#L15) to create a smaller TensorFlow binary size.

Part of those instructions involves building ` //tensorflow/contrib/android:libtensorflow_inference.so`, but that build fails every time.

I'm doing this in the `gcr.io/tensorflow/tensorflow:1.3.0-devel` Docker container (not sure if this is appropriate because I can't find documentation explaining what each container is for).  I tried to use the `1.3.0` container, but that doesn't contain the TensorFlow repo or `git`.

### Source code / logs

Here are the steps I took (the first steps succeeded so I have not included their output):
```
$ docker run -it -v $HOME/TF:/TF gcr.io/tensorflow/tensorflow:1.3.0-devel bash

# bazel build tensorflow/python/tools:print_selective_registration_header

# bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=/TF/mnist_model_graph.pb > ops_to_register.h

# bazel build -c opt --copt=""-DSELECTIVE_REGISTRATION"" --copt=""-DSUPPORT_SELECTIVE_REGISTRATION"" //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures
INFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch
WARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.
<snip repeated warning>
WARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there.
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/protobuf/BUILD:133:1: C++ compilation of rule '@protobuf//:protobuf' failed: false failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /bin/false -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -MD -MF bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.d '-frandom-seed=bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o' -fPIC -iquote external/protobuf -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -c external/protobuf/src/google/protobuf/io/printer.cc -o bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/contrib/android:libtensorflow_inference.so failed to build
INFO: Elapsed time: 202.538s, Critical Path: 11.70s
```
I also tried (with the same result):
 - `bazel clean` before the failing build step.
 - Removing the ops_to_register.h file and the `--copt` parameters.

Here's my full environment info (which shows an error when running pywrap_tensorflow_internal):
```
# cat tf_env.txt

== cat /etc/issue ===============================================
Linux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.1)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.2)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
```",0,,8,2017-09-30T23:20:48Z,CONTRIBUTOR
13413,V1.3.1 undefined reference to `clock_gettime' Error,stat:awaiting tensorflower,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
ReaHat 6.5 with self compiled gcc 4.8.2 installed locally
- **TensorFlow installed from (source or binary)**:
Compile from source
- **TensorFlow version (use command below)**:
- **Python version**: 
2.7.14 compiled from source
- **Bazel version (if compiling from source)**:
5.4.0 Compiled from source
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
bazel build //tensorflow/examples/label_image:label_image
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I working on Redhat 6.5, with gcc 4.8.2 compiled from source and installed locally, binutiles like ld, as were not updated, glic was 2.12.

I managed to compile tensorflow 1.3.1 shared C++ libs libtensorflow_cc.so, but when Iinking to my projects, it encounted with ""undefined reference to `clock_gettime' error. This error can also be reproduced by compiling label image examples with command 
``` 
bazel build //tensorflow/examples/label_image:label_image
``` 
Here are the error details:

/home/xxxxxxx/opensource/tensorflow/tensorflow/tensorflow/examples/label_image/BUILD:10:1: Linking of rule '//tensorflow/examples/label_image:label_image' failed (Exit 1).
bazel-out/local-opt/bin/tensorflow/core/kernels/libattention_ops.lo(attention_ops.o): In function `void Eigen::(anonymous namespace)::GlimpseExtractionOp<long>::eval<Eigen::TensorLayoutSwapOp<Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const>, Eigen::TensorMap<Eigen::Tensor<float, 4, 0, long>, 0, Eigen::MakePointer>, Eigen::ThreadPoolDevice>(Eigen::TensorLayoutSwapOp<Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const&, Eigen::TensorMap<Eigen::Tensor<float, 4, 0, long>, 0, Eigen::MakePointer>&, Eigen::ThreadPoolDevice const&) const':
attention_ops.cc:(.text.unlikely._ZNK5Eigen12_GLOBAL__N_119GlimpseExtractionOpIlE4evalINS_18TensorLayoutSwapOpIKNS_9TensorMapINS_6TensorIKfLi4ELi1ElEELi16ENS_11MakePointerEEEEENS5_INS6_IfLi4ELi0ElEELi0ES9_EENS_16ThreadPoolDeviceEEEvRKT_RT0_RKT1_+0xbb): undefined reference to `clock_gettime'
attention_ops.cc:(.text.unlikely._ZNK5Eigen12_GLOBAL__N_119GlimpseExtractionOpIlE4evalINS_18TensorLayoutSwapOpIKNS_9TensorMapINS_6TensorIKfLi4ELi1ElEELi16ENS_11MakePointerEEEEENS5_INS6_IfLi4ELi0ElEELi0ES9_EENS_16ThreadPoolDeviceEEEvRKT_RT0_RKT1_+0xdf): undefined reference to `clock_gettime'
collect2: error: ld returned 1 exit status
Target //tensorflow/examples/label_image:label_image failed to build
Use --verbose_failures to see the command lines of failed build steps.


I compiled python lib on the exactly the same environment. I had this error when running "" import tensorflow"". The error was fixed by modifying  ""return []"" to 'return [""-lrt""] ' in tensorflow/tensorflow.bzl line 975.

I tried the same trick for label_image example, but it didn't work out.




### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,7,2017-09-30T08:11:53Z,NONE
13375,Add python 3 iterator support for `tf.convert_to_tensor`,"stat:contributions welcome,type:feature","I am working on TensorFlow 1.3.0 and Python 3.6.3.

I found that I have to write many unnecessary code to cast python iterator (such as return value of map, filter, zip and dict_keys) to `list` so that `tf.convert_to_tensor` could work. Supporting convert python iterator to tensor could not only help python 3 user write concise code without many `list(xxx)`, but also memory saving.",0,,6,2017-09-29T05:23:17Z,NONE
13360,Feature request: tf.reduce_median(),"stat:contributions welcome,type:feature","Hi, is there any plan to support a `tf.reduce_median` operator? Now one have to resort to `tf.nn.top_k` for implementing this.",0,,5,2017-09-28T10:42:29Z,CONTRIBUTOR
13351,TensorFlow variable initializers broken,"stat:awaiting tensorflower,type:bug/performance","Three symptoms observed with models after upgrading tensorflow:
1. must feed placeholder error
or
2. things hang with 100% utilization inside python _build_initializer_expr
3. things succeed but sess.run call takes 100x slower than before

I believe this is due to this commit:
https://github.com/tensorflow/tensorflow/commit/07adc2ea910de715d31e16a019fcbcccb575e931

Because the following work-around restores good behavior:
```
from tensorflow.python.ops import variables
def passthrough(obj, value): return value
try:
  variables.Variable._build_initializer_expr=passthrough
except: # older versions of TF don't have this
  pass
```


Here's a self contained repro: https://github.com/yaroslavvb/stuff/blob/master/tf_initializer_bug_report.py

It works fine in tensorflow 1.2, or with the fix, in latest version is throws 

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a va
lue for placeholder tensor 'Wf_holder' with dtype float and shape [307328]
         [[Node: Wf_holder = Placeholder[dtype=DT_FLOAT, shape=[307328], _device
=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

```

Sorry I didn't make the repro smaller, I lost motivation after finding the quick fix :)",1,,12,2017-09-27T22:38:43Z,CONTRIBUTOR
13347,Tensorflow 1.3.0  and Python 3.5.2  Issue in Redhat RH 6.7 x86_64 issue in runtime,stat:community support,"** GLIBC version 2.12 ***
python -c ""import tensorflow""
 File ""/hdpapp/Anaconda3-4.2.0/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /hdpapp/Anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)

Upgraded *** GLIB version to 2.14*****
python -c ""import tensorflow"" 
 File ""/hdpapp/Anaconda3-4.2.0/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /opt/glibc-2.14/lib/libc.so.6: version `GLIBC_2.17' not found (required by /hdpapp/Anaconda3-4.2.0/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)

Upgraded *** GLIB version to 2.17*****
python -c ""import tensorflow""
error while loading shared libraries: __vdso_time: invalid mode for dlopen(): Invalid argument

Any idea what configuration is not matching causing the runtime issue
",0,,1,2017-09-27T17:21:35Z,NONE
13341,"LSTM RNN ""Variable rnn/basic_lstm_cell/kernel already exists, disallowed"" error ","stat:awaiting response,type:support","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,7,2017-09-27T13:58:43Z,NONE
13329,Auto-Parallel excludes update operators of sparse tensors,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
r1.3
- **Bazel version (if compiling from source)**:
0.4.5
- **CUDA/cuDNN version**:
cuda 8.0/cudnn 5.1.5
- **GPU model and memory**:
Tesla P40 
- **Exact command to reproduce**:

### Describe the problem
I'm trying to use auto_parallel in grappler, but I found it only controls dense tensors. In the code, only below operators update averaged gradients, but what about 'ScatterSub' for sparse tensors? Do you have a plan to implement it? 

```
const std::set<string> apply_gradients_ops = {""ApplyGradientDescent"",
                                                ""ApplyProximalGradientDescent"",
                                                ""ApplyAdadelta"",
                                                ""ApplyAdagrad"",
                                                ""ApplyProximalAdagrad"",
                                                ""ApplyAdagradDA"",
                                                ""ApplyFtrl"",
                                                ""ApplyMomentum"",
                                                ""ApplyAdam"",
                                                ""ApplyRMSProp"",
                                                ""ApplyCenteredRMSProp""};
```

### Source code / logs",1,,4,2017-09-27T03:00:47Z,CONTRIBUTOR
13312,Support TensorArray in BeamSearchDecoder state.,"cla: yes,stat:awaiting response","#13208 attempted to fix #13154 by representing the `alignment_history` field with a `Tensor` instead of a `TensorArray`. However, @ebrevdo pointed out that this approach led to a quadratic time and space overhead.

This PR fixes the issue by directly adding the support for `TensorArray` in the `BeamSearchDecoder` state as proposed by @ebrevdo.

@ebrevdo Let me know what you think of this implementation. Thanks!",2,,26,2017-09-26T13:07:16Z,CONTRIBUTOR
13310,Feature Request: Mixed Sparse and Dense Tensors,type:feature,"### Describe the problem
I am trying to implement a sparse convolution operation. This means I have spatially sparse locations(in this case *NHW* of *NHWC* in 2d convolutions)
and at each of these locations I have a dense vector of values (*C* of *NHWC*).
In tensorflow there are currently two classes for sparse representations:

1. **SparseTensor**:
Consisting of an indices matrix, value and shape vector.
  This allows for a fully sparse tensor, however it does not fit this use case, because representing the channels as just another sparse dimension, I cannot simply compute a matrix multiplication, with the corresponding kernel parameters. This extremely reduces efficiency. Apart from this, also the storage
is inefficient, since It redundantly stores the indices for the dense sub tensor.
2. **IndexedSlices**
Consisting of an indices vector and an arbitrarily shaped value tensor.
This is a mixed sparse dense data structure. So the individual sub tensors are stored sparsely. It does however not fit the use case, because the indexing is only a vector and not (as compared to the sparse
tensor) a matrix. So we can only address only a single index. While it is possible to encode an index vector
as a scalar index, it imposes this effort on the user, which seems to me to be non optimal.

So both data structures are inadequate for this use case. While I am talking about a single use case, I cannot imagine, that no one else stumbled across this issue, since its so general. 

### Proposed Solution
To solve this issue I propose to introduce a new class **MixedSparseDenseTensor**, which takes an indices matrix (as opposed to IndexedSlices vector), an arbitrarily shaped values tensor (as opposed to SparseTensors vector) and a shape vector. So it would thus be either a generalization of IndexedSlices to multiple dimensional indices or a generalization of SparseTensor to arbitrarily shaped sub tensors.

The dimensionality of the shape vector should then be the rank of the sparse tensor + the rank of the dense tensor.

",1,,8,2017-09-26T11:57:59Z,NONE
13308,Attempting to use the CPU Work Sharder segfaults on g++ 5.4.0,stat:awaiting tensorflower,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
  
I've adapted the ZeroOut operator from the [Adding a New Op](https://www.tensorflow.org/extend/adding_an_op) example.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:

binary GPU 1.3.0

- **TensorFlow version (use command below)**:

$ python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.3.0-rc2-20-g0787eee', '1.3.0')

- **Python version**: 

2.7.12

- **Bazel version (if compiling from source)**:

N/A

- **CUDA/cuDNN version**:

N/A

- **GPU model and memory**:

N/A

- **Exact command to reproduce**:

Test operator: [shard_fails.zip](https://github.com/tensorflow/tensorflow/files/1332745/shard_fails.zip)

```bash
$ make
$ python test_op.py
```



### Describe the problem

When the above C++ operator runs, it'll print the number of threads in the pool (8) and then segfault on the Shard call.

### Source code / logs

C++ operator code:

```cpp
#define EIGEN_USE_THREADS

#include ""tensorflow/core/lib/core/threadpool.h""
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/op_kernel.h""
#include ""tensorflow/core/framework/shape_inference.h""
#include ""tensorflow/core/util/work_sharder.h""

using namespace tensorflow;

REGISTER_OP(""ZeroOut"")
    .Input(""to_zero: int32"")
    .Output(""zeroed: int32"")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      c->set_output(0, c->input(0));
      return Status::OK();
    });

class ZeroOutOp : public OpKernel {
 public:
  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor& input_tensor = context->input(0);
    auto input = input_tensor.flat<int32>();

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),
                                                     &output_tensor));
    auto output_flat = output_tensor->flat<int32>();

    // Set all but the first element of the output tensor to 0.
    const int N = input.size();

    auto pool = context->device()->tensorflow_cpu_worker_threads()->workers;
    printf(""Pool Threads %d\n"", pool->NumThreads());
    Shard(pool->NumThreads(), pool, N, 10, [&](int64 start, int64 end) {
        for(int64 i=start; i<end; ++i)
            { output_flat(i) = 0; }
    });

    if(N > 0)
        { output_flat(0) = input(0); }
  }
};

REGISTER_KERNEL_BUILDER(Name(""ZeroOut"").Device(DEVICE_CPU), ZeroOutOp);
```


See below the gdb trace:

```
Core was generated by `python test_op.py'.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  std::_Function_handler<void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}>::_M_invoke(std::_Any_data const&, long long&&, std::_Any_data const&) (__functor=..., __args#0=<unknown type in tfop.so, CU 0x0, DIE 0x41c73>, __args#1=<unknown type in tfop.so, CU 0x0, DIE 0x41c78>) at /usr/include/c++/5/functional:1871
1871		(*_Base::_M_get_pointer(__functor))(
[Current thread is 1 (Thread 0x7f38a6605700 (LWP 3771))]
(gdb) bt
#0  std::_Function_handler<void (long long, long long), ZeroOutOp::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}>::_M_invoke(std::_Any_data const&, long long&&, std::_Any_data const&) (__functor=..., __args#0=<unknown type in tfop.so, CU 0x0, DIE 0x41c73>, __args#1=<unknown type in tfop.so, CU 0x0, DIE 0x41c78>) at /usr/include/c++/5/functional:1871
#1  0x00007f3879dcc75d in tensorflow::thread::ThreadPool::Impl::ParallelFor(long long, long long, std::function<void (long long, long long)>) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007f3879dcc93f in tensorflow::thread::ThreadPool::ParallelFor(long long, long long, std::function<void (long long, long long)>) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007f3879d4d995 in tensorflow::Shard(int, tensorflow::thread::ThreadPool*, long long, long long, std::function<void (long long, long long)>) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007f3850bfb79e in ZeroOutOp::Compute (this=0x62dacc0, context=0x7ffd1a20fe30) at tf_op.cpp:42
#5  0x00007f3879a2563c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007f38799f5a58 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007f38799f61fa in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007f3879a035c4 in std::_Function_handler<void (std::function<void ()>), tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)::{lambda(std::function<void ()>)#1}>::_M_invoke(std::_Any_data const&, std::function<void ()>) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007f38799e895b in std::function<void (std::function<void ()>)>::operator()(std::function<void ()>) const ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007f38799e9043 in tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*) [clone .part.246] () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007f38799ecf5e in tensorflow::(anonymous namespace)::ExecutorImpl::RunAsync(tensorflow::Executor::Args const&, std::function<void (tensorflow::Status const&)>) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007f3879a045e4 in tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007f38799dce27 in tensorflow::ConstantFold(tensorflow::ConstantFoldingOptions const&, tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, tensorflow::Graph*, bool*) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#14 0x00007f3879a02fea in tensorflow::GraphOptimizer::Optimize(tensorflow::FunctionLibraryRuntime*, tensorflow::Env*, tensorflow::Device*, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#15 0x00007f38799a9469 in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#16 0x00007f38799aa06c in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#17 0x00007f387799b2d7 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#18 0x00007f387799b604 in TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#19 0x00007f38778037e2 in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#20 0x00007f3877803be1 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#21 0x00007f38777ca793 in _wrap_TF_Run () from /home/sperkins/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#22 0x00000000004c468a in PyEval_EvalFrameEx ()
#23 0x00000000004c2765 in PyEval_EvalCodeEx ()
#24 0x00000000004de6fe in ?? ()
#25 0x00000000004b0cb3 in PyObject_Call ()
#26 0x00000000004c6ad1 in PyEval_EvalFrameEx ()
#27 0x00000000004c2765 in PyEval_EvalCodeEx ()
#28 0x00000000004ca8d1 in PyEval_EvalFrameEx ()
#29 0x00000000004c2765 in PyEval_EvalCodeEx ()
---Type <return> to continue, or q <return> to quit---
#30 0x00000000004ca8d1 in PyEval_EvalFrameEx ()
#31 0x00000000004c2765 in PyEval_EvalCodeEx ()
#32 0x00000000004ca8d1 in PyEval_EvalFrameEx ()
#33 0x00000000004c2765 in PyEval_EvalCodeEx ()
#34 0x00000000004ca099 in PyEval_EvalFrameEx ()
#35 0x00000000004c2765 in PyEval_EvalCodeEx ()
#36 0x00000000004c2509 in PyEval_EvalCode ()
#37 0x00000000004f1def in ?? ()
#38 0x00000000004ec652 in PyRun_FileExFlags ()
#39 0x00000000004eae31 in PyRun_SimpleFileExFlags ()
#40 0x000000000049e14a in Py_Main ()
#41 0x00007f38a5e4c830 in __libc_start_main (main=0x49dab0 <main>, argc=2, argv=0x7ffd1a213618, init=<optimised out>, fini=<optimised out>, rtld_fini=<optimised out>, stack_end=0x7ffd1a213608)
    at ../csu/libc-start.c:291
#42 0x000000000049d9d9 in _start ()
```",0,,16,2017-09-26T10:25:09Z,CONTRIBUTOR
13305,not able to install tensor flow from pip using 3.5 64 bit version of python.,stat:awaiting response,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,4,2017-09-26T03:37:54Z,NONE
13295,Pre-built binaries with symbol information?,stat:contributions welcome,"What you you guys think about providing CI version of TensorFlow with built-in symbol information? This would make it easier to report bugs.

I believe the following is sufficient to get optimized version with symbol tables.
`blaze build --cxxopt=-g2 --linkopt=-g2 --strip never -c opt`

My current problem is that I'm occasionally hitting segfaults due to `tensorflow::strings::FloatToBuffer`. I can't reproduce this in any small example. If there were a version of tf with symbol tables, I could just gdb on the core file and do `info locals` to get the value of offending float that causes the crash.

```
#0  0x00007ffb54a4941d in std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, float>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, float> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node(unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long) const ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007ffb5745b76e in float tensorflow::(anonymous namespace)::locale_independent_strtonum<float>(char const*, char const**) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007ffb5745bf4c in tensorflow::strings::safe_strtof(char const*, float*)
    ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007ffb5745bfe9 in tensorflow::strings::FloatToBuffer(float, char*) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007ffb5735d7ce in tensorflow::Tensor::SummarizeValue[abi:cxx11](long long) const ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007ffb5735e3b5 in tensorflow::Tensor::DebugString[abi:cxx11]() const ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007ffb572f21ab in tensorflow::(anonymous namespace)::SummarizeTensor(tensorflow::TensorProto const&) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007ffb572f5529 in tensorflow::SummarizeAttrValue[abi:cxx11](tensorflow::AttrValue const&) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007ffb57322b9d in tensorflow::SummarizeAttrsHelper(tensorflow::AttrSlice, tensorflow::StringPiece) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007ffb573231f3 in tensorflow::SummarizeNodeDef[abi:cxx11](tensorflow::NodeDef const&) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007ffb5732332f in tensorflow::SummarizeNode[abi:cxx11](tensorflow::Node const&) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007ffb55fc7886 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007ffb55fc93cf in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007ffb57442c51 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#14 0x00007ffb57440d37 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#15 0x00007ffb6174c260 in ?? ()
   from /home/yaroslav/anaconda3/envs/sep22/lib/python3.5/site-packages/scipy/sparse/../../../../libstdc++.so.6
#16 0x00007ffb6d9926ba in start_thread (arg=0x7ffaa4906700)
    at pthread_create.c:333
#17 0x00007ffb6cdb03dd in clone ()
    at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109

```",0,,15,2017-09-25T17:01:49Z,CONTRIBUTOR
13281,"Non-working example in documentation, with recommendations for how to fix","awaiting review,type:docs","== cat /etc/issue ===============================================
Linux EricDesktop 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux EricDesktop 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.1)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.6)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc1-2409-g5ee3804
tf.COMPILER_VERSION = v1.3.0-rc1-2409-g5ee3804
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Sun Sep 24 14:08:03 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 670     Off  | 0000:03:00.0     N/A |                  N/A |
| 33%   50C    P0    N/A /  N/A |    254MiB /  4031MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 670     Off  | 0000:04:00.0     N/A |                  N/A |
| 32%   48C    P0    N/A /  N/A |    253MiB /  4036MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0                  Not Supported                                         |
|    1                  Not Supported                                         |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61

### Describe the problem

    I have been trying to get a custom op working for many hours, and have finally collected enough information to know that it isn't entirely my fault, and I can help you improve the custom op documentation to save others such effort.  
Walkthrough to see what the problem is:
1) Following the instructions on the documentation page (https://www.tensorflow.org/extend/adding_an_op) I copy the zero_out.cc code
2) Compile with Bazel
3) Test with python.  Everything works, this example behaves exactly as it should.
4) But I want a GPU kernel, so now I try the ""example"" example.
Copy the example.h, example.cc and example.cu.cc files on the documentation page.  Didn't make any changes.
5) Now I hit some problems.  The documentation isn't very clear on how to compile this more complicated op with bazel.  I managed to figure it out, but I would strongly recommend notifying users about the ""gpu_srcs"" argument that can be used inside the BUILD file, since this took me quite a while to discover.

Working BUILD file:
load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")

tf_custom_op_library(
    name = ""example.so"",
    srcs = [""example.cc"", ""example.h""],
    gpu_srcs = [""example.cu.cc"", ""example.h""],
)
Working Bazel command to invoke the BUILD file:
bazel build --config opt --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/core/user_ops:example.so

6) Now it compiles.  But the op does not load properly in python; the module created by tf.load_op_library does not contain the actual op, as you can see by my tests under the source code section.
7) After a long time, I discover the extremely obvious problem: the example code in the documentation does not have any REGISTER_OP macro call.  This is clearly an omission in the documentation.
8) I try copying the REGISTER_OP macro call from the zero_out example, and it doesn't really work since the ""example"" example is more complicated, but python now at least recognizes the op.  I am sure if I were to spend the time to figure out how to correctly call the REGISTER_OP macro in example.cc, the example would work correctly for me.

    I could make some other recommendations about changing the ""Adding a New Op"" documentation page, though I will refrain for now since I am not sure this is the appropriate place to do so.  I would be happy to take a stab at editing the doc page myself, though since I am very new to github I am concerned that I would end up creating more problems than I would fix, so it might be better to have someone with more experience do it.  I would be happy to help though.

    One thing I will say though: I would really love it if some TF expert would add a fully fleshed out template op to the user op documentation page with all the bells and whistles, and with clear instructions on exactly how to compile and run it.  It should have both GPU support and a gradient implementation.  And ideally it would be multi-threaded (if the ""example"" example isn't already - its not obvious to me either way).  The template would be provided with everything you need, and would have a clearly labeled code block where the user can add their own code:  ""here is a for loop that iterates over every element in the tensor.  write whatever you want here.""  If you can make it really easy for users to add their own, high-quality operators, you might be able to cut down on your workload responding to problems with custom ops and with users requesting new ops.  And I think that a template that we can fill in would be enough to do that for many people.

### Source code / logs

=========================================== start test.py:
import tensorflow as tf
zero_out_module = tf.load_op_library('./zero_out.so')
with tf.Session(''):
  print ""zero_out:""
  print(zero_out_module.zero_out([[1, 2], [3, 4]]).eval())

example_module = tf.load_op_library('./example.so')
with tf.Session(''):
  print ""example:""
  try:
    print(example_module.example([[1, 2], [3, 4]]).eval())
  except AttributeError as err:
    print ""Error: "", err
    
  
print ""Analysis of zero_out_module:""  
print zero_out_module.__dict__.keys()
print zero_out_module.OP_LIST

print ""Analysis of example_module:""
print example_module.__dict__.keys()
print example_module.OP_LIST

====================================== end test.py

Output of running test.py
eric@EricDesktop:~/tensorflow/tensorflow/core/user_ops$ python test.py2017-09-24 14:14:08.183509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-09-24 14:14:08.183794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties: 
name: GeForce GTX 670 major: 3 minor: 0 memoryClockRate(GHz): 1.0455
pciBusID: 0000:04:00.0
totalMemory: 3.94GiB freeMemory: 3.66GiB
2017-09-24 14:14:08.208238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-09-24 14:14:08.208514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 1 with properties: 
name: GeForce GTX 670 major: 3 minor: 0 memoryClockRate(GHz): 1.0455
pciBusID: 0000:03:00.0
totalMemory: 3.94GiB freeMemory: 3.66GiB
2017-09-24 14:14:08.208964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:980] Device peer to peer matrix
2017-09-24 14:14:08.208988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] DMA: 0 1 
2017-09-24 14:14:08.208994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] 0:   Y Y 
2017-09-24 14:14:08.209000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] 1:   Y Y 
2017-09-24 14:14:08.209012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:04:00.0, compute capability: 3.0)
2017-09-24 14:14:08.209020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 670, pci bus id: 0000:03:00.0, compute capability: 3.0)
zero_out:
[[1 0]
 [0 0]]
2017-09-24 14:14:08.239952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:04:00.0, compute capability: 3.0)
2017-09-24 14:14:08.239970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 670, pci bus id: 0000:03:00.0, compute capability: 3.0)
example:
Error:  'module' object has no attribute 'example'
Analysis of zero_out_module:
['_op_def_pb2', '_op_def_lib', '_op_def_registry', '_ops', '_collections', '_common_shapes', '__builtins__', 'zero_out', '__package__', '_op_def_library', 'OP_LIST', 'LIB_HANDLE', '__name__', '_InitOpDefLibrary', '__doc__']
op {
  name: ""ZeroOut""
  input_arg {
    name: ""to_zero""
    type: DT_INT32
  }
  output_arg {
    name: ""zeroed""
    type: DT_INT32
  }
}

Analysis of example_module:
['_op_def_pb2', '_op_def_lib', '_op_def_registry', '_ops', '_collections', '_common_shapes', '__builtins__', '__package__', '_op_def_library', 'OP_LIST', 'LIB_HANDLE', '__name__', '_InitOpDefLibrary', '__doc__']


",1,,9,2017-09-24T21:58:17Z,NONE
13269,TensorFlow 1.0 and 1.2 behave differently on MultiRNNCell.,stat:community support,"The following code works well on TF 1.0.1, but doesn't work on TF 1.2 and above, leaving error massage, 

File ""pb_OE_column_on_the_spot.py"", line 318, in <module>
    outputs1, _states = tf.nn.dynamic_rnn(_multi_cells, tf.one_hot(_X, data_dim), dtype=tf.float32)
ValueError: Trying to share variable rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel, but specified shape (256, 512) and found shape (132, 512).

I followed the change after version 1.2: [https://github.com/tensorflow/tensorflow/releases](url),
where states: To get 5 layers each with their own parameters, write: MultiRNNCell([LSTMCell(...) for _ in range(5)])

and I also reviewed similar posts regarding same issue: [https://github.com/udacity/deep-learning/issues/132](url)

    seq_length = 6
    data_dim =4
    hidden_dim = 12
    X = tf.placeholder(tf.int32, [None, seq_length])
    Y = tf.placeholder(tf.int32, [None]) 
    keep_prob = tf.placeholder(tf.float32) 

    X_one_hot = tf.one_hot(X, data_dim)
    Y_one_hot = tf.one_hot(Y, 2) 

    def lstm_cell():
        lstm = tf.contrib.rnn.BasicLSTMCell(hidden_dim, state_is_tuple=True)
        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)
        return drop

    multi_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(3)], state_is_tuple=True)
    outputs1, _states = tf.nn.dynamic_rnn(multi_cells, X_one_hot, dtype=tf.float32)

Why does this error happen?
.
.
.
by the way, would 12 for the number of units in the LSTM cell be too small?",0,,1,2017-09-24T05:33:15Z,NONE
13259,Implement SpatialPyramidPooling,"awaiting review,cla: yes","PR Inspired from the work of @luizgh and @RikHeijdens.
References:
- He, Kaiming et al (2015): Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. http://arxiv.org/pdf/1406.4729.pdf.
- [Implement SpatialPyramidPooling](https://github.com/Lasagne/Lasagne/pull/799)",1,,11,2017-09-23T10:32:57Z,CONTRIBUTOR
13258,small mistake,"stat:awaiting response,type:bug/performance","https://github.com/tensorflow/tensorflow/blob/b46340f40fe5e2ec9bfcd385b07cfb914055fb51/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py#L48

this should be only y, not ||y||^2",0,,4,2017-09-23T10:23:12Z,NONE
13246,Documentation correction,type:docs,"Hi, 

I think there might be a possible documentation error in that of `tf.stack`. It's said that the numpy equivalent is `np.asarray`. But `np.asarray([])` will take lists of arbitrary shapes and makes it to a `ndarray` whereas `tf.stack` requires all the dimensions of objects in the list to be same. So the equivalent ideally would be `np.stack`.

Cheers, 
Ramana",1,,5,2017-09-22T20:37:06Z,NONE
13243,Linking of rule '//tensorflow/contrib/factorization:gen_gen_clustering_ops_py_wrappers_cc' failed (missing -lcuda?),,"Trying to build Tensorflow from a6f856b2f7920d4f74d7ca4e71967258423cc9f0 with CUDA and just started running into this issue:

```
____[7,182 / 7,674] Compiling tensorflow/core/graph/node_builder.cc
____[7,183 / 7,675] Compiling tensorflow/core/graph/costmodel.cc
____[7,245 / 7,715] Linking tensorflow/contrib/factorization/gen_gen_clustering_ops_py_wrappers_cc [for host]
____[7,246 / 7,715] Linking tensorflow/contrib/tensor_forest/hybrid/gen_training_ops_py_wrappers_cc [for host]
____[7,247 / 7,715] Linking tensorflow/cc/ops/lookup_ops_gen_cc [for host]
____[7,248 / 7,715] Linking tensorflow/contrib/tensor_forest/gen_gen_model_ops_py_py_wrappers_cc [for host]
____[7,249 / 7,715] Linking tensorflow/contrib/tensor_forest/gen_gen_tensor_forest_ops_py_wrappers_cc [for host]
____[7,250 / 7,715] Linking tensorflow/python/gen_set_ops_py_wrappers_cc [for host]
____[7,251 / 7,715] Linking tensorflow/python/gen_linalg_ops_py_wrappers_cc [for host]
ERROR: /build/tensorflow-git/src/tensorflow-cuda/tensorflow/contrib/factorization/BUILD:106:1: Linking of rule '//tensorflow/contrib/factorization:gen_gen_clustering_ops_py_wrappers_cc' failed (Exit 1).
/usr/bin/ld: warning: libcuda.so.1, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemFree_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD32Async'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventCreate'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamAddCallback'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleLoadFatBinary'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxEnablePeerAccess'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemGetInfo_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuLaunchKernel'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamSynchronize'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventQuery'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventElapsedTime'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceCanAccessPeer'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxSynchronize'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetAttribute'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuFuncGetAttribute'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoH_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamQuery'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxGetState'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxSetCurrent'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamWaitEvent'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventSynchronize'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleUnload'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGet'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD32_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxGetSharedMemConfig'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemFreeHost'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuFuncSetCacheConfig'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamCreate'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemGetAddressRange_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxGetDevice'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetProperties'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoHAsync_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetCount'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleGetFunction'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemHostRegister_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxRelease'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyHtoDAsync_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoD_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleLoadDataEx'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxRetain'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemHostAlloc'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuInit'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDriverGetVersion'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetPCIBusId'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventRecord'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuPointerGetAttribute'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceTotalMem_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD8_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceComputeCapability'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemAlloc_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetName'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxSetFlags'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemHostUnregister'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleGetGlobal_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoDAsync_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventDestroy_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuOccupancyMaxActiveBlocksPerMultiprocessor'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxGetCurrent'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamDestroy_v2'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxSetSharedMemConfig'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD8Async'
bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyHtoD_v2'
collect2: error: ld returned 1 exit status
____Building complete.
____Elapsed time: 1247.002s, Critical Path: 405.23s
```

My previous successful build (I haven't tried revisions in between) was from abfc9deb7. My build environment hasn't changed significantly since then (no compiler, CUDA, or relevant library changes). I suspect it must be a recent change in the Tensorflow repo that's the cause.

The only difference I see between abfc9deb7 and a6f856b2f7920d4f74d7ca4e71967258423cc9f0  in the tensorflow/contrib/factorization path is this:

```diff
diff --git a/tensorflow/contrib/factorization/kernels/BUILD b/tensorflow/contrib/factorization/kernels/BUILD
index 9a6d3c6f5..44eab5601 100644
--- a/tensorflow/contrib/factorization/kernels/BUILD
+++ b/tensorflow/contrib/factorization/kernels/BUILD
@@ -6,6 +6,8 @@ exports_files([""LICENSE""])

 package(default_visibility = [""//tensorflow:__subpackages__""])

+load(""//tensorflow:tensorflow.bzl"", ""tf_cc_test"")
+
 cc_library(
     name = ""all_kernels"",
     deps = [
@@ -50,7 +52,7 @@ cc_library(
     alwayslink = 1,
 )

-cc_test(
+tf_cc_test(
     name = ""clustering_ops_test"",
     srcs = [""clustering_ops_test.cc""],
     deps = [
```

I'm not super familiar with how Bazel works, but this looks innocuous to me. I guess something else must be implicated?

Any idea what could cause it to not add `-lcuda` on the link line? Or perhaps why it didn't need to before but does now?

```
$ pacman -Q | grep -e gcc-mult -e ^cuda -e ^glibc -e ^cudnn -e ^gcc5 -e '^python ' -e bazel
bazel 0.5.4-1
cuda 8.0.61-3
cudnn6 6.0.21-2
gcc-multilib 7.2.1.20170910-1
gcc5 5.4.0-1
glibc 2.26-3
python 3.6.2-1
```",1,,9,2017-09-22T19:29:32Z,NONE
13222,SVD in TensorFlow is slower than in numpy,"stat:awaiting tensorflower,type:bug/performance","I am observing that on my machine SVD in tensorflow is running significantly slower than in numpy. I have GTX 1080 GPU, and expecting SVD to be at least as fast as when running the code using CPU (numpy).

**Environment Info**

Operating System

    lsb_release -a
    No LSB modules are available.
    Distributor ID:	Ubuntu
    Description:	Ubuntu 16.10
    Release:	16.10
    Codename:	yakkety

Installed version of CUDA and cuDNN:

    ls -l /usr/local/cuda-8.0/lib64/libcud*
    -rw-r--r-- 1 root      root    556000 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudadevrt.a
    lrwxrwxrwx 1 root      root        16 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
    lrwxrwxrwx 1 root      root        19 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
    -rwxr-xr-x 1 root      root    415432 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
    -rw-r--r-- 1 root      root    775162 Feb 22  2017 /usr/local/cuda-8.0/lib64/libcudart_static.a
    lrwxrwxrwx 1 voldemaro users       13 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5
    lrwxrwxrwx 1 voldemaro users       18 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10
    -rwxr-xr-x 1 voldemaro users 84163560 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10
    -rw-r--r-- 1 voldemaro users 70364814 Nov  6  2016 /usr/local/cuda-8.0/lib64/libcudnn_static.a

TensorFlow Setup

    python -c ""import tensorflow; print(tensorflow.__version__)""
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
    1.0.0

**Code:**

    '''
    Created on Sep 21, 2017
    
    @author: voldemaro
    '''
    import numpy as np
    import tensorflow as tf
    import time;
    import numpy.linalg as NLA;
    
    
    
    
    N=1534;
    
    svd_array = np.random.random_sample((N,N));
    svd_array = svd_array.astype(complex);
    
    specVar = tf.Variable(svd_array, dtype=tf.complex64);
    
    [D2, E1,  E2] = tf.svd(specVar);
    
    init_OP = tf.global_variables_initializer();
    
    with tf.Session() as sess:
        # Initialize all tensorflow variables
        start = time.time();
        sess.run(init_OP);
        print 'initializing variables: {} s'.format(time.time()-start);
        
        start_time = time.time();
        [d, e1, e2]  = sess.run([D2, E1,  E2]);
        print(""Tensorflow SVD ---: {} s"" . format(time.time() - start_time));
    
    
    # Equivalent numpy 
    start = time.time();
    
    u, s, v = NLA.svd(svd_array);   
    print 'numpy SVD  ---: {} s'.format(time.time() - start);


Code Trace:

    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
    I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
    name: GeForce GTX 1080
    major: 6 minor: 1 memoryClockRate (GHz) 1.7335
    pciBusID 0000:01:00.0
    Total memory: 7.92GiB
    Free memory: 7.11GiB
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
    initializing variables: 0.230546951294 s
    Tensorflow SVD ---: 6.56117296219 s
    numpy SVD  ---: 4.41714000702 s

",0,,12,2017-09-21T23:53:20Z,NONE
13221,Memory leak in zeros_like/Tile,stat:contributions welcome,"So I'm trying to figure out why my resnets are running out of memory, and it seems that there's a memory leak in Tile and zeros_like operations.

Those ops have memory allocated during each session run but there's no `__LOG_MEMORY__` deallocation messages corresponding to them. The sum of missing deallocations matches the amount of memory leaked as reported by allocator as `max_bytes_in_use` (accessed through `tf.contrib.memory_stats.MaxBytesInUse` op)

Here's a simplified repro, at each sess.run, the memory grows by 1.15 GB until it crashes with OOM
https://github.com/yaroslavvb/stuff/blob/master/resnet_leak_report2.py

When I run it, I see
```
Run 0, GBs in use 2.30
Run 1, GBs in use 3.60
Run 2, GBs in use 4.75
Run 3, GBs in use 5.90
2017-09-21 14:56:31.994302: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 137.33MiB.  Current allocation summary follows....
```

Offending ops:
```
gradients/leaky_relu_grad/zeros_like 576MB
gradients/Sum_grad/Tile  576MB
```
Version:
Ubuntu 16:04
official TensorFlow Linux GPU Python 3.5 nightly wheel from [today](https://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3.5,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tf_nightly_gpu-1.head-cp35-cp35m-linux_x86_64.whl)

```
version: 1.4.0-dev20170921
__git_version__: v1.3.0-rc1-2408-ge9d5ee1
Commit https://github.com/tensorflow/tensorflow/commit/e9d5ee1

```",0,,29,2017-09-21T22:22:23Z,CONTRIBUTOR
13211,transform_graph does not allow ~/ in path,stat:contributions welcome,"when using ~/ in path, transform_graph returns file not found",0,,4,2017-09-21T13:01:46Z,NONE
13206,Feature Request - Check parameter types at C++ compile time ,"stat:awaiting tensorflower,type:feature","e.g. Tensor oTensor( DT_INT64, TensorShape( { 4, 3 } ) );

The type of parameters **{4, 3}** should be checked at compile time whether is corresponding to the **DataType** of **Tensor(DataType type, const TensorShape& shape);**.

See #12501

",0,,5,2017-09-21T08:26:22Z,NONE
13202,tf.InteractiveSession leaks sessions,type:bug/performance,"The following works fine with tf.Session() but will fail to release resources in tf.InteractiveSession

```
sess = tf.InteractiveSession()
# do stuff  
sess.close()
del sess
```
The reason is that interactive session enters a context using `__enter()__` and never quits it, leaving a reference from a DefaultStack object. I found this when debugging why my notebook was hogging all GPU RAM.

The two work-arounds:
1. Force C_API to close the session using `sess.__del__()`
2. Get rid of the dangling reference

```
    sess._default_session.__exit__(None, None, None)
    del sess
    import gc
    gc.collect()
```

I think a better solution would be to have `sess.close()` call both `TF_CloseSession` and `TF_DeleteSession`, or have a method that will reset all sessions like `session_lib.Reset`",1,,13,2017-09-21T03:44:15Z,CONTRIBUTOR
13196,ModuleNotFoundError: No module named '_pywrap_tensorflow_internal',"stat:awaiting response,type:build/install","Hi - Thanks for all your hard work on this! - I've been having a problem getting Tensorflow-GPU to work on my Windows 10 notebook with a GTX 1080. I've tried to make sure all the paths are correct, etc. and have followed all the tips I can find.

I ran the tensorflow_self_check.py script and got the following result:

PS D:\Users\Frank Davidson\Documents\python> python .\tensorflow_self_check.py
ERROR: Failed to import the TensorFlow module.

- Python version is 3.6.

- TensorFlow is installed at: C:\Program Files\Python36\lib\site-packages\tensorflow

- All required DLLs appear to be present. Please open an issue on the
  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues
PS D:\Users\Frank Davidson\Documents\python>

Here is the full stack trace when I try to import tensorflow:

PS C:\Users\Frank Davidson> python
Python 3.6.2 (v3.6.2:5fd33b5, Jul  8 2017, 04:57:36) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_i
mport_helper
    return importlib.import_module(mname)
  File ""C:\Program Files\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <modul
e>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_i
mport_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Program Files\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_i
mport_helper
    return importlib.import_module(mname)
  File ""C:\Program Files\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 978, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 950, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 648, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 560, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <modul
e>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_i
mport_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Program Files\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Any help is greatly appreciated!

Frank",0,,6,2017-09-20T20:32:28Z,NONE
13188,third_party/zlib: use -DZ_HAVE_UNISTD_H instead of suppressing warnings,"stat:awaiting response,type:build/install","Hi,

I noticed that you built zlib by suppressing warnings about it using undeclared functions. However, I discovered that adding `copts = [""-DZ_HAVE_UNISTD_H""]` could make zlib to include unistd.h and therefore get rid of the warnings completely.

While this change is very minor, I think declaring the macro is better than suppressing the warnings.",0,,4,2017-09-20T15:29:02Z,CONTRIBUTOR
13187,parse_example is awfully slow,"stat:awaiting response,type:bug/performance","@skearnes
you have indicated in this post of yours https://github.com/tensorflow/tensorflow/issues/390 way back in 2015 that parse_example is about 30 times faster than parse_single_example.
I have tried different options to modify my simple training script which only prints about 100000 tfrecords batched in 1000 and just does a print of feature and label after session.run(feature, label). Feature is a sparseTensor BTW.
Can you please put a test sample which proved that parse_example was that fast. parse_single_example was taking ~320 secs, now parse_example takes ~240 secs.

@Admin, please do not close this issue and refer to stackoverflow, as I don't think this is something to do with API usage or wrong parameters.
This is to do with the performance of queues (enqueue, dequeue) & threads",0,,12,2017-09-20T15:20:07Z,NONE
13176,Raspberry Pi Makefile issues with proto_text,"stat:contributions welcome,type:build/install","### System information
- **Raspberry Pi on Ubuntu Mate 16.04 (Also tried Raspbian Stretch but GUI would freeze a lot and still gave similar errors)**:

### Describe the problem
Building tensorflow from source using makefile using the code provided at: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile. I've included two log files in which i ran the initial setup and ran into a zlib.h error which i resolved by running 'sudo apt-get install libz-dev' but then re-run the last make-f line which gave me another error.

### Error:

```
/home/sensor1/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/env.o: In function `tensorflow::mutex::mutex()':
env.cc:(.text._ZN10tensorflow5mutexC2Ev[_ZN10tensorflow5mutexC5Ev]+0xc): undefined reference to `nsync::nsync_mu_init(nsync::nsync_mu_s_*)'
/home/sensor1/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/env.o: In function `tensorflow::mutex::lock()':
env.cc:(.text._ZN10tensorflow5mutex4lockEv[_ZN10tensorflow5mutex4lockEv]+0xc): undefined reference to `nsync::nsync_mu_lock(nsync::nsync_mu_s_*)'
/home/sensor1/tensorflow/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/platform/env.o: In function `tensorflow::mutex::unlock()':
env.cc:(.text._ZN10tensorflow5mutex6unlockEv[_ZN10tensorflow5mutex6unlockEv]+0xc): undefined reference to `nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)'
collect2: error: ld returned 1 exit status
tensorflow/contrib/makefile/Makefile:632: recipe for target '/home/sensor1/tensorflow/tensorflow/contrib/makefile/gen/host_bin/proto_text' failed
make: *** [/home/sensor1/tensorflow/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1
```

### Logs
Output file 1 (initial run, stopped at zlib error):  https://pastebin.com/dmqWYAs6
Output file 2 (current error after fixing zlib error):  https://pastebin.com/aE51br80

#### What I've tried
Looked at similar issues but they were related to iOS and didn't make sense to me. 
",0,,11,2017-09-20T08:22:55Z,NONE
13169,nightly-devel-gpu Docker broken with ImportError: libcuda.so.1: cannot open shared object file,stat:awaiting tensorflower,"To reproduce:
sudo docker run -it --name t2 tensorflow/tensorflow:nightly-devel-gpu
python -c ""import tensorflow""

It's looking for libcuda.so.1, but I can't find that file in the image
Furthermore, LD_LIBRARY_PATH is pointing to /usr/local/nvidia/lib64 but there's no such folder. There's /usr/local/cuda/lib64, but no libcuda.so.1 there either (should it be loading libcudart.so.8.0 instead?)

cc @craigcitro ",1,,4,2017-09-19T22:59:04Z,CONTRIBUTOR
13164,BUG: No GPU kernel for tf.scatter_nd and tf.gather_nd with int32 or int64 tensors,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
binary (pip)
- **TensorFlow version (use command below)**:
v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 
Python 3.5.2
- **Bazel version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
CUDA-8.0 / cuDNN-5.1
- **GPU model and memory**:
NVidia GeForce GTX TITAN with 5.93GiB
- **Exact command to reproduce**:
```
import tensorflow as tf
import numpy as np

val_num = 5
val_dim = 2

with tf.device(""/gpu:0""):
    indices = tf.reshape(tf.range(val_num, dtype=tf.int64), [-1, 1])
    updates = tf.constant(np.tile(np.expand_dims(np.arange(val_num, dtype=np.int64), 1), [1, val_dim]))

    res = tf.scatter_nd(indices, updates, [val_num, val_dim])
    #res = tf.gather_nd(updates, indices)

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    print(sess.run(res))
```

### Describe the problem
**tf.scatter_nd** and **tf.gather_nd** do not support **int32** or **int64** tensors on GPU.

### Source code / logs
tf.scatter_nd:
```
2017-09-19 22:33:55.447883: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-19 22:33:55.447965: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-19 22:33:55.649706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-09-19 22:33:55.650199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX TITAN
major: 3 minor: 5 memoryClockRate (GHz) 0.8755
pciBusID 0000:04:00.0
Total memory: 5.93GiB
Free memory: 5.63GiB
2017-09-19 22:33:55.650286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-09-19 22:33:55.650299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-09-19 22:33:55.650316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:04:00.0)
Traceback (most recent call last):
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1327, in _do_call
    return fn(*args)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1297, in _run_fn
    self._extend_graph()
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1358, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'ScatterNd': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: ScatterNd = ScatterNd[T=DT_INT64, Tindices=DT_INT64, _device=""/device:GPU:0""](Reshape, Const, ScatterNd/shape)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bug.py"", line 15, in <module>
    sess.run(tf.global_variables_initializer())
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'ScatterNd': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: ScatterNd = ScatterNd[T=DT_INT64, Tindices=DT_INT64, _device=""/device:GPU:0""](Reshape, Const, ScatterNd/shape)]]

Caused by op 'ScatterNd', defined at:
  File ""bug.py"", line 11, in <module>
    res = tf.scatter_nd(indices, updates, [val_num, val_dim])
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2961, in scatter_nd
    shape=shape, name=name)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'ScatterNd': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: ScatterNd = ScatterNd[T=DT_INT64, Tindices=DT_INT64, _device=""/device:GPU:0""](Reshape, Const, ScatterNd/shape)]]

```

tf.gather_nd:
```
2017-09-19 22:34:26.298344: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-19 22:34:26.298436: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-19 22:34:26.504483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-09-19 22:34:26.504948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX TITAN
major: 3 minor: 5 memoryClockRate (GHz) 0.8755
pciBusID 0000:04:00.0
Total memory: 5.93GiB
Free memory: 5.61GiB
2017-09-19 22:34:26.505032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-09-19 22:34:26.505044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-09-19 22:34:26.505061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:04:00.0)
Traceback (most recent call last):
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1327, in _do_call
    return fn(*args)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1297, in _run_fn
    self._extend_graph()
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1358, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'GatherNd': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: GatherNd = GatherNd[Tindices=DT_INT64, Tparams=DT_INT64, _device=""/device:GPU:0""](Const, Reshape)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bug.py"", line 15, in <module>
    sess.run(tf.global_variables_initializer())
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'GatherNd': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: GatherNd = GatherNd[Tindices=DT_INT64, Tparams=DT_INT64, _device=""/device:GPU:0""](Const, Reshape)]]

Caused by op 'GatherNd', defined at:
  File ""bug.py"", line 12, in <module>
    res = tf.gather_nd(updates, indices)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1338, in gather_nd
    name=name)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/daniyar/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'GatherNd': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: GatherNd = GatherNd[Tindices=DT_INT64, Tparams=DT_INT64, _device=""/device:GPU:0""](Const, Reshape)]]

```",0,,10,2017-09-19T21:33:56Z,CONTRIBUTOR
13160,[feature request]recomputable operation annotation,type:feature,"'Training Deep Nets with Sublinear Memory Cost' and 'Memory-Efficient Implementation of DenseNets' indicate that use drop intermediate feature map and recompute it if needed can save memory(while add computation burden),

so we need some mechanism to annotate some op's inputs  `recomputable` , and drop this input memory after op finish(set input's reference count to 0), when need this op again, recompute it.

```python
a = tf.get_varible(shape=[None,10])
b = tf.get_varible(shape=[None,10])
c = tf.get_varible(shape=[None,10])
d = a*b
d_recomputable = tf.recomputable(d)
e = d_recomputable+c
```
relate issue 
- https://github.com/tensorflow/tensorflow/issues/1934
- https://github.com/tensorflow/tensorflow/issues/12948

in short, normal reference add reference count, recomputable reference do not add reference count
",1,,11,2017-09-19T17:17:57Z,NONE
13154,BeamSearchDecoder should support an AttentionWrapper cell with alignment_history enabled,,"### System information
- **Have I written custom code**: yes
- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.3.0
- **Python version**: 2.7
- **Exact command to reproduce**: see the code snippet below.

### Describe the problem

Currently, setting `tf.contrib.seq2seq.AttentionWrapper`'s `alignment_history` argument to `True` and using this cell in a `tf.contrib.seq2seq.BeamSearchDecoder` does not work for 2 reasons:

1. In this configuration, the `tf.contrib.seq2seq.AttentionWrapper.state_size` property is invalid as it does not have the same structure as `zero_state` (see the code below). The [decoder state initialization](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L193) is failing because of this.
2. `tf.contrib.seq2seq.BeamSearchDecoder` [raises an error](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L123) when the state contains a `TensorArray`, which is the type currently used to gather alignments.

I believe this configuration should be supported as it is a standard use case for sequence to sequence models.

To address both of these limitations, it seems this `alignment_history` could be a `Tensor` on which alignments are repeatedly concatenated. Would it work?

### Source code / logs

This code sample reproduces 1. which is the error directly visible when using this configuration.

```python
import tensorflow as tf

batch_size = 2
num_units = 10

memory = tf.placeholder(tf.float32, shape=(None, None, num_units))

attention_mechanism = tf.contrib.seq2seq.LuongAttention(
  num_units,
  memory)

cell = tf.contrib.seq2seq.AttentionWrapper(
  tf.contrib.rnn.LSTMCell(num_units),
  attention_mechanism,
  alignment_history=True) # Set this to False to make it work.

tf.contrib.framework.nest.assert_same_structure(
  cell.zero_state(batch_size, dtype=tf.float32),
  cell.state_size)
```

It exits with this error:

```text
Traceback (most recent call last):
  File ""<file>"", line 19, in <module>
    cell.state_size)
  File ""<dir>/local/lib/python2.7/site-packages/tensorflow/python/util/nest.py"", line 199, in assert_same_structure
    % (len_nest1, nest1, len_nest2, nest2))
ValueError: The two structures don't have the same number of elements.

First structure (6 elements): AttentionWrapperState(cell_state=LSTMStateTuple(c=<tf.Tensor 'AttentionWrapperZeroState/checked_cell_state:0' shape=(2, 10) dtype=float32>, h=<tf.Tensor 'AttentionWrapperZeroState/checked_cell_state_1:0' shape=(2, 10) dtype=float32>), attention=<tf.Tensor 'AttentionWrapperZeroState/zeros_1:0' shape=(2, 10) dtype=float32>, time=<tf.Tensor 'AttentionWrapperZeroState/zeros:0' shape=() dtype=int32>, alignments=<tf.Tensor 'AttentionWrapperZeroState/zeros_2:0' shape=(2, ?) dtype=float32>, alignment_history=<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fbd6326ec50>)

Second structure (5 elements): AttentionWrapperState(cell_state=LSTMStateTuple(c=10, h=10), attention=10, time=TensorShape([]), alignments=<tf.Tensor 'LuongAttention/strided_slice_2:0' shape=() dtype=int32>, alignment_history=())
```",1,,8,2017-09-19T13:51:06Z,CONTRIBUTOR
13150,Handling of * in pattern of tf.contrib.data.Dataset.list_files undocumented,"stat:awaiting tensorflower,type:docs","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (see below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: GTX 1080, 8GB
- **Exact command to reproduce**: run the script

### Describe the problem
It seems that by default `list_files`' behaviour when a pattern contains `*`s is to match files at any depth in the directory tree. This is in contrast, for example, with `glob`'s default behaviour.
I could not find any mention of how `*` is evaluated in [its documentation](https://www.tensorflow.org/api_docs/python/tf/contrib/data/Dataset#list_files) or any examples of its usage in the [pogrammer's guide](https://www.tensorflow.org/programmers_guide/datasets).
Could the documentation be improved specifying how exactly `*`s are handled?

### Source code / logs
Sample dataset structure on filesystem:

```
DATASET_ROOT
    _should_be_ignored
        class3
            subclass31
                sample.txt
            subclass32
                sample.txt
        class4
            subclass41
                sample.txt
            subclass42
                sample.txt
    class1
        subclass11
            sample.txt
        subclass12
            sample.txt
    class2
        subclass21
            sample.txt
        subclass22
            sample.txt
```

Small script to test the behaviour:

```
import tensorflow as tf
import glob

ROOT = 'C:/Users/1/Desktop/test_dataset'
glob_files = glob.glob('{}/*/*/*.txt'.format(ROOT))

dataset = tf.contrib.data.Dataset.list_files('{}/*/*/*.txt'.format(ROOT))
it = dataset.make_one_shot_iterator()

files_found = []
with tf.Session() as sess:
  while True:
    try:
      files_found.append(sess.run(it.get_next()))
    except tf.errors.OutOfRangeError:
      break
```

Outputs:
```
glob_files
Out[16]: 
['C:/Users/1/Desktop/test_dataset\\class1\\subclass11\\sample.txt',
 'C:/Users/1/Desktop/test_dataset\\class1\\subclass12\\sample.txt',
 'C:/Users/1/Desktop/test_dataset\\class2\\subclass21\\sample.txt',
 'C:/Users/1/Desktop/test_dataset\\class2\\subclass22\\sample.txt']

files_found
Out[4]: 
[b'C:\\Users\\1\\Desktop\\test_dataset\\class1\\subclass11\\sample.txt',
 b'C:\\Users\\1\\Desktop\\test_dataset\\class1\\subclass12\\sample.txt',
 b'C:\\Users\\1\\Desktop\\test_dataset\\class2\\subclass21\\sample.txt',
 b'C:\\Users\\1\\Desktop\\test_dataset\\class2\\subclass22\\sample.txt',
 b'C:\\Users\\1\\Desktop\\test_dataset\\_should_be_ignored\\class3\\subclass31\\sample.txt',
 b'C:\\Users\\1\\Desktop\\test_dataset\\_should_be_ignored\\class3\\subclass32\\sample.txt',
 b'C:\\Users\\1\\Desktop\\test_dataset\\_should_be_ignored\\class4\\subclass41\\sample.txt',
 b'C:\\Users\\1\\Desktop\\test_dataset\\_should_be_ignored\\class4\\subclass42\\sample.txt']
```
",1,,5,2017-09-19T10:49:38Z,NONE
13126,installing tensorflow to a local folder results in import error with realtive paths,stat:contributions welcome,"this is on linux with python 3.6.2 and tf 1.3
i install tensorflow into a folder named 'site-packages' inside my project. i then add it to the path with a relative reference. works fine when path is absolute

pip install tensorflow -t site-packages
python
import sys
sys.path.insert(1,""site-packages"") # will fail
#sys.path.insert(1,""/home/absolute_path/site-packages"") #works
from tensorflow.contrib.framework.python.ops.checkpoint_ops import *
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""site-packages/tensorflow/contrib/framework/python/ops/__init__.py"", line 24, in <module>
    from tensorflow.contrib.framework.python.ops.checkpoint_ops import *
  File ""site-packages/tensorflow/contrib/framework/python/ops/checkpoint_ops.py"", line 32, in <module>
    resource_loader.get_path_to_datafile(""_checkpoint_ops.so""))
  File ""site-packages/tensorflow/contrib/util/loader.py"", line 55, in load_op_library
    ret = load_library.load_op_library(path)
  File ""site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: site-packages/tensorflow/contrib/util/site-packages/tensorflow/contrib/framework/python/ops/_checkpoint_ops.so: cannot open shared object file: No such file or directory
",0,,12,2017-09-18T13:10:51Z,NONE
13124,tensorflow.python.debug.cli.offline_analyzer failed to read debug data from HDFS filesys,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.2 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3.0 from master branch
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: null
- **GPU model and memory**: null
- **Exact command to reproduce**: python -m tensorflow.python.debug.cli.offline_analyzer --dump_dir=hdfs://<debug_data_dir>

### Issue description
I saved debug data by `DumpingDebugHook` into hdfs filesys and then it failed to read the data by `python -m tensorflow.python.debug.cli.offline_analyzer --dump_dir=hdfs://<debug_data_path>` with the error ""not a valid DFS filename"" as Invalid argument. But it works well for the local filesys by the same way.

#### Error info:
```
# python -m tensorflow.python.debug.cli.offline_analyzer --dump_dir=hdfs://gpu1.hs.na61.tbsite.net:9000/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100
tfdbg offline: FLAGS.dump_dir = hdfs://gpu1.hs.na61.tbsite.net:9000/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.3/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.3/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
^@hdfsOpenFile(/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/hdfs://gpu1.hs.na61.tbsite.net:9000/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/_tfdbg_graph_hash3076817912156706527_1505733016027244): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream;) error:
java.lang.IllegalArgumentException: Pathname /data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/hdfs:/gpu1.hs.na61.tbsite.net:9000/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/_tfdbg_graph_hash3076817912156706527_1505733016027244 from /data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/hdfs:/gpu1.hs.na61.tbsite.net:9000/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/_tfdbg_graph_hash3076817912156706527_1505733016027244 is not a valid DFS filename.
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:197)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:303)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:299)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:299)
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/cli/offline_analyzer.py"", line 78, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/cli/offline_analyzer.py"", line 41, in main
    FLAGS.dump_dir, validate=FLAGS.validate_graph)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 692, in __init__
    self._load_all_device_dumps(partition_graphs, validate)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 714, in _load_all_device_dumps
    self._load_partition_graphs(partition_graphs, validate)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 983, in _load_partition_graphs
    self._dump_graph_file_paths[device_name])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 145, in _load_graph_def_from_event_file
    event.ParseFromString(f.read())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 119, in read
    self._preread_check()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 79, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    c_api.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: hdfs://gpu1.hs.na61.tbsite.net:9000/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/hdfs://gpu1.hs.na61.tbsite.net:9000/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/_tfdbg_graph_hash3076817912156706527_1505733016027244; Invalid argument
```

In fact, it was able to read the hdfs dir info, as below:

```
$hdfs dfs -ls hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0
Found 7 items
-rw-r--r--   3 root supergroup     141732 2017-09-18 19:10 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/_tfdbg_graph_hash3076817912156706527_1505733016027244
drwxr-xr-x   - root supergroup          0 2017-09-18 19:10 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/gradients
drwxr-xr-x   - root supergroup          0 2017-09-18 19:10 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/layer_1
drwxr-xr-x   - root supergroup          0 2017-09-18 19:10 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/layer_2
drwxr-xr-x   - root supergroup          0 2017-09-18 19:10 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/layer_out
drwxr-xr-x   - root supergroup          0 2017-09-18 19:10 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/loss
drwxr-xr-x   - root supergroup          0 2017-09-18 19:10 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505733015456409_100/_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0/train
```

After that, I tried to change the name of the dir as above from `_tfdbg_device_,job_localhost,replica_0,task_0,cpu_0` to `_tfdbg_device`, and then it was able to load the dir into CLI UI for debug, but there was nothing about debug info to show, as below:

![image](https://user-images.githubusercontent.com/28526467/30541641-dc4329d2-9cae-11e7-8e07-c84dd1a3a7a3.png)
",1,,7,2017-09-18T12:21:45Z,NONE
13104,Fix tf.argmax/argmin documentation,type:docs,"https://www.tensorflow.org/api_docs/python/tf/argmax

- The documentation does not explain what an ""index"" is. I can imagine a billion definitions of ""index"". Is it the same as the ""index"" in tf.one_hot?
- The documentation does not explain what happens if axis is set to None.
- ""For vectors, use axis = 0."": Why?
- The documentation should clearly explain how the rank+shape of the returned tensor correlates with the rank+shape of the input tensor.
- The documentation incorrectly indicates that there is a guide if you click ""See the guide"", but it takes you to a function reference/index. A redundant 3 sentence description is not a ""guide"".

",2,,5,2017-09-17T21:49:18Z,NONE
13103,Dropout hidden-to-hidden transition within an RNN,"stat:awaiting tensorflower,type:feature","`DropoutWrapper` allows to apply dropout to either the cell's inputs, outputs or states. However, I haven't seen an option to do the same thing for the recurrent weights of the cell (for example, 4 out of the 8 different matrices used in the original LSTM formulation). I specifically refer to the hidden-to-hidden transition within an RNN. Take as an example Section 2 from https://arxiv.org/abs/1708.02182",0,,4,2017-09-17T20:19:42Z,NONE
13101,from_generator feedback and questions,,"@mrry, thank you for implementing the `from_generator` method in `tf.data`. I just wanted to provide some feedback and ask a few more questions.

# Interface

In addition to having `generator` be a callable that returns an iterator, would it be possible to support iterators that aren't wrapped in a callable? E.g. instead of 

```python
pool = multiprocessing.Pool()
dataset = tf.contrib.data.Dataset.from_generator(
    lambda: pool.imap(some_function, some_data), dtypes, shapes
)
```

also support

```python
pool = multiprocessing.Pool()
dataset = tf.contrib.data.Dataset.from_generator(
    pool.imap(some_function, some_data), dtypes, shapes
)
```

# Return types

`from_generator` does not seem to support unpacking numpy arrays at the moment. I don't think it's essential but would be a nice-to-have. E.g. this fails

```python
def generator():
    while True:
        yield np.zeros(2, np.float32)
        
dataset = tf.contrib.data.Dataset.from_generator(generator, (tf.float32, tf.float32))
x, y = dataset.make_one_shot_iterator().get_next()
session = tf.Session()
session.run([x, y])
```

but this runs smoothly

```python
def generator():
    while True:
        yield tuple(np.zeros(2, np.float32))
        
dataset = tf.contrib.data.Dataset.from_generator(generator, (tf.float32, tf.float32))
x, y = dataset.make_one_shot_iterator().get_next()
session = tf.Session()
session.run([x, y])
```

# Performance

I've played around with a *very* naive example using the generator API (in the hope to eventually leverage ipyparallel or some other distributed computing framework). Unfortunately, I can't achieve the same performance that I would get using `feed_dicts`. The setup is as follows

```python
import tensorflow as tf
from tensorflow.contrib import data as tfdata
import numpy as np
from time import time

num_batches = 1000
batch_size = 100

class Generator:
    def __init__(self):
        self.times = []
    
    def __iter__(self):
        while True:
            x = np.random.normal()
            y = 3 + 5 * x
            x, y = np.asarray([x, y], np.float32)
            self.times.append(time())
            yield x, y

generator_state1 = Generator()

dataset = tfdata.Dataset.from_generator(
    lambda: generator_state1, 
    (tf.float32, tf.float32),
    (tf.TensorShape([]), tf.TensorShape([]))
)
prefetched = dataset.prefetch(3 * batch_size)
batches = prefetched.batch(batch_size)
iterator = batches.make_one_shot_iterator()

x, y = iterator.get_next()

w = tf.Variable([0, 0], dtype=tf.float32)
prediction = w[0] + w[1] * x
loss = tf.losses.mean_squared_error(y, prediction)
optimizer = tf.train.AdamOptimizer(0.1)
train_op = optimizer.minimize(loss)
init_op = tf.global_variables_initializer()

session = tf.Session()
session.run(init_op)
```

Running the optimisation gives me

```python
losses = []

start = time()
for _ in range(num_batches):
    _, _loss = session.run([train_op, loss])
    losses.append(_loss)
time() - start  # about seven seconds
```

Doing the same using feed_dicts gives

```python
losses = []

generator_state2 = Generator()
iterator = iter(generator_state2)

start = time()
for _ in range(num_batches):
    _x, _y = np.transpose([next(iterator) for _ in range(batch_size)])
    _, _loss = session.run([train_op, loss], {x: _x, y: _y})
    losses.append(_loss)
time() - start  # about one second
```

It seems that the dataset created using the `from_generator` method isn't fetching from the generator fast enough:

```python
np.mean(np.diff(generator_state1.times))  # 7.1533812683949508e-05
np.mean(np.diff(generator_state2.times))  # 1.0633696558370612e-05
```

Thanks again for this, and looking forward to hearing your thoughts.",1,,36,2017-09-17T16:25:38Z,CONTRIBUTOR
13097,Support 64bit float point gradient,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.1.0
- **Python version**:  3.5.3
- **CUDA/cuDNN version**:Cuda 8.0 cudnn 5.1
- **GPU model and memory**:GTX 1080Ti 11GB

### Describe the problem
I use Tensorflow to train a multilayer Convolutional network.

Since my network has too many parameters and my GTX 1080Ti has limited memory(11GB), so the batch size cannot exceed 16 otherwise it would cause OutOfMemory exception.

I want to update parameters using bigger batch size, so I follow [the answer](https://stackoverflow.com/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients) that is, accumulate and average gradients over multiple batches.

**Scenario 1**

If I use batch size=16, and update parameters after each batch, my network can converge to loss=0.01.

**Scenario 2**

If I use batch size=1, and update parameters after accumulating and averaging gradients after every 16 batches, my network can only converge to loss=0.04.

Theoreticall the two scenarios should converge to the same loss, but the problem is when the network converge close to the extrema, the magnitude of the gradients is about 1e-5.

And guess how precise is float32 in Tensorflow? I compute gradients and don't update parameters, they differ after 6 significant digits.

I want my network continues to converge even the magnitude of the gradients is about 1e-5, the float32 cannot satisfy my needs.

The obvious solution is to use float64 as the data type of the parameters, but Tensorflow tells me float64 is not supported in Conv2D.",0,,6,2017-09-17T08:50:30Z,NONE
13096,No OpKernel was registered to support Op 'QuantizeV2',stat:community support,"I was able to build tf 1.3 quantize_graph on windows 10 64 using bazel 0.53 and cuda 8 (i could not build it without cuda). when i try to run it i get:
No OpKernel was registered to support Op 'QuantizeV2' with these attrs.


bazel-bin\tensorflow\tools\quantization\quantize_graph --input d:/export/saved_model.pb --output_node_names my_output --output d:/export/saved_model_quant.pb --mode=eightbit

2017-09-17 10:48:28.292364: W C:\tools\msys64\tmp\_bazel_user\8rsmy-kr\execroot\org_tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-09-17 10:48:28.292529: W C:\tools\msys64\tmp\_bazel_user\8rsmy-kr\execroot\org_tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
Traceback (most recent call last):
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\client\session.py"", line 1327, in _do_call
    return fn(*args)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\client\session.py"", line 1297, in _run_fn
    self._extend_graph()
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\client\session.py"", line 1358, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""C:\Anaconda3\lib\contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'QuantizeV2' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

         [[Node: QuantizeV2 = QuantizeV2[T=DT_QUINT8, mode=""MIN_FIRST""](QuantizeV2/input, QuantizeV2/min_range, QuantizeV2/max_range)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 1301, in <module>
    app.run()
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 1292, in main
    output_graph = rewriter.rewrite(FLAGS.output_node_names.split("",""))
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 420, in rewrite
    self.eightbitize_nodes_recursively(output_node)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 600, in eightbitize_nodes_recursively
    self.eightbitize_nodes_recursively(input_node)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 600, in eightbitize_nodes_recursively
    self.eightbitize_nodes_recursively(input_node)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 600, in eightbitize_nodes_recursively
    self.eightbitize_nodes_recursively(input_node)
  [Previous line repeated 90 more times]
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 632, in eightbitize_nodes_recursively
    for n in quantize_weight_eightbit(current_node, b""MIN_FIRST""):
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 299, in quantize_weight_eightbit
    quint8_tensor = quantize_op[0].eval()
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\framework\ops.py"", line 541, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\framework\ops.py"", line 4085, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\client\session.py"", line 895, in run
    run_metadata_ptr)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\client\session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\client\session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\client\session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'QuantizeV2' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

         [[Node: QuantizeV2 = QuantizeV2[T=DT_QUINT8, mode=""MIN_FIRST""](QuantizeV2/input, QuantizeV2/min_range, QuantizeV2/max_range)]]

Caused by op 'QuantizeV2', defined at:
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 1301, in <module>
    app.run()
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 1292, in main
    output_graph = rewriter.rewrite(FLAGS.output_node_names.split("",""))
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 420, in rewrite
    self.eightbitize_nodes_recursively(output_node)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 600, in eightbitize_nodes_recursively
    self.eightbitize_nodes_recursively(input_node)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 600, in eightbitize_nodes_recursively
    self.eightbitize_nodes_recursively(input_node)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 600, in eightbitize_nodes_recursively
    self.eightbitize_nodes_recursively(input_node)
  [Previous line repeated 90 more times]
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 632, in eightbitize_nodes_recursively
    for n in quantize_weight_eightbit(current_node, b""MIN_FIRST""):
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\tools\quantization\quantize_graph.py"", line 298, in quantize_weight_eightbit
    mode=quantization_mode)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\ops\gen_array_ops.py"", line 2381, in quantize_v2
    mode=mode, name=name)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\framework\ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""\\?\C:\Users\user\AppData\Local\Temp\Bazel.runfiles_5goewho4\runfiles\org_tensorflow\tensorflow\python\framework\ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'QuantizeV2' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

         [[Node: QuantizeV2 = QuantizeV2[T=DT_QUINT8, mode=""MIN_FIRST""](QuantizeV2/input, QuantizeV2/min_range, QuantizeV2/max_range)]]
",0,,2,2017-09-17T08:06:29Z,NONE
13094,Feature Request - SRU (Simple Recurrent Unit) Cell,"stat:contributions welcome,type:feature","ArXiv path: https://arxiv.org/abs/1709.02755

This is a recently proposed, parallelization-friendly RNN cell. The author released his own PyTorch version of the SRU. We are looking forward to an offical tensorflow implementation with Cudnn optimizations. ",0,,8,2017-09-17T06:30:54Z,NONE
13079,saved model load method support for android,"stat:contributions welcome,type:feature","I am trying load a saved model on android with java api.

 Session session = SavedModelBundle.load(modelDir, ""serve"").session();


Its works on PC. But on android i  got this error message.

E/tensorflow: CameraActivity: Exception!
                                                                 java.lang.UnsupportedOperationException: Loading a SavedModel is not supported in Android. File a bug at https://github.com/tensorflow/tensorflow/issues if this feature is important to you
                                                                     at org.tensorflow.SavedModelBundle.load(Native Method) 
my reference model for training procedure is  tf estimator for iris data.
https://www.tensorflow.org/get_started/estimator

",0,,5,2017-09-16T06:33:19Z,NONE
13069,Get stuck in the process of building from sources,"stat:awaiting response,type:build/install","## System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 LTS
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 1.3 CPU
Bazel version (if compiling from source): 5.0
Exact command to reproduce: 

`
RUN tensorflow/tools/ci_build/builds/configured CPU \
    bazel build -c opt --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" \
        tensorflow/tools/pip_package:build_pip_package && \
    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \
    pip --no-cache-dir install --upgrade /tmp/pip/tensorflow-*.whl 
`



## Describe the problem

I tried to build a docker image using the dockerfile provided by tensorflow repository, but every time I faced with the problem it got stuck in the process, repeating the output 

`
____[2,615 / 3,437] Still waiting for 2 jobs to complete:
      Running (standalone):
        Compiling tensorflow/core/kernels/matrix_solve_ls_op.cc, 851 s
        Compiling tensorflow/core/kernels/svd_op_double.cc, 839 s
____[2,615 / 3,437] Still waiting for 2 jobs to complete:
`


The following is the first output of this layer which may be helpful.

`
Extracting Bazel installation...
You have bazel 0.5.0 installed.
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]
Using python library path: /usr/local/lib/python2.7/dist-packages
No MKL support will be enabled for TensorFlow
jemalloc enabled
No VERBS support will be enabled for TensorFlow
No OpenCL support will be enabled for TensorFlow
MPI support will not be enabled for TensorFlow
Configuration finished
/tensorflow
INFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch
TF_BUILD_INFO = {container_type: ""cpu"", command: ""bazel build -c opt --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 tensorfl
s/pip_package:build_pip_package"", source_HEAD: ""b46340f40fe5e2ec9bfcd385b07cfb914055fb51"", source_remote_origin:
//github.com/tensorflow/tensorflow.git"", OS: ""Linux"", kernel: ""4.9.41-moby"", architecture: ""x86_64"", processor: ""
5550M APU with Radeon(tm) HD Graphics"", processor_count: ""2"", memory_total: ""2027780 kB"", swap_total: ""1048572 kB
l_version: ""Build label: 0.5.0"", Java_version: ""1.8.0_131"", Python_version: ""2.7.12"", gpp_version: ""g++ (Ubuntu 5
buntu1~16.04.5) 5.4.0 20160609"", swig_version: """", NVIDIA_driver_version: """", CUDA_device_count: ""0"", CUDA_device
 """", CUDA_toolkit_version: """"}
`",0,,9,2017-09-15T19:48:45Z,NONE
13068,cuDNN 6 incompatible with Tensorflow 1.3 error,"stat:awaiting response,type:build/install","Any help is greatly appreciated! I've spent way too much time on this. 

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
In tensorflow/stream_executor/cuda/cuda_gpu_executor.cc in function ""static int TryToReadNumaNode(conststring &pci_bus_id,intdevice_ordinal)"" added the following lines at the beginning of the function:
LOG(INFO) << ""ARM has no NUMA node, hardcoding to return zero"";
return 0;
modified workspace.bzl: set eigen_archive to use http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/d781c1de9834.tar.gz because of an error that kept coming up related to the current version of eigen.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
 Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
source

- **TensorFlow version (use command below)**:
1.3.0
command used: git checkout v1.3.0

- **Python version**: 
2.7

- **Bazel version (if compiling from source)**:
0.4.5

- **CUDA/cuDNN version**:
CUDA version 8.0, CUDNN version 6.0.21
cudnn was downloaded from the NVIDIA website using the cuDNN v6.0 Library for Linux version

- **GPU model and memory**:
NVIDIA Pascal GPU on the TX2

- **Exact command to reproduce**:
sudo bazel build -c opt --local_resources 3072,4.0,1.0 --verbose_failures --config=cuda //tensorflow/tools/pip_package:build_pip_package

- **Other*:
Using an 8GB swapfile
CUDA install path: usr/local/cuda/
CUDNN install paths:
     include: /usr/include/
     libs: /usr/lib/aarch64-linux-gnu/
     I used the following command on the libs: sudo chmod a+r /usr/lib/aarch64-linux-gnu/libcudnn*


### Describe the problem
When I try to install tensorflow 1.3.0 I get the error listed below. It goes through pretty much the entire build and fails at the very end. Tensorflow 1.0 installs just fine on the TX2 using cuda 8 and cudnn 5.1(these lib are no longer on my machine so its not an issue with having 5.1 installed). I would use Tensoflow 1.0, but the network I am working with has a reliance on 1.3. 

### Source code / logs
IERROR: /home/nvidia/tensorflow/tensorflow/python/BUILD:2762:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command 
  (cd /home/nvidia/.cache/bazel/_bazel_root/d2751a49dacf4cb14a513ec663770624/execroot/tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=6.2 \
    TF_CUDA_VERSION=8.0 \
    TF_CUDNN_VERSION=6.0.21 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL=0 \
  external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' -Wl,--version-script tensorflow/tf_version_script.lds -Wl,-z,muldefs -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -pthread -Wl,-no-as-needed -B/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: skipping incompatible bazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: skipping incompatible bazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: skipping incompatible /usr/lib/gcc/aarch64-linux-gnu/5/../../../aarch64-linux-gnu/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: skipping incompatible /usr/lib/gcc/aarch64-linux-gnu/5/../../../aarch64-linux-gnu/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: skipping incompatible /usr/lib/aarch64-linux-gnu/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: skipping incompatible /usr/lib/aarch64-linux-gnu/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: skipping incompatible //usr/lib/aarch64-linux-gnu/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: skipping incompatible //usr/lib/aarch64-linux-gnu/libcudnn.so.6 when searching for -l:libcudnn.so.6
/usr/bin/ld: cannot find -l:libcudnn.so.6
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 5.977s, Critical Path: 4.15s
",0,,6,2017-09-15T18:27:09Z,NONE
13064,Variance update in tf.contrib.layer.batch_norm,type:feature,"Hi,

In the current implementation of batch norm, the variance to be used for update to moving variance is computed by centering the data around the current mean. The more proper way would be to compute the variance around the moving mean. With the current method, the moving variance will depend upon the batch size. With the updated method, the batch size will have less influence on the moving variance.

Thanks,
Mayank",0,,5,2017-09-15T14:08:26Z,NONE
13061,Proposal: Making the cmake build distribution friendly,stat:contributions welcome,"The following is a proposal, and I don't have it fully working yet, so a Pull Request is too early, and I want to gather some feedback. If an issue is not appropriate, let me know and I will look for a different medium.

### System information

Almost any Linux distribution.

### Describe the problem

Most Linux distributions have similar policies/limitations:

1. Not accepting bundling of system libraries (specially those security-sensitive).
2. Requiring building the whole from source and allowing patching the sources.
3. Requiring building offline (without Internet access).
4. Not having enough manpower to package hundred of packages in a dependency chain just to get packages like maven built in these source-chains environments.

Because of 4., cmake makes things easier. It is a build tool with a few dependencies that does not need complex bootstrapping. Building bazel itself will bring you into the Java maven dependency chain which we already proved in openSUSE to expand into hundred of packages.

Both the bazel and cmake build files do not play well with 1. 2. 3., but cmake already improves 4.

The cmake build files, also pull the sources of different projects. That is because the top `CMakeLists.txt` includes:

```cmake
set(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/external)
```

into the load path.

that external/ directory is full of snippets like:

* `tensorflow/contrib/cmake/external/jpeg.cmake`
* `tensorflow/contrib/cmake/external/gif.cmake`
* ...
* etc

Those snippets use the [external project](https://cmake.org/cmake/help/v3.0/module/ExternalProject.html) cmake api to build directly from git or tarballs upstream. This clashes with
1., 2., 3.

It is a bit sad that things like curl used to be looked up in the system and developers deliberately bundled them without making the cmake snippet first look for it, and if not, configure the bundled one.

### Proposal

The proposal is to make the cmake build support both the Google/Mac user type of build with bundled sources, and the classical Linux distribution build.
This would be a gradual refactoring. Steps could be:

* Add to CMakeLists.txt an option:

```cmake
option(tensorflow_SYSTEM_LIBRARIES ""Use system libraries"" ON)
```

* Replicate the external/ directory as platform/ and conditionally make it use one or the other:

```cmake
if(tensorflow_SYSTEM_LIBRARIES)
 set(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/platform)
else()
  set(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/external)
endif()
```

So that then the part that does:

```cmake
# External dependencies
include(zlib)
include(gif)
include(png)
include(jpeg)
```

would just work...

* Replace incrementaly and one by one the $dep.cmake snippets in `platform/`.

Example with gif.cmake:

Using the standard `/usr/share/cmake/Modules/FindGIF.cmake` included in cmake, which may use `pkg-config` for some modules. The module itself documents it would then set: `GIF_LIBRARIES`, `GIF_INCLUDE_DIR`, etc.

Unfortunately the variable that the original set is called `gif_STATIC_LIBRARIES`, because it assumes it would be static. I think we could fix that later so that naming ends making sense, but lets not focus on that for now.

The `gif.cmake` I cited above would become a simple:

```cmake
find_package(GIF REQUIRED)
# dummy targets other targets depend on.
add_custom_target(gif)
# These can be removed if we fix CMakeLists
add_custom_target(gif_copy_headers_to_destination)

set(gif_STATIC_LIBRARIES ${GIF_LIBRARIES})
set(gif_INCLUDE_DIR ${GIF_INCLUDE_DIR})
```

And that is more or less enough to move forward with this dependency... repeat.
It may need some hacks also in the top level cmake files however...

I think this approach is doable, and could be turned into making the cmake build fully Linux distro enabled upstream. Slowly cleaning the naming, etc, removing these copy_headers targets so that the platform/ version of the .cmake files do not need to create dummy targets, etc.

- Similarly, the sqlite one becomes:

```cmake
find_package(SQLite3)
set(sqlite_STATIC_LIBRARIES ${SQLITE3_LIBRARIES})
set(sqlite_HEADERS ${SQLITE3_INCLUDE_DIR})
add_custom_target(sqlite)
add_custom_target(sqlite_copy_headers_to_destination)
```

With the only difference is that the `Find` module was not included in cmake, so I just copied it into
platform from https://raw.githubusercontent.com/LuaDist/libsqlite3/master/cmake/FindSQLite3.cmake somewhere.

* With this method I have been able to move forward and forward with the build.

### Current blockers

* cmake build does not work out of the box [PR](https://github.com/tensorflow/tensorflow/pull/12734)
* [Issue](https://github.com/tensorflow/tensorflow/issues/12018) with `Missing tensorflow/core/debug/debug_service.grpc.pb.h`

//cc @meaksh @dincamihai @ncounter",0,,17,2017-09-15T10:05:21Z,CONTRIBUTOR
13060,Pyinstaller with Tensorflow takes incorrect path for _checkpoint_ops.so file,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04, Pyinstaller
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7.6
- **CUDA/cuDNN version**: CUDA 8.0 cuDNN 6.0
- **GPU model and memory**: 3x nVidia GEForce 1080

### Describe the problem
As Tensorflow's `load_op_library` finds paths according to the OS it is being run on, I believe this is a problem with Tensorflow in Pyinstaller environment. 

I am trying to make an executable of my Python code which uses Tensorflow . The executable gets generated correctly but when I try to run it, I get the following error:
```

Traceback (most recent call last):
  File ""detection_init.py"", line 14, in <module>
    import lib.tensorboxDetector as tensorboxDetector
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""lib/tensorboxDetector.py"", line 26, in <module>
    from lib.train import build_forward
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""lib/train.py"", line 4, in <module>
    import tensorflow.contrib.slim as slim
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/contrib/__init__.py"", line 22, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/contrib/bayesflow/__init__.py"", line 24, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/contrib/bayesflow/python/ops/csiszar_divergence.py"", line 26, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/contrib/bayesflow/python/ops/csiszar_divergence_impl.py"", line 42, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/contrib/framework/__init__.py"", line 89, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/contrib/framework/python/ops/__init__.py"", line 24, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/PyInstaller/loader/pyimod03_importers.py"", line 396, in load_module
    exec(bytecode, module.__dict__)
  File ""tensorflow/contrib/framework/python/ops/checkpoint_ops.py"", line 32, in <module>
  File ""tensorflow/contrib/util/loader.py"", line 55, in load_op_library
  File ""tensorflow/python/framework/load_library.py"", line 64, in load_op_library
tensorflow.python.framework.errors_impl.NotFoundError: tensorflow/contrib/util/tensorflow/contrib/framework/python/ops/_checkpoint_ops.so: cannot open shared object file: No such file or directory
[11241] Failed to execute script detection_init
```
If we look carefully, Pyinstaller is expecting the file `_checkpoint_ops.so` in directory `tensorflow/contrib/util/tensorflow/contrib/framework/python/ops/` but there's no directory like this. `_checkpoint_ops.so` is located at `tensorflow/contrib/framework/python/ops/`. How can this be fixed?",0,,11,2017-09-15T09:29:05Z,NONE
13044,"Getting assertion failed: [Unable to decode bytes as JPEG, PNG, or GIF] when training using tensorflow object detection api","stat:contributions welcome,type:feature","I tried to use `Tensorflow Object detection API` with my own dataset.   
Everything was working just fine until all of a sudden it crashed with the following error messages :   

    ...
    INFO:tensorflow:global step 10560: loss = 0.4366 (0.809 sec/step)
    INFO:tensorflow:global step 10561: loss = 0.3834 (0.822 sec/step)
    INFO:tensorflow:global step 10562: loss = 0.3611 (0.829 sec/step)
    INFO:tensorflow:global step 10563: loss = 0.3549 (0.901 sec/step)
    INFO:tensorflow:global step 10564: loss = 0.3634 (0.839 sec/step)
    INFO:tensorflow:global step 10565: loss = 0.3396 (0.813 sec/step)
    INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, assertion failed: [Unable to decode bytes as JPEG, PNG, or GIF]
             [[Node: case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert = Assert[T=[DT_STRING], summarize=3, _device=""/job:localhost/replica:0/task:0/cpu:0""](case/If_0/decode_image/cond_jpeg/cond_png/is_gif, case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert/data_0)]]
    INFO:tensorflow:global step 10566: loss = 0.3459 (0.889 sec/step)
    INFO:tensorflow:Finished training! Saving model to disk.
    Traceback (most recent call last):
      File ""train.py"", line 198, in <module>
        tf.app.run()
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
        _sys.exit(main(_sys.argv[:1] + flags_passthrough))
      File ""train.py"", line 194, in main
        worker_job_name, is_chief, FLAGS.train_dir)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\trainer.py"", line 296, in train
        saver=saver)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py"", line 759, in train
        sv.saver.save(sess, sv.save_path, global_step=sv.global_step)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\Lib\contextlib.py"", line 66, in __exit__
        next(self.gen)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\training\supervisor.py"", line 964, in managed_session
        self.stop(close_summary_writer=close_summary_writer)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\training\supervisor.py"", line 792, in stop
        stop_grace_period_secs=self._stop_grace_secs)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\training\coordinator.py"", line 389, in join
        six.reraise(*self._exc_info_to_raise)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\six.py"", line 686, in reraise
        raise value
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\training\queue_runner_impl.py"", line 238, in _run
        enqueue_callable()
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\client\session.py"", line 1063, in _single_operation_run
        target_list_as_strings, status, None)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\Lib\contextlib.py"", line 66, in __exit__
        next(self.gen)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
        pywrap_tensorflow.TF_GetCode(status))
    tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, or GIF]
             [[Node: case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert = Assert[T=[DT_STRING], summarize=3, _device=""/job:localhost/replica:0/task:0/cpu:0""](case/If_0/decode_image/cond_jpeg/cond_png/is_gif, case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert/data_0)]]
    
    G:\Tensorflow_section\models-master\object_detection>

When I upgraded to the `1.3.0`, the error has changed, and  this is what I get now:   

    ...
    INFO:tensorflow:global step 10635: loss = 0.3392 (0.822 sec/step)
    INFO:tensorflow:global step 10636: loss = 0.3529 (0.823 sec/step)
    INFO:tensorflow:global step 10637: loss = 0.3305 (0.831 sec/step)
    2017-09-14 20:02:02.545415: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\framework\op_kernel.cc:1192] Invalid argument: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,240,127,4]
    INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,240,127,4]
             [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batch/padding_fifo_queue, Reshape_2, Shape_5, SparseToDense_1, Shape_2, Merge_1, Shape, Merge_2, Shape_3, SparseToDense_5, Shape_8, SparseToDense_3, Shape_6, Cast_1, Shape_1, Cast_2, Shape_7, ExpandDims_5, Shape_4, Reshape_5, Shape_10, Reshape_6, Shape_9)]]
    INFO:tensorflow:global step 10638: loss = 0.3599 (0.858 sec/step)
    INFO:tensorflow:Finished training! Saving model to disk.
    Traceback (most recent call last):
      File ""train.py"", line 198, in <module>
        tf.app.run()
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
        _sys.exit(main(_sys.argv[:1] + flags_passthrough))
      File ""train.py"", line 194, in main
        worker_job_name, is_chief, FLAGS.train_dir)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\trainer.py"", line 296, in train
        saver=saver)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py"", line 767, in train
        sv.stop(threads, close_summary_writer=True)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\training\supervisor.py"", line 792, in stop
        stop_grace_period_secs=self._stop_grace_secs)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\training\coordinator.py"", line 389, in join
        six.reraise(*self._exc_info_to_raise)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\six.py"", line 686, in reraise
        raise value
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\training\queue_runner_impl.py"", line 238, in _run
        enqueue_callable()
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\client\session.py"", line 1235, in _single_operation_run
        target_list_as_strings, status, None)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\Lib\contextlib.py"", line 66, in __exit__
        next(self.gen)
      File ""C:\Users\Master\Anaconda3\envs\anaconda35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
        pywrap_tensorflow.TF_GetCode(status))
    tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,240,127,4]
             [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batch/padding_fifo_queue, Reshape_2, Shape_5, SparseToDense_1, Shape_2, Merge_1, Shape, Merge_2, Shape_3, SparseToDense_5, Shape_8, SparseToDense_3, Shape_6, Cast_1, Shape_1, Cast_2, Shape_7, ExpandDims_5, Shape_4, Reshape_5, Shape_10, Reshape_6, Shape_9)]]
    
    G:\Tensorflow_section\models-master\object_detection>

I have no idea what is causing the issue, Could this be that some images have wrong extensions? for example, an image which was actually a png with 4 channels, has been saved as a jpg ?!
if this is the case, how to spot the faulty image file? or even better why does not TF use the correct type/number of channels by itself? 
right now, the error is not descriptive enough, it doesn't give any hint which image file is corrupted or is making the problem. 
if the cause of these errors is what I pointed out earlier, then they should be caught when the TF Record is being created. or if TF records are not the only means of inputs, then the same mechanism for knowing the culprit needs to be implemented as well
Anyway, if all my thoughts are wrong, then I would appreciate any help regarding this issue. 
 



### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64 1703, Build 15063.540
- **TensorFlow installed from (source or binary)**:binary (used pip install )
- **TensorFlow version (use command below)**: 1.2.1 and 1.3.0
- **Python version**: 3.5.3(Anaconda)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: Cuda 8.0 /cudnn v5.1 and v6.0 (after upgrading to 1.3.0, cudnnv6.0 is in the PATH)
- **GPU model and memory**: GTX-1080 - 8G
",0,,8,2017-09-14T16:38:45Z,NONE
13039,Reading tfrecord reaches deadock or crushes in one computer and works just fine on another.,stat:contributions welcome,"### Laptop -System information
- Linux Ubuntu 16.04
- TensorFlow installed with pip:
- TensorFlow 1.3.0
- Python 2.7.12
- Spyder 2.3.8

### Workstation -System information
- Linux Ubuntu 16.04
- TensorFlow installed with pip:
- TensorFlow-gpu 1.0.0
- Python 2.7.13

### Problem description
I want to create and read a tfrecord file with [build_cgd_dataset.py](https://github.com/tnikolla/grasp-detection/blob/master/build_cgd_dataset.py) as the writer and [reader_iter.py](https://github.com/tnikolla/grasp-detection/blob/master/reader_iter.py) as the reader. Everything works smooth in the workstation but it reaches a deadlock or gets stuck in the laptop. The dataset are from [Cornell grasping dataset](http://pr.cs.cornell.edu/grasping/rect_data/data.php).

I narrowed down the error in this special cases where it doesn't show any problem, for example:
  - if it reads a int64_list with one value, so a list with one elemnet
  - if it reads a float_list with one element

If the lists have more than one element the program freezes.
",0,,3,2017-09-14T12:42:21Z,NONE
13027,persist nsync.a across different platform builds,"cla: yes,stat:awaiting response","Persist nsync.a across different platform builds via copying them into gen folder, then later make can manage them (clean or something else). nsync.a is required when the built tensorflow static lib is linked by other libs, while currently the nsync.a is cleaned from each build.",1,,19,2017-09-14T02:20:59Z,CONTRIBUTOR
13020,tf.Session() freezes on GPU nodes of a SGE cluster,stat:community support,"Hello,

I'm trying to run the following script on the GPU nodes of my university's SGE cluster:

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys

import tensorflow as tf

var1 = tf.get_variable('var1', [1024, 32], initializer=tf.random_normal_initializer())
var2 = tf.get_variable('var2', [32, 1024], initializer=tf.random_normal_initializer())

m = tf.matmul(var1, var2)

init_op = tf.global_variables_initializer()

with tf.Session() as session:
	session.run(init_op)
	session.run(m)
```

Everything works if, either:
- I allocate obscene amounts of memory, like 60GB, to the job;
- Or if I run it from the command line on the cluster nodes.

However, if I allocate a reasonable amount of memory to the job (8GB), it freezes on the `tf.Session()` call. A `strace -p <pid>` on the process gives the following trace, over and over, endlessly:

```
open(""/proc/self/maps"", O_RDONLY)       = 18
fstat(18, {st_mode=S_IFREG|0444, st_size=0, ...}) = 0
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x2ab462000000
read(18, ""00400000-00634000 r-xp 00000000 ""..., 1024) = 1024
read(18, ""001d000 09:01 1056305           ""..., 1024) = 1024
read(18, ""0 r--p 001b9000 09:01 1583003   ""..., 1024) = 1024
read(18, "" ---p 00041000 09:01 1056331    ""..., 1024) = 1024
read(18, ""b4aa02000-3b4aa03000 rw-p 000020""..., 1024) = 1024
close(18)                               = 0
munmap(0x2ab462000000, 4096)            = 0
mmap(0x36be1200000, 4294967296, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 1103806595072, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 554050781184, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 279172874240, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 141733920768, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 73014444032, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 38654705664, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 21474836480, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 12884901888, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 8589934592, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 6442450944, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 5368709120, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4831838208, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4563402752, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4429185024, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4362076160, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4328521728, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4311744512, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4303355904, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4299161600, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4297064448, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4296015872, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4295491584, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4295229440, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4295098368, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4295032832, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4295000064, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294983680, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294975488, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294971392, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294969344, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294968320, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967808, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967552, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967424, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967360, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967328, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967312, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967304, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967300, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967298, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
mmap(0x36be1200000, 4294967297, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = -1 ENOMEM (Cannot allocate memory)
```

How comes TensorFlow (unsuccessfully) tries to allocate obscene amount of memory when instantiating a new session? It only happens when I run the script as a cluster GPU job, without an obscene amount of memory.

Thank you in advance for all your help.




",0,,7,2017-09-13T17:56:43Z,NONE
13017,tf.extract_image_patches gradient transpose extremely slow,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.6
- **TensorFlow installed from (source or binary)**: Binary, official docker image
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 3.5

### Problem
Backprop through `extract_image_patches` is extremly slow, specifically the `transpose` call. It appears to be this specific call: [tensorflow/python/ops/array_grad.py#L747](https://github.com/tensorflow/tensorflow/blob/f282bb1/tensorflow/python/ops/array_grad.py#L747)

### Logs
Timeline of the problem:

<img width=""1723"" alt=""screen shot 2017-09-13 at 16 01 49"" src=""https://user-images.githubusercontent.com/3015996/30382640-f5a003b8-989f-11e7-871c-1aae1a51102b.png"">

Comparable timeline when using conv2d (which, in its Eigen implementation, also [extracts image patches](https://github.com/tensorflow/tensorflow/blob/f282bb1/tensorflow/core/kernels/eigen_spatial_convolutions.h#L1063-L1064)):
<img width=""1300"" alt=""screen shot 2017-09-13 at 16 08 45"" src=""https://user-images.githubusercontent.com/3015996/30382983-e898d338-98a0-11e7-9e76-1ba01e571c0d.png"">

",0,,9,2017-09-13T14:31:56Z,NONE
13016,Distributed variable initialization never reaches some nodes (affects MonitoredTrainingSession too),,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Multiple affected in different ways, including Linux Ubuntu 16.04.03, Mac OS X 10.12.6, Windows 10 and Bash on Windows 10 running Ubuntu 16.04.03.
- **TensorFlow installed from (source or binary)**: binary, followed the pip install instructions
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 3.5.2, 3.6.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See instructions below.

### Describe the problem
In a distributed environment with 2 nodes (a chief 'foo', a non-chief 'bar') variable initialization performed by foo never reaches bar in some particular distributed combinations. If using MonitoredTrainingSession, this leads to the session in bar never starting (it keeps trying forever every 30 seconds). Further research showed that no matter what I do (including restarting sessions, delays and anything I could think of) the session in 'bar' is unable to see the initialization of the variables that 'foo' confirms as initialized.

The source code below can be used to reproduce the problem depending on the hosts used for the 'foo' and 'bar' jobs. In particular, the following has been observed and reproduced multiple times:

- When foo and bar are in the same host and OS, the problem never happens.
- When ran foo in a Linux host and bar in a Mac OS X host the problem *always* happened.
- However, if the roles are reversed (Linux runs bar, Mac OS X runs foo) the problem never happens.
- Making foo_variables below an empty list also avoids the problem entirely.

Additionally I also tested this in another couple of platforms in the same host.
- When ran foo in Windows 10 and bar in bash on Windows 10 running Ubuntu Linux 16.04, the problem *always* happened.
- When reversing it and making Linux run foo and Windows 10 run bar the problem disappeared.
- In this case both OS run in the same host and communicate through localhost sockets. Other tests suggest there's no problem in this socket communication.

### Source code / logs
```python
#!/usr/bin/env python

import sys
import tensorflow as tf

with tf.variable_scope('foo'), tf.device('job:foo/task:0'):
  foo_variables = [tf.get_variable('W', shape=(10, 5), dtype=tf.float32)]
  foo_init_vars = tf.variables_initializer(foo_variables)
  foo_pending_vars = tf.report_uninitialized_variables(foo_variables)
  foo_pending_vars.mark_used()


with tf.variable_scope('bar'), tf.device('job:bar/task:0'):
  # Expect more stuff and ops in bar in a real use case. This is just an example.
  bar_pending_vars = tf.report_uninitialized_variables(foo_variables)
  bar_pending_vars.mark_used()


cluster_spec = tf.train.ClusterSpec({
  ""foo"": [""<insert_ip_here>:55700""],
  ""bar"": [""<insert_ip_here>:55701""],
})


def foo_job():
  server = tf.train.Server(cluster_spec, job_name='foo', task_index=0)
  with tf.train.MonitoredTrainingSession(server.target, is_chief=True) as session:

    # This always runs fine.
    session.run(foo_init_vars)
    print(""Foo -- Variables not initialized: "", session.run(foo_pending_vars))
    server.join()


def bar_job():
  server = tf.train.Server(cluster_spec, job_name='bar', task_index=0)
  with tf.train.MonitoredTrainingSession(server.target, is_chief=False) as session:
    # On failure, this never gets executed...
    print(""**** Session started! ****"")

    vars_left = session.run(bar_pending_vars)
    if len(vars_left) == 0:
      print(""Bar -- Variables initialized!"")
      return

    print(""Bar -- Variables not initialized: "", vars_left)
    server.join()


if __name__ == '__main__':
  if len(sys.argv) < 2:
    print(""Usage: %s {foo|bar}"" % sys.argv[0])
    exit(1)

  if sys.argv[1] == 'foo':
    foo_job()
  else:
    bar_job()
```

@mrry, this looks like something you might have some intuition about. Any ideas of what might be going on?

This is affecting my distributed system pretty badly. I'd be happy to do more experiments to help diagnosing the problem.",0,,7,2017-09-13T14:03:09Z,CONTRIBUTOR
12997,Ability to read multi-channel image format,stat:contributions welcome,"Though the `tf.decode_image()` function can handle a few different image encodings, all of these encodings can only support a maximum of 4 channels in an image (RGBA).   One format which can support a larger number of channels is TIFF (which is currently not supported in TF, perhaps due to its complex specification?).  It would be convenient if TF could support decoding TIFF or some other format that is able to represent an arbitrary number of channels, `N` (which could be decoded into an `[H, W, N]` shaped tensor).
",0,,5,2017-09-12T14:44:42Z,NONE
12980,Blocking of tf.contrib.StagingArea get() and put() operations,,"**Work Environment**
TensorFlow release version : 1.3.0-rc2
TensorFlow git version : v1.3.0-rc1-994-gb93fd37
Operating System : CentOS Linux release 7.2.1511 (Core)

I am using TensorFlow StagingArea ops for increasing the efficiency of my input pipeline. Here is a part of my code snippet which constructs the input pipeline :
```
    train_put_op_list = []
    train_get_op_list = []
    val_put_op_list = []
    val_get_op_list = []
    with tf.variable_scope(tf.get_variable_scope()) as vscope:
        for i in range(4):
            with tf.device('/gpu:%d'%i):
                with tf.name_scope('GPU-Tower-%d'%i) as scope:
                    trainstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],
                                                                 shapes=[[64, 221, 221, 3],[64]],
                                                                      capacity=0)
                    valstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],
                                                                      shapes=[[128, 221, 221, 3],[128]],
                                                                      capacity=0)
                    train_put_op_list.append(trainstagingarea.put(train_iterator.get_next()))
                    val_put_op_list.append(valstagingarea.put(val_iterator.get_next()))
                    train_get_op_list.append(trainstagingarea.get())
                    val_get_op_list.append(valstagingarea.get())
                    with tf.device('/cpu:0'):
                        worktype = tf.get_variable(""wt"",[], initializer=tf.zeros_initializer(), trainable=False)
                    workcondition = tf.equal(worktype, 1)
                    #elem = tf.cond(workcondition, lambda: train_iterator.get_next(), lambda: val_iterator.get_next())
                    elem = tf.cond(workcondition, lambda: train_get_op_list[i], lambda: val_get_op_list[i])
                    # This is followed by the network construction and optimizer 
```
Now at the time of execution, I first run the put() ops a couple of times and then go on to run the iterations. It is shown below :
```
with tf.Session(config=config) as sess:
        sess.run(init_op)
        sess.run(iterator_training_op)
        sess.run(iterator_validation_op)
        sess.run(tf.assign(worktype, 0))
        for i in range(4):
            sess.run(train_put_op_list)
            sess.run(val_put_op_list)
        writer = tf.summary.FileWriter('.', graph=tf.get_default_graph())
        epoch = 0
        iter = 0
        previous = 0
        while(epoch<10):
            try:
                if(PROCESSINGTYPE is 'validation'):
                    sess.run(val_put_op_list)
                    [val_accu, summaries, numsamp] = sess.run([running_accuracy, validation_summary_op, processed])
                    previous+=numsamp
                    print(""Running Accuracy = {} : Number of sample processed = {} "".format(val_accu, previous))
                else:
                    sess.run(train_put_op_list)
                    [loss_value, _, train_accu, summaries, batch_accu, numsamp] = sess.run([total_loss, apply_gradient_op, running_accuracy, training_summary_op, batch_accuracy, pr\
ocessed])
                    #Remaining part of the code (not important for question)

```
The use of StagingArea improves the speed substantially (almost 3-4 times). However, the code hangs due to some block. I am not sure if the block comes from get() or put() operations. Here is the actual output :
```

# Validation is done first and the following is the output
Running Accuracy = 0.0 : Number of sample processed = 512
Running Accuracy = 0.00390625 : Number of sample processed = 1024
Running Accuracy = 0.0 : Number of sample processed = 1536
Running Accuracy = 0.001953125 : Number of sample processed = 2048
# The code hangs here
```
You can notice that in the beginning of `tf.Session() as sess:`, the `get()` and `put()` ops were run for `4` times. The output is limited to 4 lines as well. This means that, 
`sess.run(val_put_op_list)` within the `while` loop does not do anything. So, when the `get()` is called by `sess.run(running_accuracy)...`, the `StagingArea` is found empty after `4` lines and hence a blocking happens.

 - Am I correct in my analysis of the problem ?
 - What is the correct way to use the `get()` and `put()` ops here ?
 - If `StagingArea` is full and `put()` is blocked, would that also block the whole code ? TensorFlow documentation does not say anything about it.",1,,8,2017-09-11T21:08:45Z,NONE
12971,Add utf8 support for string_split,"cla: yes,stat:awaiting response","This fix is an effort to try to address the request raised in #11399 where it was not possible to split utf8 strings with `tf.string_split`.

This fix adds an additional attr of `encoding` so that `utf8` could be specified for `string_split`.

This fix fixes #11399.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,31,2017-09-11T16:53:11Z,MEMBER
12968,Feature Request / Workaround for Variable size multi-label candidate sampling in TensorFlow.,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: +
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS/Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: both
- **TensorFlow version (use command below)**:  ('v1.3.0-rc2-20-g0787eee', '1.3.0')
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: n/a


### Context:
Suppose we have a dataset with an arbitrary amount of labels per each training example (image segmentation, multi-label classification, etc.). Labels (classes) are NOT mutually exclusive, thus vary in size between examples. 

### Problem:
When trying to use provided standard `nce_loss()` -  a static `int` value for `num_true` option is required. 
- `num_true`: An `int`. The number of target classes per training example.

This probably works well for problems where we have same amount of labels per training examples and we know them in advance.
When labels have a variable shape `[None]`, (and in our case, they are also being batched and bucketed by bucket size with `.padded_batch()` + `.group_by_window()`) it is necessary to supply a variable size `num_true` in order to accustom for all training examples. This is currently unsupported to my knowledge (correct me if I'm wrong).

### Statement:
Is there a proper way to do this or any other workarounds? If not I would like to request a feature. If yes, I would appreciate a working example here or on stackoverflow.

Related [stackoverflow question](https://stackoverflow.com/questions/46085454/variable-size-multi-label-candidate-sampling-in-tensorflow).

Desired behaviour:
```
nce_loss = tf.nn.nce_loss(
    weights=nce_weights,
    biases=nce_biases,
    labels=labels,
    inputs=inputs,
    num_sampled=num_sampled,
    num_true=(tf.shape(labels)[-1]), # or tf.placeholder(""int32"", [], name=""num_trve"")
    num_classes=self.num_classes)
```

Also, is it possible to add support for weighted losses to `nce_loss()` (specifically to `_compute_sampled_logits()` as it is partially generated from a .cc) in the same fashion as it is implemented in `tf.losses.sparse_softmax_cross_entropy` or `tf.losses.sigmoid_cross_entropy`?
Thanks in advance.",0,,11,2017-09-11T16:00:00Z,CONTRIBUTOR
12964,Feature request: Google Authentication support for OAuth2 AccessTokenCredentials,"stat:contributions welcome,type:feature","
I would like to use the BigQueryReader to access  someone else's project with OAuth2 AccessTokenCredentials. I noticed that currently the google_auth_provider only uses application default credentials. I think it would be a great addition to add other methods of authentication as well.",0,,1,2017-09-11T14:36:45Z,NONE
12948,feature request: shared memory concat with new allocation for subsequent operations,type:feature,"DenseNet is an effective network design that relies on applying nn layers on recursive concatenations of data along the channel axis. Unfortunately, this has the side effect of quadratic memory growth in TensorFlow as completely new blocks of memory are allocated after each concat operation, resulting in poor performance during all phases of execution.

This is a feature request for a new `allocation='shared'` option for operations such as `tf.concat(allocation='shared')` which works seamlessly with later operations that might modify the data such as BatchNorm, which might also need to share memory. This would make it is possible to utilize the [Memory-Efficient Implementation of DenseNets](http://arxiv.org/abs/1707.06990), a paper which demonstrates that this memory utilization can be dramatically reduced through sharing of allocations. This image from the paper + pytorch implementation illustrates the shared memory approach:

![densenet shared memory](https://camo.githubusercontent.com/d3370ec4935b4bc92b736a122bc226abf48988fd/68747470733a2f2f7261772e6769746875622e636f6d2f67706c656973732f656666696369656e745f64656e73656e65745f7079746f7263682f6d61737465722f696d616765732f666f72776172642e706e67)

- [Pytorch efficient DenseNet implementation](https://github.com/gpleiss/efficient_densenet_pytorch)
- [Keras DenseNet Implementation](https://github.com/titu1994/keras-contrib/blob/ff47da56fbd54cf6cdc2ac2218529fbdadf99296/keras_contrib/applications/densenet.py) with ""naive"" allocations, works with TensorFlow backend.

This functionality would also be useful for any other application or future network design that employs recursive concatenations. Just in case I didn't find it in my search, perhaps a mechanism already exists that can meet these goals?
",0,,9,2017-09-10T19:13:20Z,NONE
12941,float64 support for conv1d and conv2d,stat:contributions welcome,"This is a feature request for `float64` support with `nn.conv1d`, `nn.conv2d`, and `nn.convolution`. Also, `conv1d` does not correctly document which types it supports. See below for details.

`conv1d` (which seems to be a wrapper for `conv2d`) and `conv2d` throw a TypeError when passed `float64` tensors. (I have only tested using a CPU; I don't have GPU access.) This occurs despite the fact that the documentation for `conv1d` claims support for `float64`. It is also worth mentioning that (at least on my CPU), `conv1d` seems to support `float16` even though this isn't mentioned in the documentation.

`conv3d` does however seem to support `float64`. Fortunately, this can at least be used as a temporary workaround to obtain `float64` support for 1d and 2d convolutions.

| Command | float16 | float32 | float64 |
| --- | --- | --- | --- |
| conv1d | works, but undocumented | works | TypeError, despite documentation |
| conv2d | works | works | TypeError |
| conv3d | TypeError | works | works |

The above table summarizes the (rather inconsistent) current state of tensorflow's support for various types according to my tests on a CPU using the code below. `convolution` appears to be a wrapper for `conv1d`, `conv2d`, and `conv3d`, and thus fails on the same types for each dimension.

```python
import tensorflow as tf
# t = tf.float16
# t = tf.float32
t = tf.float64
b, fw1, fw2, fw3, ic, oc, iw1, iw2, iw3 = range(2,11)
tf.nn.conv1d(tf.zeros([b, iw1, ic], t), tf.zeros([fw1, ic, oc], t), 1, ""VALID"")
tf.nn.conv2d(tf.zeros([b, iw1, iw2, ic], t), tf.zeros([fw1, fw2, ic, oc], t), [1]*4, ""VALID"")
tf.nn.conv3d(tf.zeros([b, iw1, iw2, iw3, ic], t), tf.zeros([fw1, fw2, fw3, ic, oc], t), [1]*5, ""VALID"")
tf.nn.convolution(tf.zeros([b, iw1, ic], t), tf.zeros([fw1, ic, oc], t), ""VALID"")
tf.nn.convolution(tf.zeros([b, iw1, iw2, ic], t), tf.zeros([fw1, fw2, ic, oc], t), ""VALID"")
tf.nn.convolution(tf.zeros([b, iw1, iw2, iw3, ic], t), tf.zeros([fw1, fw2, fw3, ic, oc], t), ""VALID"")
```

### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Arch Linux (up to date)
- **TensorFlow installed from**: source
- **TensorFlow version**: 1.3.0
- **Python version**: 3.6.2
- **Bazel version**: 0.5.4
",0,,3,2017-09-10T02:55:44Z,CONTRIBUTOR
12936,change cnn_mnist example to use Adam optimizer; added a 'loss' summary,"cla: yes,stalled,stat:awaiting response","I remember that other (non-estimator) versions of this example used the Adam optimizer, which has nicer convergence -- could we use it in this example?
Also, I added a summary for `loss`, so that it would show up on TensorBoard.

(I'd also like to add support for passing in `num_steps`, `model_dir`, etc. as command-line args with defaults, but I'll make that a separate PR unless you'd like it bundled with this one).",1,,14,2017-09-09T15:43:23Z,CONTRIBUTOR
12932,Turning on grappler makes SLIM Resnet_v1_50 slower on AWS K80,,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source binary link [here](https://s3-us-west-2.amazonaws.com/tf-benchmark/tf_binary/tensorflow-1.4.0.32ffc5a-cp27-cp27mu-linux_x86_64.whl)
- **TensorFlow version (use command below)**: 1.3+ the sha-hash is in the link to download the binary I compiled.  
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 4.5
- **CUDA/cuDNN version**: cuDNN 6 / CUDA 8
- **GPU model and memory**: K80 on AWS p2.8xlarge
- **Exact command to reproduce**: Running SLIM from tensorflow/models/slim I used the following command: `CUDA_VISIBLE_DEVICES=1 python train_image_classifier.py     --train_dir=${TRAIN_DIR}     --dataset_name=imagenet     --dataset_split_name=train     --dataset_dir=${DATASET_DIR}     --model_name=resnet_v1_50    --num_clones=1    --optimizer=sgd    --batch_size=64    --max_number_of_steps=110`


I added the following code to train_image_classifier.py:  

```python

    rewrite_options = rewriter_config_pb2.RewriterConfig()
    rewrite_options.optimizers.append('constfold')
    rewrite_options.optimizers.append('layout')
    graph_options = tf.GraphOptions(rewrite_options=rewrite_options, infer_shapes=True)
    config = tf.ConfigProto(graph_options=graph_options)

    ###########################
    # Kicks off the training. #
    ###########################
    slim.learning.train(
        train_tensor,
        session_config=config,


```

I used this binary to test and it includes the sha-hash.  The build was done from head on 09-SEP-2017 using this command `bazel build -c opt --copt=-march=""haswell"" --config=cuda //tensorflow/tools/pip_package:build_pip_package`

For /configure.  I did not include XLA I did all of the defaults with the exception of adding CUDA and cuDNN.  Nothing additional was included.  

With out grappler I get **1.5 seconds per step and with grappler 2.0 seconds per step**.  There is some variance of plus or minus .1 but it is definitely slower in my testing which was not expected.  

**Edited:** I was running v1 but I think v2 gave a very similar result.  ",1,,2,2017-09-09T07:07:12Z,MEMBER
12927,No op named GatherTree using BeamSearchDecoder,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.5
- **GPU model and memory**: GeForce GTX 1080 (8 GB)

### Describe the problem
I was implementing a seq2seq model, and inference went well using greedy algorithm(GreedyEmbeddingHelper). But when I tried to use BeamSearchDecoder to infer from a trained model, I encountered ""No op named GatherTree in defined operations."". Strangely enough, I couldn't find the same error elsewhere. 

### Error message
```
Traceback (most recent call last):
  File ""infer.py"", line 88, in <module>
    out_file='result/result.out', checkpoint=checkpoint)
  File ""infer.py"", line 48, in predict
    loader = tf.train.import_meta_graph(checkpoint + '.meta')
  File ""/home/user0/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1686, in import_meta_graph
    **kwargs)
  File ""/home/user0/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py"", line 504, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File ""/home/user0/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 283, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named GatherTree in defined operations.
```

### Source code to reproduce the problem
```
# Inference module
loaded_graph = tf.Graph()
with tf.Session(graph=loaded_graph) as sess:
	loader = tf.train.import_meta_graph(checkpoint + '.meta')
	loader.restore(sess, checkpoint)

	input_data = loaded_graph.get_tensor_by_name('inputs:0')
	logits = loaded_graph.get_tensor_by_name('inferences:0')
	src_seq_len = loaded_graph.get_tensor_by_name('source_sequence_length:0')
	tgt_seq_len = loaded_graph.get_tensor_by_name('target_sequence_length:0')

	for i in range(len(text)):
		text_seq = src2seq_word(text[i], True)
		answer = sess.run(logits, {input_data: [text_seq] * batch_size,
			                                  tgt_seq_len: [len(text_seq)] * batch_size,
			                                  src_seq_len: [len(text_seq)] * batch_size}
			                         )[:, :, 0]
```
Program failed at ```loader = tf.train.import_meta_graph(checkpoint + '.meta')```

```
# Related code
training_logits = tf.identity(train_decoder_output.rnn_output, name='logits')
inference_logits = tf.identity(infer_decoder_output.predicted_ids, name='inferences')
```",2,,15,2017-09-09T03:33:46Z,NONE
12917,"SVD on GPU: complex values, interface cleanup (Discussion)",type:feature,"Hi,
pull request #11878 brought an implementation of the SVD on the GPU. But at the moment, only real values are supported.

The current status when applying the SVD (M=USV') on a complex matrix M:
- The python interface declares U,V as complex, S as real
- The C++ kernel definition declares both U,V and S as complex
   (This simplified the CPU implementation using Eigen)
- The python code then immediately casts S to the reals
- The GPU solver (cuSolver) would, however, output the singular values directly as reals

This leads to the following questions / ideas / suggestions
(credit goes also to @rmlarsen for discussion this the first time with me)
- Change the kernel definition: Add a new kernel (V2 suffix) that returns S as a real type
- Implement the complex support on GPUs
- Adopt the CPU code to also use the new kernel definition
   OR
    Keep both definitions and let the python wrapper to choose between the two versions based on the target device (CPU vs GPU)
- ...?

What do you think?",1,,3,2017-09-08T17:41:04Z,CONTRIBUTOR
12910,is_numeric_tensor on _ref variables,type:support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**:

```python
>>> X = tf.Variable(np.random.rand(5,5))
>>> X
<tf.Variable 'Variable:0' shape=(5, 5) dtype=float64_ref>
>>> tf.is_numeric_tensor(X)
False
```

### Describe the problem
I'm not sure if this is a bug or a feature, I feel it is a bug. I want to be able to test if an input to a function was a numpy style array or a tensor. I use the tf.is_numeric_tensor to check the input, however it doesn't pick up on _ref variables such as those initialized from a numpy array. 
",0,,9,2017-09-08T13:43:00Z,NONE
12904,"make ""build_all_ios.sh""  occur error",type:build/install,"I try to build tensorflow support at Android and iOS by makefile [tutorial](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile
) in current master branch 04c318b69c5b565436cfeeaab1cb7fd5419dde27

When running the build_all_ios.sh script, the below error message show
```
Undefined symbols for architecture x86_64:
  ""nsync::nsync_mu_init(nsync::nsync_mu_s_*)"", referenced from:
      tensorflow::mutex::mutex() in env.o
      tensorflow::mutex::mutex() in random.o
  ""nsync::nsync_mu_lock(nsync::nsync_mu_s_*)"", referenced from:
      tensorflow::mutex::lock() in env.o
      tensorflow::mutex::lock() in random.o
      tensorflow::mutex::lock() in histogram.o
  ""nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)"", referenced from:
      tensorflow::mutex::unlock() in env.o
      tensorflow::mutex::unlock() in random.o
      tensorflow::mutex::unlock() in histogram.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [/Users/CSL.Peter/tensorflow/tensorflow/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1
+ '[' 2 -ne 0 ']'
+ echo 'armv7 compilation failed.'
armv7 compilation failed.
+ exit 1
```
The `download_dependencies.sh` and `compile_ios_protobuf.sh` run successfully but `compile_ios_tensorflow.sh` failed. I find same issues #3191 and #4252 and seem to be fixed at #4287, but this problem still happen.",1,,15,2017-09-08T09:34:17Z,NONE
12901,get_session_handle has no effect if not directly fetched,stat:community support,"Version `v1.3.0-rc1-1612-ga2e1a5e`, recent master.

```python
handle = tf.identity(tf.get_session_handle(tf.constant(0))).eval()
gen_data_flow_ops._get_session_tensor(handle, tf.int32).eval()
# InvalidArgumentError: The tensor with handle 'GetSessionHandle;0;/job:localhost/replica:0/task:0/device:GPU:0' is not in the session store.
```

```python
handle = tf.get_session_handle(tf.constant(0)).eval().handle
gen_data_flow_ops._get_session_tensor(handle, tf.int32).eval()
# OK
```

",0,,5,2017-09-08T08:20:57Z,CONTRIBUTOR
12888,[feature] ONNX Support,"stat:contributions welcome,type:feature","Support exporting and loading models in ONNX format.
See: https://research.fb.com/facebook-and-microsoft-introduce-new-open-ecosystem-for-interchangeable-ai-frameworks/",0,,13,2017-09-07T20:59:45Z,CONTRIBUTOR
12883,Additional arguments for summary.image,type:feature,"### System information
N/A 

### Describe the problem

It'd be nice to have more control over the color map applied to the image summaries. In particular having `vmin` and `vmax` arguments as in matplotlib [imshow](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.imshow.html) function.
If no value is given the default behaviour could be kept, but if specified, black would correspond to vmin and white to vmax.

### Source code / logs
N/A
",1,,5,2017-09-07T16:59:40Z,NONE
12853,Sub-gradient for self_adjoin_eig when eigen values are equal ,"stat:contributions welcome,type:feature","------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, I have written custom code 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux 14.04
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.2.1
- **Python version**: 
Python 2.7
- **Bazel version (if compiling from source)**:

- **CUDA/cuDNN version**:
8.0.61
- **GPU model and memory**:
Tesla K40c
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
This is a feature request. When any two eigen values are equal, the tf.gradients( tf.self_adjoint_eig(matrix), matrix) returns NaN.
While the gradient is not well defined, it would be useful if some valid sub-gradient is returned (which could be used in the optimization).
 
In particular, I am trying to optimize a function involving max eigen value of a matrix. 
Even when two eigen values are equal, a valid sub-gradient would be v_1 * v_1^T, 
where v_1 is the eigen vector corresponding to a max eigen value. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,5,2017-09-06T18:49:32Z,NONE
12851,Dataset Unzip Operation,type:feature,"@mrry This is a comment I originally posted to the ""Redesigning input pipelines"" issue, but I think it went unnoticed given the amount of comments on that thread. Given that issue is now closed (for good reason :)), I decided to post it as a separate issue.

I currently cannot see a way currently to ""unzip"" a dataset. Let's say we have a trainable model that has both a train/fit method and a infer/predict method. Let's call the type of the (potentially) nested structure of inputs to our model `I` and the type of training inputs, which are only needed when training (e.g., supervision labels), `TI`. In this case, we want the train method to accept datasets with elements of type `(I, TI)` (i.e., a tuple of `I` and `TI`) and the predict method to accept datasets with elements of type `I` or `(I, TI)` (in which case it would ignore the labels). We also want the model to only have one underlying graph, supporting all these types of input. The way I could see doing that was for the underlying model to construct two iterators (one with elements type `I` and one with type `TI`) and initialize them according to the provided datasets. However, if somebody provides a dataset with elements of type `(I, TI)` to the train method, there is no way to unzip this dataset and initialize both iterators. One has to use `Dataset.map` twice, which is not efficient (I think but please correct me if I'm wrong) and which may also not pull matching elements from the datasets (if each pull advances the current index in the original first dataset -- I'm not sure if that happens).",1,,7,2017-09-06T13:50:22Z,CONTRIBUTOR
12848,RenderScript support,,Is there a reason for not supporting RenderScript? It's there an ETA for this?,0,,5,2017-09-06T11:37:01Z,CONTRIBUTOR
12843,Error message of scatter_update is misleading ,stat:contributions welcome,"When you call scatter_update with a wrong input vector, the error message will tell you that the rank is 
wrong, which is not very helpful.
An example case in the documentation (provided) would be great.

Example:
```
      testVar = tf.Variable(tf.zeros([5,1]))
      ind = tf.constant([0,3])
      data = tf.constant([5,7], dtype=tf.float32)
      up = tf.scatter_update(testVar,  ind,  data  )
```
Error Message: 
**ValueError: Shapes must be equal rank, but are 1 and 2 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [5,1], [2], [2].**
That's not that helpful because you don't know which of the three input shapes are wrong, but mostly fine.
Changing the Code to:
```
      testVar = tf.Variable(tf.zeros([5,1]))
      ind = tf.expand_dims(tf.constant([0,3]),0)
      data = tf.expand_dims(tf.constant([5,7], dtype=tf.float32),0)
      up = tf.scatter_update(testVar,  ind,  data  )
```
**ValueError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [5,1], [1,2], [1,2].**
Is clearly wrong, because non of the inputs has rank 3!

In addition, it would be really awesome if you could add the following code as an example to the scatter_update documentation (https://www.tensorflow.org/api_docs/python/tf/scatter_update). 
(I couldn't find it in the repo(?), otherwise I would habe created a pull request)

Working Example:
```
      testVar = tf.Variable(tf.zeros([5,1]))
      ind = tf.constant([0,3])
      data = tf.expand_dims(tf.constant([5,7], dtype=tf.float32),1)
      up = tf.scatter_update(testVar,  ind,  data  )
```
",0,,3,2017-09-06T10:06:51Z,NONE
12840,User-defined functions loaders,type:feature,"I noticed user-defined functions are still [experimental](https://github.com/ipfn/tensorflow/blob/master/tensorflow/core/framework/graph.proto#L27). I have an idea about functions loaders that could allow us to use dynamically loaded functions from different sources.

Format of function address would be [multiaddr](https://github.com/multiformats/multiaddr#string-format)-like.

```
/<loader>/<namespace>/<function>
```

Loaders can be embed into tensorflow like kernels.

```
/tf/custom
/core/add
/ipfs/QmVv4Wz46JaZJeH5PMV4LGbRi3MKEmszPYY3g6fjGnVXBS
```",0,,7,2017-09-06T08:30:53Z,NONE
12838,Feature Request: ADAG,"stat:community support,type:feature","It seems difficult to add [ADAG](http://joerihermans.com/ramblings/distributed-deep-learning-part-1-an-introduction/)  as an optimizer, because by default with tf.train.replica_device_setter(), all variables get assigned to a parameter server (ps).  Thus, it is difficult to update variables locally because the optimizer first pushes updates to the ps, allowing all other workers to see its updates.  If anyone know how to create local copies of variables, I can provide an example implementation.
",0,,4,2017-09-06T04:21:45Z,NONE
12824,Apparent Segmentation Violation with Go API,,"Hi, I am trying to build a project that will take multiple URLs, download their images, and then use TensorFlow and the InceptionV3 pre-trained model to perform image recognition. For this, I am using the Go API. Most of the time, this process occurs without an issue, but every now and again an error occurs. I think this may be caused by a bug in TensorFlow as it appears to being thrown from the c code.

A sample of the code that I am using is below. In case it is relevant, I run ProcessImage from different workers concurrently. This obviously means that the tfSession variable is shared between different threads. However, I don't think this is the problem as I have tried having each worker create and use its own session, and the error still occurs.

```go
var tfSession *tf.Session
var modelGraph, normaliseGraph *tf.Graph
var normaliseInput, normaliseOutput tf.Output

/*
 * Sets up resources that can be shared by each request.
 */
func init() {
  model, _ := ioutil.ReadFile(""inception3/inception_v3_2016_08_28_frozen.pb"")
  modelGraph = tf.NewGraph()
  modelGraph.Import(model, """")
  tfSession, _ = tf.NewSession(modelGraph, nil)
  normaliseGraph, normaliseInput, normaliseOutput = ConstructNormaliseGraph()
}

/*
 * Processes the image and returns the probabilities of each label.
 */
func ProcessImage(url string) []float32 {
  tensor, okay := MakeTensorFromImage(url)
  if !okay {
    return nil
  }

  output, err := tfSession.Run(
    map[tf.Output]*tf.Tensor{
      modelGraph.Operation(""input"").Output(0): tensor,
    },
    []tf.Output{
      modelGraph.Operation(""InceptionV3/Predictions/Reshape_1"").Output(0),
    },
    nil)
  if err != nil {
    return nil
  }

  return output[0].Value().([][]float32)[0]
}

/*
 * Constructs graph used to normalise image to required dimensions.
 */
func ConstructNormaliseGraph() (graph *tf.Graph, input, output tf.Output) {
  s := op.NewScope()
  input = op.Placeholder(s, tf.String)
  output = op.Div(s,
		op.Sub(s,
			op.ResizeBilinear(s,
				op.ExpandDims(s,
					op.Cast(s,
						op.DecodeJpeg(s, input, op.DecodeJpegChannels(3)), tf.Float),
					op.Const(s.SubScope(""make_batch""), int32(0))),
				op.Const(s.SubScope(""size""), []int32{299, 299})),
			op.Const(s.SubScope(""mean""), float32(0))),
		op.Const(s.SubScope(""scale""), float32(255)))
	graph, _ = s.Finalize()
  return
}

/*
 * Creates a Tensor from the given image url.
 */
func MakeTensorFromImage(url string) (*tf.Tensor, bool) {
  r, err := client.Get(url)
  if err != nil {
    return nil, false
  }
  bytes, _ := ioutil.ReadAll(r.Body)
  r.Body.Close()

  stringBytes := string(bytes)
  if stringBytes == ""Content not found"" {
    return nil, false
  }
  tensor, _ := tf.NewTensor(stringBytes)

  session, _ := tf.NewSession(normaliseGraph, nil)
  defer session.Close()

  normalized, err := session.Run(
    map[tf.Output]*tf.Tensor{normaliseInput: tensor},
    []tf.Output{normaliseOutput},
    nil)
  if err != nil {
    return nil, false
  }
  return normalized[0], true
}
```

I'm using macOS Sierra, but this error also exists when I compile the project for Linux. I have included both of these Go environments below. On Sierra, I installed TensorFlow using Homebrew, and on Linux, I installed it using the instructions [here](https://www.tensorflow.org/install/install_go).

```
GOARCH=""amd64""
GOBIN=""""
GOEXE=""""
GOHOSTARCH=""amd64""
GOHOSTOS=""darwin""
GOOS=""darwin""
GOPATH=""/Users/Jamie/Documents/Go""
GORACE=""""
GOROOT=""/usr/local/Cellar/go/1.9/libexec""
GOTOOLDIR=""/usr/local/Cellar/go/1.9/libexec/pkg/tool/darwin_amd64""
GCCGO=""gccgo""
CC=""clang""
GOGCCFLAGS=""-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/qq/c31qf27j2mng1xxhvk0b6b6c0000gn/T/go-build437606594=/tmp/go-build -gno-record-gcc-switches -fno-common""
CXX=""clang++""
CGO_ENABLED=""1""
CGO_CFLAGS=""-g -O2""
CGO_CPPFLAGS=""""
CGO_CXXFLAGS=""-g -O2""
CGO_FFLAGS=""-g -O2""
CGO_LDFLAGS=""-g -O2""
PKG_CONFIG=""pkg-config""
```

```
GOARCH=""amd64""
GOBIN=""""
GOEXE=""""
GOHOSTARCH=""amd64""
GOHOSTOS=""linux""
GOOS=""linux""
GOPATH=""/home/ec2-user/go""
GORACE=""""
GOROOT=""/usr/local/go""
GOTOOLDIR=""/usr/local/go/pkg/tool/linux_amd64""
GCCGO=""gccgo""
CC=""gcc""
GOGCCFLAGS=""-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build126220137=/tmp/go-build -gno-record-gcc-switches""
CXX=""g++""
CGO_ENABLED=""1""
PKG_CONFIG=""pkg-config""
CGO_CFLAGS=""-g -O2""
CGO_CPPFLAGS=""""
CGO_CXXFLAGS=""-g -O2""
CGO_FFLAGS=""-g -O2""
CGO_LDFLAGS=""-g -O2""
```

The error I am getting is below. For your information, image.go line 99 is the line that contains `output, err := tfSession.Run(` in the ProcessImage function above.

```
fatal error: unexpected signal during runtime execution
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x0]

runtime stack:
runtime.throw(0x436cbee, 0x2a)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/panic.go:605 +0x95
runtime.sigpanic()
	/usr/local/Cellar/go/1.9/libexec/src/runtime/signal_unix.go:351 +0x2b8

goroutine 12 [syscall, locked to thread]:
runtime.cgocall(0x42aedc0, 0xc425d31cd8, 0x4310100)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/cgocall.go:132 +0xe4 fp=0xc425d31c90 sp=0xc425d31c50 pc=0x40044d4
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc425d69550, 0xc4200fe0e0, 0x1, 0xc425d69540, 0xc4200fe0d8, 0xc400000001, 0x0, 0x0, ...)
	github.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45 fp=0xc425d31cd8 sp=0xc425d31c90 pc=0x419af45
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc425d69550, 0xc4200fe0e0, 0x1, 0xc425d69540, 0xc4200fe0d8, 0xc400000001, 0x0, 0xc400000000, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a fp=0xc425d31d48 sp=0xc425d31cd8 pc=0x41a56ca
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc4200fd770, 0xc425d31e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f fp=0xc425d31de0 sp=0xc425d31d48 pc=0x419efff
github.com/jamiebaggott/vision.ProcessImage(0xc4202f2b60, 0x6d, 0xc420080301, 0x0, 0x0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214 fp=0xc425d31ea8 sp=0xc425d31de0 pc=0x42a8f94
github.com/jamiebaggott/vision.ImageWorker()
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c fp=0xc425d31fe0 sp=0xc425d31ea8 pc=0x42a9a3c
runtime.goexit()
	/usr/local/Cellar/go/1.9/libexec/src/runtime/asm_amd64.s:2337 +0x1 fp=0xc425d31fe8 sp=0xc425d31fe0 pc=0x4059781
created by github.com/jamiebaggott/vision.init.1
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c

goroutine 1 [IO wait, 2 minutes]:
internal/poll.runtime_pollWait(0x46adeb0, 0x72, 0xffffffffffffffff)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc420108118, 0x72, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc420108118, 0xffffffffffffff00, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Accept(0xc420108100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:334 +0x1e2
net.(*netFD).accept(0xc420108100, 0x4376820, 0xc425ce1d98, 0x400439b)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:238 +0x42
net.(*TCPListener).accept(0xc4201440b0, 0x42f7d80, 0xc425ce1dc8, 0x4003137)
	/usr/local/Cellar/go/1.9/libexec/src/net/tcpsock_posix.go:136 +0x2e
net.(*TCPListener).AcceptTCP(0xc4201440b0, 0xc425ce1e10, 0xc425ce1e18, 0xc425ce1e08)
	/usr/local/Cellar/go/1.9/libexec/src/net/tcpsock.go:234 +0x49
net/http.tcpKeepAliveListener.Accept(0xc4201440b0, 0x43761e8, 0xc42019c000, 0x44dfda0, 0xc4201365d0)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:3120 +0x2f
net/http.(*Server).Serve(0xc420160270, 0x44df960, 0xc4201440b0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:2695 +0x1b2
net/http.(*Server).ListenAndServe(0xc420160270, 0xc420160270, 0x7)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:2636 +0xa9
net/http.ListenAndServe(0x43608c9, 0x5, 0x0, 0x0, 0xc42004df70, 0x42ae572)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/server.go:2882 +0x7f
main.main()
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:18 +0x96

goroutine 5 [sleep]:
time.Sleep(0x1dcd6500)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130
gopkg.in/mgo%2ev2.(*mongoCluster).syncServersLoop(0xc4200f6000)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/cluster.go:368 +0x424
created by gopkg.in/mgo%2ev2.newCluster
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/cluster.go:78 +0x181

goroutine 24 [sleep, 1 minutes]:
time.Sleep(0x37e11d600)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130
gopkg.in/mgo%2ev2.(*mongoServer).pinger(0xc420146000, 0xc420039e01)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/server.go:301 +0x4fd
created by gopkg.in/mgo%2ev2.newServer
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/server.go:89 +0x13c

goroutine 6 [IO wait]:
internal/poll.runtime_pollWait(0x46adf70, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc420108218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc420108218, 0xc420154000, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc420108200, 0xc420154000, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc420108200, 0xc420154000, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc42000e038, 0xc420154000, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc42000e038, 0xc420154000, 0x24, 0x24, 0x0, 0x18)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc4200f80e0)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 10 [syscall, locked to thread]:
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc420188120, 0xc4200fe058, 0x1, 0xc420188110, 0xc4200fe050, 0xc400000001, 0x0, 0x0, ...)
	github.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc420188120, 0xc4200fe058, 0x1, 0xc420188110, 0xc4200fe050, 0xc400000001, 0x0, 0xc400000000, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc42038a0f0, 0xc420385e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f
github.com/jamiebaggott/vision.ProcessImage(0xc4202f2770, 0x6d, 0xc420080101, 0x0, 0x0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214
github.com/jamiebaggott/vision.ImageWorker()
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c
created by github.com/jamiebaggott/vision.init.1
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c

goroutine 11 [syscall, locked to thread]:
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc420188260, 0xc4200fe0b8, 0x1, 0xc420188240, 0xc4200fe0b0, 0xc400000001, 0x0, 0x0, ...)
	github.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc420188260, 0xc4200fe0b8, 0x1, 0xc420188240, 0xc4200fe0b0, 0xc400000001, 0x0, 0xc400000000, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc42038a270, 0xc420389e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f
github.com/jamiebaggott/vision.ProcessImage(0xc4202f25b0, 0x6d, 0xc42016e101, 0x417abd5, 0xc4200f6000)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214
github.com/jamiebaggott/vision.ImageWorker()
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c
created by github.com/jamiebaggott/vision.init.1
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c

goroutine 13 [syscall, locked to thread]:
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc425d69680, 0xc4200fe130, 0x1, 0xc425d69670, 0xc4200fe128, 0xc400000001, 0x0, 0x0, ...)
	github.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc425d69680, 0xc4200fe130, 0x1, 0xc425d69670, 0xc4200fe128, 0xc400000001, 0x0, 0xc400000000, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc4200fd950, 0xc425cdfe78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f
github.com/jamiebaggott/vision.ProcessImage(0xc4202f2d20, 0x6e, 0xc420080601, 0x0, 0x0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214
github.com/jamiebaggott/vision.ImageWorker()
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c
created by github.com/jamiebaggott/vision.init.1
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c

goroutine 14 [syscall, locked to thread]:
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SessionRun(0xb250860, 0x0, 0xc425d69700, 0xc4200fe180, 0x1, 0xc425d696f0, 0xc4200fe178, 0xc400000001, 0x0, 0x0, ...)
	github.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:705 +0x45
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run.func1(0xb250860, 0x0, 0xc425d69700, 0xc4200fe180, 0x1, 0xc425d696f0, 0xc4200fe178, 0xc400000001, 0x0, 0xc400000000, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23a
github.com/tensorflow/tensorflow/tensorflow/go.(*Session).Run(0xc42000c0a0, 0xc4200fd9e0, 0xc425d35e78, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/Users/Jamie/Documents/Go/src/github.com/tensorflow/tensorflow/tensorflow/go/session.go:87 +0x23f
github.com/jamiebaggott/vision.ProcessImage(0xc4202f2930, 0x6c, 0xc42016e301, 0x0, 0x0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:99 +0x214
github.com/jamiebaggott/vision.ImageWorker()
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:174 +0x10c
created by github.com/jamiebaggott/vision.init.1
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:38 +0x37c

goroutine 43 [IO wait]:
internal/poll.runtime_pollWait(0x46addf0, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc425cfc218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc425cfc218, 0xc420154000, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc425cfc200, 0xc420154090, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc425cfc200, 0xc420154090, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc4200fe010, 0xc420154090, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc4200fe010, 0xc420154090, 0x24, 0x24, 0x0, 0x18)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc4200f8ee0)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 66 [sleep]:
time.Sleep(0x2aea5400)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130
github.com/jamiebaggott/vision.GetRequest(0xc42005a000, 0x6b, 0x1, 0x2, 0x42d6a20, 0xc425ceebe0, 0xe, 0xc420154e40)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e
github.com/jamiebaggott/vision.GetUsers(0xc420154e40, 0x30, 0xc42013c720, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce
github.com/jamiebaggott/vision.Run(0xc42013c720, 0x1b, 0xc420084aa0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b
created by main.handler
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1

goroutine 405 [chan receive, 1 minutes]:
github.com/jamiebaggott/vision.ProcessImages(0xc42013c720, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b
created by github.com/jamiebaggott/vision.Run
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc

goroutine 29 [sleep]:
time.Sleep(0x2aea5400)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130
github.com/jamiebaggott/vision.GetRequest(0xc42005bd50, 0x6c, 0x1, 0x2, 0x42d6a20, 0xc425d9aa20, 0xe, 0xc4200181c0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e
github.com/jamiebaggott/vision.GetUsers(0xc4200181c0, 0x32, 0xc420158860, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce
github.com/jamiebaggott/vision.Run(0xc420158860, 0x1b, 0xc4200846e0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b
created by main.handler
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1

goroutine 69 [IO wait]:
internal/poll.runtime_pollWait(0x46ada30, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc42025a118, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc42025a118, 0xc420244b00, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc42025a100, 0xc420244ba0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc42025a100, 0xc420244ba0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc420286018, 0xc420244ba0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420286018, 0xc420244ba0, 0x24, 0x24, 0x0, 0x18)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425e4b420)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 33 [IO wait]:
internal/poll.runtime_pollWait(0x46adbb0, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc425e1c218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc425e1c218, 0xc420244a00, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc425e1c200, 0xc420244ae0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc425e1c200, 0xc420244ae0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc420144078, 0xc420244ae0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420144078, 0xc420244ae0, 0x24, 0x24, 0x0, 0x339cc)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc420146620)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 439 [IO wait]:
internal/poll.runtime_pollWait(0x46ad670, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc42025a298, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc42025a298, 0xc42008b000, 0x1000, 0x1000)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc42025a280, 0xc42008b000, 0x1000, 0x1000, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc42025a280, 0xc42008b000, 0x1000, 0x1000, 0x0, 0x8, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc420286078, 0xc42008b000, 0x1000, 0x1000, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
crypto/tls.(*block).readFromUntil(0xc42038b710, 0xb4640e8, 0xc420286078, 0x5, 0xc420286078, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:488 +0x95
crypto/tls.(*Conn).readRecord(0xc420120380, 0x4376817, 0xc4201204a0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:590 +0xe0
crypto/tls.(*Conn).Read(0xc420120380, 0xc420342000, 0x1000, 0x1000, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:1134 +0x110
bufio.(*Reader).Read(0xc420328b40, 0xc4201e8e38, 0x9, 0x9, 0xc425d2bc70, 0x402b956, 0x4376820)
	/usr/local/Cellar/go/1.9/libexec/src/bufio/bufio.go:213 +0x30b
io.ReadAtLeast(0x44daa60, 0xc420328b40, 0xc4201e8e38, 0x9, 0x9, 0x9, 0xc425d2bcd0, 0xc425d2bcd0, 0x4007d52)
	/usr/local/Cellar/go/1.9/libexec/src/io/io.go:309 +0x86
io.ReadFull(0x44daa60, 0xc420328b40, 0xc4201e8e38, 0x9, 0x9, 0xc420113b00, 0xc425d2bd08, 0xc400000001)
	/usr/local/Cellar/go/1.9/libexec/src/io/io.go:327 +0x58
net/http.http2readFrameHeader(0xc4201e8e38, 0x9, 0x9, 0x44daa60, 0xc420328b40, 0x0, 0xc400000000, 0xc425d2bdf0, 0x4266459)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1516 +0x7b
net/http.(*http2Framer).ReadFrame(0xc4201e8e00, 0xc4200fc180, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1774 +0xa4
net/http.(*http2clientConnReadLoop).run(0xc425d2bfb0, 0x4376220, 0xc42033cfb0)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7862 +0x92
net/http.(*http2ClientConn).readLoop(0xc42016eb60)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7788 +0x9d
created by net/http.(*http2Transport).newClientConn
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7053 +0x6b9

goroutine 67 [IO wait]:
internal/poll.runtime_pollWait(0x46adaf0, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc420108798, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc420108798, 0xc420155200, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc420108780, 0xc420155200, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc420108780, 0xc420155200, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc420286008, 0xc420155200, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420286008, 0xc420155200, 0x24, 0x24, 0x0, 0x18)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425e4a1c0)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 56 [sleep]:
time.Sleep(0x2aea5400)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130
github.com/jamiebaggott/vision.GetRequest(0xc420345ab0, 0x6c, 0x1, 0x2, 0x42d6a20, 0xc4200e1ae0, 0xe, 0xc425e04200)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e
github.com/jamiebaggott/vision.GetUsers(0xc425e04200, 0x32, 0xc4201589a0, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce
github.com/jamiebaggott/vision.Run(0xc4201589a0, 0x1b, 0xc425dc08c0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b
created by main.handler
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1

goroutine 85 [IO wait]:
internal/poll.runtime_pollWait(0x46ad970, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc42025a598, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc42025a598, 0xc420155500, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc42025a580, 0xc420155530, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc42025a580, 0xc420155530, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc420144098, 0xc420155530, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420144098, 0xc420155530, 0x24, 0x24, 0x0, 0x339cc)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc420147960)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 59 [sleep]:
time.Sleep(0x2aea5400)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/time.go:65 +0x130
github.com/jamiebaggott/vision.GetRequest(0xc425cf4000, 0x6d, 0x1, 0x2, 0x42d6a20, 0xc425d8a800, 0xe, 0xc4200185c0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:23 +0x53e
github.com/jamiebaggott/vision.GetUsers(0xc4200185c0, 0x33, 0xc42013cb40, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/request.go:151 +0x4ce
github.com/jamiebaggott/vision.Run(0xc42013cb40, 0x1b, 0xc425e205a0)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:119 +0x10b
created by main.handler
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/main/hashtag.go:66 +0x4e1

goroutine 446 [IO wait]:
internal/poll.runtime_pollWait(0x46add30, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc425e1c498, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc425e1c498, 0xc4200ae800, 0x400, 0x400)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc425e1c480, 0xc4200ae800, 0x400, 0x400, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc425e1c480, 0xc4200ae800, 0x400, 0x400, 0xc420420a00, 0x158f2dd4a2167001, 0xc42003f870)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc42000e048, 0xc4200ae800, 0x400, 0x400, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
crypto/tls.(*block).readFromUntil(0xc42024a090, 0xb4640e8, 0xc42000e048, 0x5, 0xc42000e048, 0xc42051c2c5)
	/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:488 +0x95
crypto/tls.(*Conn).readRecord(0xc420130000, 0x4376817, 0xc420130120, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:590 +0xe0
crypto/tls.(*Conn).Read(0xc420130000, 0xc425d7d000, 0x1000, 0x1000, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/crypto/tls/conn.go:1134 +0x110
bufio.(*Reader).Read(0xc420328360, 0xc425decc78, 0x9, 0x9, 0xc42003fc70, 0x402b956, 0x4376820)
	/usr/local/Cellar/go/1.9/libexec/src/bufio/bufio.go:213 +0x30b
io.ReadAtLeast(0x44daa60, 0xc420328360, 0xc425decc78, 0x9, 0x9, 0x9, 0xc42003fcd0, 0xc42003fcd0, 0x4007d52)
	/usr/local/Cellar/go/1.9/libexec/src/io/io.go:309 +0x86
io.ReadFull(0x44daa60, 0xc420328360, 0xc425decc78, 0x9, 0x9, 0xc4203283c0, 0xc42003fd08, 0xc400000001)
	/usr/local/Cellar/go/1.9/libexec/src/io/io.go:327 +0x58
net/http.http2readFrameHeader(0xc425decc78, 0x9, 0x9, 0x44daa60, 0xc420328360, 0x0, 0xc400000000, 0xc42003fdf0, 0x4266459)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1516 +0x7b
net/http.(*http2Framer).ReadFrame(0xc425decc40, 0xc42024ac00, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:1774 +0xa4
net/http.(*http2clientConnReadLoop).run(0xc42003ffb0, 0x4376220, 0xc4203397b0)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7862 +0x92
net/http.(*http2ClientConn).readLoop(0xc420080b60)
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7788 +0x9d
created by net/http.(*http2Transport).newClientConn
	/usr/local/Cellar/go/1.9/libexec/src/net/http/h2_bundle.go:7053 +0x6b9

goroutine 482 [chan receive]:
github.com/jamiebaggott/vision.ProcessImages(0xc42013cb40, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b
created by github.com/jamiebaggott/vision.Run
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc

goroutine 449 [chan receive]:
github.com/jamiebaggott/vision.ProcessImages(0xc420158860, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b
created by github.com/jamiebaggott/vision.Run
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc

goroutine 392 [IO wait]:
internal/poll.runtime_pollWait(0x46ad8b0, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc42025a198, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc42025a198, 0xc425d8ce00, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc42025a180, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc42025a180, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc420144008, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420144008, 0xc425d8ce70, 0x24, 0x24, 0x0, 0x339cc)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc420246e00)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 462 [chan receive]:
github.com/jamiebaggott/vision.ProcessImages(0xc4201589a0, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:81 +0x35b
created by github.com/jamiebaggott/vision.Run
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/database.go:118 +0xdc

goroutine 364 [IO wait]:
internal/poll.runtime_pollWait(0x46ad7f0, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc425e1c118, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc425e1c118, 0xc42001c700, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc425e1c100, 0xc42001c7b0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc425e1c100, 0xc42001c7b0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc420286000, 0xc42001c7b0, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc420286000, 0xc42001c7b0, 0x24, 0x24, 0x0, 0xa9)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425e4a2a0)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 483 [chan send]:
github.com/jamiebaggott/vision.ProcessImages.func1(0xc425d02960, 0xc4204f20c0, 0xc4200e1ba0, 0xc420345b20, 0xc42013cb40, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3
created by github.com/jamiebaggott/vision.ProcessImages
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327

goroutine 394 [IO wait]:
internal/poll.runtime_pollWait(0x46adc70, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc425cfd218, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc425cfd218, 0xc420245800, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc425cfd200, 0xc420245800, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc425cfd200, 0xc420245800, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc4200fe028, 0xc420245800, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc4200fe028, 0xc420245800, 0x24, 0x24, 0x0, 0x339cc)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc425dec000)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 385 [chan send]:
github.com/jamiebaggott/vision.ProcessImages.func1(0xc425d020f0, 0xc420119b00, 0xc425d049c0, 0xc4202f3ea0, 0xc42013c720, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3
created by github.com/jamiebaggott/vision.ProcessImages
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327

goroutine 461 [IO wait]:
internal/poll.runtime_pollWait(0x46ad4f0, 0x72, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/runtime/netpoll.go:173 +0x57
internal/poll.(*pollDesc).wait(0xc420108d98, 0x72, 0xffffffffffffff00, 0x44dd020, 0x44d9690)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:85 +0xae
internal/poll.(*pollDesc).waitRead(0xc420108d98, 0xc420244e00, 0x24, 0x24)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_poll_runtime.go:90 +0x3d
internal/poll.(*FD).Read(0xc420108d80, 0xc420244e70, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/internal/poll/fd_unix.go:125 +0x18a
net.(*netFD).Read(0xc420108d80, 0xc420244e70, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/fd_unix.go:202 +0x52
net.(*conn).Read(0xc4200fe1a0, 0xc420244e70, 0x24, 0x24, 0x0, 0x0, 0x0)
	/usr/local/Cellar/go/1.9/libexec/src/net/net.go:176 +0x6d
gopkg.in/mgo%2ev2.fill(0x44e1700, 0xc4200fe1a0, 0xc420244e70, 0x24, 0x24, 0x0, 0x1e7)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:535 +0x53
gopkg.in/mgo%2ev2.(*mongoSocket).readLoop(0xc4201e8540)
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:551 +0x658
created by gopkg.in/mgo%2ev2.newSocket
	/Users/Jamie/Documents/Go/src/gopkg.in/mgo.v2/socket.go:194 +0x23f

goroutine 463 [chan send]:
github.com/jamiebaggott/vision.ProcessImages.func1(0xc425d6c2d0, 0xc42038ad80, 0xc425d83820, 0xc42005a150, 0xc4201589a0, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3
created by github.com/jamiebaggott/vision.ProcessImages
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327

goroutine 464 [chan send]:
github.com/jamiebaggott/vision.ProcessImages.func1(0xc425d6c3c0, 0xc42038ae40, 0xc425d83960, 0xc42005a1c0, 0xc420158860, 0x1b)
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:62 +0x1a3
created by github.com/jamiebaggott/vision.ProcessImages
	/Users/Jamie/Documents/Go/src/github.com/jamiebaggott/vision/image.go:57 +0x327
```",0,,7,2017-09-05T16:25:36Z,NONE
12817,"LMDB reader Error in Reading Data of multi-thread, queue based input pipeline","stat:community support,type:bug/performance","Hi,

I am now using LMDB reader to read and decode my custom data into tensorflow training pipeline, based on the example:
```
def read_my_file_format(filename_queue):
  reader = tf.SomeReader()
  key, record_string = reader.read(filename_queue)
  example, label = tf.some_decoder(record_string)
  processed_example = some_processing(example)
  return processed_example, label

def input_pipeline(filenames, batch_size, num_epochs=None):
  filename_queue = tf.train.string_input_producer(
      filenames, num_epochs=num_epochs, shuffle=True)
  example, label = read_my_file_format(filename_queue)
  min_after_dequeue = 10000
  capacity = min_after_dequeue + 3 * batch_size
  example_batch, label_batch = tf.train.shuffle_batch(
      [example, label], batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  return example_batch, label_batch
````
Here, I designed my own decoder and used LMDB reader here. But the problem is that, when the `num_epochs` is not 1, there will be ERROR:

```
Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)
```

Could you help check this?

Thanks
",0,,17,2017-09-05T10:49:40Z,NONE
12813,How to add a user_ops to android .so file ?,stat:awaiting tensorflower,"### Discription
I want to add a custom op for tensorflow and use it in android app. But I find it only tell us how to add an op in python . I put my own .cc file witch contains register code into the user_ops folder and bazel build again to generate a new .so file . But when I test this .so in android code, It says the custom op is not registered and crashed. How can I succeed to register a new op and build it into the android .so file? 

And I found that there are two folder named ""user_ops"" : tensorflow/tensorflow/user_ops ; and tensorflow/tensorflow/core/user_ops;  witch folder should I put my ops in ?  

Hope for your answer. Thank you so much!

------------------------

### System information
Tensorflow r1.2

### Source code / logs
![image](https://user-images.githubusercontent.com/10495849/30049205-4bb48d28-924c-11e7-828e-62e14ba2e9a6.png)

![image](https://user-images.githubusercontent.com/10495849/30049227-658ed708-924c-11e7-8a77-0fa3cb4a1105.png)

![image](https://user-images.githubusercontent.com/10495849/30049236-6cfa6b06-924c-11e7-8384-6de337db0807.png)




",0,,4,2017-09-05T07:11:15Z,NONE
12810,build libtensorflow-core.a error  ,stat:awaiting response,"buf -lpthread -lm -lz
Undefined symbols for architecture x86_64:
""nsync::nsync_mu_init(nsync::nsync_mu_s_)"", referenced from:
tensorflow::mutex::mutex() in env.o
tensorflow::mutex::mutex() in random.o
""nsync::nsync_mu_lock(nsync::nsync_mu_s_)"", referenced from:
tensorflow::mutex::lock() in env.o
tensorflow::mutex::lock() in random.o
tensorflow::mutex::lock() in histogram.o
""nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)"", referenced from:
tensorflow::mutex::unlock() in env.o
tensorflow::mutex::unlock() in random.o
tensorflow::mutex::unlock() in histogram.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [/Users/9kacha/Desktop/TFFF/tensorflow/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1

    '[' 2 -ne 0 ']'
    echo 'armv7 compilation failed.'
    armv7 compilation failed.
    exit 1

how to fix this error ? ",0,,7,2017-09-05T06:21:13Z,NONE
12804,Feature request - non-scalar Multinomial draws,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.12.6 
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Python version**: 3.6.2
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: NA

### Describe the problem
For Multinomial distribution the _sample_n method does not support total_count to be a vector and throws a 
```
NotImplementedError(""Sample only supported for scalar number of draws."") 
```
[https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/ops/distributions/multinomial.py#L236](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/ops/distributions/multinomial.py#L236)
It would be a really useful feature to add. 


### Source code / logs
NA",0,,0,2017-09-05T01:07:53Z,NONE
12792,Feature request: let transform_graph use summarize_graph inputs/outputs guess as default flags,"stat:awaiting tensorflower,type:feature","`tensorflow/tools/graph_transforms/summarize_graph` is very useful for listing names of input and output nodes, however it seems like you still have to set `--inputs` and `--outputs` with `tensorflow/tools/graph_transforms/transform_graph` explicitly. Would it be possible to have `transform_graph` assume the same nodes from `summarize_graph` by default?",0,,4,2017-09-04T09:51:22Z,CONTRIBUTOR
12781,Compile from source on Skylake-X (Intel i9),"stat:awaiting response,type:build/install","Hello,

Compiling tensorflow source on Skylake-X Intel i9 with ""--config=opt"" gives the following error in the snappy external module:

-----------------------

> ERROR: /home/armafire/.cache/bazel/_bazel_armafire/efbef35334c587b69e16a82829bb0e2d/external/snappy/BUILD:19:1: C++ compilation of rule '@snappy//:snappy' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
>   (cd /home/armafire/.cache/bazel/_bazel_armafire/efbef35334c587b69e16a82829bb0e2d/execroot/org_tensorflow && \
>   exec env - \
>     CUDA_TOOLKIT_PATH=/usr/local/cuda \
>     CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \
>     GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
>     PWD=/proc/self/cwd \
>     PYTHON_BIN_PATH=/usr/bin/python \
>     PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
>     TF_CUDA_CLANG=0 \
>     TF_CUDA_COMPUTE_CAPABILITIES=6.1 \
>     TF_CUDA_VERSION=8.0 \
>     TF_CUDNN_VERSION=6 \
>     TF_NEED_CUDA=1 \
>     TF_NEED_OPENCL=0 \
>   external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++11' '-march=native' -MD -MF bazel-out/local_linux-opt/bin/external/snappy/_objs/snappy/external/snappy/snappy.pic.d '-frandom-seed=bazel-out/local_linux-opt/bin/external/snappy/_objs/snappy/external/snappy/snappy.pic.o' -fPIC -iquote external/snappy -iquote bazel-out/local_linux-opt/genfiles/external/snappy -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -Wno-shift-negative-value -Wno-implicit-function-declaration -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c external/snappy/snappy.cc -o bazel-out/local_linux-opt/bin/external/snappy/_objs/snappy/external/snappy/snappy.pic.o)
> cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
> external/snappy/snappy.cc: In member function 'void snappy::SnappySinkAllocator::Flush(size_t)':
> external/snappy/snappy.cc:1403:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
>      for (int i = 0; i < blocks_.size(); ++i) {
>                      ~~^~~~~~~~~~~~~~~~
> In file included from external/snappy/snappy-internal.h:34:0,
>                  from external/snappy/snappy.cc:30:
> external/snappy/snappy.cc: In instantiation of 'bool snappy::SnappyScatteredWriter<Allocator>::AppendFromSelf(size_t, size_t) [with Allocator = snappy::SnappySinkAllocator; size_t = long unsigned int]':
> external/snappy/snappy.cc:715:13:   required from 'void snappy::SnappyDecompressor::DecompressAllTags(Writer*) [with Writer = snappy::SnappyScatteredWriter<snappy::SnappySinkAllocator>]'
> external/snappy/snappy.cc:799:3:   required from 'bool snappy::InternalUncompressAllTags(snappy::SnappyDecompressor*, Writer*, snappy::uint32) [with Writer = snappy::SnappyScatteredWriter<snappy::SnappySinkAllocator>; snappy::uint32 = unsigned int]'
> external/snappy/snappy.cc:1460:78:   required from here
> external/snappy/snappy.cc:1316:34: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
>      if (PREDICT_TRUE(offset - 1u < op_ptr_ - op_base_ && op_end <= op_limit_)) {
>                       ~~~~~~~~~~~~^~~~~~~~~~~~~
> external/snappy/snappy-stubs-internal.h:80:25: note: in definition of macro 'PREDICT_TRUE'
>  #define PREDICT_TRUE(x) x
>                          ^
> /tmp/ccxBWytY.s: Assembler messages:
> **_/tmp/ccxBWytY.s:389: Error: no such instruction: `kmovq %rdx,%k3'
> /tmp/ccxBWytY.s:391: Error: no such instruction: `kshiftrq $32,%k3,%k2'
> /tmp/ccxBWytY.s:394: Error: no such instruction: `kmovq %k2,%rdx'
> /tmp/ccxBWytY.s:600: Error: no such instruction: `kmovq %rsi,%k1'
> /tmp/ccxBWytY.s:602: Error: no such instruction: `kshiftrq $32,%k1,%k0'
> /tmp/ccxBWytY.s:605: Error: no such instruction: `kmovq %k0,%rsi'_**
> Target //tensorflow/tools/pip_package:build_pip_package failed to build
> INFO: Elapsed time: 34.595s, Critical Path: 14.66s
> FAILED: Build did NOT complete successfully

-----------------------

The command I use is:

bazel build --config=opt -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures -j 64

If I change to --config=mkl, then it compiles fine. Therefore, it seems that the problem is ""--march=native"" (generated by ""--config=opt""), which forces the snappy module to generate AVX512, however, the generated assembly is not correct for Skylake-X Intel i9 (which supports AVX512). I tried ""--march=skylake-avx512"" and all other AVX512 options like ""-mavx512f"" and similar, and all result in the same error.

My goal is to compile tensorflow with Eigen AVX512. Any ideas how this can be done?",0,,8,2017-09-03T18:47:27Z,NONE
12761,Allow to build tensorflow as a bazel external dependency.,"stat:contributions welcome,type:feature","It would be nice to be able to just add a @org_tensorflow in bazel and be able to build it as a dependency.  

At the best of my knowledge the syntaxnet dockerfile is the best example on having tensorflow as a submodule.
https://github.com/tensorflow/models/blob/c259259299db3b486ccdfd6cdec44b884623053a/syntaxnet/Dockerfile#L63

But still building it is not straightforward and probably does not work if you activate CUDA/XLA/MLK because those depends on other bazel subprojects.

Are there any plans to support this use case or I am missing something in the best practices to build tensorflow as a subpackage ? 
",0,,3,2017-09-02T00:40:42Z,CONTRIBUTOR
12753,tf.image.resize_bilinear has nearest neighbor gradients when downscaling,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
binary

- **TensorFlow version (use command below)**:
v1.2.0-5-g435cdfc 1.2.1

- **Python version**: 
3.5.2

### Describe the problem
When using `tf.image.resize_bilinear` to downscale, the gradients of the output w.r.t. the input is the same as what we get from nearest neighbors. For instance, using the code below you can confirm that the gradients are being sparsely backpropagated to specific pixels of the input image.

### Source code / logs
```
import numpy as np
import tensorflow as tf


if __name__ == '__main__':
    session = tf.Session()

    x = tf.placeholder(tf.float32, shape=[None, 16, 16, 3])
    x_low = tf.image.resize_bilinear(x, (4, 4))
    loss = tf.reduce_sum(x_low)
    loss_grad = tf.gradients(loss, x)

    grad = session.run(loss_grad, {x: np.ones([1, 16, 16, 3], dtype=np.float32)})[0]
    grad = grad[0, ...].transpose(2, 0, 1)
    print(grad)  # should not be sparse, but it is

    session.close()
```

The output is:
```
[[[ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]
```",0,,4,2017-09-01T15:46:37Z,NONE
12750,Android-Tensorflow model loading issue with SavedModelBundle.load(),,"Loading the model in Android give below error:

FATAL EXCEPTION: main
                  Process: tensorflow.lgsi.com.posapplication, PID: 516
                  java.lang.RuntimeException: Unable to start activity ComponentInfo{tensorflow.lgsi.com.posapplication/tensorflow.lgsi.com.posapplication.MainActivity}: java.lang.U**nsupportedOperationException**: **Loading a SavedModel is not supported in Android. File a bug at https://github.com/tensorflow/tensorflow/issues if this feature is important to you**
                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2727)
                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2788)
                      at android.app.ActivityThread.-wrap12(ActivityThread.java)
                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1504)
                      at android.os.Handler.dispatchMessage(Handler.java:102)
                      at android.os.Looper.loop(Looper.java:154)
                      at android.app.ActivityThread.main(ActivityThread.java:6248)
                      at java.lang.reflect.Method.invoke(Native Method)
                      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:872)
                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:762)
                   Caused by: java.lang.UnsupportedOperationException: Loading a SavedModel is not supported in Android. File a bug at https://github.com/tensorflow/tensorflow/issues if this feature is important to you
                      at org.tensorflow.SavedModelBundle.load(Native Method)
                      at org.tensorflow.SavedModelBundle.load(SavedModelBundle.java:38)
                      at tensorflow.com.posapplication.tagger.PosTagger.<init>(PosTagger.java:23)
                      at tensorflow.lgsi.com.posapplication.tagger.PosTagger.getInsPosTagger(PosTagger.java:30)
                      at tensorflow.com.posapplication.MainActivity.onCreate(MainActivity.java:56)
                      at android.app.Activity.performCreate(Activity.java:6757)
                      at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1119)
                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2680)
                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2788) 
                      at android.app.ActivityThread.-wrap12(ActivityThread.java) 
                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1504) 
                      at android.os.Handler.dispatchMessage(Handler.java:102) 
                      at android.os.Looper.loop(Looper.java:154) 
                      at android.app.ActivityThread.main(ActivityThread.java:6248) 
                      at java.lang.reflect.Method.invoke(Native Method) 
                      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:872) 
                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:762) 
I/art: Starting

**Model is saved in Python by using below API:**
builder = tf.saved_model.builder.SavedModelBuilder(r'./tmp/model')
builder.add_meta_graph_and_variables(session, [tf.saved_model.tag_constants.SERVING])
builder.save(True) 

**Model is loading in Andoid using below api:**
inferenceInterface = new TensorFlowInferenceInterface(context.getAssets(), MODEL_FILE);",1,,4,2017-09-01T10:12:47Z,NONE
12746,Feature Request: Loading weights for layers defined in tf.layers api,type:feature,"Let's say I define a layer using the `tf.layers` API as shown below:

```
conv1 = tf.layers.conv2d(input_img, filters=32, 
                                     kernel_size=(3,3), 
                                     padding='same', 
                                     name='Conv1')
```

Now I can build a whole network defining such layers. Can you please introduce another functionality for the `tf.layers` api so that for each layer we can set the weights in a single line like this:

`conv1.set_weights(weights)` or something like this `conv1.set_params(param_values)`

This would be very very useful.",1,,6,2017-09-01T07:46:32Z,NONE
12730,Op type not registered 'CudnnRNNParamsSize' in binary,stat:awaiting response,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: example
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10 64bit
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.6
- **CUDA/cuDNN version**: Cude - 8.0, cuDNN - 6.0
- **GPU model and memory**: M1000M
- **Exact command to reproduce**: 

### Describe the problem
The tutorial RNN model fails due to: ""Op type not registered 'CudnnRNNParamsSize' in binary""

### Source code / logs
https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py

```
b'unknown' 1.3.0
2017-08-31 16:25:32.021526: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-31 16:25:32.021822: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-31 16:25:32.959216: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 0 with properties: 
name: Quadro M1000M
major: 5 minor: 0 memoryClockRate (GHz) 1.0715
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.65GiB
2017-08-31 16:25:32.959478: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:976] DMA: 0 
2017-08-31 16:25:32.959642: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 0:   Y 
2017-08-31 16:25:32.959848: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0)
Traceback (most recent call last):
  File ""C:/Work/Projects/tensorflow-models/tutorials/rnn/ptb/ptb_word_lm.py"", line 526, in <module>
    tf.app.run()
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""C:/Work/Projects/tensorflow-models/tutorials/rnn/ptb/ptb_word_lm.py"", line 470, in main
    m = PTBModel(is_training=True, config=config, input_=train_input)
  File ""C:/Work/Projects/tensorflow-models/tutorials/rnn/ptb/ptb_word_lm.py"", line 135, in __init__
    output, state = self._build_rnn_graph(inputs, config, is_training)
  File ""C:/Work/Projects/tensorflow-models/tutorials/rnn/ptb/ptb_word_lm.py"", line 174, in _build_rnn_graph
    return self._build_rnn_graph_cudnn(inputs, config, is_training)
  File ""C:/Work/Projects/tensorflow-models/tutorials/rnn/ptb/ptb_word_lm.py"", line 186, in _build_rnn_graph_cudnn
    params_size_t = self._cell.params_size()
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\python\ops\cudnn_rnn_ops.py"", line 597, in params_size
    direction=self._direction)[0]
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\ops\gen_cudnn_rnn_ops.py"", line 283, in cudnn_rnn_params_size
    name=name)
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2632, in create_op
    set_shapes_for_outputs(ret)
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1911, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 595, in call_cpp_shape_fn
    require_shape_fn)
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 654, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""C:\Programs\Anaconda3\lib\contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""C:\Programs\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'CudnnRNNParamsSize' in binary running on ULTRALISK. Make sure the Op and Kernel are registered in the binary running in this process.
```
",0,,8,2017-08-31T13:28:36Z,NONE
12704,Memory leak when reusing variables with slim,,"### System information:
- Windows 7 x64
- Python 3.5.2 |Anaconda 4.2.0 (64-bit)
- Tensorflow 1.3.0 installed via pip


### Problem
I want to use TF-Slim models to classify images in a server. For this, I would like to load the network only once and reuse the variables. I adjusted the tutorial given here: https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb

### Code to reproduce
```
import tensorflow as tf
from tensorflow.contrib import slim

import urllib.request as urllib
from nets import inception
from preprocessing import inception_preprocessing


image_size = inception.inception_v1.default_image_size

initialized = False
graph = tf.Graph()

init_fn = None

def predict():
    global initialized
    global init_fn
    with graph.as_default():
        url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'
        image_string = urllib.urlopen(url).read()
        image = tf.image.decode_jpeg(image_string, channels=3)
        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)
        processed_images  = tf.expand_dims(processed_image, 0)
        with slim.arg_scope(inception.inception_v1_arg_scope()):
            logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False, reuse=initialized)
        probabilities = tf.nn.softmax(logits)
        if not initialized:
            init_fn = slim.assign_from_checkpoint_fn(""tmp/checkpoints/inception_v1.ckpt"", slim.get_model_variables(""InceptionV1""))
        with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=8)) as sess:
            init_fn(sess)
            np_probabilities = sess.run(probabilities)
        initialized = True
    return np_probabilities.tolist()

for _ in range(20):
    predict()
```


### Memory Usage monitored with Process Explorer
![memory](https://user-images.githubusercontent.com/20746434/29866915-33ed6506-8d7a-11e7-8dd4-1fc3e1b2f1d7.png)
This is the memory usage when calling the predict function 20 times. As you can see, it keeps increasing.


Am I doing it wrong, or is it a bug?",0,,9,2017-08-30T09:58:10Z,NONE
12701,Feature Request: callback argument for tf.contrib.data.Dataset.ignore_errors() to enable error logging,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: GTX 1080, 8GB
- **Exact command to reproduce**: -

### Describe the problem
The [`tf.contrib.data.Dataset.ignore_errors()`](https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/contrib/data/Dataset#ignore_errors) function is extremely useful when processing data that has not been fully cleaned beforehand (e.g., with streaming input), but I find the ""silently ignoring all errors"" a bit too strict.
It would be very useful, for example, to know which files raise an error when processing the dataset, while keeping the exception-masking feature of the function.

IMO, the most flexible way to obtain this would be to include an optional `callback` argument to the function that gets called passing as arguments the value in the dataset that raised an error.
This way custom logging can be done for each erroneous data sample and dataset inspection becomes much simpler.

Would this be very hard to implement?
",0,,5,2017-08-30T09:03:28Z,NONE
12699,libtensorflow-core.a contains duplicate symbol CreateGPUTracerEv,"stat:awaiting tensorflower,type:build/install","Running `build_all_ios.sh` produces a `libtensorflow-core.a` that contains a symbol twice. When linking on iOS the error is

```
duplicate symbol __ZN10tensorflow15CreateGPUTracerEv in:
    <PROJDIR>/.../libtensorflow-core.a(gpu_tracer.o)
ld: 1 duplicate symbol for architecture x86_64
```

I checked with `nm` just to be sure

```
$ nm libtensorflow-core.a | grep CreateGPUTracerEv
---------------- T __ZN10tensorflow15CreateGPUTracerEv
---------------- T __ZN10tensorflow15CreateGPUTracerEv
```

Branch `master`
MacOS Sierra 10.12.6 (16G29)
Xcode Version 8.3.3 (8E3004b)",0,,7,2017-08-30T07:09:49Z,CONTRIBUTOR
12686,Feature Request: C++ gradient for SoftmaxCrossEntropyWithLogits,"stat:contributions welcome,type:feature","Implement the gradient for SoftmaxCrossEntropyWithLogits in c++ so that it is available for TF_AddGradients.

This is the python code that I believe would need to be ported:
https://github.com/tensorflow/tensorflow/blob/4b2fb49fd7578afe7e289936f347af581b5bdab1/tensorflow/python/ops/nn_grad.py#L409
",0,,37,2017-08-29T16:01:14Z,CONTRIBUTOR
12683,XLA leads to core dump,stat:contributions welcome,"### System information

[output of tf_env_collect.sh](http://paste.ubuntu.com/25424565/)

#### Tensorflow

Tensorflow compiled from the source v1.3.0(9e76bf3)

with cuda, with xla, without mpi, without mkl

#### OS
CentOS 7

out put of `uname -a`:

Linux zhanghao 3.10.0-514.26.2.el7.x86_64 #1 SMP Tue Jul 4 15:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

#### python
Python 2.7.13 |Intel Corporation| (default, Apr 27 2017, 15:33:46)

[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux2

#### Bezel
Build label: 0.5.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jun 27 13:27:03 2017 (1498570023)
Build timestamp: 1498570023
Build timestamp as int: 1498570023

#### GPU
CUDA 8.0 cuDNN 6.0.21
GPU: GeForce GTX 950M

### Describe the problem
core dump when use xla with gpu,

BTW, if use cpu only, xla won't lead to core dump

### Source code
This is code to reproduce the bug
```
import tensorflow as tf
import sys
D = 2
A = tf.random_normal(shape=[D, D, 2], dtype=tf.float32,name=""A"")
B = tf.random_normal(shape=[D, D, 2], dtype=tf.float32, name=""B"")
E = tf.ones(shape=[D], dtype=tf.float32, name=""EBA"")
H = tf.reshape(tf.constant([[0.25,0,0,0],[0,-0.25,0.5,0],[0,0.5,-0.25,0],[0,0,0,0.25]],
                           dtype=tf.float32),[2,2,2,2],name=""Hamiltonian"")
EA = tf.multiply(A,tf.reshape(E,[D,1,1]))
AB = tf.tensordot(EA,B,[[1],[0]],name=""AB"")
S, U, V = tf.svd(tf.reshape(AB,[2*D,2*D]))
UU = tf.transpose(tf.multiply(tf.reshape(U[:,:D],[D,2,D]),tf.reshape(E,[D,1,1])),[0,2,1],name=""nA"")
data = UU / tf.reduce_max(UU)
config = tf.ConfigProto()
if len(sys.argv)>1:
    config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())
print sess.run(data)
```
save as MPS.py and run `python MPS.py` and get:
```
2017-08-29 20:51:54.856662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-08-29 20:51:54.857232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 950M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:0a:00.0
Total memory: 3.95GiB
Free memory: 3.92GiB
2017-08-29 20:51:54.857292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-08-29 20:51:54.857301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-08-29 20:51:54.857312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)
[[[ 0.64684284 -0.48666194]
  [-0.56722689 -0.19181968]]

 [[ 0.34154066  0.77098727]
  [ 1.         -0.0881796 ]]]
```
and then run `python MPS.py -`, and get:
```
2017-08-29 20:52:18.127327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-08-29 20:52:18.127719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 950M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:0a:00.0
Total memory: 3.95GiB
Free memory: 3.92GiB
2017-08-29 20:52:18.127780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-08-29 20:52:18.127789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-08-29 20:52:18.127799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)
2017-08-29 20:52:18.319392: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-08-29 20:52:18.319435: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Executor present with 1 visible devices
2017-08-29 20:52:18.319739: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-08-29 20:52:18.320615: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x7f59008c0350 executing computations on platform CUDA. Devices:
2017-08-29 20:52:18.320640: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0
2017-08-29 20:52:18.474432: F tensorflow/compiler/xla/util.cc:183] Check failed: p1.size() == p2.size() (3 vs. 0)
[1]    14077 abort (core dumped)  python MPS.py -
```",0,,10,2017-08-29T12:56:28Z,NONE
12659,tf.maximum does not return nan when inputs contain nan,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: Tesla K40m, 11439MiB
- **Exact command to reproduce**: python main.py

### Describe the problem
`tf.maximum(a, b)` should return `nan` when `a` or `b` contain `nan`. However, it does not at some cases.

### Source code / logs
main.py
```python
import tensorflow as tf
import numpy as np

a = tf.placeholder(dtype=tf.float32)
max_a = tf.maximum(a, 1.)
with tf.Session():
    print max_a.eval(feed_dict={a: np.nan})
```
The output is:
```
1.0
```",1,,14,2017-08-28T20:51:57Z,CONTRIBUTOR
12658,Support CopyFile with streaming,"cla: yes,stat:awaiting tensorflower","This fix tries to address the issue raised in #12641 where it was not possible to have CopyFile with streaming. The original implementation copies the whole content of the file to a string
buffer and write to the file. This could be an issue if the file size is too large (than the memory of the host).

This fix streams the CopyFile operation.

*Also, sendfile is used if the file system is posix*

This fix fixes #12641.

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",1,,31,2017-08-28T20:40:11Z,MEMBER
12653,Device string in eager API differs from main ops API,,"In the Python API device strings are normalized such that `/cpu:0` becomes `/device:CPU:0`. This happens in the `device.py` and more specifically, [here](https://github.com/tensorflow/tensorflow/blob/668db64a5d612d5f96b5d87772ce6ff6531fc035/tensorflow/python/framework/device.py#L192). However, the eager execution API throws an error if provided `/device:CPU:0` for the device. It only works if I set it to `CPU:0`. Why does that inconsistency exist? @asimshankar @alextp 

P.S. I try to tag people that I believe are relevant based on previous issues/discussions. Please let me know if that's annoying and would prefer me not tagging anyone. :)",1,,9,2017-08-28T15:55:10Z,CONTRIBUTOR
12649,Android buffer overflow exception when running only a certain model above a certain image resolution?,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android Lollipop
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.2
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 4.5
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: Running app on android studio

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I have met with a very peculiar problem that seem to show that a certain model, Inception V3, which I got from the TF-slim library, seem to consume more memory than usual and cause a bufferoverflow problem like in here:

```
08-28 21:23:40.121 1094-1094/com.example.android.androidevaluateimagenet D/AndroidRuntime: Shutting down VM
08-28 21:23:40.122 1094-1094/com.example.android.androidevaluateimagenet E/AndroidRuntime: FATAL EXCEPTION: main
                                                                                           Process: com.example.android.androidevaluateimagenet, PID: 1094
                                                                                           java.nio.BufferOverflowException
                                                                                               at java.nio.FloatBuffer.put(FloatBuffer.java:444)
                                                                                               at org.tensorflow.Tensor.writeTo(Tensor.java:390)
                                                                                               at org.tensorflow.contrib.android.TensorFlowInferenceInterface.fetch(TensorFlowInferenceInterface.java:338)
                                                                                               at org.tensorflow.contrib.android.TensorFlowInferenceInterface.fetch(TensorFlowInferenceInterface.java:301)
                                                                                               at com.example.android.androidevaluateimagenet.TensorFlowImageClassifier.recognizeImage(TensorFlowImageClassifier.java:149)
                                                                                               at com.example.android.androidevaluateimagenet.MainActivity.getInferenceTime(MainActivity.java:267)
                                                                                               at com.example.android.androidevaluateimagenet.MainActivity$2.onClick(MainActivity.java:345)
                                                                                               at android.view.View.performClick(View.java:4763)
                                                                                               at android.view.View$PerformClick.run(View.java:19821)
                                                                                               at android.os.Handler.handleCallback(Handler.java:739)
                                                                                               at android.os.Handler.dispatchMessage(Handler.java:95)
                                                                                               at android.os.Looper.loop(Looper.java:135)
                                                                                               at android.app.ActivityThread.main(ActivityThread.java:5272)
                                                                                               at java.lang.reflect.Method.invoke(Native Method)
                                                                                               at java.lang.reflect.Method.invoke(Method.java:372)
                                                                                               at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:909)
                                                                                               at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:704)
```

Specifically, if you try an image resolution higher than 360x360 in the model, it crashes with the error. The interesting thing is that this doesn't happen for a significantly larger model, the Inception Resnet V2, although it supposedly consumes a lot more memory. With that larger inception resnet v2 model, I can use a resolution of over 400 with no issues. I have rebooted my device, switched it and run it on another identical device and another brand of device, but still there's this problem. I can't exactly locate the issue, but specifically here is what I have traced in the error:


Specific error stack trace:

**TensorFlowImageClassifier.java:**

        inferenceInterface.fetch(outputName, outputs);

**TensorFlowInferenceInterace.java:**

    public void fetch(String var1, float[] var2) {
        this.fetch(var1, FloatBuffer.wrap(var2));
    }

**Tensor.java:**

    public void writeTo(FloatBuffer var1) {
        if(this.dtype != DataType.FLOAT) {
            throw incompatibleBuffer(var1, this.dtype);
        } else {
            ByteBuffer var2 = this.buffer();
            var1.put(var2.asFloatBuffer());
        }
    }

**FloatBuffer.java:**

    public FloatBuffer put(FloatBuffer src) {
        if (src == this)
            throw new IllegalArgumentException();
        int n = src.remaining();
        if (n > remaining())
            throw new BufferOverflowException();
        for (int i = 0; i < n; i++)
            put(src.get());
        return this;
    }

I am not sure why this happens, as everything else works. In fact, if I try a resolution below 360, the Inception V3 model works perfectly fine. Note that I got the checkpoint model from TF-slim and froze it. I believe the method I used to freeze it works well, since there is no problem for all other models except Inception V3. So I can only conclude the problem lies within the layers. But I am not exactly sure how I can find out which layer is causing the problem, or even if it is because of the layers, I'm not sure how to fix it. I have included the layers of Inception V3 and Inception Resnet V2 in order here:

Inception V3 Layers: https://gist.github.com/kwotsin/82016b003057cdcffec1bc9d1ea1e02b
Inception Resnet V2 Layers: https://gist.github.com/kwotsin/893e11fe171af426091b89645d6a86d3

If it is really the problem within the model, then I thought it could be because of a faulty implementation of a certain operation that is causing overly huge memory consumed.

As an alternative fix, is there a way to check and raise the limit of the buffer size for the app to run successfully?",1,,6,2017-08-28T13:38:11Z,CONTRIBUTOR
12644,compile tensorlfow c++ object class as /clr project to make the dll  fail !!,stat:contributions welcome,"------------------------

### System information
- **windows10**:
- **install tensorflow**: from source by vs2015 
- **TensorFlow version**: r1.2
-**CMake**:  3.8.2 build

### Error List
1. 
>#error instruction:  <condition_variable> is not supported when compiling with /clr or /clr:pure.	CppWrapper	d:\Developer\Microsoft Visual Studio 14.0\VC\include\condition_variable	17	
2. 
>#error instruction:  <mutex> is not supported when compiling with /clr or /clr:pure.	CppWrapper	d:\Developer\Microsoft Visual Studio 14.0\VC\include\mutex	8	
3.
> #error instruction:  <thread> is not supported when compiling with /clr or /clr:pure.	CppWrapper	d:\Developer\Microsoft Visual Studio 14.0\VC\include\thread	8	
4. 
 >e:\tensor\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\eigen\src/Core/ArithmeticSequence.h(205): fatal error C1001: An internal error has occurred in the compiler.
",0,,3,2017-08-28T06:59:00Z,NONE
12637,Adding image captioning examples for iOS (Im2txt) ,"cla: yes,stalled,stat:awaiting response","This is my first ever contribution, so please bear with me.

Recently I've worked to implement [image captioning](https://github.com/tensorflow/models/tree/master/im2txt) with TensorFlow on iOS. To get a sense of what this is like, you can [check out my app](http://perigo.co). I've added an image captioning demo, along with links to the necessary graph and labels - I hope people find it helpful. On modern phones, inference should take a little more than a second. 

Due to the constraints of the C++ API, you'll see that I often have to traverse tensors using a for-loop. Less than ideal, but it seems to do the job.

If you have any questions, concerns, or critique, l'm happy to answer them! (here or via email: liamnakagawa [at] hunterschools.org)

",1,,13,2017-08-27T23:09:36Z,NONE
12610,tf.estimator.inputs.numpy_input_fn does not accept dict as labels.,"stat:contributions welcome,type:feature","### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10 x64
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: r1.3
- **Python version**:  3.5 amd 64
- **Bazel version (if compiling from source)**: Used binary
- **CUDA/cuDNN version**: CUDA 8.0 + CuDNN 6.0
- **GPU model and memory**:  GeForce GTX 1070 8.00GiB


According to the ```tf.estimator.Estimator``` [document](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator), estimator accept dict as labels input. However, when I creating a ```tf.estimator.inputs.numpy_input_fn``` as:
```python
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={""x"": samples.astype(np.float32)},
    y={'go_action': np.full(samples.shape[0], 1), 'operation': ops.astype(np.float32)},
    batch_size=100,
    num_epochs=None,
    shuffle=True)
``` 

then feed it to ```estimator``` like:
```python
action_estimator.train(
    input_fn=train_input_fn,
    steps=20000,
    hooks=[logging_hook])

```

it throw me an error:
```
Traceback (most recent call last):
  File ""G:/Python/onmyoji-hacker/primary/cnnopnet.py"", line 120, in <module>
    hooks=[logging_hook])
  File ""C:\Python\Python35\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 241, in train
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""C:\Python\Python35\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 628, in _train_model
    input_fn, model_fn_lib.ModeKeys.TRAIN)
  File ""C:\Python\Python35\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 499, in _get_features_and_labels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""C:\Python\Python35\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 585, in _call_input_fn
    return input_fn(**kwargs)
  File ""C:\Python\Python35\lib\site-packages\tensorflow\python\estimator\inputs\numpy_io.py"", line 109, in input_fn
    if len(set(v.shape[0] for v in ordered_dict_x.values())) != 1:
  File ""C:\Python\Python35\lib\site-packages\tensorflow\python\estimator\inputs\numpy_io.py"", line 109, in <genexpr>
    if len(set(v.shape[0] for v in ordered_dict_x.values())) != 1:
AttributeError: 'dict' object has no attribute 'shape'

```

",0,,11,2017-08-26T02:18:46Z,NONE
12604,`export_meta_graph` fails if graph has no variables,stat:awaiting response,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.3
- **Python version**: 
3.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8
- **GPU model and memory**:
1060
- **Exact command to reproduce**:
```
import tensorflow as tf

x = tf.placeholder(""float32"")
y = x + x
tf.train.export_meta_graph(""test.meta"")
tf.reset_default_graph()
g = tf.train.import_meta_graph(""test.meta"")
```
yields

**INFO:tensorflow:Saver not created because there are no variables in the graph to restore**

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The export and import meta_graph features fail if a graph has no variables.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf

x = tf.placeholder(""float32"")
y = x + x
tf.train.export_meta_graph(""test.meta"")
tf.reset_default_graph()
g = tf.train.import_meta_graph(""test.meta"")
```",0,,4,2017-08-25T18:03:26Z,NONE
12598,data dependent variable initialization in tf 1.3.0,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ArchLinux
- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`
- **TensorFlow version (use command below)**: `v1.3.0-rc2-20-g0787eee 1.3.0`
- **Python version**: `Python 3.6.2`
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: `cuda 8.0.61`/`cudnn6 6.0.21`
- **GPU model and memory**: GeForce GTX 980M 8GB
- **Exact command to reproduce**:

### Describe the problem
After updating to tf 1.3 my usual routines for data dependent initialization of variables are broken. They take massive amounts of time and memory. I have written a minimal example to reproduce the problem (see below). In fact, the example suggests that the time increases exponentially with the number of layers, i.e. it takes takes roughly 6, 12 and 24 seconds to initialize 10, 11 and 12 layers, respectively. On a different machine running on tf 1.2.1 the same code initializes 100 layers in less than a second yet it produces the same, correct values. Similiarly, the (host) memory usage explodes. I should also mention that the issue appears when defining the graph, i.e. before any session is opened, and not during execution of the initialization operation.

I would be glad if someone can point out a better way of doing the kind of data dependent initialization shown in the example (using two passes is somewhat annoying) but the issue is that the update made this method completely unusable. [Traceback from keyboard interrupt](https://github.com/tensorflow/tensorflow/files/1251882/traceback.txt) suggest that the recently introduced [`_build_initializer_expr`](https://github.com/tensorflow/tensorflow/blob/ebc421daf2c812fdfc3007294741c6c07f4957c3/tensorflow/python/ops/variables.py#L763) might be involved.

### Source code / logs

    import time
    import tensorflow as tf

    def layer(x, name, init):
        with tf.variable_scope(name, reuse = not init):
            initializer = x
            b = tf.get_variable('b', dtype=tf.float32, initializer = initializer)
            # without next if we get error
            # 'Attempting to use uninitialized variable.'
            # for layer 1
            if init:
                return x + b.initialized_value()
            else:
                return x + b


    if __name__ == ""__main__"":
        n_layers = 10

        print(""tensorflow {} {}"".format(tf.GIT_VERSION, tf.VERSION))
        print(""n_layers {}"".format(n_layers))

        def _pass(x, init):
            h = x
            for i in range(n_layers):
                h = layer(h, ""layer_{}"".format(i), init)
            return h
        
        # first pass for initialization
        x = tf.constant([1.0])
        t = time.time()
        h = _pass(x, True)
        print(""init pass {:.4}"".format(time.time() - t))

        # second pass as usual
        t = time.time()
        h = _pass(x, False)
        print(""next pass {:.4}"".format(time.time() - t))

        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            print(""final value {}"".format(h.eval()))


This is basically the data dependent initialization method as described in [OpenAI's weight norm code](https://github.com/openai/weightnorm) stripped down to the bare minimum where the problem occurs. This weight normalization code as well as the [PixelCNN++ code](https://github.com/openai/pixel-cnn) are also affected by this.

Output on 1.3.0:

    tensorflow v1.3.0-rc2-20-g0787eee 1.3.0
    n_layers 10
    init pass 5.934
    next pass 0.003919
    final value [ 1024.]

Output on 1.2.1 (different machine):

    tensorflow 1.2.1
    n_layers 10
    init pass 0.1085
    next pass 0.00644
    final value [ 1024.]




",0,,5,2017-08-25T13:14:52Z,NONE
12596,Feature request: QueueRunner for C++ API that initializes from queues and ops and start with ClientSession,"stat:contributions welcome,type:feature","Right now there is an implementation of QueueRunner in ""tensorflow/cc/training/queue_runner.h"". It's created from a QueueRunnerDef that is initialized with string names rather than queues and ops objects. QueueRunner's current implementation is also started by using the ""Session"" low level class rather than the newer ""ClientSession"" class.",0,,0,2017-08-25T13:00:46Z,NONE
12587,[building tensorflow with bazel]Error:Constants.h:429:2: error: #error The preprocessor symbol 'Success' is defined,stat:awaiting tensorflower,"- Environment information:

Ubuntu version: 14.04
bazel version: 0.5.1
tensorflow version:  r 1.1
cuda version: 8.0.44
cudnn version: 5.1.5
command: bazel build tensorflow/examples/PreProcess_modify

- Describe the problem:

tensorflow/examples/PreProcess_modify/BUILD:10:1: C++ compilation of rule '//tensorflow/examples/PreProcess_modify:chartest' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 130 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:360:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:4,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/cc/framework/ops.h:21,
                 from ./tensorflow/cc/ops/const_op.h:19,
                 from ./tensorflow/examples/PreProcess_modify/Tensorflow/TFClassifier.h:29,
                 from ./tensorflow/examples/PreProcess_modify/include/GameRecognize.h:14,
                 from ./tensorflow/examples/PreProcess_modify/GameRecog/CharRecognize.h:23,
                 from tensorflow/examples/PreProcess_modify/Projects/Src/chartest.cpp:13:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:429:2: error: #error The preprocessor symbol 'Success' is defined, possibly by the X11 header file X.h
 #error The preprocessor symbol 'Success' is defined, possibly by the X11 header file X.h
  ^
In file included from /usr/include/X11/Xlib.h:44:0,
                 from ./tensorflow/examples/PreProcess_modify/Os/TqcOs.h:21,
                 from tensorflow/examples/PreProcess_modify/Projects/Src/chartest.cpp:11:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:436:3: error: expected identifier before numeric constant
   Success = 0,        
   ^
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:436:3: error: expected '}' before numeric constant
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:436:3: error: expected unqualified-id before numeric constant
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:360:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:4,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/cc/framework/ops.h:21,
                 from ./tensorflow/cc/ops/const_op.h:19,
                 from ./tensorflow/examples/PreProcess_modify/Tensorflow/TFClassifier.h:29,
                 from ./tensorflow/examples/PreProcess_modify/include/GameRecognize.h:14,
                 from ./tensorflow/examples/PreProcess_modify/GameRecog/CharRecognize.h:23,
                 from tensorflow/examples/PreProcess_modify/Projects/Src/chartest.cpp:13:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Constants.h:549:1: error: expected declaration before '}' token
 } // end namespace Eigen
 ^
INFO: Elapsed time: 678.166s, Critical Path: 5.46s",0,,4,2017-08-25T07:07:26Z,NONE
12579,[building tensorflow with bazel ] Error:C++ compilation of rule '@boringssl//:crypto' failed.,stat:awaiting tensorflower,"  **Environment:
    GCC 4.9.1
    glibc :2.11.3
    bazel:0.4.0/0.4.5/0.5.3(these versions have been tried)
    OS: SUSE 
 It seems that boringssl can't work with command `bazel build --copt=-march=native -c opt //tensorflow/tools/pip_package:build_pip_package`. Here is the  log:**

  WARNING: /hdata/users/rll/tensorflow/tensorflow/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /hdata/users/rll/tensorflow/tensorflow/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Found 1 target...
ERROR: /var/lib/hive/.cache/bazel/_bazel_hive/e5053b6fc588ac2d9981b522e9f221e1/external/boringssl/BUILD:116:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1).
In file included from /usr/include/fcntl.h:38:0,
                 from external/boringssl/src/crypto/bio/socket_helper.c:21:
/usr/include/sys/stat.h:372:56: error: array type has incomplete element type
 extern int futimens (int __fd, __const struct timespec __times[2]) __THROW;
                                                        ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 47.092s, Critical Path: 17.01s
",0,,9,2017-08-25T02:32:21Z,NONE
12570,"No gradient for `cdf`, `sample` and other functions for several distributions in `tf.distributions`","stat:contributions welcome,type:feature","------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (pip)
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 8.0 cuDNN 6
- **GPU model and memory**: nVIDIA K2100M, 2G
- **Exact command to reproduce**: See below
dist_par = tf.Variable(1.0)
dist = tf.distributions.Beta(dist_par,1.0)
print(tf.gradients(dist.cdf(0.5), dist_par))

>> [None]

The output says there is no gradient.

### Describe the problem
For several distributions such as `Beta` and `Gamma`, there is no gradient of their functions such as `cdf`, `log_cdf`, `sample` with respect to the parameters of these distributions. While gradients are provided for these functions of distributions such as `Normal` and `Laplace`.
I think theoretically the gradients should exist. And they are useful when people build a model in which samples drawn from these distributions as prior distributions are marginalized while the parameters of these distributions are optimized. It would be nice if they can be implemented
Thanks!

### Source code / logs
See above
",0,,8,2017-08-24T21:39:50Z,NONE
12569,missing Documentation of the method AttentionWrapper.zero_state(...),type:docs,"Hello , 


I have noticed that the method AttentionWrapper.zero_state( batch_size,dtype) does not have any description of its functionality in the  documentation website , below is a reference link : 
https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionWrapper

I really hope that this gets fixed , I have spent a couple of days trying to debug a code that I have written until I realized that I was misusing the method . 


thank you ",1,,9,2017-08-24T21:04:12Z,NONE
12568,'module' object has no attribute 'sparse_column_with_vocabulary_file',,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Running on Cloud ML Engine
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**:  2.7


### Describe the problem
I am trying to use tf.contrib.layers.sparse_column_with_vocabulary_file() and I am getting an error that it does not exist. I recognize that it is not showing up when I search for it in the API, but it is showing up in the source code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/feature_column.py#L669) -- I even specified the r1.3 branch and it was still showing up.  Has this been removed and I am just looking in the wrong place? It seems like this may be a bug and the function should exist in 1.3?

If it was deprecated is it because there are workarounds when trying to generate a feature column from a sparse tensor of words? I can create the hash table with:

```
table = tf.contrib.lookup.index_table_from_file(vocabulary_file = vocab_file)
table.lookup(word)
``` 
but since I am trying to add this in the feature columns, I need something to read in the sparse tensor of words in ie. 
`words = tf.contrib.layers.???` or `words = tf.feature_column.???`

Or (Assuming deprecation) is the suggested implementation just to do all of these transformations in the `input_fn():` and just pass a sparse_column_with_integerized_feature() directly. Personally this feels awkard to perform half of the transformation in the input function but without sparse_column_with_vocabulary_file it feels like there is no other choice:

With this function it should be easy to go from:
""This is a sentence"" --> tf.string_split() yields [""This"", ""is"", ""a"", ""sentence""] (sparse tensor of strings) within the input_fn --> and then tf.contrib.sparse_column_with_vocabulary_file (sparse tensor of ids) --> tf.contrib.layers.embedding_column() which yields the embedding from a sparse tensor of id's.
",1,,6,2017-08-24T20:54:06Z,NONE
12560,"after ops_to_register.h changed, IOS camera example still return No OpKernel support 'Less' op",,"### System information
Run on MacOS 10.12
Xcode 8.3.3
Python 3.5
tensorflow 1.2.1 installed with anaconda 
bazel 0.5.2-homebrew

### Main Problem: 
Although I changed ops_to_register.h file and recompile the static library, IOS camera example code still returned No OpKernel support 'Less' op error. **The same library works fine** in another project [JieHe's ios-tensorflow object detection project](https://github.com/JieHe96/iOS_Tensorflow_ObjectDetection_Example) when I replace the model load the model. I can't tell why I got the issues with official tensorflow ios code.

### Describe the problem
I trained my model based on the ssd_mobilenet network. T hen the model was optimized for usage on ios. Freeze it with `export_inference_graph.py`, optimize it with` optimize_for_inference.py`, and then binary reduced the size with `bazel build -c tensorflow/tools/graph_transforms:transform_graph`

In that, the model was well-generated as desired. 


**For the static library:**
And then I try to import the model into my app. So I print all the ops and put the file under tensorflow/core/framework. 

>   bazel build tensorflow/python/tools:print_selective_registration_header 
  bazel-bin/tensorflow/python/tools/print_selective_registration_header \
    --graphs=path/to/graph.pb > ops_to_register.h

In the Makefile, first delete the line ""-D__ANDROID_TYPES_SLIM__ "" under ""# Settings for iOS."" for all ""$(IOS_ARCH)"". And run

```
tensorflow/contrib/makefile/download_dependencies.sh
tensorflow/contrib/makefile/compile_ios_protobuf.sh 
tensorflow/contrib/makefile/compile_ios_tensorflow.sh ""-O3  -DANDROID_TYPES=ANDROID_TYPES_FULL -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION""
```
After I generated the static tensorflow library, I `pod install` the podfile in camera example as required. Modified the input/output tensor and try to build the app. However, the same error with ""No kernel registed XXX"" still occurs .

I also tried my model and the same library on [JieHe's ios-tensorflow code](https://github.com/JieHe96/iOS_Tensorflow_ObjectDetection_Example), it can run smoothly. So I assumed] my static library was well generated to including all the ops I need. So I don't really know how to solve it with the example code?

My error log: 

> 2017-08-24 17:21:18.679927: F /Users/yingjie/tensorflow-master/tensorflow/examples/ios/App-test/camera/CameraExampleViewController.mm:730] Couldn't load model: Invalid argument: No OpKernel was registered to support Op 'Less' with these attrs.  Registered devices: [CPU], Registered kernels:
  device='CPU'; T in [DT_FLOAT]",1,,5,2017-08-24T17:28:53Z,NONE
12553,Object detection evaluation warning,stat:awaiting tensorflower,"Hi,
Here is my system details:

- macOS10
- no GPU
- python3.6
- tensorflow1.3
- installed tf from source

I'm running the evaluation of object detection, but every time I run into this warning:

```
WARNING:root:The following classes have no ground truth examples: 0
/Users/Mohamad/Projects/Python/tensorflow/models/object_detection/utils/metrics.py:145: RuntimeWarning: invalid value encountered in true_divide
  num_images_correctly_detected_per_class / num_gt_imgs_per_class)
```
I want to know how to solve this warning? Is it something serious?

Thanks.",0,,11,2017-08-24T09:19:27Z,NONE
12549,layers.py spatial_softmax activation can be selected by user,"cla: yes,stat:awaiting response","Allow user specified activation functions to be selected when calling `spatial_softmax`. 

I wanted to keep the changes minimal, but it may be worth considering a rename of the layer to `spatial_activation` with softmax as the default. `spatial_softmax` could simply call `spatial_activation` or be removed. Thoughts?",2,,15,2017-08-24T07:26:02Z,NONE
12538,FPGA Implementation on TensorFlow,"stat:contributions welcome,type:feature","Hi all,

Recently, I read some papers about implementing Intel Xeon Phi on Tensorflow. Therefore, I want to make TensorFlow support FPGA board. But there is no information in Google and other forum/community.

For my understanding, we should implement the FPGA supporting in a class of TensorFlow which distributes tasks to different devices (like GPU/CPU). Is possible that implementing the FPGA supporting in that class? Or is there any good suggestions to make the progress to support FPGA on TensorFlow? 

I am looking forward any help or advice!

Thanks,
Kevin",0,,2,2017-08-23T20:52:36Z,NONE
12537,Printing lines without logging prefix using tf.Print(),"stat:contributions welcome,type:feature","Right now, all messages printed via `tf.Print()` are prefixed by:

```
<timestamp>: I tensorflow/core/kernels/logging_ops.cc:79]
```

It would be useful to have a way to print user-friendly output from within the graph. Therefore, suggest adding a parameter for the logging format to `tf.Print()`, or at least adding a flag that disables the logging prefix.",0,,1,2017-08-23T20:30:21Z,MEMBER
12523,[feature request] Need QuantizedFusedBatchNorm ,stat:awaiting tensorflower,There is no QuantizedFusedBatchNorm operator. The graph transform tools treats FusedBatchNorm operator with fold_old_batch_morm. But not all bns are ready to be folded. This will leave many isolated un-quantized fbn ops in the graph.,0,,4,2017-08-23T10:43:02Z,NONE
12522,Stacking CNN with LSTM,,"I am trying to stack CNN before LSTM, however, I am experience a little problem. 
My LSTM + CTC works fine. However, I want to pass extracted feature from CNN to LSTM instead of whole image. 

The code is here: https://gist.github.com/kjanjua26/b756b6aae2277423c1f94b435a82f808

I error I am facing is: 

`File ""trainer2.py"", line 182, in <module>
    train()
  File ""trainer2.py"", line 75, in train
    logits, inputs, targets, seq_len,W, b = model.get_train_model()
  File ""/home2/kamranjanjua/tf_cnnlstm/tlstm9Aug/model.py"", line 97, in get_train_model
    outputs, _ = tf.nn.bidirectional_dynamic_rnn(forwardH1,backwardH1,x,seq_len,dtype=tf.float32)
  File ""/home/kamranjanjua/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 652, in bidirectional_dynamic_rnn
    time_major=time_major, scope=fw_scope)
  File ""/home/kamranjanjua/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 845, in dynamic_rnn
    dtype=dtype)
  File ""/home/kamranjanjua/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 919, in _dynamic_rnn_loop
    ""Input size (depth of inputs) must be accessible via shape inference,""
ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.`

Any help in this matter would be appreciated. I am kind of stuck here. 

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 0.12 (Using this on purpose since my older code works in 0.12 and I didn't update it for the new version.
- **Python version**: 2.7
- **GPU model and memory**: TitanX, 12 GB
",1,,13,2017-08-23T09:53:02Z,NONE
12514,incorrect gradient of real(reduce_prod(complex(...))),,"### Describe the problem
Tensorflow computes the wrong result for the following gradient:
```python
import tensorflow as tf
x = tf.Variable(1.0)
E = tf.real(tf.reduce_prod(tf.complex( [x,x], [2*x,2*x] )))
sess = tf.Session()
sess.run(tf.variables_initializer([x]))
sess.run(tf.gradients(E,x))
```
Tensorflow returns 10.0
The correct result is -6 since:
```
E = real((x+2i*x)^2) = real((1+2i)^2) * x^2 = real(1+4i-4) * x^2 = -3*x^2
dE/dx = -6*x = -6 for x=1
```
Below is mathematically equivalent code for E, for which Tensorflow returns the correct result of -6.0:
```python
E = tf.real( tf.complex(x,2*x) * tf.complex(x,2*x) )
E = tf.real(tf.exp(tf.reduce_sum(tf.log(tf.complex( [x,x], [2*x,2*x] )))))
```

### System information
Linux distribution = Arch Linux (up to date)
TensorFlow was installed from the Arch Linux package python-tensorflow
I'm using an x86_64 CPU. I'm not using my GPU.
numpy (1.13.1)
protobuf (3.3.2)
tensorflow (1.3.0)
python (3.6.2)",1,,4,2017-08-23T05:28:20Z,CONTRIBUTOR
12500,Tensorflow Debugger crashes on tab complete,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary (pip wheel)
- **TensorFlow version (use command below)**: 1.3
- **Python version**:  3.5
- **GPU model and memory**: (CPU only)

### Describe the problem
Sometimes when using `tfdbg`, tab-completing on `pt` will crash the debugger (unfortunately, I haven't figured out how to reproduce this consistently yet) and my terminal will look like:

![screenshot from 2017-08-22 14-44-11](https://user-images.githubusercontent.com/1914111/29582837-2a0cd4d8-874c-11e7-899d-8430575ce1ba.png)

the terminal will be unresponsive, and scrolling + regular mouse selection will be disabled (although `SHIFT` + mouse selection will work).

### Source code / logs

Reconstructing the traceback:

```
Traceback (most recent call last):
File ""GenerativeLSTM.py"", line 151, in <module>
    m.train(klabels, config={""epochs"": 30, ""batch_size"": 1})
File ""GenerativeLSTM.py"", line 140, in train
    [next_batch, (train_step, merged)], feed_dict)
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/wrappers/framework.py"", line 532, in run
    run_end_resp = self.on_run_end(run_end_req)
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py"", line 338, in on_run_end
    self._run_start_response = self._launch_cli()
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py"", line 429, in _launch_cli
        title_color=self._title_color)
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 502, in run_ui
    exit_token = self._ui_loop()
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 578, in _ui_loop
    tab_completed = self._tab_complete(command)
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 1507, in _tab_complete
    self._display_candidates(candidates)
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 1554, in _display_candidates
    pad, _, _ = self._display_lines(candidates_output, 0)
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 1130, in _display_lines
    pad = self._screen_new_output_pad(rows, cols)
File ""/home/alan/workspace/cognescent/py3.venv/lib/python3.5/site-packages/tensorflow/python/debug/cli/curses_ui.py"", line 978, in _screen_new_output_pad
    return curses.newpad(rows, cols)
_curses.error: curses function returned NULL
```

As I said, I unfortunately have not figured out how to reproduce this regularly -- this happens every once in a while when I'm working on the LSTM from #12465. I'll try to create a minimal reproducible test case later, but I figured I'd file this ticket first.",1,,5,2017-08-22T19:25:32Z,CONTRIBUTOR
12496,SSL certificate for tensorflow.org expired,type:docs,The SSL certificate for https://tensorflow.org (*not* https://www.tensorflow.org) expired on June 29.,1,,9,2017-08-22T15:25:02Z,CONTRIBUTOR
12487,Make scatter_* kernels to be multiple thread and gain 8x speedup.,"awaiting testing (then merge),cla: yes,stalled,stat:awaiting response","Relate to [12358](https://github.com/tensorflow/tensorflow/issues/12358).
Use the lock to deal with the duplicate. After some test, the results show the atomic_flag and spin lock are the best choice and the performance is close  to the lock-free mode.
Benchmark with tfprof, the result shows about 8x speedup.
### Env
- **CPU**
32-cores
- **MEM**
126G
### Parameters
- ref: 10000000*100
- indices: 128000
- updates: 128000*100
```
# orignial
ScatterSub                    4400.00MB (65.69%, 6.66%),        39.50ms (43.19%, 9.00%),            0us (47.10%, 0.00%),        39.50ms (43.14%, 9.11%)
# lock-free
ScatterSub                    4400.00MB (65.69%, 6.66%),         3.84ms (50.64%, 2.20%),            0us (46.37%, 0.00%),         3.84ms (50.76%, 2.27%)
# with lock
ScatterSub                    4400.00MB (65.69%, 6.66%),         4.70ms (50.06%, 2.81%),            0us (45.62%, 0.00%),         4.70ms (50.19%, 2.90%)
```",1,,45,2017-08-22T12:05:27Z,CONTRIBUTOR
12486,Feature request: stop requiring the same dtype for inputs in tf.shape_n,"stat:contributions welcome,type:feature","As for Tensorflow 1.3, [tf.shape_n](https://www.tensorflow.org/api_docs/python/tf/shape_n) takes a list of tensors as input to produce a list of shapes as output. However, it produces an error if tensors of different types are provided. As far as I can tell, whether tensors are the same type or not is completely irrelevant to the behavior of this function, making it an arbitrary constraint that limits its functionality for no particular reason.

Would it be possible to remove such restriction if there's no good reason to keep it?
",0,,3,2017-08-22T10:54:28Z,CONTRIBUTOR
12475,Feature request: sparse_tensor_dense_matmul optimization on GPU,stat:contributions welcome,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 8 (jessie)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.3.0-rc2-0-g2784b1c', '1.3.0-rc2')
- **Python version**: 2.7.9
- **Bazel version (if compiling from source)**: 0.5.3
- **CUDA/cuDNN version**: 8.0 / 5.0
- **GPU model and memory**: Nvidia GeForce GTX TITAN X
- **Exact command to reproduce**:

I would like to optimize sparse_tensor_dense_matmul operation on GPU to process sparse input completely on GPU. Now code like this:
```
import tensorflow as tf

with tf.device('/gpu:0'):
    st = tf.SparseTensor(
        tf.constant([[0, 0], [1, 1]], dtype=tf.int64),
        tf.constant([1.2, 3.4], dtype=tf.float32),
        tf.constant([2, 2], dtype=tf.int64)
    ) 
    v = tf.Variable([[1.0, 0.0], [0.0, 1.0]], dtype=tf.float32)
    st = tf.sparse_tensor_dense_matmul(st, v)
    st = tf.reduce_min(st)
    optimizer = tf.train.AdamOptimizer()
    trainer = optimizer.minimize(st)

with tf.Session() as sess:
    print(sess.run(trainer))
```
Fails with error:
```
Traceback (most recent call last):
  File ""test_tf3.py"", line 18, in <module>
    print(sess.run(trainer))
  File ""/media/awork/home/astepochkin/drecs/repo/env/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/media/awork/home/astepochkin/drecs/repo/env/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/media/awork/home/astepochkin/drecs/repo/env/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/media/awork/home/astepochkin/drecs/repo/env/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1 = StridedSlice[Index=DT_INT32, T=DT_INT64, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=""/device:GPU:0""](Const, gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1/stack, gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1/stack_1, gradients/SparseTensorDenseMatMul/SparseTensorDenseMatMul_grad/strided_slice_1/stack_2)]]
```
It looks like it requires ""int64 strided slice"" to be executed on GPU. So maybe it just needs to enable int64 strided slice on GPU.",0,,5,2017-08-22T06:03:58Z,NONE
12473,[bug] gradients of scatter_nd_add return None ,stat:contributions welcome,"The gradient of scatter_nd_add  always return None.  If the gradient is not implemented, it should raise an exception. 

```python

import tensorflow as tf
import numpy as np 
import matplotlib.pyplot as plt
rng = np.random



x = tf.Variable(np.random.random((2, 4)).astype('float32'))
indice = tf.Variable(np.random.randint(0, 4, size=(2, 4, )), dtype=tf.int32)




x_val = np.random.random((2, 4))
indice_val = np.random.randint(0, 4, size=(2, 4, ))
val_val = np.random.random((2, 4))


# tf Graph Input
X = tf.placeholder(""float"")
Y = tf.placeholder(""float"")


# Set model weights
W = tf.Variable(np.random.random((2, 4)).astype('float32'), name=""weight"")
b = tf.Variable(np.random.random((2, )).astype('float32'), name=""bias"")

# Construct a linear model
pred = tf.add(tf.multiply(X, W), b)

y = tf.scatter_nd_add(x, indice, pred)


grad = tf.gradients(y, [W,b])

```",0,,4,2017-08-22T03:25:00Z,NONE
12465,Tensorflow Debugger eats disk space with RNNs,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3
- **Python version**:  3.5

### Describe the problem

I have an RNN that I'm trying to debug using `LocalCLIDebugWrapperSession` which runs on very long sequences (4800 steps). Even for a basic LSTM cell that I apply via `tf.nn.dynamic_rnn`, `tfdbg` uses a lot of disk space (>5 GB sometimes). When I accidentally collected gradient infromation via `tf.contrib.layers.optimize_loss(..., summaries=[""gradients"", ...])`, this ballooned even more to >70 GB (which promptly crashed my laptop).

From inspecting the `tfdbg` dump in `/tmp/`, it looks like this is because tfdbg` dumps out information for each time step. Especially with `tf.contrib.layers.optimize_loss` capturing gradients, this means that there are hundreds (thousands?) of small files being created on each time step.

In some sense, this is expected behavior (each time step represents a group of TF operations), but using 70 GB seems like a pretty sharp-edged API that's easy to mis-use. I'm not sure what to really do here -- maybe there's a way to somehow compress these files or to combine all these small files across time steps into one large file? It could also just be a documentation problem.",1,,6,2017-08-21T23:56:09Z,CONTRIBUTOR
12460,TensorFlow Android 1.2 - Adds READ_PHONE_STATE permission,,,1,,6,2017-08-21T21:51:15Z,NONE
12454,Misleading error message on type mismatch,"stat:contributions welcome,type:feature","- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Archlinux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 3.6
```python
import tensorflow as tf
x = tf.get_variable('asdfds', shape=[10], dtype=tf.int32)
x*0.5
```
Prints:
```
Traceback (most recent call last):               
  File ""a.py"", line 9, in <module>               
    x*0.5                                        
TypeError: unsupported operand type(s) for *: 'Variable' and 'float' 
```
Variable with matching dtype can multiply with float, the problem here is int32 cannot multiply with float.
Since usually the dtype of some tensor is not directly written in code, this misleading message can cause confusions.",0,,3,2017-08-21T17:31:51Z,CONTRIBUTOR
12408,[XLA][WIP] Add support for Polyhedral compilation through Polly,"cla: yes,stat:awaiting response","Added Bazel build files for compiling Polly with LLVM to enable Polyhedral compilation, as discussed in #8100",1,,18,2017-08-19T06:46:04Z,NONE
12389,Python quit unexpectedly while using the _batch_ops.so plug-in.,stat:awaiting tensorflower,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**: both source and binary
- **TensorFlow version (use command below)**: ('v1.3.0-0-g9e76bf324', '1.3.0')
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**: 0.5.3-homebrew
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**:pydoc modules



### Describe the problem


Every time I use _pydoc modules_, it crashes with this message:
_python(9152,0x7fffbdeb33c0) malloc: *** error for object 0x11531fb58: pointer being freed was not allocated_

The same result for both 1.2.1 and 1.3.0, official build or custom builds.


### Source code / logs

The backtrace:
Thread 0 Crashed:: Dispatch queue: com.apple.main-thread
0   libsystem_kernel.dylib        	0x00007fffb50cdd42 __pthread_kill + 10
1   libsystem_pthread.dylib       	0x00007fffb51bb457 pthread_kill + 90
2   libsystem_c.dylib             	0x00007fffb5033420 abort + 129
3   libsystem_malloc.dylib        	0x00007fffb5122fe7 free + 530
4   _batch_ops.so                 	0x0000000119fb853c tensorflow::OpDef::SharedDtor() + 108
5   _batch_ops.so                 	0x0000000119fb838c tensorflow::OpDef::~OpDef() + 28
6   _batch_ops.so                 	0x0000000119f4b274 _GLOBAL__sub_I_batch_ops.cc + 388
7   dyld                          	0x000000010ea9aa1b ImageLoaderMachO::doModInitFunctions(ImageLoader::LinkContext const&) + 385
8   dyld                          	0x000000010ea9ac1e ImageLoaderMachO::doInitialization(ImageLoader::LinkContext const&) + 40
9   dyld                          	0x000000010ea964aa ImageLoader::recursiveInitialization(ImageLoader::LinkContext const&, unsigned int, char const*, ImageLoader::InitializerTimingList&, ImageLoader::UninitedUpwards&) + 338
10  dyld                          	0x000000010ea95524 ImageLoader::processInitializers(ImageLoader::LinkContext const&, unsigned int, ImageLoader::InitializerTimingList&, ImageLoader::UninitedUpwards&) + 138
11  dyld                          	0x000000010ea955b9 ImageLoader::runInitializers(ImageLoader::LinkContext const&, ImageLoader::InitializerTimingList&) + 75
12  dyld                          	0x000000010ea8a7cd dyld::runInitializers(ImageLoader*) + 87
13  dyld                          	0x000000010ea923ec dlopen + 556
14  libdyld.dylib                 	0x00007fffb4f9c832 dlopen + 59
15  _pywrap_tensorflow_internal.so	0x0000000110c3165f tensorflow::internal::LoadLibrary(char const*, void**) + 47
16  _pywrap_tensorflow_internal.so	0x0000000110c30b74 tensorflow::(anonymous namespace)::PosixEnv::LoadLibrary(char const*, void**) + 20
17  _pywrap_tensorflow_internal.so	0x0000000110b27f17 tensorflow::LoadLibrary(char const*, void**, void const**, unsigned long*) + 1431
18  _pywrap_tensorflow_internal.so	0x000000010edaff44 TF_LoadLibrary + 52
19  _pywrap_tensorflow_internal.so	0x000000010eb2b452 _wrap_TF_LoadLibrary(_object*, _object*) + 162
20  org.python.python             	0x00000001096fd4d4 PyEval_EvalFrameEx + 14624
21  org.python.python             	0x00000001096f99be PyEval_EvalCodeEx + 1617
22  org.python.python             	0x00000001097003e2 0x109677000 + 562146
23  org.python.python             	0x00000001096fce4e PyEval_EvalFrameEx + 12954
24  org.python.python             	0x00000001096f99be PyEval_EvalCodeEx + 1617
25  org.python.python             	0x00000001097003e2 0x109677000 + 562146
26  org.python.python             	0x00000001096fce4e PyEval_EvalFrameEx + 12954
27  org.python.python             	0x00000001096f99be PyEval_EvalCodeEx + 1617
28  org.python.python             	0x00000001096f9367 PyEval_EvalCode + 48
29  org.python.python             	0x000000010970e6bd PyImport_ExecCodeModuleEx + 241
30  org.python.python             	0x00000001097113c7 0x109677000 + 631751
31  org.python.python             	0x0000000109710e2c 0x109677000 + 630316
32  org.python.python             	0x0000000109710a00 0x109677000 + 629248
33  org.python.python             	0x000000010970fc10 PyImport_ImportModuleLevel + 1185
34  org.python.python             	0x00000001096f5006 0x109677000 + 516102
35  org.python.python             	0x00000001096816fb PyObject_Call + 99
36  org.python.python             	0x00000001096ffdbb PyEval_CallObjectWithKeywords + 165
37  org.python.python             	0x00000001096fbc0f PyEval_EvalFrameEx + 8283
38  org.python.python             	0x00000001096f99be PyEval_EvalCodeEx + 1617
39  org.python.python             	0x00000001096f9367 PyEval_EvalCode + 48
40  org.python.python             	0x000000010970e6bd PyImport_ExecCodeModuleEx + 241
41  org.python.python             	0x00000001097113c7 0x109677000 + 631751
42  org.python.python             	0x000000010971164f 0x109677000 + 632399
43  org.python.python             	0x0000000109710e2c 0x109677000 + 630316
44  org.python.python             	0x0000000109710a00 0x109677000 + 629248
45  org.python.python             	0x000000010970fc10 PyImport_ImportModuleLevel + 1185
46  org.python.python             	0x00000001096f5006 0x109677000 + 516102
47  org.python.python             	0x00000001096fd4d4 PyEval_EvalFrameEx + 14624
48  org.python.python             	0x0000000109696b00 0x109677000 + 129792
49  org.python.python             	0x00000001096fa0ec PyEval_EvalFrameEx + 1336
50  org.python.python             	0x0000000109696b00 0x109677000 + 129792
51  org.python.python             	0x00000001096fa0ec PyEval_EvalFrameEx + 1336
52  org.python.python             	0x0000000109696b00 0x109677000 + 129792
53  org.python.python             	0x00000001096fa0ec PyEval_EvalFrameEx + 1336
54  org.python.python             	0x00000001096f99be PyEval_EvalCodeEx + 1617
55  org.python.python             	0x00000001097003e2 0x109677000 + 562146
56  org.python.python             	0x00000001096fce4e PyEval_EvalFrameEx + 12954
57  org.python.python             	0x00000001096f99be PyEval_EvalCodeEx + 1617
58  org.python.python             	0x00000001097003e2 0x109677000 + 562146
59  org.python.python             	0x00000001096fce4e PyEval_EvalFrameEx + 12954
60  org.python.python             	0x0000000109700475 0x109677000 + 562293
61  org.python.python             	0x00000001096fce4e PyEval_EvalFrameEx + 12954
62  org.python.python             	0x0000000109700475 0x109677000 + 562293
63  org.python.python             	0x00000001096fce4e PyEval_EvalFrameEx + 12954
64  org.python.python             	0x00000001096f99be PyEval_EvalCodeEx + 1617
65  org.python.python             	0x00000001096f9367 PyEval_EvalCode + 48
66  org.python.python             	0x00000001097195dd 0x109677000 + 665053
67  org.python.python             	0x0000000109719680 PyRun_FileExFlags + 133
68  org.python.python             	0x00000001097191d1 PyRun_SimpleFileExFlags + 702
69  org.python.python             	0x000000010972ab6a Py_Main + 3094
70  libdyld.dylib                 	0x00007fffb4f9f235 start + 1",0,,6,2017-08-18T10:08:07Z,NONE
12357,tf.contrib.slim evaluation: outdated documentation,stat:contributions welcome,"https://github.com/tensorflow/tensorflow/blob/d7fa7ae8ac15118393b6a549eb98ec9ca23497c0/tensorflow/contrib/slim/python/slim/evaluation.py
The documentation to this, in the first section (Evaluating metrics) uses this code to do the evaluation of the metrics directly (within an existing session, without having to reference a specific checkpoint):
```
  with tf.Session() as sess:
    metric_values = slim.evaluation(
        sess,
        num_evals=1,
        inital_op=initial_op,
        eval_op=names_to_updates.values(),
        final_op=name_to_values.values())
```
This code, however, does not work anymore, as the function `slim.evaluation` doesn't exist now.
what would now be the preferred way to do this?  ",0,,5,2017-08-17T10:54:20Z,NONE
12345,PEP 484 Type Annotations (feature request),"stat:contributions welcome,type:feature","### System information
N/A

### Describe the problem
## Background
PEP 484 [1] added support for type hints in Python. These are purely annotations and are not enforced by the interpreter, however there are tools such as mypy [2] which can be run to check for consistency in the annotations. The typeshed initiative [3] has started to build external collections of type annotations for commonly used libraries.

When adding type annotations to a codebase, it is best if you can achieve near 100% coverage, otherwise uncertainty propagates out from everywhere the ""untyped"" code is called. A codebase using TF would likely struggle to gain much benefit from type-checking in any of the core code built on top of TF.

## Benefits of Adding Type Annotations
 * The expected inputs and outputs of functions become much clearer
 * Code completion is able to provide more useful suggestions, boosting productivity by reducing amount of time spent referring to docs
 * Static analysis can uncover latent bugs (case study here[5])

## Difficulties/Drawbacks
 * People may be encouraged to overly constrain types, removing some of the flexibility of a dynamic language. But given that Google's Python style-guide discourages ""Power Features"" [4] I would argue that striving towards code that is explicit is a similar philosophy
 * The protobuf compiler would need to be augmented to generate type annotations.
 * The Tensorflow Python codebase is huge, so at this point adding the annotations would be a huge undertaking.
 * Tensorflow still supports python 2.7, 3.3 and 3.4 which do not have the type annotation syntax. So if this were implemented it would probably have to be in external *.pyi files, which is harder to maintain compared to inline type annotations in the source code.

## Final thoughts
I realise that this would be a major undertaking and wouldn't be likely to ship any time soon, but I'm curious to gauge Google's thoughts on this new feature in Python. I'm about to start building a new codebase from scratch and was keen to use it as a chance to try out type annotations. I probably still will give it a shot, but I suspect that unless most of the common data science libs out there adopt this standard then its usefulness will be quite limited.

[1] https://www.python.org/dev/peps/pep-0484/
[2] http://mypy-lang.org/
[3] https://github.com/python/typeshed
[4] https://google.github.io/styleguide/pyguide.html#Power_Features
[5] http://blog.zulip.org/2016/10/13/static-types-in-python-oh-mypy/",0,,7,2017-08-17T02:33:49Z,NONE
12330,Request for computation of hessian wrt tensor of shape 1 x n,stat:contributions welcome,"There currently exists tf.hessians function which returns 2nd order *y* derivatives w.r.t. to a specified tensor *x*. Currently *x* has to be one dimensional.

In my application, I need to differentiate with respect to a tensor that has dimensions batch_size x layer_width. (I am interested in second derivative of output from neural net with respect to a particular layer.) I can bring dimensionality down to 1 x layer_width, by setting batch_size to 1. Unfortunately, this still does not let me use tf.hessian.

Would it be possible to add functionality where hessian w.r.t. *effectively* one-dimensional tensors can be computed? So that, for example tensors of shape 1 x n (or 1 x 1 x n) can be used. It feels like it shouldn't be a hard problem, but I'm completely lost when I look at tf.gradients code.

Thanks",0,,8,2017-08-16T14:01:49Z,NONE
12326,"import tensorflow error with correct installation,  the problem  is ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options""",,"Hi, everyone.

------------------------

### System information
Operating System: Ubuntu 16.04 LTS
Graphics card: Tesla K40
Installed version of CUDA: 8.0 
Installed version of cuDNN: v5 , for CUDA 8.0 
pip --version 9.0.1
pip 9.0.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)

Tensorflow-gpu installed from pip
$sudo pip install tensorflow-gpu
Version: 1.2.1

----------------------------------------------------------------
pip version
Name: pip
Version: 9.0.1
Summary: The PyPA recommended tool for installing Python packages.
Home-page: https://pip.pypa.io/
Author: The pip developers
Author-email: python-virtualenv@groups.google.com
License: MIT
Location: /usr/local/lib/python2.7/dist-packages
Requires: 
--------------------------------
tensorboard version 

Name: tensorboard
Version: 1.0.0a6
Summary: Standalone TensorBoard for visualizing in deep learning
Home-page: https://github.com/dmlc/tensorboard
Author: zihaolucky
Author-email: zihaolucky@gmail.com
License: Apache 2.0
Location: /usr/local/lib/python2.7/dist-packages
Requires: mock, Pillow, numpy, protobuf, wheel, six, werkzeug
-------------------------------------------------------------
tensorflow-gpu version

Name: tensorflow-gpu
Version: 1.2.1
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /usr/local/lib/python2.7/dist-packages
Requires: mock, numpy, bleach, markdown, wheel, six, protobuf, backports.weakref, html5lib, werkzeug
---------------------------------------------------------






### The problem
When I open the terminal and type
$python
$import tensorflow 
I get

I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/bids/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/bids/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 75, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/bids/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 10, in <module>
    from google.protobuf import descriptor_pb2
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/descriptor_pb2.py"", line 409, in <module>
    options=None),
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/descriptor.py"", line 501, in __new__
    return _message.default_pool.FindFieldByName(full_name)
KeyError: ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options""



### Source code / logs
Before I upgrade the tensorboard and pip version(the default pip version is 8.x  in Ubuntu 16.04 LTS)
After that I type following code in the terminal 
$python /home/wcm/.local/lib/python2.7/site-packages/tensorboard/tensorboard.py --logdir='/tmp/log'
The problem is KeyError: ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options""
Next, I type 
$ import tensorflow
The same problem is KeyError: ""Couldn't find field google.protobuf.DescriptorProto.ExtensionRange.options"".

Finally, I re-installing tensorflow-gpu, tensorflow and tensorboard step by step :no change. The same problem for import tensorflow.

 Anyone have an idea for this problem?
Thanks in advance
jiandanjinxin
",0,,22,2017-08-16T11:54:45Z,NONE
12316,training argument for tf.nn.rnn_cell.DropoutWrapper,"cla: yes,stat:awaiting tensorflower","This PR resolves issue #9775 

Added a `training` argument to  `tf.nn.rnn_cell.DropoutWrapper`, identical to `tf.layers.dropout`.

Also added to testcase to `tf.contrib.rnn.python.kernel_tests/core_rnn_cell_test.py` for this new argument.",1,,10,2017-08-16T06:42:11Z,CONTRIBUTOR
12302,memory leak bug,"stat:contributions welcome,type:bug/performance","Hi, I have seen many issues reporting Tensorflow memory leak, so I wanted to report another sample of leak. 
I was testing the GA3C code and after a while (about a day) the process taking all of 32g of memory.
system spec is 
OS : Ubuntu 17.04
tensorflow version : 1.2.1 binary instalation
cuda version : 7.5
gpu : GeForce GTX 1080 SLI, 8gig of gpu memory

you can get the code from : 
https://github.com/babak-badnava/GA3C

with many thanks 
",0,,3,2017-08-15T18:42:47Z,NONE
12301,graph transforms tool missing in windows,,"i installed tensorflow_gpu-1.3.0rc2-cp36-cp36m-win_amd64.whl
i cannot seem to find the graph transforms tools: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms",1,,7,2017-08-15T18:25:56Z,NONE
12293,tf.nn.avg_pool NaN bug with pool size 7 and stride 1,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu
- **TensorFlow version (use command below)**:  1.2.1
- **Python version**: Python 3.6.1 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0 / libcudnn.so.5.1.10
- **GPU model and memory**: titan x (pascal) 12gb
- **Exact command to reproduce**:



### Describe the problem
When performing tf.nn.avg_pool over a large binary image, containing a few small blobs (diameter ~ 100px), I get NaN errors and all-zero outputs depending on stride and poolsize option. I've added a test script below, which results in the following output on my setup. The results for strides 1 and pool >= 7 are incorrect:

```
strides (1, 1, 1, 1)
Pool: 5 len where: 7955
min: 0.0 max: 1.0
Pool: 6 len where: 7997
min: 0.0 max: 1.0
Pool: 7 len where: 0
min: 0.0 max: 0.0
Pool: 8 len where: 0
min: 0.0 max: 0.0
Pool: 9 len where: 49939008
min: nan max: nan
Pool: 10 len where: 33141389
min: nan max: nan

strides (1, 2, 2, 1)
Pool: 5 len where: 12045
min: 0.0 max: 1.0
Pool: 6 len where: 12584
min: 0.0 max: 1.0
Pool: 7 len where: 13093
min: 0.0 max: 1.0
Pool: 8 len where: 13608
min: 0.0 max: 1.0
Pool: 9 len where: 10588
min: 0.0 max: 1.0
Pool: 10 len where: 2707
min: 0.0 max: 1.0
```

### Source code / logs
```python
import numpy as np
import tensorflow as tf

maps = np.load('/tmp/test.npy')
in_shape = (9, 4096, 4096, 2)
padding = 'VALID'
sess = tf.Session()
input = tf.placeholder('float32', in_shape)

for strides in [(1, 1, 1, 1), (1, 2, 2, 1)]:
    print('strides', strides)
    for pool in range(5, 11):
        pool_size = (1, pool, pool, 1)
        x = tf.nn.avg_pool(input, pool_size, strides, padding=padding)
        pooled_maps = sess.run(x, {input: maps.astype('float32')})
        print('Pool:', pool, 'len where:', len(np.where(pooled_maps[..., 1] != 0)[0]))
        print('min:', pooled_maps[..., 1].min(), 'max:', pooled_maps[..., 1].max())
```

maps is too large to upload for me, but can be replaced with `maps = np.random.binomial(1, 0.0000001, in_shape)` to reproduce the NaNs for pool >= 8 


```

== cat /etc/issue ===============================================
Linux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux DTA-160200 4.4.0-91-generic #114-Ubuntu SMP Tue Aug 8 11:56:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.1)
numpydoc (0.6.0)
protobuf (3.3.0)
tensorflow-gpu (1.2.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /home/basv/.local/lib/cuda:/usr/local/cuda-8.0/lib64:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Tue Aug 15 11:50:59 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |
|  0%   44C    P0    58W / 250W |      0MiB / 12189MiB |      2%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
```",1,,7,2017-08-15T10:36:34Z,CONTRIBUTOR
12284,Cudnn `params_to_canonical` failed,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.3.0-rc2
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.52
- **CUDA/cuDNN version**: 8.0/6.0.21
- **GPU model and memory**:  Tesla K80/11.17GiB
- **Exact command to reproduce**:

```
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))

# Works 
cell = cudnn_rnn_ops.CudnnGRU(1, 5, 5, input_mode=""linear_input"")
sess.run(cell.params_to_canonical(tf.zeros([cell.params_size()])))

# aborts with ""Check failed""
cell = cudnn_rnn_ops.CudnnGRU(1, 5, 5, input_mode=""skip_input"")
sess.run(cell.params_to_canonical(tf.zeros([cell.params_size()])))
```
### Describe the problem
If `input_mode` is ""skip_input"", `params_to_canonical` fails with a ""Check failed"" error for at least CudnnGRU

### Logs
2017-08-15 03:05:45.807704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-08-15 03:05:45.808201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-08-15 03:05:45.808229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-08-15 03:05:45.808241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-08-15 03:05:45.808261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)
2017-08-15 03:05:46.543863: F tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc:627] Check failed: size == width * height Params size mismatch. Expected 25, got 0
Aborted (core dumped)
",0,,6,2017-08-15T03:19:45Z,NONE
12268,add args to control padding in the definition of pretrained model in slim,type:feature,"in some situation, the outputs of ""same"" and ""valid"" padding are same for original model, but when do fine-tuning with a new model, they are not,  adding an arg to control padding is meaningful.",0,,11,2017-08-14T15:27:15Z,NONE
12264,Simple EditDistance constructor is missing in C++,"stat:contributions welcome,type:feature","### System information
- **Windows 10**
- **TensorFlow installed from source**
- **TensorFlow version 1.3-rc2**
- **Python version 3.5.3**:
- **Bazel N/A**
- **CUDA/cuDNN version N/A**
- **GPU model and memory N/A**
- **N/A**

### Describe the problem
There is no simplier EditDistance::EditDistance() constructor there which only accept sparse::SparseTensor argmuents. The EditDistance constructor wants a lot of arguments

`EditDistance::EditDistance(const ::tensorflow::Scope& scope,
                           ::tensorflow::Input hypothesis_indices,
                           ::tensorflow::Input hypothesis_values,
                           ::tensorflow::Input hypothesis_shape,
                           ::tensorflow::Input truth_indices,
                           ::tensorflow::Input truth_values,
                           ::tensorflow::Input truth_shape, const
                           EditDistance::Attrs& attrs)`

instead of

`EditDistance::EditDistance(const ::tensorflow::Scope& scope,
                           const sparse::SparseTensor& hypothesis,
                            const sparse::SparseTensor& truth,
                           EditDistance::Attrs& attrs)`

Internally all hypothesis and truth parameters are put into SparseTensor object. Why SparseTensor parameters are not used in the constructor?

### Source code / logs
N/A
",0,,5,2017-08-14T12:32:17Z,NONE
12260,"Hexagon build fails, readme.md needs to be revisited.","stat:awaiting tensorflower,type:docs","OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b

Hexagon build readme should be revisited after recent code changes.


I used same command as given in the readme.md
`
tensorflow/tensorflow/contrib/makefile/build_all_android.sh -x /home/kzos/TFHEXLIBS -t hexagon_graph_execution -s /home/kzos/experiment/tensorflow/tensorflow/contrib/makefile/sub_makefiles/hexagon_graph_execution/Makefile.in
`

I am getting below error:
'
tensorflow/contrib/makefile/Makefile:46: *** ""hexagon is only supported on Android"".  Stop.
`


",0,,6,2017-08-14T06:35:13Z,NONE
12257,Add focal_loss,"awaiting review,cla: yes","Add a new loss function, focal_loss, which was described in [this paper](https://arxiv.org/pdf/1708.02002.pdf).",1,,20,2017-08-14T04:48:55Z,CONTRIBUTOR
12215,CTC loss with dynamic length,stat:awaiting tensorflower,"This is a very specific questions, I'm afraid nobody on stackoverflow will ever answer this. I will copy the text from there, the original question can be found there: 
https://stackoverflow.com/questions/45568266/tensorflow-ctc-loss-ctc-merge-repeated-parameter

And I'm not 100% sure if this behaviour is wanted or a bug (I think its the former one but I'm really not sure).


I'm using Tensorflow 1.0 and its CTC loss [1]. When training, I sometimes get the ""No valid path found."" warning (which harms learning). It is not due to a high learning rate as sometimes reported by other Tensorflow users.

After analyzing it a bit, I found the pattern that causes this warning:
 - feeding an input sequence into the ctc_loss with length seqLen
 - feeding a label with labelLen characters
 - label has numRepeatedChars repeated chars in it, where I count ""ab"" as 0, ""aa"" as 1, ""aaa"" as 2 and so on 
 - warning occurs, when: seqLen - labelLen < numRepeatedChars


Three examples:

 - Ex.1: label=""abb"", len(label)=3, len(inputSequence)=3 => (3-3=0)<1 is true --> warning
 - Ex.2: label=""abb"", len(label)=3, len(inputSequence)=4 => (4-3=1)<1 is false --> no warning
 - Ex.3: label=""bbb"", len(label)=3, len(inputSequence)=4 => (4-3=1)<2 is true --> warning

When I now set the ctc_loss parameter ctc_merge_repeated=False, then the warning disappears.

Three questions:

 - Q1: why is there a warning when repeated chars occur? I thought, as long as the input sequence is not shorter than the target labelling, there is no problem. And when repeated chars are merged in the label, then it gets even shorter, therefore the condition that the input sequence is not shorter still holds.
 - Q2: why does the ctc_loss in its default settings produce this warning? Repeated chars are common in the domains CTCs are used such as handwritten text recognition (HTR)
 - Q3: what settings should I use when doing HTR? Of course labels can have repeated chars. Therefore ctc_merge_repeated=False would make sense. Any suggestions?

Python program to reproduce warning:

```
import tensorflow as tf
import numpy as np

def createGraph():
    tinputs=tf.placeholder(tf.float32, [100, 1, 65]) # max 100 time steps, 1 batch element, 64+1 classes
    tlabels=tf.SparseTensor(tf.placeholder(tf.int64, shape=[None,2]) , tf.placeholder(tf.int32,[None]), tf.placeholder(tf.int64,[2])) # labels
    tseqLen=tf.placeholder(tf.int32, [None]) # list of sequence length in batch
    tloss=tf.reduce_mean(tf.nn.ctc_loss(labels=tlabels, inputs=tinputs, sequence_length=tseqLen, ctc_merge_repeated=True)) # ctc loss
    return (tinputs, tlabels, tseqLen, tloss)

def getNextBatch(nc): # next batch with given number of chars in label
    indices=[[0,i] for i in range(nc)]
    values=[i%65 for i in range(nc)]
    values[0]=0
    values[1]=0 # TODO: (un)comment this to trigger warning
    shape=[1, nc]
    labels=tf.SparseTensorValue(indices, values, shape)
    seqLen=[nc]
    inputs=np.random.rand(100, 1, 65)
    return (labels, inputs, seqLen) 


(tinputs, tlabels, tseqLen, tloss)=createGraph()

sess=tf.Session()
sess.run(tf.global_variables_initializer())

nc=3 # number of chars in label
print('next batch with 1 element has label len='+str(nc))
(labels, inputs, seqLen)=getNextBatch(nc)
res=sess.run([tloss], { tlabels: labels, tinputs:inputs, tseqLen:seqLen } )
```

This is the C++ Tensorflow code [2] where the warning comes from:
```
// It is possible that no valid path is found if the activations for the
// targets are zero.
if (log_p_z_x == kLogZero) {
    LOG(WARNING) << ""No valid path found."";
    dy_b = y;
    return;
}
```

[1] https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/ctc_loss
[2] https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_loss_calculator.cc


-----

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: costum
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.0.0-rc2-15-g47bba63-dirty, 1.0.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: [problem also on CPU]
- **GPU model and memory**: [problem also on CPU]
- **Exact command to reproduce**: see code above
",0,,7,2017-08-11T12:19:12Z,NONE
12202,Using keras built-in models,stat:awaiting tensorflower,"#### Version
v1.2.0-rc2-21-g12f033d

#### Problem
The Keras built-in models in `tf.contrib.keras.applications.*` cannot be used as a subgraph in TF.

#### Example
https://stackoverflow.com/questions/45585546/error-with-tf-contrib-keras-tf-placeholder

#### Cause
Calling `keras.applications.InceptionV3(weights='imagenet')(input_tensor)` is supposed to load pre-trained weights only for related variables, but it initializes the entire TF graph.
",0,,4,2017-08-11T05:31:48Z,NONE
12194,Incorrect Command Line in Image Training Tutorial,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.6
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: none
- **Exact command to reproduce**: 
```
bazel build tensorflow/examples/label_image:label_image && \
bazel-bin/tensorflow/examples/label_image/label_image \
--graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt \
--output_layer=final_result \
--image=$HOME/flower_photos/daisy/21652746_cc379e0eea_m.jpg
```
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The [tutorial for image retraining](https://www.tensorflow.org/tutorials/image_retraining) has an incorrect command line, which prevents the label_image classifier from running.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
If you run the command as is, you get the following output:
```E tensorflow/examples/label_image/main.cc:349] Running model failed: Not found: FeedInputs: unable to find feed output input```

### Solution
Please see [this StackOverflow post](https://stackoverflow.com/questions/43022516/tensorflow-inception-feedinputs-unable-to-find-feed-output-input).

The solution is to add the option `--input_layer=Mul` to the command line. The new command line should read:
```
bazel build tensorflow/examples/label_image:label_image && \
bazel-bin/tensorflow/examples/label_image/label_image \
--graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt \
--input_layer=Mul \
--output_layer=final_result \
--image=$HOME/flower_photos/daisy/21652746_cc379e0eea_m.jpg
```",0,,4,2017-08-11T00:06:19Z,CONTRIBUTOR
12175,[OpenCL] Registers AvgPool and AvgPoolGrad (#105),"awaiting review,cla: yes,stat:awaiting tensorflower",,1,,6,2017-08-10T11:13:38Z,CONTRIBUTOR
12162,build_all_xxx.sh support for Tizen target,stat:contributions welcome,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS 64bit
- **TensorFlow installed from (source or binary)**: Yes
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.1.3
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: GTX Titan XP
- **Exact command to reproduce**:


### Describe the problem
I can find appropriate build scripts for iOS, Android, and Linux at the below webpage.
- https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile/

Where can I also find a build script in case that I want to build Tensorflow on the Tizen  target device ?

- Tizen (for platform developers): https://source.tizen.org/
- Tizen (for application developers): https://developer.tizen.org/

### Source code / logs
Nothing
",0,,3,2017-08-10T02:50:46Z,NONE
12157,Bug - Restoring a graph created by tensorflow.python.tools.optimize_for_inference has errors with RNN models,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tensorflow-gpu (1.1.0)
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**:
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
- **GPU model and memory**: Tesla K80 24GB
- **Exact command to reproduce**: see below

### Describe the problem
I believe I've found a bug. The freeze and optimize scripts appear to have bugs related to the proper function of RNNs. Creating a simple RNN, running the freeze script and the optimize script, and then attempting to restore and use the optimized graph creates a puzzling series of errors.

1. After running freeze and optimize, the placeholder for sequence lengths has datatype `float32`, instead of `tf.int32`, even though the placeholder specifies that it is `tf.int32`. This breaks evaluating an instance of GRUCell, which expects length to be of type `tf.int32`.

2. If I add a `tf.to_int32()` to coerce the sequence length placeholder to type `tf.int32`, then we obtain a different error, which appears to pertain to the internal operation of the `tf.nn.dynamic_rnn()` function.

### Source code / logs
The code is divided into 2 user-created scripts (and 2 TF-provided scripts are employed along the way). The first of my scripts defines a model and saves it, and is called ""optimize_graph_minimal.py"". Then the freeze and optimize scripts are run. The second of my scripts attempts to restore the model to a new Python session, and this appears to be buggy.

#### This is the code I used to create and save the graph.

```
import numpy as np
import tensorflow as tf
import tensorflow.contrib.rnn as rnn

class tf_rnn_model(object):
    def __init__(self, seq_length=10, num_units=2):
        self.seq_length = seq_length
        self.num_units = num_units
        self.graph_context = tf.Graph()
        self.graph_specification()

    def graph_specification(self):
        with self.graph_context.as_default():
            self.X = tf.placeholder(dtype=tf.float32, shape=[None, self.seq_length, 2], name=""X"")
            self.X_length = tf.placeholder(dtype=tf.int32, shape=[None], name=""X_length"")

            cell = rnn.GRUCell(self.num_units)
            Y, rnn_state = tf.nn.dynamic_rnn(cell=cell,
                                             inputs=self.X,
                                             sequence_length=self.X_length,
                                             dtype=tf.float32,
                                             swap_memory=False)

            self.Y = tf.identity(Y, name=""Y"")
            self.saver = tf.train.Saver()

        return None

    def restore_optimized_graph(self, graph_def_optimized):
        with tf.gfile.GFile(graph_def_optimized, 'rb') as f:
            graph_def_optimized = tf.GraphDef()
            graph_def_optimized.ParseFromString(f.read())

        self.Y, = tf.import_graph_def(graph_def_optimized, return_elements=[""Y:0""])
        self.X = self.graph_context.get_tensor_by_name(""import/X:0"")
        self.X_length = self.graph_context.get_tensor_by_name(""import/X_length:0"")
        tf.global_variables_initializer().run()

        return None

model = tf_rnn_model()
with tf.Session(graph=model.graph_context) as sess:
    sess.run(tf.global_variables_initializer())
    inputs = np.arange(20).reshape([1, 10, 2])
    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})
    print(out)

    tf.train.write_graph(sess.graph_def, ""."", ""toy_graph.pb"")
    model.saver.save(sess, save_path=""toy_saved"")

    print(""These are some helpful things to know for the script."")
    print(""saver.as_saver_def()= %s"" % model.saver.as_saver_def())
```

## Freeze and optimize scripts are executed here.

```
python -m tensorflow.python.tools.freeze_graph \
--input_graph toy_graph.pb \
--input_checkpoint toy_saved \
--output_graph graph_frozen.pb \
--output_node_names=Y \
--filename_tensor_name=save/Const:0 \
--restore_op_name=save/restore_all

python -m tensorflow.python.tools.optimize_for_inference \
--input graph_frozen.pb \
--output graph_optimized.pb \
--input_names=X,X_length \
--output_names=Y
```

#### Attempt to restore and `run` using this script in a new Python session.

```
# This line just imports the model class from the previous Python script because this is a new Python session.
from optimize_graph_minimal import tf_rnn_model
import numpy as np
import tensorflow as tf

model = tf_rnn_model()

with tf.Session(graph=model.graph_context) as sess:
    model.restore_optimized_graph(""graph_optimized.pb"")
    inputs = np.arange(20).reshape([1, 10, 2])
    out = sess.run(fetches=[model.Y], feed_dict={model.X: inputs, model.X_length: [10]})
    print(out)
```
#### The following errors are produced.

1. Without explicitly coercing the sequence length placeholder using `tf.to_int32()`, we get an error indicating that the sequence length tensor is of type `float32` but must be type `int32`.

```
Traceback (most recent call last):
  File ""tf_minimal/optimize_restore_graph.py"", line 14, in <module>
    model.restore_optimized_graph(""graph_optimized.pb"")
  File ""optimize_graph_minimal.py"", line 44, in restore_optimized_graph
    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[""Y:0""])
  File ""python2.7/site-packages/tensorflow/python/framework/importer.py"", line 388, in import_graph_def
    node, 'Input tensor %r %s' % (input_name, te)))
ValueError: graph_def is invalid at node u'rnn/Shape_1': Input tensor 'X_length:0' Cannot convert a tensor of type float32 to an input of type int32.
```

2. If we change the graph specification to use an explicit coercion to int32 type
`self.X_length = tf.to_int32(tf.placeholder(dtype=tf.int32, shape=[None], name=""X_length""))`
then we get this error instead.

```
2017-08-09 19:19:10.910686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)
Traceback (most recent call last):
  File ""optimize_restore_graph.py"", line 14, in <module>
    model.restore_optimized_graph(""graph_optimized.pb"")
  File ""optimize_graph_minimal.py"", line 44, in restore_optimized_graph
    self.Y = tf.import_graph_def(graph_def_optimized, return_elements=[""Y:0""])
  File ""python2.7/site-packages/tensorflow/python/framework/importer.py"", line 362, in import_graph_def
    % (input_name,)))
ValueError: graph_def is invalid at node u'rnn/while/gru_cell/gates/gates/concat/axis': More inputs specified ('rnn/while/Switch:1') than the op expects..
```",1,,11,2017-08-09T20:29:07Z,NONE
12154,Feature request: document which inputs have gradients,"stat:contributions welcome,type:feature","For most operations, the documentation does not make clear what gradients are implemented. Including this information for the inputs (e.g. annotating the inputs that do not have gradients implemented) would help the user better understand the resulting graph. 

It appears a related issue was closed, as it was not a feature request. https://github.com/tensorflow/tensorflow/issues/6025",0,,3,2017-08-09T19:51:55Z,NONE
12143,const variable placement issue in distributed tensorflow,stat:awaiting response,"### Describe the problem
In my model, I use the FTRL Optimizer like below:

`self.optimizer = tf.train.FtrlOptimizer(0.005,
                learning_rate_power=-0.5,
                initial_accumulator_value=0.1,
                l1_regularization_strength=1.0,
                l2_regularization_strength=0.00001)
`

Inside the FtrlOptimizer it will create several const variables for the parameters, such as learning rate, learning rate power, etc. 

When I run the distributed tensorflow job, from the timeline I can see that for each session run I can see that the worker will send the above const variables to all the ps nodes. This is a cost since the variables are const and not needed to sent to ps nodes repeatedly.  

I was wondering is there a way to pin those const variables to the ps and save the transferring cost during each session run.

Thanks.
",0,,12,2017-08-09T13:08:33Z,NONE
12134,Nudge function in fake quantization returns non-nudegd scale value ,type:support,"The Nudge function(tensorflow/tensorflow/core/kernels/fake_quant_ops_functor.h) aims to keep the real zero value including in quantization input range. 
After min/max values are nudged, the scale keeps its original value. Is it intended to be?
",0,,10,2017-08-09T09:28:15Z,NONE
12132,slim.separable_conv2d is too slow,stat:awaiting response,"------------------------
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom, yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: from pip
- **TensorFlow version (use command below)**: ('v1.2.0-5-g435cdfc', '1.2.1')
- **Python version**: python2.7
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: CPU version, no CUDA
- **GPU model and memory**: CPU version, no CUDA
- **Exact command to reproduce**:

### Describe the problem
the depthwise+pointwise structure is faster than the traditional convolution layer theoretically, but the implemetation of tensorflow make it slower. it doesn't make sense.
here is part of my network defination:
#net = slim.conv2d(net, 32, [3, 3], scope='conv1-2')
    #end_points['conv1-2'] = net
    net = slim.separable_conv2d(net,None,[3,3],depth_multiplier=1,stride=1,rate=1,normalizer_fn=slim.batch_norm,scope='conv1-2-depthwise')
    end_points['conv1-2-depthwise'] = net
    net = slim.conv2d(net, depth(32), [1, 1], stride=1, normalizer_fn=slim.batch_norm, scope='conv1-2-pointwise')
    end_points['conv1-2-pointwise'] = net

    net = slim.max_pool2d(net, [2, 2], 2, scope='pool1')
    end_points['pool1'] = net # 58*58

    #net = slim.conv2d(net, 48, [3, 3], padding='VALID', scope='conv2')
    #end_points['conv2'] = net
    net = slim.separable_conv2d(net,None,[3,3],depth_multiplier=1,stride=1,rate=1,normalizer_fn=slim.batch_norm,scope='conv2-depthwise')
    end_points['conv2-depthwise'] = net
    net = slim.conv2d(net, depth(48), [1, 1], stride=1, normalizer_fn=slim.batch_norm, scope='conv2-pointwise')
    end_points['conv2-pointwise'] = net

    net = slim.max_pool2d(net, [2, 2], 2, scope='pool2')
    end_points['pool2'] = net # 28*28

i just change the network defination 
from: 
net = slim.conv2d(net, 32, [3, 3], scope='conv1-2')
end_points['conv1-2'] = net
to:
net = slim.separable_conv2d(net,None,[3,3],depth_multiplier=1,stride=1,
         rate=1,normalizer_fn=slim.batch_norm,scope='conv1-2-depthwise')
end_points['conv1-2-depthwise'] = net
net = slim.conv2d(net, depth(32), [1, 1], stride=1, normalizer_fn=slim.batch_norm, 
         scope='conv1-2-pointwise')
end_points['conv1-2-pointwise'] = net
i do not think i am doing something wrong. so where the problem is?
",1,,12,2017-08-09T08:41:36Z,NONE
12121,tf.random_normal_initializer produces inconsistent results with fixed seed on GPU,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.0.0, 1.1.0, 1.2.1
- **Python version**: 2.7.10, 3.5.2
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: CUDA release 8.0, V8.0.46; cuDNN 8.0
- **GPU model and memory**: GeForce GTX TITAN X 12GB, GK210GL [Tesla K80] 12GB
- **Exact command to reproduce**: below

### Describe the problem
Setting both graph-level and op-level random seeds to fixed values, I still get inconsistent results initializing variables with `tf.random_normal_initializer`. Here's the code to reproduce the problem

	import numpy as np
	import tensorflow as tf
	
	tf.set_random_seed(0)
	np.random.seed(0)
	shape = (100, 2048)
	seed = 0
	for i in range(100):
	    seed += 1
	    init = tf.random_normal_initializer(stddev=0.02, seed=seed)
	    tf.get_variable(str(i), shape, initializer=init)
	
	session = tf.Session()
	session.run(tf.global_variables_initializer())
	var_dict = {}
	for var in tf.trainable_variables():
	    var_dict[var.name] = session.run(var.name)
	
	np.savez_compressed(""weights.npz"", **var_dict)
	session.close()

Here I initialize 100 variables with `tf.random_normal_initializer` with a fixed op-level seed and with a fixed graph-level seed.

Running this two times I get different results saved in `weights.npz`. Interestingly, this happens only when using GPU and the difference between the saved weights is very slight: usually only some of the variables are different, and they only differ in some small number of positions. 

I experience this problem on Tensorflow 1.0.0 (Python2), 1.1.0, 1.2.1 (Python3) and on two different GPUs. ",0,,4,2017-08-08T22:38:01Z,NONE
12106,Build fails for certain GCC paths,type:build/install,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.3-rc2
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
5.2
- **CUDA/cuDNN version**:
8.0 / 5.1.10
- **GPU model and memory**:
Nvidia GTX 1080 Ti
- **Exact command to reproduce**:
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures --spawn_strategy=standalone

### Describe the problem
Build will fail if compiler is not located in specific paths (like `/usr/bin`). Also will happen by compiling with a symbolic link to compiler if the link reside there.

**Steps to reproduce**
Make a symbolic link to GCC and store it somewhere like `/etc/gcc`. run `./configure` and set compiler path to `/etc/gcc` then run bazel build. This is probably why builds failing on certain many Linux distributions and is related to issues like #3550 and many other abandoned ones.

### Source code / logs

`$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures --spawn_strategy=standalone`
```
WARNING: /opt/tensorflow-1.3.0-rc2/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /opt/tensorflow-1.3.0-rc2/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/84ac956a7b3384a65a68aa2a845ef1a1/external/lmdb/BUILD.bazel:8:1: C++ compilation of rule '@lmdb//:lmdb' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/84ac956a7b3384a65a68aa2a845ef1a1/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/opt/tensorflow-1.3.0-rc2/cuda-plat-sym \
    CUDNN_INSTALL_PATH=/opt/tensorflow-1.3.0-rc2/cuda-plat-sym \
    GCC_HOST_COMPILER_PATH=/etc/some-gcc \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \
    TF_CUDA_VERSION=8.0 \
    TF_CUDNN_VERSION=5.1.10 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL=0 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' -MD -MF bazel-out/local_linux-opt/bin/external/lmdb/_objs/lmdb/external/lmdb/mdb.pic.d -fPIC -iquote external/lmdb -iquote bazel-out/local_linux-opt/genfiles/external/lmdb -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -w -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c external/lmdb/mdb.c -o bazel-out/local_linux-opt/bin/external/lmdb/_objs/lmdb/external/lmdb/mdb.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
some-gcc: error trying to exec 'cc1': execvp: No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```",1,,7,2017-08-08T12:40:24Z,NONE
12101,Build the latest source code will fail under Linux platform,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10 (Artful Aardvark)
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: N/A
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.5.3
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
Build the the TF from the latest version of source code will fail.

### Source code / logs
WARNING: /home/kevin/research/openSource/tensorflow-fork/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/kevin/research/openSource/tensorflow-fork/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (177 packages loaded).
INFO: Found 1 target...
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: no such package '@protobuf//src/google/protobuf': Could not find handler for bind rule //external:protobuf
INFO: Elapsed time: 10.961s, Critical Path: 0.12s
FAILED: Build did NOT complete successfully
",0,,9,2017-08-08T07:44:39Z,NONE
12090,imagenet_distributed_train using inception v3 stuck on saving check points forever.,"stat:awaiting response,type:support","System information
```bash
== cat /etc/issue ===============================================
Linux ip-172-30-4-87 3.10.0-514.16.1.el7.x86_64 #1 SMP Wed Apr 12 15:04:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux ip-172-30-4-87 3.10.0-514.16.1.el7.x86_64 #1 SMP Wed Apr 12 15:04:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow-gpu (1.2.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.0
tf.GIT_VERSION = v1.2.0-rc2-21-g12f033d
tf.COMPILER_VERSION = v1.2.0-rc2-21-g12f033d
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Mon Aug  7 21:00:40 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 0000:00:1E.0     Off |                    0 |
| N/A   51C    P0    72W / 149W |  10944MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      2886    C   /bin/python                                  10938MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
```
I am running the imagenet_distributed_train.py of inception: https://github.com/tensorflow/models/tree/master/inception, with 16 AWS p2x2 machines. I didn't change any code of inception and follow the guidance to run imagenet_distributed_train using parallel-ssh.

The script I use to run parallel-ssh:
```python
from pssh.pssh_client import ParallelSSHClient
import datetime
from pprint import pprint
from pssh.utils import load_private_key

output_ps = []
output_worker = []
some host ip here
ps = [host1,host2,host3]
worker = [host0,host1,host2,host3,host4,host5,host6,host7,host8,host9,host10,host11,host12,host13,host14,host15]
client_ps = ParallelSSHClient(ps, user='centos')
client_worker = ParallelSSHClient(worker, user='centos')

output_ps = client_ps.run_command('%s', host_args=(
    ('/imagenet/run_ps.sh --job_name ps --task_id 0 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_ps.sh --job_name ps --task_id 1 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_ps.sh --job_name ps --task_id 2 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ))

output_worker = client_worker.run_command( '%s', host_args=(
    ('/imagenet/run_worker.sh --job_name worker --task_id 0 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 1 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 2 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 3 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 4 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 5 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 6 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 7 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 8 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 9 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 10 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 11 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 12 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 13 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 14 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 15 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
       ))

client_ps.join(output_ps)
#client_worker.join(output_worker)
pprint(output_ps.values()[0].exit_code)
#pprint(output_worker.values()[0].exit_code)

for host, host_output in output_ps.items():
    for line in host_output.stdout:
        print(""Host [%s] - %s"" % (host, line))
```
I think this script worked fine because I logged in every machine and checked with ps command and ensured the program was running with correct parameters. Then the program just worked fine but to some point, it started to save checkpoints forever(here is the output of worker0):

```bash
INFO:tensorflow:Worker 0: 2017-08-04 06:46:08.510727: step 2340, loss = 11.22(2.0 examples/sec; 15.788  sec/batch)
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Worker 0: 2017-08-04 06:53:55.553703: step 2370, loss = 10.30(2.1 examples/sec; 15.573  sec/batch)
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Worker 0: 2017-08-04 07:01:44.226068: step 2400, loss = 10.84(2.1 examples/sec; 15.421  sec/batch)
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
(same saving checkpoint output forever)
```
I ran nvidia-smi and found the GPU wasn't working and same with other nodes. The output of worker 1-15 just stucked on step 2400 and didn't do any progress. I tried this several time on new set of 16 machines but it all stucked on saving checkpoint forever problem at some time. I guess it might be a bug in tensorflow? Or does this caused network failure? but it didn't retrun any network failure error.",0,,8,2017-08-07T22:46:08Z,NONE
12084,InvalidArgumentError mobilenet,"stat:awaiting tensorflower,type:support","im getting the following error while training my own dataset with mobilenet

```
Caused by op 'MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise', defined at:
  File ""tensorflow/examples/image_retraining/retrain.py"", line 1326, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tensorflow/examples/image_retraining/retrain.py"", line 984, in main
    create_model_graph(model_info))
  File ""tensorflow/examples/image_retraining/retrain.py"", line 282, in create_model_graph
    model_info['resized_input_tensor_name'],
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 287, in import_graph_def
    op_def=op_def)
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): NodeDef mentions attr 'data_format' not in Op<name=DepthwiseConv2dNative; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=[""SAME"", ""VALID""]>; NodeDef: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise = DepthwiseConv2dNative[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/MobilenetV1/Conv2d_0/Relu6, MobilenetV1/Conv2d_1_depthwise/depthwise_weights/read)
	 [[Node: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise = DepthwiseConv2dNative[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/MobilenetV1/Conv2d_0/Relu6, MobilenetV1/Conv2d_1_depthwise/depthwise_weights/read)]]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tensorflow/examples/image_retraining/retrain.py"", line 1326, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tensorflow/examples/image_retraining/retrain.py"", line 1025, in main
    bottleneck_tensor, FLAGS.architecture)
  File ""tensorflow/examples/image_retraining/retrain.py"", line 476, in cache_bottlenecks
    resized_input_tensor, bottleneck_tensor, architecture)
  File ""tensorflow/examples/image_retraining/retrain.py"", line 418, in get_or_create_bottleneck
    bottleneck_tensor)
  File ""tensorflow/examples/image_retraining/retrain.py"", line 373, in create_bottleneck_file
    str(e)))
RuntimeError: Error during processing file tensorflow/examples/image_retraining/dataset/female/2Q== (1).jpg (NodeDef mentions attr 'data_format' not in Op<name=DepthwiseConv2dNative; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=[""SAME"", ""VALID""]>; NodeDef: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise = DepthwiseConv2dNative[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/MobilenetV1/Conv2d_0/Relu6, MobilenetV1/Conv2d_1_depthwise/depthwise_weights/read)
	 [[Node: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise = DepthwiseConv2dNative[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/MobilenetV1/Conv2d_0/Relu6, MobilenetV1/Conv2d_1_depthwise/depthwise_weights/read)]]

Caused by op 'MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise', defined at:
  File ""tensorflow/examples/image_retraining/retrain.py"", line 1326, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""tensorflow/examples/image_retraining/retrain.py"", line 984, in main
    create_model_graph(model_info))
  File ""tensorflow/examples/image_retraining/retrain.py"", line 282, in create_model_graph
    model_info['resized_input_tensor_name'],
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 287, in import_graph_def
    op_def=op_def)
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/zumbala/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): NodeDef mentions attr 'data_format' not in Op<name=DepthwiseConv2dNative; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=padding:string,allowed=[""SAME"", ""VALID""]>; NodeDef: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise = DepthwiseConv2dNative[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/MobilenetV1/Conv2d_0/Relu6, MobilenetV1/Conv2d_1_depthwise/depthwise_weights/read)
	 [[Node: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise = DepthwiseConv2dNative[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV1/MobilenetV1/Conv2d_0/Relu6, MobilenetV1/Conv2d_1_depthwise/depthwise_weights/read)]]
)

```",0,,11,2017-08-07T18:00:28Z,NONE
12077,Occur error when compile tf_core_gpu_kernels/generated_adjust_hue_op_gpu.cu.cc file in VS2015,stat:community support,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
windows 10
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.3
- **IDE version**: 
vs2015 Debug mode
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA8.0 cuDNN5.1
- **GPU model and memory**:
4GB
- **Exact command to reproduce**:
D:/tensorflow-r1.3\tensorflow/stream_executor/device_description.h(85): warning : type qualifier on return type is meaningless
35>D:/tensorflow-r1.3\tensorflow/stream_executor/device_description.h(144): warning : type qualifier on return type is meaningless
35>E:/vs2015/VC/bin/../../VC/INCLUDE\xutility(911): **error : calling a __host__ function(""std::_Debug_message"") from a __device__ function(""std::_Debug_lt<const int &, const int &> "") is not allowed**
35>  1 error detected in the compilation of ""C:/Users/hh/AppData/Local/Temp/tmpxft_0000425c_00000000-15_adjust_hue_op_gpu.cu.compute_52.cpp1.ii"".
35>  adjust_hue_op_gpu.cu.cc
35>  CMake Error at tf_core_gpu_kernels_generated_adjust_hue_op_gpu.cu.cc.obj.Debug.cmake:282 (message):
35>    Error generating file
35>    D:/tensorflow-r1.3/CMAKE-GPU/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Debug/tf_core_gpu_kernels_generated_adjust_hue_op_gpu.cu.cc.obj

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I built tensorflow project for GPU version in vs2015, and get CUDA error. It seems like call host function in the device function, but I can't find the place where error occur
",0,,3,2017-08-07T13:01:29Z,NONE
12071,"Numerical instability of gradient calculation of tf.norm (nan at 0, inf for small values) ",stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes see below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.11.6
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: #v1.2.0-5-g435cdfc    1.2.1
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: On CPU
- **GPU model and memory**:
- **Exact command to reproduce**: tf.norm at [0,0] see below for code

```
import numpy as np
import tensorflow as tf
print(tf.GIT_VERSION, ""  "", tf.VERSION) #v1.2.0-5-g435cdfc    1.2.1

X = tf.placeholder(tf.float32, shape=(4,None))
Z = tf.norm(X, ord='euclidean', axis=1, name='logit')
var_grad = tf.gradients(Z, [X])

with tf.Session() as sess:
    X_ = np.array([
        [1],  # Grad OK
        [0],  # Grad NaN
        [1e-16],  # Grad OK
        [1e-19] #Grad Inf
    ], dtype=np.float32)
    sess.run(tf.global_variables_initializer())
    print(sess.run((Z, var_grad), feed_dict={X: X_}))
    # Result:
    #(array([9.99999940e-01, 0.00000000e+00, 9.99999951e-17,
    #        0.00000000e+00], dtype=float32), [array([[1.00000012],
    #                                                 [nan],
    #                                                 [1.],
    #                                                 [inf]], dtype=float32)])
```

### Describe the problem
`nan` is calculated for the gradient of `tf.norm` at zero values. For extremely small values `inf` is calculated. Note that the exact result should be 1 in all cases above. 

Above is a minimal example to reproduce it. The problem occurred in a real world scenario, when implementing a custom loss function (the entropy in https://arxiv.org/abs/1611.01449) and two embeddings where too close to each other (distance practically 0).

### Source code / logs
See above 

#### Output of logfile
```
== cat /etc/issue ===============================================
Darwin Olivers-MBP-5.fritz.box 15.6.0 Darwin Kernel Version 15.6.0: Tue Apr 11 16:00:51 PDT 2017; root:xnu-3248.60.11.5.3~1/RELEASE_X86_64 x86_64
Mac OS X 10.11.6

== are we in docker =========================================  echo == are we in docker ====================================num echo == are we in docker =========================================  ec==  echo == are we in docker =======================================c++ --version

== uname -a =====================================================
Darwin Olivers-MBP-5.fritz.box 15.6.0 Darwin Kernel Version 15.6.0: Tue Apr 11 16:00:51 PDT 2017; root:xnu-3248.60.11.5.3~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.2.1)

== check for virtualenv ==============  echo == check for virtualenv =====on_b echo == check fo sys  echo == check for virtualenv ============== echo == check for virtualenv ============================================

== cat /etc/issue ===============================================
Darwin Olivers-MBP-5.fritz.box 15.6.0 Darwin Kernel Version 15.6.0: Tue Apr 11 16:00:51 PDT 2017; root:xnu-3248.60.11.5.3~1/RELEASE_X86_64 x86_64
Mac OS X 10.11.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 7.3.0 (clang-703.0.31)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin Olivers-MBP-5.fritz.box 15.6.0 Darwin Kernel Version 15.6.0: Tue Apr 11 16:00:51 PDT 2017; root:xnu-3248.60.11.5.3~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.2.1)

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh.txt: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
```",0,,11,2017-08-07T07:32:05Z,NONE
12046,tf.scatter_update to variable pinned on GPU fails,stat:contributions welcome,"### System information
- Linux Ubuntu 16.04
- tensorflow-gpu v1.2.0 binary installed from pip
- Python 3.5
- CUDA 8.0, cuDNN v5.1 
- GeForce GTX 1080 Ti, 11GB
- A simple example I came up with which reproduces the error follows below:
**************************************************************************************************
```python
import tensorflow as tf
with tf.device(""/gpu:0""):
    a = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
    c = tf.Variable([0, 0, 0, 0, 0, 0, 0, 0])
    step_sos = tf.Variable([False, False, True, True, False, False, True, True])
    write_ops = []
    for b in range(8):
        write_ops.append(tf.cond(step_sos[b], lambda: tf.scatter_update(a, b, 0), lambda: a))

    with tf.control_dependencies(write_ops):
       d = tf.assign(c, a)


session_config = tf.ConfigProto(allow_soft_placement=False, log_device_placement=True)

with tf.Session(config=session_config) as sess:
    init_op = tf.global_variables_initializer()
    sess.run(init_op)
    sess.run(d)
    print(sess.run(c))
```
********************************************************************************************************              

### 
When setting allow_soft_placement=True the error is solved but the variable and some operations which are often used are placed in the CPU, which leads to fluctuating GPU utilization.

### Source code / logs
```
Traceback (most recent call last):
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1139, in _do_call
    return fn(*args)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1117, in _run_fn
    self._extend_graph()
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1166, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'Variable_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices: 
Assign: CPU 
Identity: CPU 
VariableV2: CPU 
	 [[Node: Variable_2 = VariableV2[container="""", dtype=DT_BOOL, shape=[8], shared_name="""", _device=""/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""scatter_test.py"", line 20, in <module>
    sess.run(init_op)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'Variable_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices: 
Assign: CPU 
Identity: CPU 
VariableV2: CPU 
	 [[Node: Variable_2 = VariableV2[container="""", dtype=DT_BOOL, shape=[8], shared_name="""", _device=""/device:GPU:0""]()]]

Caused by op 'Variable_2', defined at:
  File ""scatter_test.py"", line 7, in <module>
    step_sos = tf.Variable([False, False, True, True, False, False, True, True])
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 200, in __init__
    expected_shape=expected_shape)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 297, in _init_from_args
    name=name)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py"", line 128, in variable_op_v2
    shared_name=shared_name)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 684, in _variable_v2
    name=name)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/ylli/neuralattention/code/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'Variable_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices: 
Assign: CPU 
Identity: CPU 
VariableV2: CPU 
	 [[Node: Variable_2 = VariableV2[container="""", dtype=DT_BOOL, shape=[8], shared_name="""", _device=""/device:GPU:0""]()]]
```
",0,,6,2017-08-04T19:05:03Z,NONE
12032,Save and restore feature request,"stat:contributions welcome,type:feature","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0/v5.1
- **GPU model and memory**: GeForce GTX TITAN X / 12205MiB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

 I am sorry to bother you all, here this is not a bug but, in my view, a feature request. 

I have trained a model and initialized a Saver instance by defining


<!-- language: python -->

    value_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/old_scope')
    value_list.extend(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='global/actor_critic'))
    saver = tf.train.Saver(value_list, max_to_keep=100)

    with tf.Session(config=tf_configs) as sess:
        coord = tf.train.Coordinator()
        if load_model:
            print('Loading Model...')
            ckpt = tf.train.get_checkpoint_state(model_path)
            saver.restore(sess, ckpt.model_checkpoint_path)
        else:
            sess.run(tf.global_variables_initializer())

And later in a new sub-scope, I added a new layer, with the same `saver` defined above, I trained the model, however, I found that weights of the new layer were not saved.

Here is my network

<!-- language: python -->

    with tf.variable_scope(scope):
        with tf.variable_scope('old_scope'):
            self.inputs = tf.placeholder(shape=[None, 80, 80, 1], dtype=tf.float32)
            self.conv_1 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.inputs, num_outputs=32,
                                      kernel_size=[8, 8], stride=4, padding='SAME')
            self.conv_2 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_1, num_outputs=64,
                                      kernel_size=[4, 4], stride=2, padding='SAME')
            self.conv_3 = slim.conv2d(activation_fn=tf.nn.relu, inputs=self.conv_2, num_outputs=64,
                                      kernel_size=[3, 3], stride=1, padding='SAME')
            self.fc = slim.fully_connected(slim.flatten(self.conv_3), 512, activation_fn=tf.nn.elu)

        with tf.variable_scope('added_layer'):
            self.fc_1 = slim.fully_connected(self.fc, 512, activation_fn=tf.nn.elu)

        with tf.variable_scope('actor_critic'):
            # Output layers for policy and value estimations
            self.policy = slim.fully_connected(self.fc_1,
                                             cfg.ACTION_DIM,
                                             activation_fn=tf.nn.softmax, 
                                             biases_initializer=None)
            self.value = slim.fully_connected(self.fc_1,
                                              1,
                                              activation_fn=None,
                                              biases_initializer=None)

And I found that the [`var_list`][1] defines values to be restored and saved. But in my case, there is no checkpoint data of the new layer in the checkpoint file. 

Since before adding the new layer, I have trained the model and save the checkpoint data, and then after adding the new layer, I wanna train the network.

And I can define a new instance of Saver to save the model

`new_saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=GLOBAL_SCOPE))`

However, I think it is not an elegant way to do so.

And can you add a feature to restore some values specified by users and also save some specified values when saving?

And in fact, it is a question asked by me on [SO](https://stackoverflow.com/questions/45502149/tensorflow-save-and-restore-model-after-adding-one-layer)

  [1]: https://www.tensorflow.org/api_docs/python/tf/train/Saver#__init__



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,0,2017-08-04T09:08:01Z,NONE
12022,Error exporting TensorForestEstimator model for serving,"stat:awaiting tensorflower,type:bug/performance","### Problem
I am trying to host a TensorForestEstimator model on Google Cloud's ML Engine. Everything works right, but at the very end the model fails to export with stack trace:

```
Traceback (most recent call last):
[...]
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 502, in train_and_evaluate
  export_results = self._maybe_export(eval_result)
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 597, in _maybe_export
  eval_result=eval_result))
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/export_strategy.py"", line 87, in export
  return self.export_fn(estimator, export_path, **kwargs)
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/utils/saved_model_export_utils.py"", line 412, in export_fn
  checkpoint_path=checkpoint_path)
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1280, in export_savedmodel
  actual_default_output_alternative_key)
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/utils/saved_model_export_utils.py"", line 252, in build_all_signature_defs
  for input_key, inputs in input_alternatives.items()
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/utils/saved_model_export_utils.py"", line 254, in <dictcomp>
  in output_alternatives.items()}
File ""/root/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/utils/saved_model_export_utils.py"", line 119, in build_standardized_signature_def
  input_tensors, output_tensors)
File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py"", line 146, in predict_signature_def
  signature_constants.PREDICT_METHOD_NAME)
File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py"", line 45, in build_signature_def
  signature_def.outputs[item].CopyFrom(outputs[item])
TypeError: None has type NoneType, but expected one of: bytes, unicode
```

Based on that trace, I'm thinking the error is in the make_export_strategy function with `default_output_alternative_key=None`. So what I did is set `default_output_alternative_key='default'` but then got the error:

```
ValueError: Requested default_output_alternative: default, but available output_alternatives are: [None]
```

So this shows that there are no output alternatives and my model is single-headed. Here is the code:

```
def serving_input_fn():
    feature_placeholders = {
    column['name']: tf.placeholder(dtype=column['dtype'], shape=[None])
    for column in columns_list if column['derived'] == 'N' and column['column_role'] != 'label'
    }

    features = {
        key: tf.expand_dims(tensor, -1)
        for key, tensor in feature_placeholders.items()
    }

    return InputFnOps(
        features=features,
        labels=None,
        default_inputs=feature_placeholders
    )

def get_experiment_fn(args):
    def _experiment(run_config, hparams):
        return Experiment(
            estimator=TensorForestEstimator(
                params=ForestHParams(
                    num_trees=args.num_trees,
                    max_nodes=10000,
                    min_split_samples=2,
                    num_features=7,
                    num_classes=args.num_projections,
                    regression=True
                ),
                model_dir=args.job_dir,
                graph_builder_class=RandomForestGraphs,
                config=run_config,
                report_feature_importances=True,
            ),
            train_input_fn=get_input_fn(
                project_name=args.project,
                data_location=args.train_data,
                dataset_size=args.train_size,
                batch_size=args.train_batch_size
            ),
            train_steps=args.train_steps,
            eval_input_fn=get_input_fn(
                project_name=args.project,
                data_location=args.eval_data,
                dataset_size=args.eval_size,
                batch_size=args.eval_batch_size
            ),
            eval_steps=args.eval_steps,
            eval_metrics=get_eval_metrics(),
            export_strategies=[
                make_export_strategy(
                    serving_input_fn,
                    default_output_alternative_key=None,
                    exports_to_keep=1
                )
            ]
        )
    return _experiment


def main():
    args = get_arg_parser().parse_args()

    learn_runner.run(
        experiment_fn=get_experiment_fn(args),
        run_config=RunConfig(model_dir=args.job_dir),
        hparams=HParams(**args.__dict__)
    )

if __name__ == '__main__':
    main()
```

This seems like a bug, but I could be wrong.

### System information
```
== cat /etc/issue ===============================================
Darwin mbmagenic12 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.4

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.1.0 (clang-802.0.42)
Target: x86_64-apple-darwin16.5.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== uname -a =====================================================
Darwin mbmagenic12 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.1)
protobuf (3.1.0.post1)
tensorflow (1.2.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
```
",0,,8,2017-08-03T22:08:10Z,NONE
12019,foldr is too restrictive:  dimension 0 in both shapes must be equal,"stat:contributions welcome,type:feature","Using TF 1.2.0-rc1 on Ubuntu 16.04.

There are cases where `tf.foldr` should work, but is unable to because of a restriction that the first shape dimensions be identical for all list elements.  Below is a self-contained example that demonstrates the problem:

```
import tensorflow as tf
sess = tf.InteractiveSession()

def concat2(A, B):
    return tf.concat([A, B], axis=0)

A = tf.constant([[10,10]])             # A.shape => (1,2)
B = tf.constant([[20, 20], [30, 30]])  # B.shape => (2,2)

print(concat2(A, B).eval())              # => [[10, 10], [20, 20], [30, 30]]
print(tf.foldr(concat2, [A, B]).eval())  # => ERROR!
```
",0,,2,2017-08-03T20:17:42Z,NONE
12011,Quantized graph not running with commit:bb88ec7ecc4dc7ba72548a5115fb86e20b14de5b,type:bug/performance,"OS: Ubuntu 16.04 64bits
 Android Version: 7.1 (Nougat)
 NDK Version: android-ndk-r12b

commit bb88ec7ecc4dc7ba72548a5115fb86e20b14de5b
Author: Alan Yee <alyee@ucsd.edu>
Date:   Mon Jul 24 22:46:38 2017 -0700



LOG:

```
native : benchmark_model.cc:405 Input layers: [Variable]
native : benchmark_model.cc:406 Input shapes: [1,227,227,3]
native : benchmark_model.cc:407 Input types: [float]
native : benchmark_model.cc:408 Output layers: [prob]
native : benchmark_model.cc:409 Num runs: [50]
native : benchmark_model.cc:410 Inter-run delay (seconds): [-1.0]
native : benchmark_model.cc:411 Num threads: [16]
native : benchmark_model.cc:412 Benchmark name: []
native : benchmark_model.cc:413 Output prefix: []
native : benchmark_model.cc:414 Show sizes: [0]
native : benchmark_model.cc:415 Warmup runs: [2]
native : benchmark_model.cc:54 Loading TensorFlow.
native : benchmark_model.cc:61 Got config, 0 devices
can't determine number of CPU cores: assuming 4
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseAnd
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseAnd
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseAnd
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseAnd
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseAnd
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseAnd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseAnd
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseXor
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseXor
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseXor
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseXor
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseXor
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseXor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseXor
native : op_kernel.cc:1142 OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: Invert
native : op_kernel.cc:1142 OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: Invert
native : op_kernel.cc:1142 OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: Invert
native : op_kernel.cc:1142 OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: Invert
native : op_kernel.cc:1142 OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: Invert
native : op_kernel.cc:1142 OpKernel ('op: ""Invert"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: Invert
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT16 } } }') for unknown op: BitwiseOr
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }') for unknown op: BitwiseOr
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }') for unknown op: BitwiseOr
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }') for unknown op: BitwiseOr
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT16 } } }') for unknown op: BitwiseOr
native : op_kernel.cc:1142 OpKernel ('op: ""BitwiseOr"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT8 } } }') for unknown op: BitwiseOr
native : benchmark_model.cc:74 Could not create TensorFlow Session: Not found: Op type not registered 'RoundToSteps' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.

```

Earlier this error was not getting reported.

Thanks",1,,10,2017-08-03T17:00:28Z,NONE
12009,Expose Tensorflow Go library as cgo_library rule in Bazel,"stat:contributions welcome,type:feature",Currently it's not possible to reference @org_tensorflow//tensorflow/go:go_default_library from a BUILD file. It would be great to have this ability.,0,,3,2017-08-03T16:27:03Z,NONE
12002,tf.nn.sparse_softmax_cross_entropy_with_logits() seems to return bad values !,"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: from pip
- **TensorFlow version (use command below)**: 'v1.2.0-5-g435cdfc', '1.2.1'
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: cudNN v8.0
- **GPU model and memory**: 2* NVidia GeForce 1080Ti (11Go each)
- **Exact command to reproduce**: Following code

### Describe the problem
It seems that `tf.nn.sparse_softmax_cross_entropy_with_logits() ` and `tf.nn.softmax_cross_entropy_with_logits()` are returning bad values. According to this [stackOverflow post](https://stackoverflow.com/questions/36078411/tensorflow-are-my-logits-in-the-right-format-for-cross-entropy-function/36086477#36086477), `tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels)` is almost equivalent to `-tf.reduce_sum(labels * tf.log(tf.nn.softmax(logits) + 1e-10), 1))`.
But when I'm using the provided optimized function, I don't get the same results. It appears that its come from the log function when logits is equal to 0. But I've read that `tf.nn.sparse_softmax_cross_entropy_with_logits()` handle that case, and that's the case, cause I would have some *Nan* output. But instead I have huge numbers, so I (naturally) thought that to avoid *log(0)* a small constant must have been added to the problematic numbers. So I tried to reproduce this tip (with 1e-10) and I don't still have the same result. So I tried to read the code [here](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/nn_ops.py) to understand what's going on. But I can't find in the repo the gen_nn_ops module to understand why this function returns such a ""strange"" result. I will be pleased to contribute to understand what happens (and to correct it, if needed of course !).
Here is a really simple piece of code to reproduce the ""error"" (if it's indeed one). And we have the same behavior with the sparse version of the function (with proper labels).
Thanks, 
### Source code / logs
```
graph = tf.Graph()

features = np.array([[6.83324017e-02, 4.55211316e-01,-1.41892820e-01, 6.41751984e-01, -5.45895865e-01, 5.38657679e-01, 1.93379897e-01, 1.60154529e-01, 1.57859872e-02, 1.36758294e-02, 4.40859703e+00, 4.96067050e+03, -5.95230431e+01, 2.29624126e+00, 4.02069655e+00], [8.82284599e-01, 6.42900440e-01,-4.27639642e-02, 1.83567706e-01, 7.52404702e-01, -6.32605771e-01, 5.40391531e-01, 5.84584613e-01,-7.15044264e-03,-8.23328268e-02, 6.29273115e+00,-4.32369561e+01, 7.07259958e+00,-1.02810233e+00,-7.04034886e-01], [5.48660773e-01, 8.08794529e-01,-5.96924524e-02,-7.26052964e-01,-2.70772000e-02, 6.87105464e-01, 5.68913359e-01, 4.76252594e-01, 4.14203699e-02,-5.79935485e-03, 9.40232256e+00,-2.01665599e+04, 1.34500232e+01,-2.24989629e-01, 2.52753983e-01], [7.46613308e-01, 8.23272733e-01,-1.04753678e-01, 7.87653516e-01, 5.33736860e-01, 3.07777360e-01, 8.51814816e-01, 7.29870149e-01,-5.67521706e-03, 2.37203887e-02, 6.33280960e+00, 4.08845288e+05, 4.48007235e+01, 5.33139458e-02, 2.37384134e-02], [4.47498908e-01, 1.49080014e-01,-9.07106172e-03,-2.67174181e-01,-5.21700457e-01, 8.10213916e-01, 9.18038857e-01, 8.36740457e-01,-7.64173908e-03,-1.18870530e-02, 6.18394833e+00, 7.37307204e+01,-5.58432681e+01, 3.83996968e-01, 9.18497562e-01], [4.71607629e-01, 1.31179570e-01,-4.56846546e-02,-9.27597302e-01,-3.63639607e-01,-8.56123912e-02, 3.32925650e-01, 2.86999292e-01,-1.37396795e-01,-2.39745171e-01, 6.28318531e+00,-9.03421275e+04,-9.83543039e+03,-1.09839821e+00, 1.05041514e+00], [4.71613040e-01, 1.31166299e-01,-4.56797268e-02,-9.27775404e-01,-3.64117510e-01,-8.15551274e-02, 3.32854008e-01, 2.86979856e-01,-1.36950051e-01,-2.39623484e-01, 6.28318531e+00,-2.85787226e+05, 1.02588457e+05,-1.09795489e+00, 1.05020120e+00], [1.72510574e-01, 3.40244123e-02,-1.78258372e-01,-1.78623912e-01, 9.82406854e-01,-5.45001987e-02, 6.49133952e-01, 4.58514334e-01,-1.05587941e-01,-1.50382361e-01, 6.56445597e+00,-7.39915259e+01,-3.39043636e+01, 8.32312454e-01, 1.66266815e+00]])

labels = np.array([[ 1., 0.], [ 0., 1.], [ 0., 1.], [ 1., 0.], [ 0., 1.], [ 0., 1.], [ 0., 1.], [ 1., 0.]])

totalLoss = 0
totalTest = 0

with graph.as_default():
    x = tf.placeholder(""float"", [None, 15], name = ""x"")
    y = tf.placeholder(""int64"", [None, 2], name = ""y"")

    h1 = tf.Variable(tf.truncated_normal([15, 100], stddev = 0.1), name = ""h1"") 
    out = tf.Variable(tf.truncated_normal([100, 2], stddev = 0.1), name = ""out"")
    b1 =  tf.Variable(tf.truncated_normal([100], stddev = 0.1), name = ""b1"")
    bout = tf.Variable(tf.truncated_normal([2], stddev = 0.1), name = ""bout"")


    def model(x):
        layer_1 = tf.add(tf.matmul(x, h1), b1)
        layer_1 = tf.nn.relu(layer_1)

        out_layer = tf.matmul(layer_1, out) + bout
        return out_layer

    logits = model(x)
    
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y))
    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)

    with tf.Session(graph = graph) as session:
        for i in xrange(10):
            tf.global_variables_initializer().run()
            
            _ = session.run(optimizer, feed_dict = {x : features, y : labels})
            l = session.run(loss, feed_dict = {x : features, y : labels})
            test = session.run(tf.reduce_mean(-tf.reduce_sum(labels * tf.log(tf.nn.softmax(logits) + 1e-10), 1)), feed_dict = {x : features})
            totalLoss += l 
            totalTest += test

print(""mathematical : "", totalTest *1. /10)
print(""sparse_softmax_cross_entropy : "", totalLoss *1. /10)
```
",0,,13,2017-08-03T14:17:14Z,NONE
12001,Feature Request: Add separable_conv2d_transpose operation,"stat:contributions welcome,type:feature","Some recent papers (e.g.) have shown that transposed separable convolutions can be a great choice for decoders in encoder decoder architectures.

Can you add a seperable_conv2d_transpose operation comparable to the conv2d_transpose operation?",0,,4,2017-08-03T13:12:24Z,CONTRIBUTOR
11986,The FixedLenFeature of parse_example?,type:docs,"View[ API DOC](https://www.tensorflow.org/versions/master/api_docs/python/tf/parse_example).

The description maybe wrong?
`Each FixedLenFeature df maps to a Tensor of the specified type (or tf.float32 if not specified) and shape (serialized.size(),) + df.shape.`

But the example shows:
For dense results in two serialized Examples:

```
[
  features {
    feature { key: ""age"" value { int64_list { value: [ 0 ] } } }
    feature { key: ""gender"" value { bytes_list { value: [ ""f"" ] } } }
   },
   features {
    feature { key: ""age"" value { int64_list { value: [] } } }
    feature { key: ""gender"" value { bytes_list { value: [ ""f"" ] } } }
  }
]
```
We can use arguments:

```
example_names: [""input0"", ""input1""],
features: {
    ""age"": FixedLenFeature([], dtype=tf.int64, default_value=-1),
    ""gender"": FixedLenFeature([], dtype=tf.string),
}
```
And the expected output is:
```

{
  ""age"": [[0], [-1]],
  ""gender"": [[""f""], [""f""]],
}
```
The shape of output is (2, 1) not equal to (2, ) + (), where  (2,) is `(serialized.size(),)` and () is `df.shape`.
",1,,6,2017-08-03T03:52:02Z,NONE
11982,Feature Request: Kill session->run process,type:feature,"For mobile & embedded devices `session->run` is typically initiated through a user interaction. If the user presses the back button or continues to another screen before `session->run` finishes, the process is still lingering in the background wasting resources. Since these devices are relatively low powered, it would be great if we could cancel/kill the process when it's not needed anymore.


",1,,5,2017-08-03T01:53:12Z,NONE
11963,Infiniband with tensorflow,stat:community support,"-----------------------
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
commit 3bee923c9
- **Bazel version (if compiling from source)**:
0.4.5
- **CUDA/cuDNN version**:
cuda 8.0/cudnn 5.1.5
- **GPU model and memory**:
Titan Xp
- **Exact command to reproduce**:

### Describe the problem
I tried to use Infiniband with tensorflow using ` server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index, protocol='grpc+verbs')`.
But the session is not hanged.
I used S1, and S2, the cluster is configured with the Infiniband ip address. Is there something that I missed?


ibdev2netdev 
S1
mlx5_0 port 1 ==> ib0 (Down)
mlx5_1 port 1 ==> ib1 (Up)
S2
mlx5_0 port 1 ==> ib0 (Up)
mlx5_1 port 1 ==> ib1 (Up)

### Source code / logs",0,,1,2017-08-02T07:58:09Z,CONTRIBUTOR
11956,Feature Request: Correlation Layer ,,"There is a surging interest in Geometric Computer Vision and a large number of recent papers leveraging an operation(with small variations) dubbed ""Correlation"" layer. There is a CUDA kernel for this operation in the FlowNet paper's author's fork of Caffe. Is there plan on including it in Tensorflow? I couldn't locate a relevant issue anywhere and this is why I am raising this issue. ",0,,8,2017-08-02T01:06:17Z,NONE
11954,Dilated convolution does not preserve tensor shape,"stat:contributions welcome,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04.5 LTS
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
('unknown', '1.3.0-rc0')
- **Python version**: 
2.7.12

- **Exact command to reproduce**:
```
input_tensor = tf.placeholder(tf.float32, (10, None, 256, 3))

dilated = tf.nn.convolution(input_tensor,
                            tf.zeros((3, 1, 3, 16)),
                            dilation_rate=[2, 1],
                            padding='SAME')

print(dilated.get_shape()) # Displays: [10, ?, ?, 16], expected [10, ?, 256, 16]
```

### Describe the problem
The documentation for tf.nn.convolution has the spatial dimensions of the output given as:

```
If padding == ""SAME"": output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])
```

Which suggests that input_spatial_shape[0] should not affect output_spatial_shape[1], as is the case in the code block above.

This problem arises when using dilated convolutions as part of a larger model containing recurrent layers, in which one spatial dimension is left undefined to allow for unrolling the recurrent layers out during training along the undefined dimension.

This might be related to a [previously fixed problem with undefined batch sizes](https://github.com/tensorflow/tensorflow/issues/4742).
",0,,2,2017-08-02T00:39:43Z,NONE
11948,Memory leak in Java API when using GPU,type:bug/performance,"### System information
- **Custom code**: https://github.com/riklopfer/TensorflowJavaGpuMemoryTest
- **OS**: CentOS 7
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: n/a
- **Python version**: n/a
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: GeForce GTX 1080
- **Exact command to reproduce**: see https://github.com/riklopfer/TensorflowJavaGpuMemoryTest

### Describe the problem
Main memory on the machine is continuously consumed when running on the GPU. Memory consumption hovers around 600M when running on the CPU.

### Source code / logs
see: https://github.com/riklopfer/TensorflowJavaGpuMemoryTest",0,,12,2017-08-01T18:52:55Z,NONE
11943,Consoles freezes while reading an image. ,stat:community support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.2.0-5-g435cdfc 1.2.1
- **Python version**:  3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32)  GCC 4.4.7 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 5.1
- **GPU model and memory**: GTX-1050 4GB


### Describe the problem

Consoles freezes while reading an image. 

### Source code / logs

```python
import tensorflow as tf
image_filename = ""/home/kaiyin/PycharmProjects/tensorflow-for-machine-intelligence/images/chapter-05-object-recognition-and-classification/working-with-images/test-input-image.jpg""
filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(image_filename))
image_reader = tf.WholeFileReader()
_, image_file = image_reader.read(filename_queue)
image = tf.image.decode_jpeg(image_file)
sess = tf.InteractiveSession()
sess.run(image)
```

Also tried the non-interactive session:

```python
import tensorflow as tf
with tf.Session() as sess:
    image_filename = ""/home/kaiyin/PycharmProjects/tensorflow-for-machine-intelligence/images/chapter-05-object-recognition-and-classification/working-with-images/test-input-image.jpg""
    filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(image_filename))
    image_reader = tf.WholeFileReader()
    _, image_file = image_reader.read(filename_queue)
    image = tf.image.decode_jpeg(image_file)
    sess.run(image)
```

Error:

```
2017-08-01 17:39:36.997011: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-01 17:39:36.997023: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-01 17:39:36.997026: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-01 17:39:36.997028: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-01 17:39:36.997031: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-08-01 17:39:37.078504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-08-01 17:39:37.078697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1050
major: 6 minor: 1 memoryClockRate (GHz) 1.493
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 1.84GiB
2017-08-01 17:39:37.078705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-08-01 17:39:37.078708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-08-01 17:39:37.078715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0)
```

After showing the message above, the console is not responsive any more. 
",0,,1,2017-08-01T15:41:48Z,NONE
11937,TPU support,stat:community support,"I wanna add support for my Tensor Processing Unit chip in TensorFlow. 

My TPU is implemented as an accelerator for ARM v7 32bit processor and implements multiple arithmetic kernels, similar to GPU. It implements a simple memory mapped interface, SGDMA and vector instructions over tensors. I added vector extension to GCC 7.1.1 and can run bare metal C++ nets on embedded Ubuntu 16.04

I also checked the TF port  for Raspberry Pi 3, but it looks outdated and barely supported.

I'm not currently aware about the scope of work, but believe that should not be that complex, given open examples from GPU vendors and already existing port for Google TPU

Anyone interested in joining this project is highly welcome! Advise, links and code examples are much appreciated

Thank you",0,,3,2017-08-01T09:39:58Z,NONE
11930,No OpKernel was registered to support Op 'Dequantize' with these attrs,"stat:contributions welcome,type:feature","Im getting the following error while running quantized graph

```
   raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'Dequantize' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: final_training_ops/weights/final_weights/read/_1__cf__1 = Dequantize[T=DT_QUINT8, mode=""MIN_FIRST""](final_training_ops/weights/final_weights/read/_1__cf__1_quantized_const, final_training_ops/weights/final_weights/read/_1__cf__1_quantized_min, final_training_ops/weights/final_weights/read/_1__cf__1_quantized_max)]]

```",0,,10,2017-08-01T06:41:55Z,NONE
11923,Race condition in add_arg_scope causes silent incorrect behavior,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
Linux Mint 17.3 Rosa
- **TensorFlow installed from (source or binary)**: 
binary
- **TensorFlow version (use command below)**: 
v1.2.0-5-g435cdfc 1.2.1
- **Python version**: 
3.6.1
- **Bazel version (if compiling from source)**: 
N/A
- **CUDA/cuDNN version**: 
CUDA Version 8.0.44
cudnn 5.1.5
- **GPU model and memory**: 
GTX 970 4GB
- **Exact command to reproduce**:
python add_arg_scope.py

### Describe the problem

There is a race condition in `tensorflow.contrib.framework.python.ops.add_arg_scope` where it doesn't reliably extract the arg list. Sometimes the list is incorrect and sometimes when a function is redefined or reloaded, the old arg list is returned. 

In practice, even a function that isn't reloaded can get the wrong arg list. The behavior is strange and seems to depend on the contents of the function and not just its args.

This may be causing errors since `arg_scope` silently ignores any arguments not in the argspec of the ops it's given.

### Source code / logs
```python
import tensorflow as tf
from tensorflow.contrib.framework.python.ops import add_arg_scope, arg_scope, arg_scoped_arguments

# initial definition
@add_arg_scope
def foo(x='x', y='y'):
    if x:
        pass
    if y:
        pass

for i in range(50):
    # redefine the function with different args
    @add_arg_scope
    def foo(a=1, b=2, c=3, d=4, e=5, f=6, g=7, h=8):
        pass
    
    print(arg_scoped_arguments(foo))
```

sample output (it isn't always regular):

('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('x', 'y')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('x', 'y')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('x', 'y')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('x', 'y')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
('x', 'y')
('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')
...
",1,,8,2017-07-31T23:55:49Z,NONE
11909,Numeric instability of tf model when run o CPU,stat:community support,"I'm having problem with running a model on CPU. I trained it on GPU and it works just great on GPU with no issues whatsoever yet when run on CPU it computes differently and quickly falls into returning just NaNs.

I used Keras to construct the model which looks like this:
```
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input (InputLayer)               (None, 500)           0                                            
____________________________________________________________________________________________________
embedding_1 (Embedding)          (None, 500, 60)       300000      input[0][0]                      
____________________________________________________________________________________________________
conv1d_1 (Conv1D)                (None, 500, 128)      7808        embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_2 (Conv1D)                (None, 500, 128)      15488       embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_3 (Conv1D)                (None, 500, 128)      23168       embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_4 (Conv1D)                (None, 500, 128)      30848       embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_5 (Conv1D)                (None, 500, 32)       9632        embedding_1[0][0]                
____________________________________________________________________________________________________
conv1d_6 (Conv1D)                (None, 500, 32)       11552       embedding_1[0][0]                
____________________________________________________________________________________________________
global_average_pooling1d_1 (Glob (None, 128)           0           conv1d_1[0][0]                   
____________________________________________________________________________________________________
global_average_pooling1d_2 (Glob (None, 128)           0           conv1d_2[0][0]                   
____________________________________________________________________________________________________
global_average_pooling1d_3 (Glob (None, 128)           0           conv1d_3[0][0]                   
____________________________________________________________________________________________________
global_average_pooling1d_4 (Glob (None, 128)           0           conv1d_4[0][0]                   
____________________________________________________________________________________________________
global_average_pooling1d_5 (Glob (None, 32)            0           conv1d_5[0][0]                   
____________________________________________________________________________________________________
global_average_pooling1d_6 (Glob (None, 32)            0           conv1d_6[0][0]                   
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 576)           0           global_average_pooling1d_1[0][0] 
                                                                   global_average_pooling1d_2[0][0] 
                                                                   global_average_pooling1d_3[0][0] 
                                                                   global_average_pooling1d_4[0][0] 
                                                                   global_average_pooling1d_5[0][0] 
                                                                   global_average_pooling1d_6[0][0] 
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 576)           0           concatenate_1[0][0]              
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 576)           2304        dropout_1[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 300)           173100      batch_normalization_1[0][0]      
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 300)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
batch_normalization_2 (BatchNorm (None, 300)           1200        dropout_2[0][0]                  
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 24)            7224        batch_normalization_2[0][0]      
====================================================================================================
Total params: 582,324
Trainable params: 580,572
Non-trainable params: 1,752
```

I used following code to debug it:
```
from keras import backend as K
import numpy as np

inp = model.input                                           # input placeholder
outputs = [layer.output for layer in model.layers]          # all layer outputs
functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function


# Testing
#test = np.random.random(model.input_shape[1])[np.newaxis,...]
x = numpy.asarray(tknzr.texts_to_sequences([str(x) for x in X]))
x = sequence.pad_sequences(x, maxlen=500)
layer_outs = functor([x, 1.])
i=0;
for l in layer_outs:
    print (model.layers[i].name)
    i+=1
    print (l)
```

I fed it with the very simple input just to show the differences.
The results on CPU are quickly starting to diverge from the values obtained on GPU. On GPU it looks like:
```
input
[[    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.    27.    13.     3.   233.  2459.     5.   689.]]
embedding_1
[[[ -3.76313413e-03   3.56433578e-02  -2.13286784e-02 ...,   4.60807569e-02
     1.64003521e-02   4.84493654e-03]
  [ -3.76313413e-03   3.56433578e-02  -2.13286784e-02 ...,   4.60807569e-02
     1.64003521e-02   4.84493654e-03]
  [ -3.76313413e-03   3.56433578e-02  -2.13286784e-02 ...,   4.60807569e-02
     1.64003521e-02   4.84493654e-03]
  ...,
  [ -6.31065369e+00  -6.24338293e+00   2.05590415e+00 ...,   9.74539161e-01
    -1.58533490e+00  -2.32490934e-02]
  [ -1.79465318e+00   7.12853432e+00  -9.40279942e-03 ...,  -8.01290665e+01
     1.42804585e+01  -2.88563843e+02]
  [ -8.28844547e+00  -1.10367613e+01   7.69042683e+00 ...,   1.41618121e+00
     1.20486283e+00   1.61890488e+01]]]
conv1d_1
[[[  0.00000000e+00   0.00000000e+00   5.55836601e+01 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   0.00000000e+00   5.55836601e+01 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   0.00000000e+00   5.55836601e+01 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  ...,
  [  0.00000000e+00   4.61124207e+02   0.00000000e+00 ...,   8.68512988e-01
     2.12859364e+01   3.05228138e+01]
  [  0.00000000e+00   0.00000000e+00   5.23455273e+03 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  1.76998459e+02   1.92677148e+03   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   3.46375618e+01]]]
conv1d_2
[[[     0.            294.24438477      0.         ...,    145.89456177
       88.91067505      0.        ]
  [     0.            294.24438477      0.         ...,    145.89456177
       88.91067505      0.        ]
  [     0.            294.24438477      0.         ...,    145.89456177
       88.91067505      0.        ]
  ...,
  [     0.          12730.79589844      0.         ...,   7905.12939453
     1696.24743652      0.        ]
  [     0.              0.          33181.72265625 ...,   4034.12573242
        0.              0.        ]
  [     0.            880.89868164      0.         ...,    102.81720734
      112.0918808       0.        ]]]
conv1d_3
[[[  0.00000000e+00   2.28604034e+02   0.00000000e+00 ...,   0.00000000e+00
     1.81265926e+01   1.41597879e+00]
  [  0.00000000e+00   2.57441193e+02   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   2.57441193e+02   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  ...,
  [  4.42018008e+04   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  7.06631055e+03   4.40339990e+03   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   1.90917981e+03   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   1.50991055e+04]]]

```

Whereas on CPU it looks like:
```
input
[[    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
      0.     0.     0.    27.    13.     3.   233.  2459.     5.   689.]]
embedding_1
[[[ -3.76313413e-03   3.56433578e-02  -2.13286784e-02 ...,   4.60807569e-02
     1.64003521e-02   4.84493654e-03]
  [ -3.76313413e-03   3.56433578e-02  -2.13286784e-02 ...,   4.60807569e-02
     1.64003521e-02   4.84493654e-03]
  [ -3.76313413e-03   3.56433578e-02  -2.13286784e-02 ...,   4.60807569e-02
     1.64003521e-02   4.84493654e-03]
  ...,
  [ -6.31065369e+00  -6.24338293e+00   2.05590415e+00 ...,   9.74539161e-01
    -1.58533490e+00  -2.32490934e-02]
  [ -1.79465318e+00   7.12853432e+00  -9.40279942e-03 ...,  -8.01290665e+01
     1.42804585e+01  -2.88563843e+02]
  [ -8.28844547e+00  -1.10367613e+01   7.69042683e+00 ...,   1.41618121e+00
     1.20486283e+00   1.61890488e+01]]]
conv1d_1
[[[  0.00000000e+00   0.00000000e+00   5.55836601e+01 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   0.00000000e+00   5.55836601e+01 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   0.00000000e+00   5.55836601e+01 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  ...,
  [  0.00000000e+00   4.61124207e+02   0.00000000e+00 ...,   8.68513644e-01
     2.12859344e+01   3.05228119e+01]
  [  0.00000000e+00   0.00000000e+00   5.23455322e+03 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  1.76998474e+02   1.92677136e+03   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   3.46375618e+01]]]
conv1d_2
[[[            nan    294.24438477      0.         ...,    145.89456177
       88.91065979      0.        ]
  [            nan    294.24438477      0.         ...,    145.89456177
       88.91065979      0.        ]
  [            nan    294.24438477      0.         ...,    145.89456177
       88.91065979      0.        ]
  ...,
  [            nan  12730.79394531      0.         ...,   7905.12939453
     1696.24743652      0.        ]
  [            nan      0.          33181.7265625  ...,   4034.12597656
        0.              0.        ]
  [            nan    880.89862061      0.         ...,    102.81723785
      112.0918808       0.        ]]]
conv1d_3
[[[  0.00000000e+00   2.28604034e+02   0.00000000e+00 ...,              nan
     1.81265984e+01   1.41597819e+00]
  [  0.00000000e+00   2.57441193e+02   0.00000000e+00 ...,              nan
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   2.57441193e+02   0.00000000e+00 ...,              nan
     0.00000000e+00   0.00000000e+00]
  ...,
  [  4.42018008e+04   0.00000000e+00   0.00000000e+00 ...,              nan
     0.00000000e+00   0.00000000e+00]
  [  7.06631006e+03   4.40339746e+03   0.00000000e+00 ...,              nan
     0.00000000e+00   0.00000000e+00]
  [  0.00000000e+00   1.90918152e+03   0.00000000e+00 ...,              nan
     0.00000000e+00   1.50991055e+04]]]
```

Note the NaNs in the last shown layer though the values started to diverge much quicker.  The first difference is in conv1d_1 where it computes on the CPU:
```
  [  0.00000000e+00   4.61124207e+02   0.00000000e+00 ...,   8.68513644e-01
     2.12859344e+01   3.05228119e+01]
  [  0.00000000e+00   0.00000000e+00   5.23455322e+03 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  1.76998474e+02   1.92677136e+03   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   3.46375618e+01]]]
```
where is should:
```
  [  0.00000000e+00   4.61124207e+02   0.00000000e+00 ...,   8.68512988e-01
     2.12859364e+01   3.05228138e+01]
  [  0.00000000e+00   0.00000000e+00   5.23455273e+03 ...,   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [  1.76998459e+02   1.92677148e+03   0.00000000e+00 ...,   0.00000000e+00
     0.00000000e+00   3.46375618e+01]]]
```

Note: 8.68513644e-01 vs 8.68512988e-01 and following...

Unfortunately it renders perfectly working model into a worthless pile of weights that produces a vector full of NaNs :(
Does anyone have any idea of what could go wrong?

For the record, the model's  weights are:
```
[array([[ -3.76313413e-03,   3.56433578e-02,  -2.13286784e-02, ...,
          4.60807569e-02,   1.64003521e-02,   4.84493654e-03],
       [ -1.49039514e+03,   1.54171045e+03,   3.97881046e-02, ...,
         -5.78388453e+00,   2.43417993e-02,  -1.80144477e+00],
       [ -7.30040884e+00,  -6.69775963e-01,  -2.57102852e+01, ...,
          1.29456043e+01,   2.43919420e+00,  -2.05847025e-02],
       ..., 
       [ -2.07939720e+00,   1.65184236e+00,   5.03200665e-02, ...,
         -9.66950320e-03,  -3.28505486e-02,  -1.60967112e-01],
       [  2.00684814e+01,  -4.48382616e+00,   9.10888481e+00, ...,
          5.54858351e+00,   1.92856118e-01,  -3.27318764e+00],
       [  1.32376838e+00,  -8.82686138e+00,  -5.80457896e-02, ...,
          4.60517597e+00,   1.85110033e-01,  -7.66239548e+00]], dtype=float32), array([[[ -1.99184626e-01,  -6.24039583e-02,  -5.06775379e-02, ...,
           1.50278226e-01,   1.72856063e-01,   9.54210311e-02],
        [  8.40011835e-02,  -1.04346856e-01,  -1.50010496e-01, ...,
          -6.32669926e-02,   3.96224223e-02,  -4.31677438e-02],
        [ -8.77222940e-02,   5.68446703e-02,   5.21141998e-02, ...,
          -4.07455601e-02,  -1.41425105e-02,  -1.18918315e-01],
        ..., 
        [  3.44693642e+01,   9.11418945e-02,   1.19048271e+01, ...,
           1.09344691e-01,   1.87920347e-01,   1.70073420e-01],
        [  1.95824668e-01,   7.89859332e-03,   9.49118510e-02, ...,
          -3.29354890e-02,   9.31546241e-02,  -1.15318425e-01],
        [  5.89678064e-02,   1.41023742e-02,   1.11247830e-01, ...,
          -9.51733999e-03,  -1.24835804e-01,  -1.12498775e-01]]], dtype=float32), array([  1.22442953e-02,  -1.09238578e-02,  -2.47095129e-04,
         1.17717348e-02,  -3.92556889e-03,  -5.25355758e-03,
         6.99595024e-04,  -1.10572961e-03,  -1.23395994e-02,
                    nan,  -1.07570309e-02,              nan,
        -4.08349838e-03,              nan,  -4.71794903e-02,
                    nan,  -8.35025460e-02,   4.59762150e-03,
        -1.97616145e-02,  -4.07275278e-03,              nan,
        -2.22547930e-02,  -1.18769081e-02,  -4.17554192e-03,
        -1.11441838e-03,  -4.26767347e-03,  -7.31970591e-04,
         1.48863369e-03,  -8.20796192e-03,  -5.81618951e-05,
        -9.59698856e-03,   1.10042130e-03,  -2.86204537e-04,
        -1.64017070e-03,  -3.14154982e-04,   9.65116825e-03,
        -3.80394212e-03,  -1.14975907e-02,  -1.14118000e-02,
        -6.63896417e-03,  -1.02947457e-02,  -9.60258301e-03,
        -1.01221241e-02,  -3.38621135e-03,  -9.19509027e-03,
                    nan,  -2.48736516e-03,  -2.78100204e-02,
        -6.50373427e-03,  -1.12824216e-02,  -1.99352647e-03,
        -2.70526763e-03,  -3.97901144e-03,  -8.55945144e-03,
        -2.47867964e-03,  -7.23447651e-03,  -1.89489545e-03,
                    nan,   2.34743766e-03,  -1.76552832e-02,
        -1.13650626e-02,  -8.72352626e-03,  -1.39924623e-02,
        -9.96223418e-04,   1.19819669e-02,  -1.65980589e-02,
        -4.43597836e-03,  -1.32924877e-03,   5.39703481e-03,
        -5.20827901e-03,   2.09201197e-03,  -9.91921872e-04,
        -4.76511335e-03,  -2.82827131e-02,  -3.15303504e-02,
         7.75449863e-03,  -2.50613503e-03,   5.26739890e-03,
        -9.09337029e-03,  -4.06189971e-02,  -2.45879288e-03,
        -6.14755554e-03,  -4.51790220e-05,  -1.96866468e-02,
        -6.05669746e-04,  -1.08566531e-03,  -2.80132494e-03,
         1.35421744e-02,  -1.56419240e-02,  -9.22969636e-03,
        -1.79088686e-03,  -6.13477267e-03,   3.58441076e-03,
        -7.55022466e-03,   7.20449630e-03,   9.64386389e-03,
        -2.01407354e-02,   3.64139187e-03,  -8.29497911e-03,
        -9.83765721e-03,  -6.11743657e-03,   1.19033596e-03,
         3.14918067e-03,   9.48947109e-03,  -1.80235994e-03,
        -3.43534909e-03,  -9.94156580e-03,  -1.02966810e-02,
        -1.11212442e-02,  -1.83315631e-02,   1.77474413e-02,
        -5.63624455e-03,   1.24310488e-02,  -7.89506827e-03,
         5.76251280e-03,   3.04201362e-03,  -9.81117040e-03,
        -2.30816868e-03,  -1.17079932e-02,  -3.04500442e-02,
         1.04938364e-02,  -1.00002484e-02,  -5.61673800e-03,
        -1.49540678e-02,  -4.57247645e-02,  -2.97049657e-02,
        -1.49060250e-03,  -4.22246335e-03], dtype=float32), array([[[ -5.67133713e+00,   4.49010801e+00,  -3.19202495e+00, ...,
           8.94742459e-02,   5.86951338e-02,  -4.10384983e-02],
        [  1.06694847e-01,  -1.19669974e-01,   1.73447832e-01, ...,
          -4.61597033e-02,   7.81161070e+00,  -9.81731415e-02],
        [  3.78304683e-02,   6.29944146e-01,   5.74416220e-01, ...,
          -3.67318280e-02,   1.13924325e-01,  -5.70971444e-02],
        ..., 
        [  3.19900885e-02,  -1.08785249e-01,   1.04148674e+01, ...,
          -1.18532476e+01,   1.17602840e-03,   6.20494075e-02],
        [  1.15054836e+01,   1.16688490e-01,   1.07223682e+01, ...,
           8.48904774e-02,   3.37078786e+00,   1.72410712e-01],
        [ -6.89478666e-02,  -5.79792976e-01,   1.74256325e+00, ...,
           3.34965885e-02,   9.88691524e-02,  -7.72289336e-02]],

       [[ -4.56401205e+00,  -1.70166504e+00,  -4.00359268e+01, ...,
          -1.60190001e-01,   7.67084712e-04,  -6.53180247e-03],
        [  1.53721035e-01,   4.46713977e-02,  -4.76150699e-02, ...,
          -8.13984126e-02,  -4.89648283e-02,  -5.83464168e-02],
        [ -7.04783201e-02,  -1.08484268e-01,   2.35563189e-01, ...,
           4.65062571e+00,   8.50204751e-02,   5.00446837e-03],
        ..., 
        [ -1.37988487e-02,  -4.87490520e-02,   8.56983513e-02, ...,
           9.54836905e-02,   7.68516883e-02,   4.86173406e-02],
        [  1.28548712e-01,   2.28847917e-02,   9.46553797e-02, ...,
          -3.44736390e-02,   5.21991348e+00,  -5.61943185e-03],
        [ -8.80202651e-02,   6.42642140e-01,  -1.28573000e-01, ...,
          -6.45207912e-02,   3.76606435e-02,   6.43695444e-02]]], dtype=float32), array([             nan,  -1.16861016e-02,   1.06510427e-02,
        -1.00857085e-02,  -3.16432514e-03,   5.28910290e-03,
        -3.37183755e-03,  -5.42259403e-03,  -1.71696593e-03,
         6.63183979e-04,  -1.14967767e-02,  -1.24864047e-02,
         8.57937802e-03,  -8.48316122e-03,  -1.21079152e-02,
        -3.48650361e-03,  -1.25225978e-02,   6.70570601e-03,
         5.04712947e-03,   6.85022306e-03,              nan,
         3.81274032e-03,              nan,   9.87051427e-03,
         7.05182599e-03,  -4.13431972e-03,  -7.64692994e-03,
        -5.04446309e-03,   9.21117794e-03,  -8.85901693e-03,
         5.76300500e-03,   1.10929953e-02,  -4.79056872e-02,
         2.45477562e-03,   5.19062718e-03,  -1.07234372e-02,
         1.28654959e-02,  -2.64256280e-02,  -7.82623887e-03,
         1.58936554e-03,   1.94144645e-03,  -9.01379809e-03,
        -7.94421230e-03,  -9.22279246e-03,   1.28184948e-02,
         8.28053430e-03,  -1.91762717e-03,  -7.50862667e-03,
         5.61357196e-03,  -1.29625732e-02,  -9.95500293e-03,
        -1.55696608e-02,  -1.02757392e-02,  -8.53954721e-03,
        -5.20441961e-03,  -6.20087667e-04,  -4.11103945e-03,
        -5.66026429e-05,  -4.81751822e-02,  -1.19420085e-02,
        -1.14781095e-03,   1.82268117e-02,  -4.04010108e-03,
        -3.97138792e-04,   1.23193730e-02,  -5.21201408e-03,
        -9.81894135e-03,   2.68496876e-03,   2.54207547e-03,
        -8.91120639e-03,  -1.21979211e-02,  -1.08713415e-02,
         5.36955427e-04,   6.40868861e-03,   1.28432624e-02,
         1.19460337e-02,   1.27818873e-02,  -1.24154398e-02,
         1.63561814e-02,  -8.23633932e-03,  -4.27962840e-03,
        -1.16055720e-02,  -1.09054958e-02,   5.52257756e-03,
         1.22179277e-02,  -1.70459468e-02,   1.45145757e-02,
        -2.81992904e-03,   1.21280942e-02,  -4.49353713e-04,
         5.24557894e-04,  -9.54091083e-03,  -1.64333021e-03,
        -1.64759357e-03,  -2.43817759e-03,  -1.37002217e-02,
         3.06799076e-03,   1.03644496e-02,   1.23127848e-02,
        -8.38474371e-04,  -8.28741584e-03,  -4.09937929e-03,
         2.41700746e-03,  -7.54709821e-03,  -4.19640495e-03,
        -6.47489447e-03,  -1.27521744e-02,   1.19293816e-02,
        -1.73897448e-03,  -1.77855510e-02,   9.67702712e-04,
        -1.86440512e-03,  -1.19959423e-02,   2.26790202e-03,
         1.28469197e-02,   1.03012251e-04,  -7.98405055e-03,
         3.69331776e-03,  -2.29048952e-02,  -2.48414255e-03,
        -4.03112406e-03,  -1.02750035e-02,   9.63258557e-03,
        -9.45603568e-03,  -9.57334414e-03,  -3.22731212e-03,
         1.06190313e-02,  -3.17891054e-02], dtype=float32), array([[[ -1.61977196e+00,  -7.39741027e-02,   3.43860276e-02, ...,
          -8.21563378e-02,  -3.90652902e-02,   4.53755051e-01],
        [  1.00042380e-01,  -7.75875032e-01,  -1.36523447e+01, ...,
           1.06767498e-01,  -2.50063915e+01,  -7.44080126e-01],
        [  3.38117170e+00,   3.06568718e+00,   3.14826891e-02, ...,
           2.25776862e-02,  -9.88149464e-01,  -4.45492458e+00],
        ..., 
        [  9.40100002e+00,  -5.44576719e-02,   2.02827530e+01, ...,
           1.68967806e-02,   1.54567789e-02,   5.55494428e-01],
        [  4.40017819e-01,  -2.21299052e+00,  -2.51157563e-02, ...,
          -7.26501718e-02,   3.84688005e-02,  -3.95980949e+01],
        [  8.49678397e-01,  -3.78436089e-01,  -7.45657778e+00, ...,
          -1.15545931e+01,   7.55678117e-02,  -5.93765163e+00]],

       [[ -1.09657323e+00,  -3.41127610e+00,  -2.64547355e-02, ...,
          -1.05148535e+01,  -2.34183741e+00,   6.30887461e+00],
        [  1.08152907e-02,  -5.99248447e-02,  -4.27437496e+00, ...,
           9.48090839e+00,  -1.31728077e+01,  -1.99199450e+00],
        [  4.63601875e+00,   8.85547578e-01,   8.49755383e+00, ...,
           4.01883647e-02,  -5.40873070e+01,  -8.10760593e+00],
        ..., 
        [  1.63729572e+00,   1.07432418e-01,   5.13684988e+00, ...,
           9.78041458e+00,   1.18023157e+01,  -1.92248020e+01],
        [  2.18332148e+00,   2.69323587e-01,   5.46097644e-02, ...,
          -6.50963048e-03,   1.79492927e+00,  -4.89809561e+00],
        [ -9.75892162e+00,  -5.55556975e-02,  -4.50018120e+00, ...,
          -5.22859767e-02,  -9.14887714e+00,   6.72427177e-01]],

       [[ -1.28133631e+00,  -1.15324832e-01,   4.84604597e+00, ...,
           8.53913128e-01,  -4.12158108e+00,   3.20745516e+00],
        [  5.03665566e-01,  -6.51536644e-01,  -1.99298458e+01, ...,
          -4.51152563e+00,  -3.04961085e+00,  -7.68840981e+00],
        [  8.86888266e-01,   1.83413160e+00,   1.15422651e-01, ...,
           3.19552784e+01,  -1.02603951e+01,   5.06386347e-02],
        ..., 
        [ -3.43910828e-02,   8.03594384e-03,  -6.82456121e-02, ...,
          -1.32336438e+00,   9.69354534e+00,   1.43188864e-01],
        [  1.94831336e+00,   7.06176579e-01,  -1.22930088e+01, ...,
           3.19514275e+01,  -3.98706011e-02,   1.26935318e+02],
        [ -1.76737213e+02,   6.87187672e-01,   8.70995164e-01, ...,
           5.70003223e+00,  -1.45483494e+00,   2.32137394e+01]]], dtype=float32), array([ -3.26319179e-03,   1.00775659e-02,   1.24532217e-02,
        -5.61445113e-03,   1.23609733e-02,   2.54739518e-03,
         9.75468103e-03,   2.58134492e-03,              nan,
        -6.60398882e-03,  -6.77689118e-03,              nan,
        -6.14733994e-03,  -1.29952980e-02,  -8.97676032e-03,
        -8.59634299e-03,              nan,              nan,
        -2.95513729e-03,   1.18087698e-02,  -6.92531653e-03,
        -3.81476502e-03,   4.01055673e-03,  -1.87762303e-03,
                    nan,  -8.76397081e-03,   3.31577263e-03,
        -7.15260301e-03,              nan,  -9.94501822e-03,
         8.71287752e-03,   2.85709789e-03,   1.01934960e-02,
         5.10863215e-03,   8.00231192e-03,   1.30663458e-02,
                    nan,  -2.66836630e-03,  -5.84459817e-03,
        -9.70377401e-03,  -5.44005353e-03,  -1.94316905e-03,
                    nan,   6.81864610e-03,  -3.55707551e-03,
                    nan,              nan,              nan,
         7.12703820e-03,  -6.48293830e-03,  -5.05002216e-03,
        -5.49217407e-03,  -6.58929441e-03,   3.22370703e-04,
                    nan,  -4.25100280e-03,  -1.21072698e-02,
        -4.67845378e-03,   1.12837339e-02,              nan,
        -5.03929658e-03,  -7.51174660e-03,  -1.92871108e-03,
        -7.48544186e-03,  -8.55511334e-03,              nan,
         1.22985756e-02,  -9.50173382e-03,              nan,
        -7.84607977e-03,              nan,              nan,
         2.10464559e-03,  -2.24326691e-03,   8.51140916e-03,
         8.25999025e-03,   1.06525635e-02,   1.98795414e-03,
        -4.74094879e-03,  -6.73289353e-04,  -6.25591958e-03,
         5.25373733e-03,  -1.02844061e-02,  -1.83374190e-03,
         3.19173466e-03,  -1.91105681e-03,  -1.02188773e-02,
         1.23149445e-02,   8.52429774e-04,   3.51795199e-04,
         3.75404325e-03,              nan,  -3.79106204e-05,
         8.06951057e-03,              nan,  -2.73329369e-03,
        -1.09396372e-02,              nan,   6.13762764e-03,
        -2.86296476e-04,   1.28226317e-02,  -3.92029062e-03,
                    nan,              nan,              nan,
         3.60080437e-03,              nan,   8.31638649e-03,
        -6.92761596e-03,              nan,  -1.35375967e-03,
         1.14998326e-03,   3.87885934e-03,  -2.76077818e-03,
        -6.00072276e-03,  -5.45156840e-03,  -4.58881212e-03,
        -4.49480955e-03,              nan,   1.20337764e-02,
        -7.77600612e-03,              nan,  -1.05871297e-02,
        -6.26315596e-03,  -6.49133092e-03,              nan,
        -4.12164629e-03,  -1.56654476e-03], dtype=float32), array([[[  9.79139938e+01,   6.50725784e+01,  -2.97711365e+02, ...,
          -5.06063690e+01,  -2.56701141e+02,  -3.16261673e+01],
        [ -1.51150751e+01,  -1.56986221e+02,   1.86006622e+02, ...,
          -3.05852753e+02,  -7.03881741e+00,   4.88232346e+01],
        [  4.23546844e+02,  -5.02201891e+00,   8.98978577e+01, ...,
           1.63829773e+02,  -1.78304108e+02,  -1.39583206e+02],
        ..., 
        [ -2.89913425e+01,  -3.32941986e+02,  -3.21323486e+02, ...,
           2.13999649e+02,   4.47361803e+00,   1.70371838e+01],
        [ -4.92524338e+00,   2.07512909e+02,   1.72584229e+01, ...,
          -6.62303925e+01,   3.61030388e+01,   1.54256191e+01],
        [ -1.19239189e+02,   8.50090885e+00,  -1.25474405e+01, ...,
           2.98828545e+01,  -2.49162731e+01,   1.00076149e+02]],

       [[  3.35705017e+02,  -3.44381237e+00,  -7.37603149e+01, ...,
           1.34216904e+02,  -2.61415283e+02,   3.10259857e+02],
        [ -2.39945786e+02,   1.41973862e+02,   1.38914764e+02, ...,
           8.80347639e-02,  -2.73359741e+02,   2.96114716e+02],
        [  1.49376358e+02,   4.49186897e+01,   2.00130661e+02, ...,
           9.72330994e+02,  -1.42100105e+01,  -6.58187927e+02],
        ..., 
        [  2.92934055e+01,  -6.77076578e-02,   7.36021271e+01, ...,
           3.20087932e-02,   1.15392891e+02,  -9.85379791e+01],
        [ -9.74929581e+01,   4.77340408e-02,  -1.07744355e-02, ...,
          -2.54074135e+01,   2.96503563e+01,   2.98027916e+01],
        [  4.05228519e+00,   5.41728783e+01,  -1.24106041e+02, ...,
           4.01345432e-01,  -7.40911961e+00,  -2.39570007e+02]],

       [[ -1.43696884e+02,   1.93436527e+01,  -2.52150314e+02, ...,
          -1.49458786e+02,   3.11022583e+02,  -1.83917038e+02],
        [  2.52352753e+01,  -1.12239952e+02,   4.66152840e+01, ...,
          -7.23185272e+01,  -1.00572090e+01,   7.35368805e+01],
        [ -3.30404144e+02,  -1.20080490e+02,   1.45473413e+01, ...,
           4.90700653e+02,   3.48218232e-02,   2.57165771e+02],
        ..., 
        [ -7.71125412e+01,  -7.23573542e+00,   8.59337151e-02, ...,
          -6.72250519e+01,  -8.87803650e+01,   6.36297760e+01],
        [  4.29378033e+00,  -8.53653107e+01,  -5.06322823e+01, ...,
          -7.49750900e+01,  -6.81370010e+01,   3.04435005e+01],
        [ -1.38102093e+01,   6.35605591e+02,   1.25637688e+02, ...,
           3.12087307e+01,   2.33276215e+01,  -9.11381607e+01]],

       [[  1.19963753e+02,   1.25849480e+02,   1.68638840e+01, ...,
           3.44137230e+01,  -8.09484329e+01,  -2.24104404e+01],
        [  3.10278137e+02,   5.95514870e+01,   4.31755753e+01, ...,
           3.43056755e+01,   8.27812862e+00,   1.58922095e-02],
        [  5.67219238e+01,  -4.74581299e+01,  -7.78491516e+01, ...,
           3.26776505e+01,  -2.56649200e+02,   1.01390474e-01],
        ..., 
        [ -1.75327194e+02,  -4.58938560e+01,   6.34404242e-01, ...,
          -3.87439613e+01,  -7.91211367e+00,  -8.94857712e+01],
        [  7.56060104e+01,   1.56444870e+02,  -2.60908478e+02, ...,
           1.68213852e+02,   5.67190979e+02,   4.63721466e+00],
        [ -5.50123482e+01,   1.95592957e+01,  -7.65384293e+01, ...,
           1.04166008e+02,   8.10883789e+01,   5.42043671e-02]]], dtype=float32), array([-0.00303183,  0.00052687,         nan, -0.00276367, -0.00478679,
        0.00573551,         nan, -0.00471952,  0.00341398,  0.00209433,
               nan,         nan,         nan,         nan,  0.01182292,
        0.00603716,  0.0003571 ,  0.00553664, -0.01277675,  0.00630027,
        0.01577267, -0.00024848, -0.00744215,         nan,  0.00770565,
        0.0108814 , -0.00526975,         nan,         nan, -0.00473122,
               nan, -0.00862104,  0.01198716,         nan, -0.00185599,
        0.01280991, -0.00830201,  0.0110528 ,         nan,  0.00829809,
               nan,         nan,         nan,         nan,  0.00017231,
        0.01054838, -0.00451169, -0.00078534,  0.01054926,  0.00073076,
               nan,  0.00404945, -0.01106562, -0.00458357, -0.00236127,
       -0.00407398, -0.0123809 ,  0.01148851,         nan,  0.00426665,
               nan,  0.00728147,  0.00257697,         nan,         nan,
        0.0035989 ,  0.01292581,         nan, -0.00101485,         nan,
        0.00752651,  0.012406  , -0.00747198,         nan,         nan,
        0.00028732,         nan,         nan, -0.00726563,         nan,
               nan, -0.00202225, -0.01011117, -0.00427364,  0.01191354,
               nan, -0.00349384, -0.00765174,         nan,         nan,
       -0.0057144 ,         nan,  0.01273667,  0.00771824,  0.00584222,
        0.00526332,  0.01213388,         nan, -0.00803087,         nan,
       -0.01128767,         nan,  0.00313656,         nan,         nan,
               nan, -0.00105658,         nan, -0.00222129,  0.00126256,
       -0.00483474,  0.00181649,         nan,  0.01274615, -0.0035703 ,
        0.01252608,  0.00395002,  0.00793831,  0.00475878,         nan,
        0.00117349,         nan, -0.00574742, -0.00536615,  0.00187141,
       -0.00195374,  0.01258923,  0.00935928], dtype=float32), array([[[ -1.45296729e+00,  -1.85899353e+01,   1.85860240e+00, ...,
           1.94930897e+01,  -1.47400606e+00,   7.29043732e+01],
        [  2.35075054e+01,  -1.03659582e+01,   9.96242142e+00, ...,
           2.11247150e-02,   2.00708313e+01,  -6.38016558e+00],
        [ -4.31753695e-01,   4.08484497e+01,   1.61803894e+01, ...,
          -6.04199505e+00,   6.41501397e-02,   9.52337086e-01],
        ..., 
        [ -2.21003017e+01,  -1.18904546e-01,  -1.55363083e-01, ...,
          -2.38874340e+00,  -4.60414673e+02,  -9.21500702e+01],
        [ -2.44020879e-01,  -3.07760040e+02,   2.20665344e+02, ...,
           1.41504839e-01,   6.73939667e+01,   7.69760971e+01],
        [ -6.71635568e-02,  -3.54697342e+01,   2.49731827e+01, ...,
           6.77688932e+00,  -1.29692221e+01,   7.68926392e+01]],

       [[ -8.56240845e+00,  -4.88954186e-01,   9.49547005e+00, ...,
          -1.01107016e-01,  -6.38556331e-02,   1.50050968e-01],
        [ -7.05387020e+00,   1.79977454e-02,   2.79764473e-01, ...,
          -2.17094421e+00,   9.58358228e-01,   3.31778831e+01],
        [ -1.36463273e+00,   6.40443116e-02,   7.02730036e+00, ...,
          -3.51816406e+01,  -5.56423092e+00,   1.91442057e-01],
        ..., 
        [ -1.49651198e-02,  -2.20929161e-02,   1.22701049e+00, ...,
           2.77249590e-02,   6.97759092e-02,  -5.58288574e+01],
        [  7.06718369e+01,  -3.51797342e-02,  -6.28136826e+01, ...,
           4.55904268e-02,  -1.19507370e+02,  -1.35787094e+00],
        [  2.48525453e+00,  -8.05968463e-01,  -3.65290785e+00, ...,
           2.53703240e-02,   8.64613712e-01,  -4.69191790e+00]],

       [[  9.13305879e-01,  -2.86780268e-01,   8.63831234e+00, ...,
          -1.64243639e-01,   4.79303040e-02,  -1.34833694e+00],
        [  4.19871140e+00,   2.35252619e-01,   5.80482446e-02, ...,
           1.02745809e-01,  -6.02718890e-02,   2.01890364e-01],
        [ -1.49204123e+00,  -3.45432043e-01,   1.39521313e+00, ...,
           1.53291887e-02,   3.16416211e-02,   1.99632749e-01],
        ..., 
        [  3.85478997e+00,  -4.91042061e+01,   1.10719744e-02, ...,
          -4.59006042e+01,   2.95897903e+01,   3.59708995e-01],
        [  9.65245056e+00,   2.97684765e+01,  -8.52102280e+00, ...,
           5.24145317e+00,   6.61757469e-01,  -7.93726778e+00],
        [ -1.76229572e+00,  -3.71834159e-01,   3.96519870e-01, ...,
           4.75902596e+01,  -1.80244904e+01,  -5.53226042e+00]],

       [[ -5.77183228e+01,   8.02351151e+01,  -8.58829956e+01, ...,
           1.63730297e+01,  -7.77448273e+00,   3.93538404e+00],
        [  1.75697727e+01,  -3.36315422e+01,  -4.92112541e+00, ...,
          -9.84368744e+01,   1.35106974e+01,  -1.07538238e-01],
        [ -2.01689930e+01,  -5.16754723e+01,  -3.77257729e+01, ...,
          -3.77422869e-01,  -1.33594424e-02,   6.95656281e+01],
        ..., 
        [  2.45753989e-01,  -1.22433269e+00,  -2.04659209e-01, ...,
          -4.91189808e-02,   2.15090290e-01,   4.25090647e+00],
        [  4.65992361e-01,  -2.33611241e-02,   1.78628671e+00, ...,
          -6.76035285e-02,   7.90065527e-01,   1.43017685e+00],
        [ -9.79941368e+00,   3.30868387e-03,  -8.15405846e+00, ...,
          -1.62937809e-02,  -2.52626985e-01,  -8.99091840e-01]],

       [[ -4.05211896e-02,   2.87306875e-01,   8.19576073e+00, ...,
           9.16721573e+01,   1.19460239e+01,  -1.11535025e+01],
        [  6.69084883e+00,  -2.85312481e+01,  -1.31200695e+01, ...,
          -2.19567269e-01,   3.48937774e+00,   1.40147152e+01],
        [  9.00131524e-01,   3.83975296e+01,  -8.44452381e-01, ...,
          -2.13302597e-01,  -3.27482596e-02,   3.68042976e-01],
        ..., 
        [  4.49458542e+01,  -1.46812403e+00,   1.56103373e+00, ...,
          -3.38927956e+01,   1.97558090e-01,  -1.12726234e+02],
        [  3.74297786e+00,  -2.31305864e-02,  -1.06778107e+01, ...,
           3.03148955e-01,   2.86338590e-02,  -5.93775749e+00],
        [ -1.43102903e+01,  -3.51021767e+01,  -7.25477314e+00, ...,
           7.86737502e-02,  -4.04430218e-02,  -1.03887154e+02]]], dtype=float32), array([ 0.00721407, -0.01080991,  0.00202953,         nan, -0.00871999,
       -0.00979585, -0.0051407 ,         nan,  0.01252265, -0.00181422,
       -0.00819429,         nan,  0.00209477,  0.00645181, -0.00805668,
               nan, -0.00669367,  0.0101859 , -0.00478634,         nan,
               nan, -0.01159984, -0.00527002,  0.01011875,         nan,
        0.01290197,         nan, -0.00313366,  0.01090364,         nan,
               nan, -0.00534851], dtype=float32), array([[[ -8.29690695e-01,   1.51981525e-02,   1.80010319e-01, ...,
           5.66750526e-01,  -4.03445870e-01,   2.89482236e-01],
        [ -1.01449096e+00,   2.62717247e+00,   1.47955343e-02, ...,
          -2.47280979e+00,   3.46152306e-01,  -1.45272362e+00],
        [ -5.35625994e-01,   9.26369488e-01,   1.48123455e+00, ...,
           2.37583661e+00,  -9.48905349e-01,   4.46271926e-01],
        ..., 
        [ -4.07793236e+00,   9.04592097e-01,   4.52610940e-01, ...,
           7.79820025e-01,   8.25595617e-01,  -2.73653299e-01],
        [  1.01398051e+00,   2.77464420e-01,  -4.08575125e-02, ...,
          -7.94092119e-02,  -4.73003477e-01,  -3.22694874e+00],
        [  1.34389770e+00,   7.39578426e-01,  -1.99999583e+00, ...,
           1.59634852e+00,  -4.43105774e+01,   3.48869658e+00]],

       [[  4.49796051e-01,   1.62432404e+01,   2.99024284e-01, ...,
           2.39469528e+00,   3.63545680e+00,   1.33222399e+01],
        [ -1.25804222e+00,   5.93616903e-01,  -2.24094465e-01, ...,
           7.14776611e+00,  -6.07950096e+01,  -3.97061610e+00],
        [  5.73225451e+00,   3.44473243e-01,   4.89822502e+01, ...,
          -1.02140198e+01,  -8.63099694e-02,   1.03545511e+00],
        ..., 
        [ -2.90418053e+00,   1.66334426e+00,   5.34012127e+00, ...,
           5.08385658e+00,  -8.84643495e-01,   9.50575471e-02],
        [  2.43404126e+00,   3.19609120e-02,   1.15552902e+00, ...,
          -1.97065187e+00,  -2.18373016e-02,  -1.87884569e+00],
        [ -1.10491252e+00,  -7.00622857e-01,  -2.75327936e-02, ...,
          -1.67351559e-01,  -3.56536369e+01,   4.31534672e+00]],

       [[ -2.98323005e-01,   1.95138149e+01,  -6.61930680e-01, ...,
          -8.12640414e-02,   1.63551956e-01,  -1.92686641e+00],
        [ -2.47889729e+01,   2.75876876e-02,  -2.04139900e+00, ...,
          -4.11038667e-01,   2.69464999e-01,  -8.74109194e-02],
        [  5.85711956e+00,   3.21791115e+01,   3.46343189e-01, ...,
           4.58834410e+00,   6.28389931e+01,  -8.28920782e-01],
        ..., 
        [ -4.79541969e+00,   1.23082197e+00,   2.88488054e+00, ...,
           4.17237043e+00,   9.18720588e-02,   2.71237111e+00],
        [ -6.11321092e-01,   9.34896886e-01,   3.61941648e+00, ...,
          -2.09522057e+00,  -4.29104716e-02,   2.33770385e-01],
        [ -2.10204840e+00,   2.41703320e+00,   4.08353806e-01, ...,
          -1.11578882e+00,   6.10901237e-01,   3.12420082e+00]],

       [[  3.17858648e+00,  -1.15199342e-01,   7.99448907e-01, ...,
          -6.94288686e-02,  -3.78224194e-01,  -2.11228147e-01],
        [ -1.01672611e+01,   2.29932928e+00,  -8.23774040e-02, ...,
           1.10687828e+01,  -5.56976497e-01,  -4.18549194e+01],
        [  4.57473211e-02,  -1.62644148e+00,   1.10198345e+01, ...,
           1.72234133e-01,   4.72544543e-02,   9.63192642e-01],
        ..., 
        [  1.93458311e-02,   4.66402806e-02,   1.37197465e-01, ...,
           2.74113345e+00,   1.18698873e-01,   1.47488102e-01],
        [ -3.48606199e-01,   7.13406861e-01,   8.62872303e-01, ...,
           3.86153483e+00,  -3.22620296e+00,   1.43851032e+01],
        [ -1.28992152e+00,  -3.58179271e-01,  -1.59407692e+01, ...,
          -2.38189086e-01,   6.28528297e-01,   1.44906259e+00]],

       [[  1.38401061e-01,   1.56333103e+01,   3.94406766e-02, ...,
          -7.97948956e-01,  -8.32110122e-02,  -2.61989832e-01],
        [ -1.69780898e+00,   1.22613108e+00,   1.13238543e-01, ...,
          -5.42741203e+00,   5.35991639e-02,  -1.43280470e+00],
        [ -4.69797134e-01,  -1.67963159e+00,   8.70674551e-01, ...,
          -5.95084608e-01,  -4.11402397e-02,   5.14732115e-03],
        ..., 
        [ -1.86762452e+00,  -2.84470558e-01,   4.23804569e+00, ...,
           1.27319336e+01,  -1.56363716e+01,   2.92534500e-01],
        [ -5.73735118e-01,  -8.57480049e-01,   3.85818887e+00, ...,
          -7.57689953e+00,   1.69330168e+00,   1.80779419e+01],
        [ -3.45315456e+00,  -1.05621368e-02,  -4.53398257e-01, ...,
           2.06666350e+00,   7.84944892e-02,   3.17968488e+00]],

       [[ -4.06911325e+00,   1.65015548e-01,  -1.14256665e-01, ...,
           8.55081439e-01,  -1.74662575e-01,  -1.13633204e+00],
        [ -4.77266431e-01,   1.00441754e+00,   4.50561941e-01, ...,
          -7.69126475e-01,  -5.32188594e-01,  -8.28091562e-01],
        [  5.19197750e+00,  -2.57612914e-01,   4.44432318e-01, ...,
           1.72394907e+00,  -9.16882098e-01,  -1.48226023e+00],
        ..., 
        [ -2.42185307e+01,  -6.19122810e+01,   1.09572971e+00, ...,
           1.69736347e+01,   1.08710063e+00,   9.96017396e-01],
        [ -2.44375134e+01,   8.00353050e-01,   5.87797318e+01, ...,
          -9.42115688e+00,   9.32907388e-02,  -3.28873873e+00],
        [ -9.75492287e+00,  -4.38124895e-01,  -4.97199476e-01, ...,
          -3.35016060e+00,  -6.08749568e-01,   6.51416397e+00]]], dtype=float32), array([-0.00091459, -0.00620937, -0.00180343,  0.01052671,  0.00611617,
        0.00269699, -0.00578218,  0.01065915, -0.00869957,  0.01294277,
       -0.00639585, -0.0065877 , -0.00597737, -0.00342507, -0.0046289 ,
       -0.00190541,  0.00475265,  0.00023435,  0.00337634, -0.00540435,
       -0.00607256, -0.00419708,  0.01165059,  0.01108866, -0.00320541,
        0.01025646,  0.00874494,  0.01261826, -0.00963546,  0.00792126,
       -0.00331757,  0.01240073], dtype=float32), array([ 0.92324513,  0.91189975,  0.68247992,  0.611655  ,  1.11188841,
        1.24183393,  0.78877187,  0.94186455,  1.27621102,  0.95670766,
        1.2502116 ,  0.95994872,  0.80079126,  1.22881901,  1.41063344,
        1.07295191,  1.24689925,  0.9035126 ,  1.27278912,  1.34401119,
        1.23818433,  1.2192806 ,  1.19316161,  1.38558877,  1.18151259,
        0.70934945,  1.14419794,  0.70987469,  0.9374221 ,  1.27000499,
        1.3482002 ,  0.78130794,  1.02721739,  1.192191  ,  0.91440892,
        0.62458515,  0.81259495,  0.72212356,  1.28875387,  0.71674573,
        0.77234554,  0.79238915,  1.33870089,  0.8651765 ,  1.2067343 ,
        1.30049622,  0.77098888,  1.29051161,  1.23092282,  0.62862951,
        1.18639112,  1.28262627,  0.94983268,  0.65229762,  1.37430549,
        0.82133031,  1.33457494,  1.38797319,  0.78886795,  1.26026869,
        0.86639565,  0.66859865,  1.36260259,  1.06364739,  0.8305313 ,
        1.14732647,  1.18739545,  0.99207777,  0.7789138 ,  0.63479638,
        0.75854886,  1.22457278,  0.87885702,  1.41933584,  1.28638506,
        0.71523923,  1.14043164,  0.81472951,  1.39107215,  1.17304611,
        1.30299258,  0.81510711,  0.84077132,  1.22211564,  0.9681775 ,
        0.9281354 ,  1.23058033,  0.79885459,  1.24401665,  0.8758862 ,
        1.25450766,  0.84477127,  0.86915898,  0.63901693,  0.62361622,
        0.88031119,  1.35723126,  0.84122556,  0.76101047,  0.9330076 ,
        0.72560656,  0.67724234,  0.86384225,  1.01724434,  0.93573648,
        0.76780319,  1.31037223,  1.07925224,  0.81563425,  1.30601621,
        0.94119728,  1.2825371 ,  0.97992492,  1.22965431,  0.53950727,
        1.23549151,  0.59556764,  1.27590203,  1.25413597,  1.23823452,
        0.70959306,  0.62548274,  0.87274724,  1.23207903,  1.36108971,
        1.29653132,  1.18485701,  1.07082903,  0.82756746,  0.74832225,
        0.86865455,  0.93214756,  1.01476288,  0.9942596 ,  0.80549979,
        0.97460073,  0.92048162,  0.77916354,  0.78707469,  0.83674943,
        1.01871479,  0.78273112,  0.81403154,  0.88662291,  0.77351379,
        0.87571979,  0.92801058,  0.74901462,  0.77704167,  0.83975536,
        1.22084785,  1.0269258 ,  0.7466014 ,  1.32603633,  0.73203731,
        0.88649112,  0.7401551 ,  0.87404191,  0.89444137,  0.81067967,
        1.4649024 ,  0.75762224,  0.93519962,  0.74893814,  0.95110834,
        1.280568  ,  0.87244642,  0.7525841 ,  0.94060266,  0.77005023,
        1.25788486,  0.94583333,  0.87172806,  1.08644712,  0.91021127,
        0.86235201,  1.05104804,  1.22341335,  0.86605495,  1.27367413,
        0.76196283,  0.85116506,  0.70819497,  0.78221506,  1.0321089 ,
        1.12106144,  1.44357586,  0.75676209,  1.01206946,  1.02126384,
        1.32443583,  0.99048209,  1.03620136,  0.83227968,  0.79153019,
        0.82600629,  0.84851086,  0.81706792,  1.24497879,  1.26714015,
        0.77497232,  0.72850466,  0.80097783,  1.12743843,  0.81188363,
        0.77680135,  0.9681018 ,  0.86912555,  0.82433802,  1.08783257,
        0.77873075,  1.08205795,  0.73998272,  1.29796326,  1.03962433,
        0.79080981,  0.87378049,  1.25883913,  0.92012763,  0.99345338,
        1.16669178,  0.82504064,  0.91854829,  1.05217016,  1.02248108,
        0.82858986,  1.02929378,  1.09943044,  0.87474597,  0.8325696 ,
        0.75225061,  0.82186985,  0.88399786,  0.99284208,  0.77929509,
        0.80184114,  0.92587566,  1.37938547,  1.10543239,  0.79352069,
        0.80869478,  0.85203063,  0.89897668,  0.75929564,  0.86093128,
        0.87196112,  1.38894391,  0.86825073,  0.74169791,  0.76852977,
        0.91970271,  0.72150081,  0.73341006,  0.84463739,  0.83543485,
        1.34363723,  0.83324951,  0.92552757,  1.02850258,  0.71077508,
        0.93726856,  1.04080963,  0.85020447,  0.81692302,  0.82796645,
        0.6400485 ,  0.62768459,  0.947245  ,  0.88588703,  0.93196899,
        0.93230802,  0.95469648,  0.92390162,  0.84833068,  0.94646561,
        0.89167571,  0.63733917,  0.9116236 ,  0.82794297,  0.91070575,
        0.8822006 ,  0.98996753,  0.88207477,  0.88646972,  0.8521868 ,
        0.89941269,  0.77922833,  0.84261811,  0.88188922,  1.05048823,
        0.93200248,  0.98309511,  1.02783   ,  0.8090719 ,  0.70652324,
        0.73236096,  0.90449786,  0.87350255,  0.84028536,  1.10842824,
        0.9247309 ,  0.96409667,  0.7645945 ,  0.97348124,  0.83638608,
        0.98999095,  0.85562307,  0.95512122,  0.72635466,  0.88122612,
        0.91798496,  0.70071429,  0.82288027,  1.11360848,  0.95942098,
        1.11058652,  0.92326015,  0.98234093,  0.72201574,  0.87033051,
        0.77146524,  1.00500035,  0.72814441,  0.719607  ,  1.03981459,
        0.68174195,  1.01526725,  0.86931908,  0.82885873,  0.9725039 ,
        0.89089197,  1.05959928,  0.8540464 ,  0.90424043,  0.81220067,
        0.84160411,  0.6650098 ,  0.95070642,  0.90326285,  0.81896961,
        0.98918557,  0.89003968,  0.90541989,  0.92553186,  0.87018538,
        0.73151058,  0.85450697,  0.924833  ,  0.67955649,  0.8936466 ,
        0.96428728,  1.00697994,  1.1095928 ,  0.96397698,  0.91212779,
        0.98802084,  0.87135857,  0.72244912,  0.88761735,  0.9826352 ,
        0.90775639,  0.814991  ,  0.97274172,  0.87164116,  0.87200755,
        0.87039524,  0.86348069,  0.60782027,  0.99143809,  0.82865047,
        0.76348358,  0.82481432,  1.00521755,  0.95388275,  0.93471348,
        0.80328858,  0.97608858,  0.90786624,  0.78293693,  0.9387188 ,
        1.05676043,  0.94996649,  0.90885735,  0.76560307,  0.84717047,
        0.79366243,  0.98399621,  0.71567577,  0.66029119,  0.85207433,
        1.00126958,  0.69157439,  0.9107157 ,  0.85799575,  0.92462587,
        0.88748997,  0.93318915,  0.99592036,  0.7729736 ,  0.75125623,
        0.7421515 ,  0.7371279 ,  0.8069917 ,  0.89432222,  0.87229955,
        0.87646377,  0.64453566,  0.91080266,  0.97707778,  0.68118942,
        0.60430533,  0.92588139,  0.8567751 ,  0.93447566,  0.94679332,
        0.67847568,  0.83453822,  0.91654968,  0.92968297,  0.69324344,
        0.75036299,  0.77830368,  0.92005759,  0.87036562,  0.9363668 ,
        0.88637435,  0.80963498,  0.76762754,  0.92501837,  0.9008624 ,
        0.88113987,  0.83168811,  0.94614244,  0.82872683,  0.7752685 ,
        0.69449437,  0.60647815,  0.87106222,  0.6449452 ,  0.91489285,
        0.83349478,  0.76603216,  0.85015899,  0.89259475,  0.96830028,
        0.84974003,  0.77153814,  0.89535224,  0.9256832 ,  0.8008877 ,
        0.80640543,  0.83236629,  0.71014738,  0.76220351,  0.80116212,
        0.84920239,  0.71114242,  0.91479725,  0.78226274,  0.94460845,
        0.94747585,  0.97313702,  0.59300864,  0.92920971,  0.96162492,
        0.75395739,  0.55505848,  0.84639651,  0.64516205,  0.89154035,
        0.87502444,  0.62925559,  0.96463913,  0.91576618,  0.65746689,
        0.68906087,  0.66600591,  0.78059584,  0.94482565,  0.83121347,
        0.93048126,  0.89082116,  0.73019499,  0.89990819,  0.82093835,
        0.77312094,  0.87820232,  0.88318926,  0.94799238,  0.75950092,
        0.8085044 ,  0.6941905 ,  0.80920118,  0.93610948,  0.57750458,
        0.73357487,  0.8286469 ,  0.90382361,  0.6823318 ,  0.9106403 ,
        0.93044192,  0.87453932,  0.86136389,  0.78060842,  0.92122746,
        1.00319707,  0.68839288,  0.64943296,  0.79142654,  0.86752546,
        0.70153332,  0.91624457,  0.94828254,  0.83849299,  0.79837543,
        0.87679446,  0.8695612 ,  0.86987436,  0.86089462,  0.92754692,
        0.6679092 ,  0.66677892,  0.95932406,  0.97985977,  0.9611063 ,
        0.85794193,  0.87591904,  0.94417387,  0.94389588,  0.89519042,
        0.74272192,  1.01115835,  0.95259851,  0.86745769,  0.92278951,
        0.72078449,  0.93177384,  0.91099179,  0.94293749,  0.7468816 ,
        0.91201252,  0.590123  ,  0.92652237,  0.92053473,  0.98247588,
        0.86670363,  0.89657253,  0.95276397,  1.09993672,  0.84992331,
        0.61647707,  1.0624218 ,  0.9760294 ,  0.84544462,  0.93171477,
        0.66878033,  1.00695813,  0.97923803,  0.6804266 ,  0.95166844,
        0.99310899,  1.08601403,  1.04561758,  1.13575077,  0.66119641,
        1.04587078,  0.97103989,  1.0984236 ,  1.10031962,  0.91157776,
        1.19642639,  0.7539537 ,  0.85630423,  0.75334775,  0.83235133,
        0.94932777], dtype=float32), array([ 0.21513477,  0.25235781, -0.01164734,  0.00812957,  0.0469191 ,
        0.08426256,  0.02624334,  0.18139027,  0.13159387,  0.08998515,
        0.14502546, -0.04822301,  0.01167602,  0.10503929,  0.14026111,
        0.04108373,  0.03667439,  0.20382529,  0.18656163,  0.01321671,
        0.08295929,  0.16116051,  0.0947966 , -0.04603532,  0.09742413,
       -0.07467403,  0.24833094,  0.08291947,  0.01852527,  0.14373298,
        0.05248534,  0.20675589,  0.13275369,  0.07756286,  0.41444346,
       -0.07379562,  0.03522586,  0.1551806 ,  0.12376447, -0.08178429,
        0.07966474,  0.16586709,  0.05122001,  0.00604945,  0.22456609,
        0.13572276,  0.03780139,  0.17800449,  0.20268792,  0.01079178,
        0.09938767,  0.18528275,  0.20099923,  0.06780296,  0.00305275,
        0.09349702,  0.13340999,  0.18285613, -0.03720064,  0.20336342,
        0.15889709, -0.044036  ,  0.19432218,  0.0673499 ,  0.08878616,
       -0.00126485,  0.16699122,  0.21126172,  0.12083656, -0.0176493 ,
        0.16961034,  0.07944823,  0.03459396,  0.19645755,  0.13866211,
        0.06702986,  0.00886732, -0.02252088,  0.19451457,  0.16268517,
        0.15687318,  0.00331449,  0.09069867,  0.25872436, -0.12164863,
        0.16358218, -0.00682826,  0.03762042,  0.15828508,  0.07392085,
        0.13210936,  0.06433506,  0.18269709, -0.00348008,  0.04271064,
        0.04527429,  0.17402175,  0.12602551, -0.03505278,  0.14879747,
        0.00327524, -0.00505609,  0.00789965,  0.24499258,  0.18764867,
        0.02787114,  0.12370888,  0.18646622,  0.08006537,  0.31765482,
        0.09984814,  0.22597547,  0.10502543,  0.10769939, -0.08103713,
        0.14144586, -0.05742846,  0.19790782,  0.14855613,  0.1048301 ,
        0.0265718 , -0.09612875,  0.06837879,  0.09417342,  0.10076804,
        0.21487097,  0.11882482,  0.1344099 ,  0.01039768,  0.01046966,
        0.12080838,  0.17098039,  0.23318933,  0.13605478, -0.01817689,
        0.08002071,  0.07361093, -0.07623066,  0.06926445,  0.17542176,
        0.14412902,  0.22412172,  0.05991406,  0.09023374,  0.15624791,
        0.08426542,  0.17060365, -0.07120038, -0.05670423,  0.03806323,
        0.10895428,  0.31922793,  0.11434312,  0.10919707,  0.14502959,
        0.1610183 ,  0.00681128, -0.08269095,  0.24219224,  0.05926536,
        0.14226501,  0.14173776,  0.06112398,  0.03121125,  0.12308633,
        0.09533465, -0.02837656, -0.02005078,  0.11338665, -0.01487743,
        0.10338601,  0.1129363 ,  0.19798772,  0.1456272 ,  0.19310625,
        0.10701656,  0.25977972,  0.15427302,  0.05986759,  0.22551021,
        0.09458067,  0.10495061,  0.09350866,  0.06876841,  0.1423347 ,
        0.309156  ,  0.18146063,  0.06937418,  0.25378922, -0.03416175,
        0.02536071,  0.09677454,  0.14686505,  0.19095816,  0.07507709,
        0.18157071,  0.3017295 ,  0.10140018,  0.16234942,  0.19093814,
        0.09805069,  0.0550074 ,  0.13936727,  0.1347481 ,  0.19129212,
        0.09916603,  0.11527727,  0.12738715, -0.04907956,  0.20409778,
       -0.05126302,  0.07003123,  0.07933259,  0.15789157,  0.16495503,
        0.0382163 ,  0.16530749,  0.09226055,  0.29120147,  0.21301824,
        0.04310212, -0.05778586,  0.00651748,  0.22950931,  0.17440093,
        0.08809182,  0.09717909,  0.08513435,  0.19778129, -0.01846456,
       -0.05024394,  0.1230069 ,  0.04975546,  0.08784546,  0.00666083,
        0.11113517,  0.23783061,  0.17325942,  0.12386075,  0.0473346 ,
        0.03064803,  0.17498848,  0.24725163,  0.06897967,  0.03023582,
        0.13333851,  0.13429347, -0.02490993,  0.10004763, -0.00632021,
        0.01631161, -0.02700441,  0.17108987,  0.13485585,  0.05454494,
        0.09426814,  0.16256647,  0.05861462,  0.09804872, -0.03055473,
        0.14543988,  0.05096266,  0.10780343, -0.0242221 ,  0.00553415,
        0.0134938 , -0.02397695,  0.06497488,  0.02675983, -0.17460628,
       -0.04864439,  0.21374881,  0.12452196, -0.07948656,  0.31697804,
       -0.11074805,  0.03184726,  0.11444523, -0.01209346,  0.37230873,
        0.05219135,  0.15265796,  0.01635455,  0.16254823, -0.05262664,
        0.1656882 ,  0.04892838,  0.04358613, -0.01831526,  0.14575137,
       -0.04428541,  0.06114314,  0.01055301,  0.0806742 , -0.03822853,
        0.0024281 ,  0.23819065,  0.14820386,  0.15432395,  0.06820562,
        0.14084032,  0.0214096 ,  0.28960019,  0.03336281, -0.02258998,
       -0.11918389,  0.12191802,  0.12011044, -0.0383323 ,  0.09663165,
       -0.04327046,  0.23696648,  0.03797962,  0.16609034,  0.00134832,
        0.12600201,  0.06433844,  0.2159729 ,  0.12042333,  0.184242  ,
        0.07827154, -0.07142582,  0.13497566,  0.12408919,  0.08139872,
        0.08778475,  0.05593739, -0.07034422, -0.02145396,  0.1858903 ,
        0.13324609,  0.21348356,  0.06271571,  0.24681482,  0.03502885,
        0.09164923, -0.09670884,  0.13099472, -0.06682523,  0.06847583,
        0.15508497, -0.03456884,  0.17532405,  0.06655746,  0.06141814,
        0.09758208, -0.08340237, -0.07836234, -0.04713979,  0.26549336,
        0.08241519,  0.26755059,  0.15660191,  0.0140149 ,  0.06114695,
        0.1236652 ,  0.20641492, -0.0086607 ,  0.25696442,  0.16652805,
       -0.0189483 ,  0.08821324, -0.0561601 ,  0.09646437,  0.05534786,
        0.06144878,  0.08153529, -0.03351871,  0.18770348,  0.21821322,
        0.00923865,  0.05793909, -0.03316918, -0.01503262, -0.08808464,
        0.06295279,  0.03633495,  0.13560405, -0.09101282,  0.0784924 ,
        0.13943812,  0.07187323,  0.07224862,  0.00436772,  0.1421919 ,
        0.13261436, -0.04384675,  0.06922174, -0.05535286,  0.01790292,
        0.02594931,  0.03137456,  0.14343001,  0.13875815,  0.18751529,
        0.18230127,  0.16239385, -0.04877168,  0.05408951,  0.13819633,
        0.04689167,  0.00860408, -0.05521136,  0.08899331,  0.12256701,
        0.09942619,  0.05431732,  0.01246066,  0.2459348 ,  0.03505556,
        0.00352251,  0.10704872,  0.13250764,  0.09410823,  0.21223374,
       -0.06725354,  0.20313561,  0.05718818,  0.15772417,  0.08655146,
        0.18685333,  0.24251266,  0.04728935,  0.08336292, -0.01416809,
        0.11174773,  0.00846751,  0.09750774,  0.17642273,  0.20093188,
        0.08958908,  0.06244315,  0.06603803,  0.12445851,  0.10244825,
        0.03678581, -0.03146201,  0.07758824,  0.00737987,  0.05445781,
        0.08941389,  0.15300757,  0.01156699,  0.18133481,  0.02707617,
        0.01896188,  0.00373267,  0.05308403,  0.0893611 ,  0.07354195,
        0.2719883 ,  0.06033295,  0.11146184, -0.0334769 ,  0.17474252,
        0.0170496 , -0.03238125,  0.07332145,  0.00221918,  0.10075361,
        0.14380831,  0.05464551,  0.08960186,  0.08277151,  0.15450172,
        0.07375888, -0.00090652,  0.0227281 ,  0.03489426, -0.00458596,
        0.15148938, -0.02450214,  0.21064126,  0.20087112, -0.08557961,
        0.03035768,  0.00841392,  0.15346257,  0.09999306,  0.15065986,
        0.13216971,  0.14718296,  0.1095356 ,  0.00530122,  0.2183297 ,
        0.11066475,  0.25523499,  0.20002022, -0.11860739,  0.06214419,
       -0.01568105,  0.27799031,  0.14767797,  0.10479995,  0.10038255,
        0.04629319,  0.09810003,  0.07883403, -0.00560048,  0.23447773,
        0.2438803 ,  0.20737502,  0.13416626,  0.28730634,  0.05690536,
       -0.06244919,  0.03087391, -0.00481488,  0.20564254,  0.12845384,
        0.06240393,  0.13889894,  0.14797753,  0.15924339,  0.20609157,
        0.12777169,  0.16959696, -0.0650304 ,  0.23496245,  0.09176328,
        0.10268437, -0.01722782,  0.11177473,  0.01012664,  0.05449714,
        0.02712695,  0.24581461,  0.19195949,  0.06926737,  0.06519087,
        0.14836258, -0.01333803,  0.13641383,  0.06160649,  0.29746476,
        0.03355586,  0.06637412,  0.15873741,  0.04920393, -0.0238049 ,
       -0.083992  , -0.06237444,  0.04802573,  0.07770825,  0.10175433,
        0.11417089,  0.17024639,  0.21109106,  0.20851119,  0.23614784,
       -0.00223412,  0.0691645 ,  0.10060007,  0.18423948,  0.12191705,
       -0.05729315,  0.00972765,  0.13062176,  0.03442303,  0.14358045,
        0.21901843,  0.0838166 ,  0.19728287,  0.02123089, -0.03895708,
        0.2586911 ,  0.28226635,  0.13332252, -0.10844424,  0.13561204,
        0.19466975,  0.0516293 ,  0.07846542,  0.06355014,  0.05162555,
        0.17901592], dtype=float32), array([  5.29013176e+01,   3.68298279e+02,   1.58932693e+02,
         3.13076721e+02,   1.72377571e-01,   1.25030443e-01,
         1.27369705e+02,   2.41604366e+01,   1.39345556e-01,
         5.12570478e-02,   1.63797006e-01,   2.24519502e-02,
         5.02344131e+01,   3.71608138e-03,   1.11178495e-01,
         5.23512065e-03,   9.21985656e-02,   4.72296448e+01,
         2.08315969e-01,   1.15286283e-01,   3.14273615e-03,
         1.53550237e-01,   1.37613684e-01,   1.96638629e-01,
         1.86812878e-01,   5.63835632e+02,   1.55304492e-01,
         8.92956314e+01,   7.52598206e+02,   1.51206240e-01,
         1.17755756e-01,   5.77467918e+01,   2.37712509e+02,
         1.44288942e-01,   8.16054993e+01,   3.33516815e+02,
         7.57081528e+01,   7.09654770e+01,   1.40709385e-01,
         6.22298622e+01,   7.43702087e+01,   1.32977905e+02,
         1.41323179e-01,   5.85510597e+01,   2.54116893e-01,
         2.97157839e-03,   7.30314697e+02,   1.31483257e-01,
         2.38155365e+01,   3.59857605e+02,   1.24962874e-01,
         1.42724335e-01,   2.33147354e+01,   6.62400131e+01,
         1.57808691e-01,   8.03918228e+01,   1.26261771e-01,
         3.26975831e-03,   5.21077766e+01,   2.89877045e+02,
         4.42206497e+01,   1.89649010e+01,   1.23163067e-01,
         1.12137894e+02,   7.10229568e+01,   6.70116699e+02,
         1.77359521e-01,   6.12951698e+01,   8.30807571e+01,
         4.12999512e+02,   4.19509552e+02,   1.13279961e-01,
         1.69872162e+02,   1.50238186e-01,   1.35774821e-01,
         7.70510330e+01,   1.30124778e-01,   8.54601288e+01,
         1.39189273e-01,   1.56786576e-01,   1.49796903e-01,
         1.60520996e+02,   4.16353516e+02,   1.85329527e-01,
         1.60984680e+02,   1.20601280e+02,   1.14089131e-01,
         1.61643646e+02,   1.85202137e-01,   5.05330544e+01,
         1.30995050e-01,   2.30380801e+04,   3.75291656e+02,
         7.00347748e+01,   2.31097015e+02,   6.78052444e+01,
         1.08042598e-01,   6.86257095e+01,   8.28457642e+01,
         4.24259071e+01,   2.31480072e+02,   1.39489395e+02,
         1.76346302e+01,   3.17238495e+02,   4.91219177e+01,
         1.58652771e+02,   1.40976071e-01,   7.54999466e+01,
         2.15405838e+02,   1.68837905e-01,   8.79115601e+01,
         1.47948965e-01,   9.01728745e+01,   1.67503044e-01,
         5.95936133e+04,   1.90694198e-01,   4.04954987e+01,
         1.24202691e-01,   1.15148850e-01,   1.81677163e-01,
         3.56195259e+01,   8.88218918e+01,   9.05546112e+01,
         1.79674968e-01,   1.14744417e-01,   1.20044470e-01,
         1.58811241e-01,   2.82923549e-01,   4.59666539e-04,
         6.35243164e+02,   6.48225220e+02,   4.00935181e+02,
         1.01392296e+02,   7.27658264e+02,   9.59493179e+01,
         6.60831421e+02,   1.60758087e+02,   2.94946747e+02,
         2.69049683e+02,   2.02686279e+02,   4.14429108e+02,
         2.34200882e+02,   5.25431702e+02,   2.19347366e+02,
         1.22508453e+02,   2.69395874e+02,   1.75890030e+02,
         1.75082626e+02,   1.97738479e-03,   6.86364746e+02,
         7.31368004e-07,   3.50071350e+02,   3.18454803e+02,
         9.92241949e-02,   3.27594757e+02,   6.58869202e+02,
         2.37637222e+02,   1.56215729e+02,   1.98578064e+02,
         1.89657013e+02,   9.23661217e-02,   2.23594482e+02,
         3.97281372e+02,   4.90556152e+02,   8.02289734e+02,
         1.02253422e-01,   2.50522797e+02,   4.50917358e+02,
         7.23524658e+02,   3.86128876e+02,   2.12493181e-01,
         1.42017792e+02,   1.15965393e+02,   7.42478027e+01,
         6.34436707e+02,   8.22630066e+02,   1.59623749e+02,
         1.54434860e-01,   1.92384872e+02,   1.13033667e-01,
         4.16869354e+02,   3.87392700e+02,   6.75103638e+02,
         1.33600723e+02,   4.61286163e+01,   5.69286194e+01,
         1.07615136e-01,   4.87922241e+02,   1.09750562e+03,
         2.57252930e+02,   9.13989022e-02,   3.43379810e+03,
         3.40020416e+02,   3.12283386e+02,   4.95360107e+02,
         5.79436890e+02,   5.34526550e+02,   4.00680420e+02,
         2.36818880e-01,   1.32217571e-01,   1.29922986e+03,
         6.07961243e+02,   8.96932007e+02,   9.17435303e+02,
         4.57122894e+02,   5.17504395e+02,   6.48910522e+02,
         3.30657166e+02,   1.75505783e+02,   2.80984344e+02,
         1.74758804e+02,   2.08989716e+02,   6.61557556e+02,
         9.93769243e-02,   8.19757080e+01,   5.00759491e+02,
         6.07085571e+02,   6.29775635e+02,   4.57315735e+02,
         9.63794174e+01,   7.09169617e+01,   6.01780151e+02,
         3.06086140e+01,   2.90993958e+02,   2.32205658e+02,
         8.25352295e+02,   3.10921841e+01,   1.76693085e+02,
         1.46209703e+05,   3.44789154e+02,   5.03325165e+02,
         5.48049453e+04,   1.00943123e+02,   6.24874420e+01,
         6.31356812e+02,   1.50489899e+02,   1.10429832e+02,
         1.20430648e-01,   4.27515198e+02,   1.77617310e+02,
         2.28568527e+02,   1.99913818e+02,   2.26644638e+02,
         2.15966812e+02,   2.24030502e+02,   1.01033301e+03,
         1.19160265e-01,   3.25658752e+02,   4.94112366e+02,
         3.66817261e+02,   4.21857330e+02,   3.44939087e+02,
         1.80054428e+02,   6.33526184e+02,   5.76601624e+02,
         8.18330422e-02,   7.79961914e+02,   9.31102234e+02,
         3.59356964e+02,   9.81664297e+04,   6.03922791e+02,
         6.64522949e+02,   1.92235596e+03,   1.43135742e+03,
         1.06152905e+03,   9.14043281e+04,   7.49058594e+04,
         1.84903784e-05,   8.60325439e+02,   1.34697617e+02,
         1.54310120e+02,   1.94524988e+03,   3.11508593e-05,
         1.79827976e+00,   4.11105988e+02,   1.35709229e+03,
         2.41047754e+04,   4.64194244e+02,   2.31814990e+03,
         2.46742065e+02,   2.20986143e-01,   2.88030457e+02,
         2.32577686e+03,   4.62291473e+02,   3.78230071e+00,
         7.18686157e+02,   4.25875946e+02,   4.60051636e+02,
         1.18072180e+03,   9.04094925e+01,   3.29402496e+02,
         3.36625244e+02,   7.97540299e-04,   7.79839050e+02,
         9.12524609e+04,   1.38928953e+05,   5.20552185e+02,
         7.71098877e+02,   1.30964404e+03,   4.08867432e+02,
         4.43175415e+02,   1.75749694e-04,   2.26342630e+00,
         5.86277398e-04,   5.19271057e+02,   6.75552597e+01,
         1.29423145e+03,   1.35464111e+02,   2.08412227e+04,
         4.68114471e+02,   3.89939669e-05,   9.54547500e+04,
         2.03766650e+03,   1.17901642e+02,   5.55593811e+02,
         3.91676003e-04,   1.22785324e+02,   3.87807983e+02,
         1.00350266e+05,   9.06684326e+02,   8.55342407e+02,
         5.38626546e-06,   5.68653687e+02,   1.19883648e+05,
         3.63806159e-08,   3.39570703e+04,   1.63535748e-04,
         6.88466579e-02,   8.01904297e+02,   3.44243506e+03,
         2.89363708e+02,   2.69104736e+02,   1.01401208e+03,
         8.34419495e+02,   4.95362549e+02,   9.31297485e+02,
         9.64531797e+04,   2.63933258e+02,   3.45696808e+02,
         9.18420715e+02,   2.12337509e+02,   1.17244080e+03,
         7.64988770e+02,   1.53447974e+03,   7.86241516e+02,
         8.23347109e+04,   8.06836487e+02,   7.87529815e-03,
         2.33504156e+05,   7.90595459e+02,   4.00759396e-04,
         6.31914185e+02,   1.96726654e+02,   8.74345642e-05,
         7.12424844e+04,   1.28315112e+03,   1.38505359e+03,
         2.76464375e+04,   2.04282532e+01,   2.29135986e+02,
         2.07299232e+00,   1.08086279e+03,   4.14172973e-04,
         1.24269482e+03,   7.39336304e+02,   1.50823947e-02,
         7.26363623e+03,   6.34344188e+05,   2.47653137e+02,
         1.41914075e+03,   1.41438049e+03,   1.21932325e+06,
         6.47305359e+02,   5.80179321e+02,   2.17027217e-03,
         3.71571719e+04,   1.24817664e+03,   4.98597219e-04,
         1.77981030e+03,   3.95596405e+02,   1.22562109e+03,
         4.32819914e-04,   4.60019958e+02,   1.41190100e+03,
         9.41332129e+03,   1.09653809e+04,   3.15492647e-03,
         1.54994078e+05,   5.23385391e+04,   9.22623145e+03,
         4.98499488e-04,   3.13364938e+05,   7.49179346e+03,
         1.00305547e+04,   1.82671659e-02,   3.42344213e+00,
         4.30668592e+00,   4.16045514e-04,   1.03824775e+04,
         1.23922656e+05,   1.04631006e+04,   1.73410047e+05,
         8.55786406e+04,   6.04137158e+03,   2.45309277e+04,
         8.89998340e+03,   2.56647750e+05,   1.70954451e-01,
         2.58657148e+04,   4.36246688e+05,   5.87789141e+04,
         1.23386428e-01,   3.66295959e+02,   1.85506699e+04,
         3.94269142e+01,   1.44688359e+05,   1.45298477e+04,
         6.21279478e+00,   6.63667529e+03,   1.65185953e+05,
         1.97631230e+04,   4.81436328e+03,   1.40221679e+00,
         9.09212012e+03,   2.44030178e-01,   1.94093132e+01,
         3.32279022e+02,   2.92363472e+01,   1.05144541e+04,
         7.98557910e+03,   1.18249258e+04,   1.39883062e+05,
         1.07809453e+04,   9.80455469e+03,   1.64741135e+02,
         5.09485875e+05,   2.78596344e+05,   6.52749902e+03,
         5.84930195e+04,   7.87608398e+03,   1.88581758e+04,
         1.18888516e+04,   1.52794098e+02,   1.30843457e+04,
         2.18986487e+00,   1.14318955e+04,   3.12385375e+05,
         7.70872116e-01,   1.69423599e+01,   4.86643375e+05,
         8.11400391e+03,   1.74439545e+01,   3.48252281e+05,
         1.87914600e+01,   4.64235254e+03,   1.01091338e+04,
         1.47928438e+04,   2.79598942e+01,   2.45827949e+04,
         7.65991553e+03,   2.00238895e+00,   3.10605913e-01,
         7.81298594e+04,   2.86300537e+02,   1.99413319e+01,
         2.27015254e+04,   2.19956250e+05,   1.09991318e+04,
         1.81497953e+05,   1.63340271e+00,   9.53981641e+03,
         5.85154609e+04,   1.06890038e-01,   5.10188141e+02,
         4.31207094e+05,   4.47639453e+04,   5.45675688e+05,
         8.08595508e+03,   1.01950957e+04,   1.00513789e+04,
         1.57426543e+04,   1.10389585e+01,   8.30430566e+03,
         7.10388303e-01,   1.07709609e+05,   1.03372437e+02,
         1.12308057e+04,   8.98787415e+02,   3.63446414e-01,
         1.23672510e+04,   5.79760107e+03,   2.11794297e+04,
         1.09236570e+05,   1.37908730e+04,   6.53607500e+05,
         9.86244531e+03,   1.82566872e+01,   5.03345312e+03,
         2.09913812e+05,   1.89372016e+05,   1.18128057e+04,
         3.34898711e+04,   5.14254453e+04,   2.74777679e+02,
         8.40752637e+03,   1.13671128e-09,   1.40161156e+05,
         2.76869344e+05,   8.98101270e+03,   7.23281738e+03,
         2.95665844e+05,   8.28646289e+03,   1.26285315e+03,
         5.59499707e+03,   9.33632507e+02,   4.17510059e+03,
         2.74917554e+03,   1.77040662e+03,   1.05599475e+03,
         1.28719270e+00,   4.38650781e+04,   2.99222598e+04,
         2.16534888e+03,   1.85546465e-04,   4.12549011e+02,
         5.87204468e+02,   2.01756494e+03,   2.98604941e+00,
         1.06492188e+03,   4.36787695e+03,   1.74426062e+05,
         2.23833093e-04,   9.97683883e-01,   3.52064771e+03,
         1.63819739e+03,   1.69842798e+03,   9.01733971e+00,
         3.50203955e+03,   3.52579713e+00,   6.51048320e+04,
         1.78168835e+03,   3.99957578e+04,   4.32379171e-03,
         5.37734473e+03,   4.18319733e+02,   2.20450635e+03,
         3.08879224e+03,   3.07227051e+03,   9.02617264e+01,
         2.16442773e+03,   1.82850219e+05,   9.95169144e+01,
         5.80445801e+03,   1.53985059e+03,   1.54938342e+03,
         1.65538812e+05,   3.12529388e+02,   4.37371704e+02,
         1.26923102e+05,   2.81344757e+02,   9.64415222e+02,
         1.80920517e+02,   3.56961670e+02,   3.33044281e+01,
         2.57207938e+05,   5.01052734e+02,   3.10455902e+02,
         2.39062057e+02,   6.41142807e+01,   2.90034570e+03,
         1.02433784e+02,   1.55525141e+05,   3.53992871e+03,
         7.01231875e+04,   4.46191943e+03,   2.23219946e+03], dtype=float32), array([  6.56725879e+03,   1.77622344e+05,   3.18103145e+04,
         2.41600844e+05,   7.54997134e-02,   3.44786420e-02,
         2.81869980e+04,   9.40850647e+02,   4.77921106e-02,
         2.52545327e-01,   4.29868847e-02,   4.87780310e-02,
         5.01154639e+03,   1.92321301e-03,   3.98116410e-02,
         1.80527964e-03,   2.74859406e-02,   6.12046777e+03,
         6.90781176e-02,   4.14036177e-02,   1.30904000e-03,
         4.53408845e-02,   4.51114476e-02,   7.10743815e-02,
         1.46589354e-01,   6.51259562e+05,   8.97554904e-02,
         2.29651914e+04,   1.86265762e+06,   6.77037165e-02,
         3.93539295e-02,   7.69707666e+03,   1.15184508e+05,
         5.41263446e-02,   1.62433037e+04,   1.89716875e+05,
         1.77742266e+04,   8.33265039e+03,   6.64749071e-02,
         6.58396240e+03,   1.62296406e+04,   3.88601484e+04,
         6.64772242e-02,   1.10456992e+04,   2.13279590e-01,
         8.68510571e-04,   1.13872125e+06,   3.98312919e-02,
         1.28476770e+03,   3.61016469e+05,   4.65687551e-02,
         4.18955944e-02,   6.57615173e+02,   1.13869990e+04,
         5.44546731e-02,   1.42056416e+04,   5.52582741e-02,
         1.30865094e-03,   7.35240332e+03,   1.80242859e+05,
         4.18325000e+03,   7.03952148e+02,   4.66260165e-02,
         2.31643262e+04,   1.05575215e+04,   8.50128125e+05,
         1.16116919e-01,   9.12049805e+03,   1.63498652e+04,
         2.34684406e+05,   6.22357688e+05,   3.49865668e-02,
         6.18355312e+04,   7.85629079e-02,   6.14080355e-02,
         1.22910215e+04,   3.67580876e-02,   1.55048467e+04,
         5.30930012e-02,   8.40283632e-02,   1.06895901e-01,
         7.93618516e+04,   2.74736500e+05,   7.57213831e-02,
         4.64126719e+04,   2.31482207e+04,   3.84591371e-02,
         5.47133594e+04,   8.00890550e-02,   5.03970410e+03,
         4.58921753e-02,   1.46375392e+08,   2.80774281e+05,
         1.01872686e+04,   5.96545547e+04,   1.04652324e+04,
         3.27632017e-02,   1.18556875e+04,   1.89156836e+04,
         2.46120850e+03,   1.59834141e+05,   3.15576582e+04,
         7.31501404e+02,   2.08305359e+05,   3.41946118e+03,
         6.01592695e+04,   5.18381707e-02,   1.47427959e+04,
         6.23734414e+04,   6.84033409e-02,   1.15035801e+04,
         6.99213520e-02,   1.47401875e+04,   1.05047785e-01,
         9.51572160e+08,   8.03274214e-02,   1.84672205e+03,
         3.45594361e-02,   2.39903089e-02,   8.19043294e-02,
         4.81728857e+03,   1.53356064e+04,   1.94567285e+04,
         7.26292431e-02,   4.16457020e-02,   5.72962649e-02,
         4.70973030e-02,   1.26155123e-01,   1.16627999e-02,
         4.57733250e+05,   8.70579375e+05,   3.12152844e+05,
         2.06735000e+04,   1.46355475e+06,   1.32723682e+04,
         1.20402750e+06,   7.92076250e+04,   2.58246297e+05,
         1.94664422e+05,   6.44915039e+04,   4.05692750e+05,
         1.48230453e+05,   5.79201688e+05,   1.42105141e+05,
         2.67509238e+04,   1.76364828e+05,   5.60092383e+04,
         2.95030586e+04,   1.36257365e-01,   1.16693838e+06,
         2.95148027e-07,   3.00831656e+05,   2.38597672e+05,
         4.44938764e-02,   3.45833750e+05,   1.12516375e+06,
         1.30464727e+05,   3.98782891e+04,   6.22198086e+04,
         8.91793672e+04,   3.92676927e-02,   1.57008156e+05,
         2.81842125e+05,   4.45475688e+05,   1.59314875e+06,
         4.76403832e-02,   1.17160281e+05,   3.40225875e+05,
         9.16864875e+05,   5.81662656e+04,   8.15862641e-02,
         3.22163008e+04,   5.35540234e+04,   9.53132617e+03,
         1.11055862e+06,   1.36656112e+06,   1.36821266e+05,
         4.82784398e-02,   4.62502773e+04,   4.28558923e-02,
         6.30767438e+05,   3.69278219e+05,   1.00224300e+06,
         2.20270254e+04,   1.01537031e+04,   5.39678906e+03,
         4.43979800e-02,   3.88127719e+05,   2.80469900e+06,
         1.40893828e+05,   2.74416450e-02,   2.72335420e+07,
         3.32222344e+05,   2.69213844e+05,   6.23885250e+05,
         9.10986062e+05,   8.97708188e+05,   1.72020688e+05,
         1.38641834e-01,   6.81143105e-02,   4.46147500e+06,
         7.65871188e+05,   2.02227762e+06,   2.60089325e+06,
         5.93394500e+05,   7.20972062e+05,   6.46433562e+05,
         1.10797102e+05,   6.97056562e+04,   1.41376344e+05,
         1.23979359e+05,   1.06408672e+05,   7.05495438e+05,
         4.74322885e-02,   1.13823115e+04,   4.88212188e+05,
         9.90942438e+05,   1.10041038e+06,   7.28137875e+05,
         2.49954980e+04,   9.77100391e+03,   9.24850250e+05,
         2.94580493e+03,   2.37913234e+05,   1.15229695e+05,
         1.78638825e+06,   1.75375525e+03,   4.82480898e+04,
         5.82342861e+09,   3.84025562e+05,   6.34016688e+05,
         1.00981203e+09,   2.61069648e+04,   6.54391016e+03,
         1.09530300e+06,   6.80156797e+04,   1.77738086e+04,
         3.50512266e-02,   5.02550062e+05,   6.86984922e+04,
         1.49380781e+05,   1.04811117e+05,   9.95024766e+04,
         1.27687305e+05,   8.33934062e+04,   1.56131538e+06,
         5.89982830e-02,   3.29635719e+05,   5.61151062e+05,
         4.29612250e+05,   5.54313312e+05,   3.80469906e+05,
         5.28989180e+04,   6.95368688e+05,   6.17497062e+05,
         2.92687602e-02,   1.27342300e+06,   1.50443600e+06,
         2.13756984e+05,   2.53844838e+09,   7.35767062e+05,
         1.05289362e+06,   9.28481700e+06,   4.52070850e+06,
         6.73601600e+06,   2.18595379e+09,   1.47850125e+09,
         1.71202549e-03,   1.80524650e+06,   2.56987285e+04,
         4.60143047e+04,   7.32025000e+06,   3.79995140e-03,
         2.19851523e+04,   4.11323219e+05,   2.88072800e+06,
         1.51594736e+08,   3.60528156e+05,   1.35424120e+07,
         1.17154414e+05,   1.08761269e+02,   1.45091250e+05,
         1.43434010e+07,   3.64486219e+05,   5.40734766e+03,
         9.25089625e+05,   2.75619531e+05,   3.94881312e+05,
         3.56706200e+06,   2.73784824e+04,   2.91637406e+05,
         4.86528625e+05,   5.73409259e-01,   1.92818112e+06,
         2.16013850e+09,   5.11070362e+09,   7.83293125e+05,
         2.06747762e+06,   6.55942600e+06,   2.85351781e+05,
         3.14499688e+05,   2.41670907e-02,   2.38311670e+03,
         6.28750086e-01,   4.12087344e+05,   1.33410449e+04,
         3.38972725e+06,   2.91469961e+04,   1.12226760e+08,
         4.78038969e+05,   3.31788673e-03,   2.37769984e+09,
         1.20188740e+07,   2.40251035e+04,   6.18608938e+05,
         3.60166915e-02,   3.55320977e+04,   2.31391766e+05,
         2.64104653e+09,   1.58894662e+06,   1.91879550e+06,
         2.25834758e-03,   5.89070750e+05,   3.75344998e+09,
         9.73730963e-08,   3.01804736e+08,   3.02301832e-02,
         1.52924747e+01,   8.82315125e+05,   3.52988080e+07,
         1.43543703e+05,   1.60795438e+05,   1.78715288e+06,
         1.46677988e+06,   2.76105188e+05,   2.22614450e+06,
         2.42787763e+09,   1.42952625e+05,   1.60724656e+05,
         1.49458050e+06,   1.46047344e+05,   2.76745200e+06,
         1.17231375e+06,   2.76334150e+06,   1.24400888e+06,
         1.80372915e+09,   9.92899875e+05,   3.15896893e+00,
         1.41939425e+10,   1.26099962e+06,   1.14125289e-01,
         1.10785950e+06,   4.45960156e+04,   2.58721467e-02,
         1.35744973e+09,   3.68730100e+06,   5.46133250e+06,
         2.02761856e+08,   5.48238477e+04,   1.03384750e+06,
         3.93404443e+03,   2.16825900e+06,   2.67905354e-01,
         2.80396725e+06,   1.45971425e+06,   8.95416927e+00,
         2.49809760e+07,   1.06471219e+11,   1.15776516e+05,
         5.06676450e+06,   4.31984050e+06,   3.86451997e+11,
         5.98350312e+05,   1.38594500e+06,   1.67351604e+00,
         3.68885536e+08,   3.60366800e+06,   4.16667581e-01,
         7.80595050e+06,   3.08655125e+05,   5.23512200e+06,
         2.79271722e-01,   3.34777125e+05,   3.99767675e+06,
         1.09258584e+08,   1.97274624e+08,   3.16495838e+01,
         6.13972480e+09,   9.94024960e+08,   1.00567448e+08,
         2.10300946e+00,   2.53692457e+10,   1.26955896e+08,
         2.01173968e+08,   1.02804810e+02,   1.66388156e+05,
         1.26302492e+05,   1.50857806e+00,   8.21985440e+07,
         4.11486976e+09,   2.26806864e+08,   7.90428621e+09,
         1.93021158e+09,   5.40854800e+07,   3.57005472e+08,
         1.18079800e+08,   1.70579804e+10,   3.29691968e+03,
         1.74607526e+09,   4.95405629e+10,   1.14627213e+09,
         1.24449133e+03,   7.17408750e+06,   6.19507968e+08,
         2.00560975e+06,   5.47243674e+09,   4.73584448e+08,
         1.47082984e+05,   6.36617560e+07,   7.41921485e+09,
         2.01332688e+08,   3.39079960e+07,   6.99887354e+03,
         1.16970744e+08,   9.32351367e+03,   3.48604125e+05,
         1.90951060e+07,   2.54747875e+05,   2.30601856e+08,
         1.21317712e+08,   2.79921376e+08,   4.98754202e+09,
         1.43456912e+08,   2.03330944e+08,   4.65217700e+06,
         6.72014336e+10,   2.00895427e+10,   9.09570800e+07,
         9.75377280e+08,   7.56335920e+07,   5.70409152e+08,
         2.47780272e+08,   3.27594625e+06,   4.14175232e+08,
         4.35209805e+04,   1.88619648e+08,   2.56333128e+10,
         1.60992012e+04,   2.72850000e+05,   6.20860948e+10,
         7.28272800e+07,   2.82648975e+06,   3.16500439e+10,
         1.31043250e+06,   2.41057440e+07,   1.43970016e+08,
         4.99416992e+08,   1.01184600e+06,   3.68047898e+09,
         1.20624256e+08,   2.43332812e+04,   8.15136328e+03,
         1.60642598e+09,   2.73450200e+06,   2.38838203e+05,
         5.12689408e+08,   1.25280942e+10,   1.84381472e+08,
         8.63307469e+09,   6.08516094e+04,   1.62093040e+08,
         2.82314291e+09,   1.32952258e+03,   1.62178140e+07,
         4.81663345e+10,   1.21457367e+10,   7.68626033e+10,
         8.02472080e+07,   2.93666976e+08,   1.49485664e+08,
         4.27040096e+08,   4.29687125e+05,   1.28158904e+08,
         8.97039355e+03,   3.02248934e+09,   1.03696210e+07,
         2.00021152e+08,   2.98153600e+07,   1.00804482e+04,
         9.39922560e+08,   4.73496560e+07,   2.76551731e+09,
         3.77426304e+09,   4.35165472e+08,   1.09742006e+11,
         2.15231920e+08,   3.09728500e+06,   3.24399940e+07,
         1.22994432e+10,   1.08861686e+10,   2.79660576e+08,
         9.37724736e+08,   1.02720493e+09,   2.17777050e+06,
         1.54798112e+08,   1.00629443e-08,   5.19118694e+09,
         1.98968300e+10,   1.33751944e+08,   9.35871520e+07,
         2.28296315e+10,   9.38741040e+07,   3.17882250e+06,
         8.31164240e+07,   1.46775562e+06,   6.01824640e+07,
         1.75525580e+07,   5.50511050e+06,   2.18296225e+06,
         1.07290801e+04,   4.99514304e+08,   2.29417152e+08,
         8.99616100e+06,   1.12912692e-01,   2.42840719e+05,
         1.13189812e+06,   7.25623850e+06,   8.52977930e+03,
         2.10469600e+06,   4.55028320e+07,   7.80608819e+09,
         2.87974954e-01,   8.70923340e+02,   2.96686880e+07,
         7.41351750e+06,   3.24923525e+06,   5.72499062e+04,
         2.77035780e+07,   4.16185693e+03,   1.09000768e+09,
         5.04991100e+06,   4.49137312e+08,   4.01553993e+01,
         5.70331200e+07,   4.28945562e+05,   1.06906340e+07,
         2.11904900e+07,   2.61208980e+07,   3.01649570e+04,
         9.72933000e+06,   8.66692198e+09,   8.41177266e+04,
         1.02964984e+08,   7.68585550e+06,   7.45714400e+06,
         6.98213274e+09,   2.38885984e+05,   1.02112962e+06,
         4.27480960e+09,   3.26569906e+05,   1.77353412e+06,
         5.66584922e+04,   1.22934812e+06,   4.77232617e+03,
         1.71293143e+10,   5.42164000e+05,   1.90681484e+05,
         1.16951258e+05,   1.15400928e+04,   2.35181320e+07,
         2.42172090e+04,   6.32247757e+09,   2.86867180e+07,
         1.27844915e+09,   4.70369600e+07,   1.15285590e+07], dtype=float32), array([[-0.04769275,  0.069238  , -0.00462658, ..., -0.08036393,
        -0.05525096, -0.00468105],
       [ 0.0016573 ,  0.00850066, -0.07921569, ..., -0.08608776,
         0.01443016,  0.05530938],
       [-0.01991984, -0.06943925, -0.02920824, ..., -0.01871235,
         0.06272089,  0.0801362 ],
       ..., 
       [ 0.02875734, -0.02720934, -0.04642835, ..., -0.02848272,
         0.07837038, -0.00966376],
       [-0.02375437,  0.0391067 , -0.07079554, ...,  0.02161885,
         0.08407549, -0.00626772],
       [ 0.00421856, -0.04084457, -0.13998236, ..., -0.03473885,
        -0.00353694, -0.03559897]], dtype=float32), array([-0.04281327,  0.01216352, -0.04227917,  0.00750893, -0.01155498,
       -0.10221472, -0.1214705 , -0.13738319,  0.05585212, -0.15259944,
       -0.06488334, -0.06068194, -0.02622675, -0.08340055, -0.11234758,
       -0.02888185, -0.04345198,  0.02169439,  0.02590524, -0.04059396,
       -0.06806512,  0.10729537, -0.18412711, -0.18169376,  0.00365732,
       -0.13488761, -0.02717731, -0.00244496,  0.06433829, -0.11677473,
       -0.01639851, -0.03303393, -0.02688541,  0.04380631, -0.00033412,
        0.02736358,  0.05983658,  0.02838399, -0.17597876,  0.04450758,
        0.00798095,  0.01551016,  0.04845837,  0.036789  , -0.01422661,
        0.01329577, -0.04310149, -0.03296043, -0.09829519, -0.01581104,
       -0.03864533,  0.07951146, -0.03805969, -0.02215071, -0.03068955,
        0.01017272, -0.04202718,  0.02586712,  0.03728069, -0.165975  ,
       -0.04635691,  0.07902595,  0.01165657,  0.0273642 , -0.05795354,
        0.01866121, -0.03403607, -0.00425029, -0.01559693, -0.12403741,
        0.04839318, -0.00974488, -0.07547898, -0.17886929, -0.00342553,
       -0.05279821,  0.02622259, -0.12527826,  0.00409175,  0.01612878,
       -0.00909053, -0.04103935, -0.04583444,  0.04986244, -0.05952312,
       -0.0086245 , -0.06176755,  0.03476633, -0.06459755, -0.03509617,
       -0.11843704, -0.16909009,  0.05126577,  0.05601902, -0.02887684,
        0.00571529, -0.02757956,  0.01492239,  0.04096997,  0.00517426,
       -0.09337299, -0.10719658,  0.02460384,  0.01244749, -0.06192895,
        0.05721438, -0.09381114, -0.02609875, -0.07876792, -0.10560443,
        0.02266885, -0.04450804, -0.18668133, -0.093195  , -0.06256788,
        0.06355501, -0.0322827 ,  0.04231226,  0.00050422,  0.0583259 ,
       -0.03034916, -0.09061082,  0.02164552, -0.0799282 ,  0.0472419 ,
       -0.04796644,  0.00187331, -0.12954311, -0.01791267, -0.07327066,
       -0.09112413, -0.04374129, -0.050823  ,  0.00941752, -0.06980613,
       -0.02574478, -0.2491547 , -0.1225718 , -0.06167391,  0.04720496,
       -0.11496516,  0.00070918, -0.11957023,  0.05516461,  0.00511729,
       -0.02611975, -0.0194354 , -0.00131737, -0.00630221, -0.05635685,
       -0.11458802,  0.014326  , -0.02076014, -0.06513453, -0.14417651,
       -0.06692553, -0.02526882,  0.03328592, -0.04254598, -0.02013853,
       -0.04922098, -0.09137172, -0.01722721, -0.06816894, -0.0259109 ,
       -0.01487811, -0.05329435, -0.0315166 , -0.07660367,  0.02827635,
       -0.15094604,  0.01775419,  0.03518398,  0.02181572, -0.02780074,
       -0.02563138, -0.04151968, -0.07021532,  0.0409584 , -0.1852023 ,
       -0.03211535, -0.00469262,  0.01153537, -0.04135527, -0.08311858,
       -0.0674094 , -0.02219914, -0.12330494, -0.02713043,  0.01014902,
       -0.03629309, -0.04927927, -0.12445687, -0.00322825, -0.02708133,
       -0.05924047, -0.04556635,  0.00729214, -0.08192374,  0.01589071,
       -0.00263936,  0.01880972, -0.19471456,  0.01881176, -0.01513805,
       -0.03726128,  0.01239012, -0.13099153, -0.07545547, -0.06204348,
       -0.07222242, -0.05149313, -0.08179797,  0.05838239, -0.03805961,
       -0.05964502, -0.04124784, -0.13633013,  0.02435996, -0.01846947,
       -0.14851616, -0.0667586 ,  0.04615407, -0.10091442, -0.04483977,
       -0.02565717,  0.00274817, -0.04863312,  0.01534853, -0.010924  ,
        0.01179601, -0.05243185, -0.0294415 , -0.07210685, -0.05832606,
       -0.04773422,  0.01780162, -0.02805614, -0.10551364, -0.05942029,
       -0.08747935,  0.03103399,  0.00280847,  0.04558571, -0.0268664 ,
       -0.05908133, -0.02920071, -0.05185449, -0.05839225, -0.00542642,
       -0.00445425, -0.00277337, -0.09241011, -0.1817136 , -0.02085226,
        0.02530239, -0.02431361, -0.02471693, -0.10894374, -0.11241273,
       -0.05965532, -0.04742953, -0.0284279 ,  0.01174705, -0.0459118 ,
       -0.08097897, -0.09698882,  0.01121806, -0.01535511, -0.10678045,
       -0.03162777, -0.03982999,  0.00554388,  0.00179311, -0.07819723,
       -0.17190899, -0.03242657, -0.03468801,  0.01528743, -0.06650851,
        0.0190498 , -0.01271552, -0.03651275, -0.11232013, -0.05504088,
       -0.03477527, -0.05536038, -0.23618491, -0.14842159, -0.14404929,
       -0.09345041,  0.00977631, -0.01399187, -0.01725124,  0.00727773,
        0.02457467,  0.01258498, -0.05015456, -0.08532293, -0.11646874], dtype=float32), array([ 0.87176639,  0.93463355,  1.05634081,  0.99340051,  1.0030396 ,
        0.99227065,  1.07705748,  1.1993829 ,  0.91247821,  1.12197948,
        1.05622685,  1.04016495,  0.96569908,  1.08073354,  1.09519255,
        1.03536379,  0.94631213,  0.99006516,  0.98306018,  1.03557265,
        1.06246316,  0.90030062,  1.14284647,  1.11873901,  0.95603698,
        1.08676267,  1.01677489,  0.93079323,  1.01469243,  1.00669801,
        0.97528404,  0.99322295,  1.08552587,  0.96151406,  0.97922933,
        0.94758064,  0.94741124,  1.00225997,  0.98095411,  0.94945347,
        1.07860887,  0.93168348,  0.91968876,  0.92890793,  0.97574204,
        1.19683862,  0.98550284,  0.9843815 ,  1.09685063,  0.91151792,
        1.01290405,  0.89867115,  1.06257439,  0.94521379,  1.12563264,
        0.91047913,  0.90380287,  1.03080583,  1.01078689,  1.06201088,
        1.14023697,  0.93335462,  0.91904873,  0.86279535,  1.11908197,
        0.92907482,  1.08038664,  1.01428044,  0.95855457,  1.0398047 ,
        0.95748085,  1.03991616,  0.95625305,  1.09788918,  1.0463078 ,
        0.97386622,  0.96178865,  1.22783625,  0.91931695,  0.99592876,
        1.11665428,  1.02903068,  0.89683247,  0.98548013,  1.11801124,
        1.04297292,  0.95071673,  0.94948286,  1.0440582 ,  1.09026253,
        1.15528381,  1.07348859,  1.1052078 ,  1.00697756,  1.02022457,
        0.96277684,  0.91864967,  1.20153558,  1.06757641,  0.99407727,
        1.10569465,  1.24604774,  0.93461794,  0.93011755,  1.11834908,
        1.00567818,  1.09637153,  0.91049117,  1.06878328,  1.00739777,
        1.03471887,  1.10538578,  1.10195613,  1.06552505,  1.05732918,
        0.98002946,  0.93754977,  0.94159895,  0.99337161,  0.86666179,
        0.96387154,  1.04916489,  1.10477781,  1.29178476,  0.9523856 ,
        0.94455338,  0.96811038,  1.18081236,  0.93842161,  1.01636326,
        0.98871404,  0.95899242,  0.91982192,  0.95779598,  1.10919225,
        1.0903461 ,  1.08609915,  1.0404433 ,  0.96200049,  0.89642465,
        1.12744498,  1.01105285,  1.07991314,  0.93388069,  1.00590289,
        0.92252302,  0.99469012,  0.8675974 ,  1.08350885,  0.95367026,
        1.10333335,  0.91295874,  1.20902872,  0.95180273,  1.04733539,
        1.1583041 ,  0.93378431,  0.94954377,  1.08910704,  0.94165903,
        1.0202949 ,  1.02597845,  0.94184482,  0.95451266,  1.10715771,
        1.03222644,  0.98962945,  1.05778515,  0.99307364,  0.87771612,
        1.09873402,  0.92734551,  1.01758647,  0.9831512 ,  1.20215917,
        0.92206228,  1.0119828 ,  0.98569953,  0.96064812,  1.16997325,
        0.93985933,  0.99224442,  0.93972802,  1.02293193,  0.98777872,
        1.06081343,  0.94340861,  1.07796156,  0.99668258,  0.95350105,
        1.10059285,  0.90825182,  1.05968821,  1.07461452,  0.92003191,
        1.00912607,  0.91402423,  0.93052262,  0.97435498,  0.88573182,
        1.00183964,  0.93959558,  1.01498902,  0.97465479,  1.06606197,
        1.11691356,  0.96486741,  1.0107826 ,  1.05988026,  1.12390065,
        1.11638784,  1.15644038,  1.00571382,  0.93838054,  0.96072191,
        0.94599783,  1.12893295,  1.1230365 ,  0.88623613,  1.17280185,
        1.07552314,  0.97262222,  1.01057529,  1.0089252 ,  1.10838652,
        0.90431851,  0.92546988,  1.02088475,  0.97890371,  0.91935927,
        1.09139442,  1.05249536,  0.98707712,  0.99708903,  0.9559375 ,
        0.97608489,  0.99335748,  1.00746489,  1.16643882,  1.06395233,
        1.08416784,  1.05056548,  0.94751292,  1.02552378,  0.93117982,
        0.99507368,  0.98581773,  0.96943289,  1.1225698 ,  1.04918706,
        1.1006186 ,  1.04070008,  0.97809011,  1.12040222,  1.02568603,
        1.03338635,  0.97896522,  1.07827854,  1.08026075,  1.02890062,
        1.13584721,  0.94108975,  0.93482053,  0.96129233,  1.01920295,
        1.08889484,  1.06581569,  0.97552782,  0.90931129,  1.14291739,
        0.94304538,  0.86557966,  1.08406758,  1.025388  ,  1.01034272,
        1.11826336,  1.16416299,  0.90759176,  0.99313092,  1.04457438,
        0.94098908,  0.92880487,  1.15274727,  1.05287194,  0.97517741,
        0.92147702,  0.92111331,  1.23986077,  1.11298263,  1.00378525,
        1.11741269,  0.93636656,  0.88912165,  1.1682471 ,  0.94735444,
        0.93080258,  0.97969508,  1.1736064 ,  0.94570416,  1.08708167], dtype=float32), array([ 0.00105192,  0.1075988 , -0.03282657,  0.03583052, -0.09719235,
        0.10098293, -0.07340404,  0.03293641,  0.065913  , -0.03426898,
        0.05921084,  0.05246812,  0.03162163,  0.05474028,  0.08947311,
        0.01194484, -0.07671205,  0.0631092 ,  0.07323366,  0.0793419 ,
       -0.04232517,  0.08939039, -0.02628171, -0.00756457,  0.05183554,
       -0.12899128, -0.0649024 , -0.04325962, -0.02710859, -0.09890834,
        0.07437202, -0.07601923, -0.11400878,  0.04129992,  0.08282767,
        0.08283643, -0.05385976, -0.03914045, -0.12124286,  0.03088612,
        0.03944312, -0.09534793,  0.06200753, -0.01494889, -0.0153994 ,
        0.1093872 ,  0.00861222, -0.00998991, -0.09372575,  0.07211181,
       -0.00128495,  0.050912  , -0.08632752, -0.04408937, -0.03642046,
       -0.06745459,  0.05850372, -0.01044809,  0.05830123, -0.09542446,
        0.0233317 ,  0.07115889,  0.08189265,  0.01408185, -0.08020137,
        0.06224453, -0.02057605, -0.07207014,  0.03757225, -0.10853849,
        0.04602966,  0.04792535, -0.0802042 , -0.10549779,  0.06760156,
       -0.03262317, -0.00384597, -0.1187655 ,  0.0324718 ,  0.02293467,
        0.07470402, -0.00473271, -0.05201067,  0.00340916, -0.07972595,
       -0.06715551, -0.04450863, -0.01131769,  0.11351115,  0.02656087,
        0.03106523,  0.05401589,  0.01870393, -0.10399695,  0.07486138,
        0.10062269,  0.00317511,  0.07580896, -0.05176559, -0.07679165,
        0.03077197, -0.06874954,  0.04182817, -0.00021885,  0.00777751,
       -0.00386811, -0.06315943, -0.02873971, -0.09663004, -0.08720001,
        0.05925692, -0.03412884, -0.09969616, -0.10604034, -0.09998439,
        0.0165443 , -0.05464287,  0.02691977,  0.03697906,  0.05903339,
        0.00373324,  0.03420821,  0.05734671, -0.08574876,  0.03399953,
        0.04508731,  0.03038682, -0.07434025,  0.02477123, -0.06707739,
        0.00520484, -0.05636477, -0.0444801 ,  0.04341142, -0.11206874,
        0.04344311, -0.02316927, -0.03908125, -0.09280184, -0.10791238,
       -0.03243571,  0.03864868,  0.02267985,  0.02916247, -0.03753981,
       -0.07467007, -0.07640166,  0.08990327, -0.07352129, -0.00924637,
       -0.07852473, -0.08742116,  0.04097183,  0.04054951, -0.06483995,
        0.04285421, -0.05109795,  0.08268256,  0.14438044,  0.07374576,
       -0.05631001, -0.03801958,  0.0659643 ,  0.03456411,  0.10542175,
       -0.04591293, -0.04668155, -0.05933658, -0.07865544,  0.09005108,
       -0.09962866,  0.00698445, -0.00094486,  0.01116829,  0.00763724,
       -0.08532009, -0.05005287, -0.08039762,  0.07219297, -0.10870604,
        0.05073224, -0.05017154,  0.07427768,  0.02236671, -0.0603907 ,
        0.04971685, -0.04218143, -0.1090948 , -0.11825089,  0.04080078,
        0.037702  , -0.05006854, -0.01802806, -0.01644355,  0.06621083,
       -0.04078118,  0.01575663,  0.06474546, -0.07074669,  0.04355057,
        0.0229033 ,  0.04121767,  0.07368467, -0.056196  ,  0.05615422,
        0.0617256 ,  0.07434787,  0.04947244, -0.02962077,  0.10924897,
        0.096898  , -0.06690084, -0.11307403, -0.06736805,  0.04571798,
       -0.0564863 , -0.08323038,  0.12810753,  0.08982489,  0.12296901,
       -0.12568548, -0.09132   ,  0.01673149,  0.01547858,  0.08331845,
       -0.03638335,  0.04122225,  0.05720593,  0.05331337, -0.00744243,
        0.03796619,  0.07079853, -0.05719955, -0.07888139, -0.0270002 ,
        0.01639183, -0.01545628, -0.06905092, -0.07906485, -0.0905702 ,
       -0.08095042, -0.03649227, -0.0561366 , -0.08276156,  0.0895219 ,
        0.02497489, -0.06564935, -0.07411634,  0.0231353 , -0.04208171,
       -0.10946783, -0.02992818, -0.00608243, -0.09065883,  0.07754683,
       -0.04593742, -0.0468175 ,  0.09627265,  0.07830583, -0.03170425,
       -0.07183324, -0.05017394, -0.05594379, -0.01742457,  0.02904778,
       -0.08004445,  0.09018414,  0.03322495, -0.03285638,  0.0429967 ,
        0.05266179, -0.01548739, -0.1070734 ,  0.01433286,  0.13911456,
        0.05454878, -0.04002381,  0.03345147,  0.02733856, -0.06829462,
        0.04791171,  0.07573467, -0.08281509, -0.06768331,  0.07354324,
       -0.03069789,  0.06341367, -0.01724629,  0.14409827,  0.0323025 ,
        0.03999797,  0.03899879,  0.03868518,  0.06184839, -0.01204476,
        0.07907918, -0.01912301,  0.02162754, -0.06985147,  0.12258166], dtype=float32), array([ 1.58741736,  0.83046049,  0.49278846,  0.66355884,  1.35883749,
        0.38173139,  0.47138804,  0.43110391,  1.80101788,  0.35205626,
        0.54460412,  0.56293535,  1.7665    ,  0.285238  ,  0.55082303,
        0.68496764,  1.15205204,  0.50222516,  0.63375694,  0.6813013 ,
        0.50210482,  0.77778488,  0.45924455,  0.31066194,  1.13828421,
        0.37113306,  0.64763331,  1.06094396,  1.37464523,  1.39178431,
        2.22035289,  0.89710766,  0.5950098 ,  1.93965924,  0.48359066,
        0.89201689,  0.96112823,  1.27325726,  0.22908144,  0.64389646,
        0.64823657,  0.64834362,  1.7579354 ,  0.7597174 ,  0.39607292,
        0.99729741,  1.41259146,  2.59125447,  0.70576864,  1.13219118,
        1.09767771,  1.41419458,  0.60766506,  0.53881752,  0.56293666,
        0.89360815,  0.6194123 ,  0.93562204,  1.02484131,  0.40006694,
        0.59434503,  1.91167617,  2.34298611,  1.53296733,  0.75691116,
        0.89003527,  0.61783952,  0.81138378,  1.64371562,  0.35430235,
        1.34343517,  0.46472439,  1.466272  ,  0.33931288,  0.47045052,
        0.51161039,  1.53993666,  0.47928429,  1.95763087,  1.77608705,
        0.57341701,  0.50211096,  0.50817102,  1.14388573,  0.56272131,
        0.58736807,  1.19793773,  0.65035653,  0.53783292,  0.7115159 ,
        0.37626556,  0.35046262,  1.07449734,  0.89419812,  0.51580989,
        2.02214575,  0.72173238,  0.92564106,  0.95200509,  1.1591835 ,
        0.44617423,  0.52955109,  0.6664145 ,  1.86956346,  0.50393599,
        0.97062725,  0.3529757 ,  1.66795802,  0.43336105,  0.32954726,
        0.64877206,  0.57209402,  0.35647091,  0.50420207,  0.53642792,
        1.07529521,  0.74749094,  1.5213623 ,  1.32599914,  0.66948628,
        1.7666868 ,  0.38221186,  0.77170169,  0.64681786,  1.28200209,
        1.39162767,  1.65997553,  0.45464477,  1.46914268,  1.43028915,
        0.49979123,  1.82406127,  1.66969693,  0.8893832 ,  0.29520938,
        0.54352462,  0.18788485,  0.45428935,  0.51939195,  1.681422  ,
        0.44644737,  0.47918871,  0.38756549,  1.18757832,  0.5216372 ,
        1.55489326,  0.57255518,  1.36661553,  0.77448469,  0.97621095,
        0.54026169,  0.840128  ,  0.68622601,  1.18797326,  0.51033252,
        0.55350024,  0.62252474,  1.17693615,  0.57898831,  1.31683397,
        0.83644539,  0.65491253,  1.74810565,  0.5600279 ,  0.55141366,
        0.71456146,  1.75648773,  0.41260162,  1.00958979,  0.98862243,
        0.43453613,  1.54910636,  2.59015441,  1.96257162,  0.71596181,
        1.56761777,  0.87569118,  1.15905666,  1.1935333 ,  0.42628354,
        0.78581393,  1.07278121,  1.99670708,  1.12757969,  0.57352549,
        0.6526348 ,  1.93397689,  0.5525946 ,  0.82916188,  1.3793608 ,
        0.58608443,  0.54909378,  0.35643783,  0.67872632,  0.62405974,
        1.2140013 ,  1.59627366,  1.17699718,  1.11011863,  1.01137257,
        1.27424181,  0.61385417,  0.46987227,  0.9759801 ,  0.68343341,
        0.53237557,  0.6793381 ,  0.40485594,  0.54794008,  0.55342531,
        0.58519548,  0.4213807 ,  0.53137642,  0.96648145,  0.47418526,
        1.018273  ,  0.42210507,  0.57122999,  1.42477369,  0.69322109,
        0.4378559 ,  1.0747174 ,  0.66998529,  0.63857651,  0.4999207 ,
        1.47753966,  1.40612018,  0.50477082,  1.63557124,  0.66427088,
        1.08031964,  0.44587383,  1.56299174,  2.19856787,  0.33994609,
        1.22838247,  1.09135532,  0.5140515 ,  0.53565055,  0.54737002,
        0.49584809,  1.10968137,  0.45442119,  0.63489652,  2.29406357,
        0.57527053,  1.13013721,  1.46603131,  0.56037319,  1.05982244,
        0.8541944 ,  0.64797914,  1.46328151,  2.06331658,  1.18198347,
        1.14532745,  1.42629218,  0.55044883,  0.56926167,  0.22092894,
        0.47292885,  1.37812161,  1.44022894,  0.65858173,  0.48263684,
        0.52305466,  0.51428097,  0.83840215,  1.32551217,  0.47651047,
        1.59928846,  0.68244648,  0.84140319,  0.9045108 ,  0.43812665,
        0.29034892,  0.37342277,  1.70375502,  1.29215324,  0.62352604,
        2.20307136,  1.07089543,  0.6581471 ,  0.37593204,  1.44360352,
        1.69619274,  0.68847704,  0.31797802,  0.46018013,  1.0798614 ,
        0.53224015,  1.01210105,  1.73447263,  0.58204806,  1.09177899,
        0.87288809,  0.60713041,  0.56325537,  1.52981806,  0.43680874], dtype=float32), array([  8.50832558,   2.1948173 ,   1.47156119,   0.86793345,
         7.56267262,   0.52743137,   0.85967022,   0.62174785,
        10.84791374,   0.64472038,   0.82473201,   0.98221791,
         9.53833866,   0.35674441,   0.88372427,   1.6631583 ,
         5.36925888,   0.80712402,   1.09701276,   1.23362648,
         1.11603653,   1.11818266,   1.0072875 ,   0.60041934,
         4.53394604,   0.74621695,   1.43284988,   2.08176494,
         4.83439207,   7.614923  ,  16.18638992,   2.83269095,
         1.31545651,  12.51511383,   0.61761016,   2.36314249,
         2.0805409 ,   4.92221832,   0.31338164,   1.32354605,
         1.58822548,   1.2469064 ,   9.65171814,   2.08367968,
         0.60319811,   2.24880552,   7.51644802,  23.40749359,
         1.50852871,   4.15203428,   4.4296093 ,   6.12872124,
         1.60210764,   0.97422212,   0.90519387,   2.52471852,
         1.20459402,   3.34684873,   3.56357598,   0.69929022,
         1.34190381,  11.26649666,  16.90973663,   7.20012379,
         1.80595815,   2.31266427,   1.50483   ,   1.73913181,
        10.19339943,   0.5774774 ,   5.92594194,   0.72164756,
         8.07087803,   0.5097748 ,   0.71391815,   1.14628077,
         8.90550423,   0.81803834,  13.52776527,  11.54738617,
         1.974316  ,   0.96892279,   0.83481431,   6.48693037,
         0.94531   ,   1.09711421,   5.2431798 ,   1.1112318 ,
         0.92293882,   1.50891697,   0.50405174,   0.46424854,
         2.94919944,   2.2419188 ,   0.82716382,  13.67724323,
         1.24847305,   1.8736645 ,   2.58528948,   4.62311459,
         0.76796061,   1.13415301,   1.42504084,  12.19272518,
         0.82796019,   2.61683321,   0.7400111 ,   9.48672771,
         0.95302379,   0.55652112,   0.94581527,   1.13498831,
         0.6069448 ,   1.30285597,   1.0415802 ,   4.11059332,
         2.08264923,   8.45399284,   5.44919157,   1.7273649 ,
        11.37794971,   0.57353026,   2.17279673,   1.65181482,
         5.30215359,   7.01115894,   9.79617119,   0.8279829 ,
         7.78252077,   8.06094265,   0.84786183,  11.35456276,
         9.68571854,   2.36841798,   0.35148033,   0.7865324 ,
         0.2493078 ,   0.92990696,   1.05748153,   8.88444996,
         0.96934944,   0.59279555,   0.61410642,   5.03259468,
         1.89128411,   9.22836876,   1.73151112,   6.26345968,
         1.92788625,   3.81693125,   1.41330862,   2.70214033,
         1.33875644,   5.00235558,   1.16972899,   1.40213168,
         0.86328924,   5.56713915,   1.25635326,   6.66478014,
         2.57906127,   1.41762722,  11.49940205,   1.33765638,
         1.02641749,   1.54289806,  11.9556179 ,   0.60686398,
         3.93033481,   3.6158402 ,   0.97632676,   8.70140362,
        22.98396301,  12.16709232,   2.21411014,   9.55394077,
         1.70245385,   5.27477169,   4.74877644,   1.01315928,
         1.61747551,   3.68872881,  12.4381752 ,   4.22976732,
         1.97770393,   1.44307554,  13.54532623,   3.2463553 ,
         1.74849665,   5.55321932,   1.15992761,   0.85573345,
         0.5789004 ,   1.21010411,   1.30119526,   5.43155909,
         8.7329483 ,   5.60314178,   4.95734215,   3.36326861,
         6.02288437,   1.08533168,   0.75165719,   3.02577829,
         1.48395681,   1.01436627,   1.15552723,   0.49574229,
         0.94032437,   0.78715765,   1.16505706,   0.76025128,
         0.9624024 ,   2.56594992,   0.70326924,   4.19901848,
         0.61401999,   1.07683265,   6.89854956,   1.37091768,
         0.78282034,   4.47012424,   1.0680604 ,   1.19640577,
         0.61692232,   7.67789888,   6.89219618,   0.96714169,
         9.25763035,   1.96722925,   3.51632738,   0.71485782,
         8.45778179,  18.48162079,   0.45194376,   5.02067232,
         3.45283651,   0.99955332,   1.52892911,   1.08288383,
         1.09432375,   4.1948781 ,   0.84037805,   1.27640307,
        17.65620422,   1.79641867,   4.39294624,   8.48449612,
         1.24177361,   2.94928694,   2.24756908,   1.34676874,
         7.93221474,  17.47136497,   5.24520254,   5.34199238,
         7.50105429,   0.9347291 ,   1.20254219,   0.328188  ,
         1.29352927,   7.25458622,   7.36333513,   1.24048805,
         0.62080872,   1.03044081,   0.72553873,   1.86116457,
         5.35340405,   0.86338186,   9.29167747,   1.67049587,
         2.16708922,   2.42692399,   0.71743947,   0.49024102,
         0.76039803,   9.41758251,   5.52104521,   0.99792773,
        16.67811775,   3.89839673,   2.56528449,   0.60313815,
         7.14359474,  10.68365765,   1.57200813,   0.75602102,
         0.75752109,   4.691257  ,   0.80761522,   3.18514919,
         8.88020992,   1.16923141,   4.12701082,   2.37390041,
         1.1352998 ,   0.97557211,   9.01546001,   0.71548557], dtype=float32), array([[ 0.01159549,  0.03520122, -0.01593706, ...,  0.02099873,
        -0.1069295 ,  0.04460481],
       [-0.01836603,  0.14524864, -0.04236738, ..., -0.03102439,
         0.04471595,  0.03375527],
       [ 0.13399771,  0.06113688,  0.05495071, ...,  0.02231013,
        -0.12279303,  0.06027269],
       ..., 
       [ 0.10680949,  0.06601008, -0.094094  , ..., -0.0516983 ,
        -0.16597772, -0.0913434 ],
       [ 0.06883431, -0.01142251, -0.03041806, ...,  0.05104952,
        -0.07710856, -0.0078621 ],
       [ 0.01068867,  0.03643836, -0.07430133, ..., -0.13916948,
         0.02187075, -0.1535801 ]], dtype=float32), array([-0.01494258, -0.05401299, -0.13052739,  0.07408305, -0.02245741,
       -0.08479612, -0.04052221, -0.10860188, -0.10309392, -0.05075988,
        0.05745222, -0.05651722,  0.08794922,  0.00829016,  0.00629124,
       -0.02105193, -0.0215585 , -0.02681834, -0.08603896,  0.0633048 ,
       -0.00288377, -0.07038491,  0.06781502, -0.09325983], dtype=float32)]
```",0,,9,2017-07-31T14:02:48Z,NONE
11905,No registered 'ResizeBilinear' OpKernel for XLA_CPU_JIT,,"Similar to https://github.com/tensorflow/tensorflow/issues/11890, `tf.image.resize_images` and its siblings haven't been made available for XLA yet. Is there a timeline for when core ops will be supported by XLA? Is there a short instruction somewhere on how to implement ops kernels for the XLA bridge so we could do pull requests as needed to speed up development?

Related: https://github.com/tensorflow/tensorflow/issues/11275",1,,7,2017-07-31T11:52:12Z,CONTRIBUTOR
11903,Missing input file mpi:mpio.h,"stat:community support,type:support","### System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution: **Linux Ubuntu 16.04)**
- TensorFlow installed from: **source**
- TensorFlow version: **master**
- Python version: **3.5.2**
- Bazel version (if compiling from source): **0.5.2**
- CUDA/cuDNN version: **8.0**
- GPU model and memory: **K80**
- Exact command to reproduce:

```bash
#!/usr/bin/env bash
# Only the compilation step for tensorflow is in this script, for clarity.

git clone https://github.com/tensorflow/tensorflow
cd ./tensorflow
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/targets/x86_64-linux/lib:/usr/lib/x86_64-linux-gnu/
export PYTHON_BIN_PATH=""/home/ubuntu/anaconda3/bin/python""
export PYTHON_LIB_PATH=""/home/ubuntu/anaconda3/lib/python3.6/site-packages""
export TF_NEED_JEMALLOC=1
export TF_NEED_GCP=0
export TF_NEED_HDFS=0
export TF_ENABLE_XLA=0
export TF_NEED_VERBS=0
export TF_NEED_OPENCL=0
export TF_NEED_CUDA=1
export TF_CUDA_CLANG=0
export TF_NEED_MPI=1
export MPI_HOME=""/usr/lib/openmpi""
export GCC_HOST_COMPILER_PATH=""/usr/bin/gcc""
export CUDA_VERSION='8.0'
export CUDNN_VERSION='6'
export CUDNN_INSTALL_PATH=/usr/local/cuda
export CUDA_COMPUTE_CAPABILITIES='3.7'
export CUDA_PATH='/usr/local/cuda'
export CUDA_PATH_LINUX='/opt/cuda'
yes """" | ./configure
bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package && \
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
```

### Describe the problem

When turning on `mpi`, the compile fails with the following error:

```error
INFO: Found 1 target...
ERROR: missing input file '//third_party/mpi:mpicxx.h'.
ERROR: missing input file '//third_party/mpi:mpi.h'.
ERROR: missing input file '//third_party/mpi:mpio.h'.
ERROR: /home/ubuntu/scripts/tensorflow/third_party/mpi/BUILD:18:1: //third_party/mpi:mpi: missing input file '//third_party/mpi:mpicxx.h'.
ERROR: /home/ubuntu/scripts/tensorflow/third_party/mpi/BUILD:18:1: //third_party/mpi:mpi: missing input file '//third_party/mpi:mpio.h'.
ERROR: /home/ubuntu/scripts/tensorflow/third_party/mpi/BUILD:18:1: //third_party/mpi:mpi: missing input file '//third_party/mpi:mpi.h'.
```

### Source code / logs
before running the build script I install bazel 0.5.2 (0.5.3 breaks the build)",0,,14,2017-07-31T09:09:55Z,NONE
11896,[Feature request] Dynamically add new machines in distributed TensorFlow,type:feature,"I'm not sure this has been raised before. I did some search on Google and haven't found relevant stuff. If it do exist, please direct me there. Thank you.

I'm currently experimenting with distributed TensorFlow. When building a distributed cluster, all machines in the cluster should be fed into tf.train.Server as parameters. That is, the disitributed cluster configuration is defined when building the computation graph. Like the example provided in https://github.com/tensorflow/models/blob/master/inception/inception/imagenet_distributed_train.py.

But I have also read papers about robust distributed cluster that it would be nice if the framework support dynamically adding or removing machines if the cluster get larger or some machine goes down.

Is this doable in current version of TensorFlow. If so, is there an example to implement this? If not, is there plans for this?",0,,13,2017-07-31T02:27:05Z,NONE
11888,Can't import graph containing MutableHashTable,"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18
- **TensorFlow installed from (source or binary)**: Binary (pip)
- **TensorFlow version (use command below)**: v1.3.0.0rc0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
Import a meta graph containing `MutableHashTable` operations fails. The MutableHashTable in my use case is named and inside a scope. After some digging around I found that the error is a result of a collection `saveable_objects` containing names of `MutableHashTable`s but _without_ the proper scoping.

### Source code / logs
```
graph = create_eval_graph()
tf.train.export_meta_graph('eval_model.meta', graph=graph, as_text=True)

# ...
s = tf.train.import_meta_graph('eval_model.meta') # Fails 
```

This throws the following

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-238-7de9a7b0d1f2> in <module>()
----> 1 s = tf.train.import_meta_graph('eval_model.meta')

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)
   1696                                       clear_devices=clear_devices,
   1697                                       import_scope=import_scope,
-> 1698                                       **kwargs)
   1699   if meta_graph_def.HasField(""saver_def""):
   1700     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)
    690           for value in field.value:
    691             col_op = graph.as_graph_element(
--> 692                 ops.prepend_name_scope(value, scope_to_prepend_to_names))
    693             graph.add_to_collection(key, col_op)
    694         elif kind == ""int64_list"":

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in as_graph_element(self, obj, allow_tensor, allow_operation)
   2704 
   2705     with self._lock:
-> 2706       return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
   2707 
   2708   def _as_graph_element_locked(self, obj, allow_tensor, allow_operation):

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _as_graph_element_locked(self, obj, allow_tensor, allow_operation)
   2764         if name not in self._nodes_by_name:
   2765           raise KeyError(""The name %s refers to an Operation not in the ""
-> 2766                          ""graph."" % repr(name))
   2767         return self._nodes_by_name[name]
   2768 

KeyError: ""The name 'lstm_c_table' refers to an Operation not in the graph.""
```

Where `lstm_c_table` is created as follows

```
tf.contrib.lookup.MutableHashTable(key_dtype=tf.string, value_dtype=tf.float32, default_value=value, name='lstm_c_table')
```

I looked at the generated proto and it contains the following node:

```
  node {
    name: ""input/lstm_c_table""
    op: ""MutableHashTableOfTensorsV2""
    attr {
      key: ""_output_shapes""
      value {
        list {
          shape {
          }
        }
      }
    }
    attr {
      key: ""container""
      value {
        s: """"
      }
    }
    attr {
      key: ""key_dtype""
      value {
        type: DT_STRING
      }
    }
    attr {
      key: ""shared_name""
      value {
        s: """"
      }
    }
    attr {
      key: ""use_node_name_sharing""
      value {
        b: true
      }
    }
    attr {
      key: ""value_dtype""
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: ""value_shape""
      value {
        shape {
          dim {
            size: 512
          }
        }
      }
    }
  }
```

```
collection_def {
  key: ""saveable_objects""
  value {
    node_list {
      value: ""lstm_c_table""
      value: ""lstm_h_table""
      value: ""history_table""
      value: ""first_table""
      value: ""encode_lstm_c_table""
      value: ""encode_lstm_h_table""
    }
  }
}
```

Either removing the above collection or prefixing all the values with `input/` results in the following error:

```
TypeError: Can't convert Operation 'input/lstm_c_table' to Tensor (target dtype=None, name=None, as_ref=True)
```

This solution is part of an imitation of `batch_sequences_with_states` so a graph can be exported that does not rely on queues but instead uses placeholders and the `feed_dict` mechanism, for use in interactive model evaluation.",0,,3,2017-07-30T20:23:11Z,CONTRIBUTOR
11882,conv2d_transpose produce different results on GPU,type:bug/performance,"### System information
== cat /etc/issue ===============================================
Linux ST 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""14.04.4 LTS, Trusty Tahr""
VERSION_ID=""14.04""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux ST 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
msgpack-numpy (0.4.1)
numpy (1.13.1)
protobuf (3.2.0)
tensorflow (0.10.0)
tensorflow-gpu (1.0.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.0.0
tf.GIT_VERSION = v1.0.0-rc2-15-g47bba63-dirty
tf.COMPILER_VERSION = v1.0.0-rc2-15-g47bba63-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally

== env ==========================================================
LD_LIBRARY_PATH /home/abc/torch/install/lib:/usr/lib/x86_64-linux-gnu:/home/abc/torch/install/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:/usr/local/cuda/lib64::/usr/local/computecpp/lib:/data/software/gurobi652/linux64/lib
DYLD_LIBRARY_PATH /home/abc/torch/install/lib:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:

== nvidia-smi ===================================================
Sun Jul 30 17:45:45 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 0000:01:00.0      On |                  N/A |
|  0%   53C    P2    47W / 260W |   7909MiB /  8112MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1308    G   /usr/bin/X                                     357MiB |
|    0      2590    G   compiz                                         229MiB |
|    0      3254    G   ...el-token=CBAE43C38254E155E78826C3F38F0092    99MiB |
|    0      9480    C   python                                        1039MiB |
|    0     10432    C   /usr/bin/python                               5895MiB |
|    0     20408    C   /usr/bin/python                                283MiB |
|    0     28024    G   /usr/local/MATLAB/R2015a/bin/glnxa64/MATLAB      2MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so.8.0
/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/MATLAB/R2017a/bin/glnxa64/libcudart.so.8.0.44
/usr/local/MATLAB/R2015a/bin/glnxa64/libcudart.so.6.5.14
### Describe the problem
I am trying to use `tf.nn.conv2d_transpose` but it produces different results every time on GPU. However, the result would be the same when switching the device to CPU. It seems like a bug. Please check the toy model below for more details.

### Source code / logs
```python
import tensorflow as tf
import numpy as np

np.random.seed(1234)
conv_ = np.random.randn(10, 7, 7, 56)

with tf.device('/gpu:0'):
    bottom = tf.constant(conv_, dtype=tf.float32)
    weight = tf.get_variable(""weight"", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))
    bias = tf.get_variable(""bias"", initializer=np.zeros(1, dtype=np.float32))	

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv = tf.nn.bias_add(conv, bias)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
np.array_equal(sess.run(conv), sess.run(conv))
```
`Out[2]: False`",2,,12,2017-07-30T10:11:36Z,NONE
11865,"Batchnorm errors in ""successful"" Windows builds",stat:contributions welcome,"* Current system configuration: 
* Windows 10 64 bit, intel i7-7700HQ latest microcode, Nvidia 1050 4GB.
* Driver: 384.94
* Python used: Anaconda 4.4.0 Python 3.6.2 and 3.5.3
* CUDA/cuDNN: 8.0.61/5.1 or 8.0.61.2/6.0
* swigwin 3.0.12
* Built 1.2.1 from source using VS 2015 Update 3, CMake 3.9.0 or 3.9.0 RC5, swigwin 3.0.12.
* Code modifications: in builds with both cuDNN and AVX enabled, the code was [modified accord to this comment](https://github.com/tensorflow/tensorflow/issues/11096#issuecomment-312049089)
* Issue description: In certain conditions ""successful"" builds of tensorflow with GPU support, results in broken batchnorm functionality. An example error:
 > InvalidArgumentError (see above for traceback): indices[1] is out of range
	 [[Node: gradients/batch_normalization/moments/Mean_1_grad/DynamicStitch = DynamicStitch[N=2, T=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/batch_normalization/moments/Mean_1_grad/range, gradients/batch_normalization/moments/Mean_1_grad/mod, gradients/batch_normalization/moments/Mean_1_grad/Shape, gradients/batch_normalization/moments/Mean_1_grad/Fill)]]

This error was encountered in a variety of different builds. But it was most surprising when it occurred in an unmodified python 3.6 gpu build. Files and [configuration can be found here](https://github.com/aluo-x/tensorflow_windows).
",0,,7,2017-07-29T07:05:18Z,NONE
11848,Can't import graph containing batch_sequences_with_states,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18
- **TensorFlow installed from (source or binary)**: Binary (pip)
- **TensorFlow version (use command below)**: v1.3.0.0rc0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
As I'm working with sequences I make extensive use of `tf.contrib.training.batch_seq_with_states`. I need to be able to load my graph afterwards so I write out a meta graph file containing a graph definition using `Saver.save`. Upon loading using `tf.train.import_meta_graph` I get an error hinting the `batch_seq_with_states` operation isn't saved in the graph:

```
(Pdb) tf.train.import_meta_graph('model.ckpt-1.meta')
*** KeyError: ""The name 'input/batch_seq_with_states/InputQueueingStateSaver/' refers to an Operation not in the graph.""
```

Using Tensorboard I can inspect `input/batch_seq_with_states/InputQueueingStateSaver` just fine from the same files.

I will for now try to work around this by writing out a separate graph that relies on placeholders for data loading instead of `batch_seq_with_states` and then load the weights separate. ",0,,7,2017-07-28T13:50:01Z,CONTRIBUTOR
11846,Fractional 3d Max Pooling,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:8/5
- **GPU model and memory**:Nvidia 740M

### Describe the problem
There is a fractional maxpool op for 4D tensors. For medical imaging, data is available in the form of 3d images. Hence a fractional maxpool/avgpool  op for 5D tensors i.e., [batch_size, n_channels, depth, height, width] would be really useful.

",0,,3,2017-07-28T10:44:58Z,NONE
11831,No mention of how to use custom RunConfig with Estimator in the Estimator tutorial,,"On the tutorial of creating estimators using tf.contrib.learn there doesn't seem to be any mention of how to create your own RunConfig object in order to specify the configurations for an Estimator run. The configuration in particular I wanted to find was on how to write summaries after custom sized steps. I eventually found it in the RunConfig description, but I think it would be worthwhile to mention it in the tutorial.

Link to the tutorial:
https://www.tensorflow.org/extend/estimators

Link to the RunConfig description:
https://www.tensorflow.org/api_docs/python/tf/contrib/learn/RunConfig

I was wondering if the tutorial could be updated to show how to create your own RunConfig object and use it with the Estimator. 
",1,,6,2017-07-27T22:39:54Z,NONE
11823,ERROR message when using tf.SyncReplicasOptimizer,,"I'm running distributed tensorflow with estimators, and in order to it in sync mode, I'm using tf.SyncReplicasOptimizer, but  casually (specially after evaluation) I see the following error on the master:
```
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'report_uninitialized_variables/boolean_mask/Gather:0' shape=(?,) dtype=string>

['File ""cifar10_main.py"", line 538, in <module>\n    tf.app.run()', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))', 'File ""cifar10_main.py"", line 518, in main\n    hooks), run_config=config)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 210, in run\n    return _execute_schedule(experiment, schedule)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py"", line 47, in _execute_schedule\n    return task()', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 501, in train_and_evaluate\n    hooks=self._eval_hooks)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 681, in _call_evaluate\n    hooks=hooks)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 292, in evaluate\n    name=name)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 638, in _evaluate_model\n    features, labels, model_fn_lib.ModeKeys.EVAL)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 545, in _call_model_fn\n    features=features, labels=labels, **kwargs)', 'File ""cifar10_main.py"", line 331, in _resnet_model_fn\n    gradvars, global_step=tf.train.get_global_step())', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/sync_replicas_optimizer.py"", line 252, in apply_gradients\n    variables.global_variables())', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]']
==================================

```
Code available at:https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10_estimator/cifar10_main.py
",0,,20,2017-07-27T18:16:25Z,NONE
11816,Snappy related tests are failing,"stat:contributions welcome,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 'v1.2.1-0-gb4957ff', '1.2.1'
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: No GPU
- **GPU model and memory**: No GPU
- **Exact command to reproduce**: bazel test //tensorflow/core:lib_io_snappy_snappy_buffers_test

### The problem:
While executing test `TEST(SnappyBuffers, MultipleWritesWithoutFlush)`. It fails when `Snappy_Uncompress()` method is called which internally calls `snappy::RawUncompress()`.
Compared the same on intel x86 where it works fine; However the data somehow gets lost on s390x.

I am aware that Snappy behaves differently on s390x as compared to others.

There is another test `//tensorflow/core:lib_io_table_test` which fails when snappy compress/uncompress is used.
Would like to know if the mentioned test-cases are used to test some complex functionality of TensorFlow? Can they be ignored?

### Source code / logs
Running main() from test_main.cc
[==========] Running 5 tests from 1 test case.
[----------] Global test environment set-up.
[----------] 5 tests from SnappyBuffers
[ RUN      ] SnappyBuffers.MultipleWritesWithoutFlush
2017-07-27 12:25:34.898300: F tensorflow/core/lib/io/snappy/snappy_buffers_test.cc:148] Non-OK-status: TestMultipleWrites(10000, 10000, 10000, 10000, 2) status: Data loss: Snappy_Uncompress failed
external/bazel_tools/tools/test/test-setup.sh: line 159: 17664 Aborted                 (core dumped) ""${TEST_PATH}"" ""$@""
",0,,1,2017-07-27T13:20:07Z,NONE
11812,InternalError: Blas GEMM launch failed ,,"------------------------

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Distributor ID: Ubuntu
Description:    Ubuntu 16.04.2 LTS
Release:        16.04
- **TensorFlow installed from (source or binary)**:
pip3 install tensorflow-gpu

- **TensorFlow version (use command below)**:
v1.2.0-5-g435cdfc 1.2.1

- **Python version**: 
3.5

- **CUDA/cuDNN version**:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61

- **GPU model and memory**:
 description: 3D controller
          product: GK210GL [Tesla K80]
          vendor: NVIDIA Corporation
          physical id: 0
          bus info: pci@99ba:00:00.0
          version: a1
          width: 64 bits
          clock: 33MHz
          capabilities: bus_master cap_list
          configuration: driver=nvidia latency=0
          resources: iomemory:100-ff iomemory:140-13f irq:24 memory:21000000-21ffffff 
          memory:1000000000-13ffffffff memory:1400000000-1401ffffff

- **Code example**:
estimator = KerasRegressor(build_fn=self.create_model_function,
                                   input_dim=self.input_dim, output_dim=self.output_dim,
                                   **self.model_parameters)

param_grid = {'epochs': [5]
              ,'batch_size': [256]
              ,'neurons': [[10, 10, 10]]
              ,'dropout': [[0.0, 0.0]]}

grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1)


### Describe the problem
The InternalError occurred when I fit a sklearn.GridSearchCV object.
The error occurred only if I use GPU and I I use GridSearch object. It works fine on CPU and on single model fitting (using Keras wrapper).


### Error log
File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/model_selection/_search.py"", line 945, in fit
    return self._fit(X, y, groups, ParameterGrid(self.param_grid))
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/model_selection/_search.py"", line 564, in _fit
    for parameters in parameter_iterable
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 728, in __call__
    n_jobs = self._initialize_backend()
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 540, in _initialize_backend
    **self._backend_args)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py"", line 311, in configure
    self._pool = MemmapingPool(n_jobs, **backend_args)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py"", line 600, in __init__
    super(MemmapingPool, self).__init__(**poolargs)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/pool.py"", line 420, in __init__
    super(PicklingPool, self).__init__(**poolargs)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/pool.py"", line 168, in __init__
    self._repopulate_pool()
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/pool.py"", line 233, in _repopulate_pool
    w.start()
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/context.py"", line 267, in _Popen
    return Popen(process_obj)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/popen_fork.py"", line 20, in __init__
    self._launch(process_obj)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/popen_fork.py"", line 74, in _launch
    code = process_obj._bootstrap()
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/process.py"", line 249, in _bootstrap
    self.run()
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py"", line 344, in __call__
    return self.func(*args, **kwargs)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py"", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py"", line 136, in fit
    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))
  File ""/home/aateam/Amplifon/amplifon-adv-planning/src/libs/amplifon_objects.py"", line 176, in create_test_model
    model.add(Dense(neurons[0], input_dim=input_dim, activation=last_activation))
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/keras/models.py"", line 436, in add
    layer(x)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/keras/engine/topology.py"", line 596, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/keras/layers/core.py"", line 838, in call
    output = K.dot(inputs, self.kernel)
  File ""/home/aateam/.conda/envs/amplifon-dev3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 978, in dot
    out = tf.matmul(x, y)
  File ""/home/aateam/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 1816, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/home/aateam/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1217, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/home/aateam/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/aateam/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/aateam/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Blas GEMM launch failed : a.shape=(256, 32), b.shape=(32, 10), m=256, n=10, k=32
         [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_arg_dense_1_input_0_0/_15, dense_1/kernel/read)]]
         [[Node: mul_1/_43 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_795_mul_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

",0,,15,2017-07-27T10:07:15Z,NONE
11807,"tensorflow build error in Illegal ambiguous match on configurable attribute ""copts"" in //tensorflow/python:gen_math_ops_py_wrappers_cc:","stat:awaiting tensorflower,type:build/install","$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package 
ERROR: /root/tools/tensorflow-master/tensorflow/python/BUILD:1166:1: Illegal ambiguous match on configurable attribute ""copts"" in //tensorflow/python:gen_math_ops_py_wrappers_cc:
@local_config_cuda//cuda:using_clang
@local_config_cuda//cuda:using_nvcc
Multiple matches are not allowed unless one is unambiguously more specialized.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
INFO: Elapsed time: 0.190s",0,,18,2017-07-27T09:23:09Z,NONE
11806,sparse ClusterSpec fails when using tf.cond,"stat:awaiting tensorflower,type:bug/performance","Here's the minimal code to reproduce.
on machine 1 and machine 2
```python
import sys
import tensorflow as tf

cluster_spec = tf.train.ClusterSpec({
  ""a"": { 0: ""machine1:8000"" },
  ""b"": { 0: ""machine2:8001"" },
})
jobname = sys.argv[1]
taskid = int(sys.argv[2])
server = tf.train.Server(cluster_spec, jobname, taskid)

with tf.device(""/job:a/task:0/cpu:0""):
  queue = tf.FIFOQueue(
    capacity=100, dtypes=[tf.int64],
    shapes=[[]], shared_name=""a_queue"", name=""a_queue"")

if jobname == ""a"" and taskid == 0:
  enqueue_op = queue.enqueue(10)
  sess = tf.Session(server.target)
  while True:
    sess.run(enqueue_op)
else:
  dequeue_op = queue.dequeue()
  sess = tf.Session(server.target)
  while True:
    print(sess.run(dequeue_op))
```

on machine 3:

```python
import sys
import tensorflow as tf

cluster_spec = tf.train.ClusterSpec({
  ""a"": { 0: ""machine1:8000"" },
  ""b"": { 1: ""machine3:8001"" },
})
jobname = sys.argv[1]
taskid = int(sys.argv[2])
server = tf.train.Server(cluster_spec, jobname, taskid)

with tf.device(""/job:a/task:0/cpu:0""):
  queue = tf.FIFOQueue(
    capacity=100, dtypes=[tf.int64],
    shapes=[[]], shared_name=""a_queue"", name=""a_queue"")

if jobname == ""a"" and taskid == 0:
  enqueue_op = queue.enqueue(10)
  sess = tf.Session(server.target)
  while True:
    sess.run(enqueue_op)
else:
  with tf.device(""/job:b/task:1""):
    out = queue.dequeue()
    queue_b = tf.FIFOQueue(capacity=100, dtypes=[tf.int64], shapes=[[]], name=""b_queue"")
    # 1.
    # enq = queue_b.enqueue(out)
    # no_op = tf.no_op()
    # out = tf.cond(tf.equal(out, 10), lambda: enq, lambda: no_op)
    # 2.
    out = tf.cond(tf.equal(out, 10), lambda: queue_b.enqueue(out), lambda: tf.no_op())

  sess = tf.Session(server.target)
  while True:
    print(sess.run(out))
```

On machine3, it crashes complaining

```shell
tensorflow.python.framework.errors_impl.InternalError: No worker known as /job:b/replica:0/task:1
	 [[Node: cond/pred_id_S5 = _HostRecv[client_terminated=false, recv_device=""/job:a/replica:0/task:0/cpu:0"", send_device=""/job:b/replica:0/task:1/gpu:0"", send_device_incarnation=720279685140440577, tensor_name=""edge_8_cond/pred_id"", tensor_type=DT_BOOL, _device=""/job:a/replica:0/task:0/cpu:0""]()]]
```
There is no problem if the true_fn and false_fn just returns a already constructed op, like in the commented code.",1,,5,2017-07-27T08:30:47Z,CONTRIBUTOR
11802,3D Convolutions not being forwarded to MKL,type:feature,"This is a placeholder reminder for the Tensorflow/Intel team.  I'm in touch with Toby Boyd and Intel on this issue, I just want it to be in the databasase.

When compiling for MKL (--config=mkl) 3D convolutions remain in native Eigan. This strongly impacts a 3D medical application that needs to run inferencing on an edge device.



------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04 and CentOS 7

- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.2.0rc0
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.5.2
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:
Follow standard bazel build, say ""yes"" for MKL, build  wheel with --config=mkl. and install with pip

",1,,4,2017-07-27T05:55:19Z,NONE
11791,Feature request: equivalent of tf.nn.maxpooling_with_argmax for 3D maxpooling,stat:contributions welcome,"It would be great to have the equivalent of tf.nn.maxpooling_with_argmax in 3D, in order to allow for 3D unpooling layers.

I am implementing a 3Dversion of the originally 2D Deconvolution network [Noh et al. 2015]. It has been implemented in 2D in Tensorflow [here](https://github.com/fabianbormann/Tensorflow-DeconvNet-Segmentation/blob/master/DeconvNet.py) and in 3D in caffe [here](https://github.com/Microsoft/O-CNN/blob/master/caffe/examples/o-cnn/segmentation_5.prototxt). 

I need to use unpooling, and for that I need the indexes of the elements selected during pooling. This feature is implemented for 2D (tf.nn.maxpooling_with_argmax), but not for 3D.
",0,,3,2017-07-26T21:11:39Z,NONE
11785,proposed new github for tensorflow notebooks,"stat:awaiting tensorflower,type:docs","I would like to propose that we make a separate repository in github for jupyter notebooks.

I think it should be separate from the main tensorflow github so that people can check it out without having to check out all of tensorflow.

I've created such a github and will work on it by myself for now but I think eventually there should be something more official or at least maybe what I have can be considered official enough to have pointers to it from the main tensorflow github.

https://github.com/reedkotler/tensorflow-notebooks
",1,,5,2017-07-26T13:49:09Z,NONE
11782,CUDA_ERROR_LAUNCH_FAILED when using conv2d/max_pool on Tensorflow GPU (Windows 10),"stat:community support,type:build/install","When using conv2d and/or max_pool, the error below shows and stops the code. I used the code available here: [https://github.com/dennybritz/cnn-text-classification-tf](https://github.com/dennybritz/cnn-text-classification-tf)

```
2017-07-26 21:41:27.467585: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_driver.cc:1068] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED
2017-07-26 21:41:27.467797: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_timer.cc:54] Internal: error destroying CUDA event in context 000001178B37E810: CUDA_ERROR_LAUNCH_FAILED
2017-07-26 21:41:27.468679: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_timer.cc:59] Internal: error destroying CUDA event in context 000001178B37E810: CUDA_ERROR_LAUNCH_FAILED
2017-07-26 21:41:27.469846: F c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_dnn.cc:2479] failed to enqueue convolution on stream: CUDNN_STATUS_EXECUTION_FAILED
```

**What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?**

I have searched through all websites including GitHub and StackOverflow, and these two are the most relevant results and why they did not help:

1. [https://github.com/tensorflow/tensorflow/issues/6783](https://github.com/tensorflow/tensorflow/issues/6783) - The issue pertains to tf.one_hot. Is this function used in either one of the functions above? The issue seems to be not solved too. I tried using the code on a Linux/GPU and on a Windows/CPU setting as well and it worked.
2. [https://github.com/dennybritz/cnn-text-classification-tf/issues/90](https://github.com/dennybritz/cnn-text-classification-tf/issues/90) - They kind of 'resolved' the issue by reducing the batch size. I tried this and it worked, but it does not make sense. For one thing, I tried using the code on another Windows machine with an older GPU and it works well.

**Environment info**

- Tensorflow 1.2.1
- Python 3.5.3
- CUDA 8.0
- cuDNN 5.1
- OS: Windows 10
- GPU: GeForce GTX 1060

[EDITED] edited the links",0,,5,2017-07-26T12:55:12Z,NONE
11777,No OpKernel was registered to support Op 'Ceil' on Android,stat:awaiting response,"I'm running tensorflow on android. And it reports a exception of one of my op 'Ceil'. The exception info is as below:
`Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Ceil' with these attrs.  
Registered devices: [CPU], Registered kernels:  <no registered kernels>
[[Node: model/frame/Ceil = Ceil[T=DT_DOUBLE](model/frame/truediv)]]
   at org.tensorflow.Session.run(Native Method)`

I believe Ceil is a basic op and it should has CPU implement. So maybe I miss sth. ?   ( I clone tensorflow master branch and build the lib and java interface on that)",0,,9,2017-07-26T10:02:55Z,NONE
11776,//py_test_dir/tensorflow/python:bitwise_ops_test failing on Windows,,"http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/32/console
```
ERROR: testPopulationCountOp (__main__.BitwiseOpTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""\\?\C:\tmp\Bazel.runfiles_5m16karn\runfiles\org_tensorflow\py_test_dir\tensorflow\python\ops\bitwise_ops_test.py"", line 66, in testPopulationCountOp
    inputs = np.array(raw_inputs, dtype=dtype.as_numpy_dtype)
OverflowError: Python int too large to convert to C long
```
Culprit: cl/163090921 ",0,,6,2017-07-26T09:17:07Z,MEMBER
11765,cond with gradients of map_fn hangs,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: `('v1.2.0-5-g435cdfc', '1.2.1')`
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0 / 5.1.5
- **GPU model and memory**: GeForce GTX 1080, 8113MiB
- **Exact command to reproduce**: `python test.py` (see below)

### Describe the problem
Running a `cond` in which a lambda (even the one that isn't used) includes the `gradients` of a tensor made by `map_fn` makes TensorFlow hang. See test.py below for reproduction.

Doing the `gradients` outside of the lambda makes it work. See test-workaround.py for example.

### Source code / logs
test.py:
```py
import tensorflow as tf

print 'start'
numbers = tf.zeros([2], dtype=tf.float32)

result = tf.map_fn(lambda image: image, numbers)

def get_next_step():
  objective = result[0]
  grads, = tf.gradients(objective, numbers)
  return numbers + grads

def current_or_next(use_next):
  return tf.cond(use_next,
                 get_next_step,
                 lambda: numbers)

always_old = current_or_next(use_next=tf.constant(False))

print 'creating session'
sess = tf.Session()
print 'before run'
sess.run(always_old)
print 'after run'
```

test-workaround.py:
```py
import tensorflow as tf

print 'start'
numbers = tf.zeros([2], dtype=tf.float32)

result = tf.map_fn(lambda image: image, numbers)

def get_next_step():
  objective = result[0]
  grads, = tf.gradients(objective, numbers)
  return numbers + grads
next_step = get_next_step() # <--

def current_or_next(use_next):
  return tf.cond(use_next,
                 lambda: next_step, # <--
                 lambda: numbers)

always_old = current_or_next(use_next=tf.constant(False))

print 'creating session'
sess = tf.Session()
print 'before run'
sess.run(always_old)
print 'after run'
```

I haven't been able to get a traceback after it hangs.",1,,5,2017-07-25T22:50:51Z,NONE
11756,Infinity mask breaks gradient,"stat:community support,type:support","I'm trying to do softmax over selected indices, using infinity mask to silent out the unwanted ones. However, the gradient of those unwanted entires become nan as opposed to 0.

The reason I didn't use boolean mask is that the mask indices are different in my batch, which can't end up with a nice matrix form. If there's workaround here I'll be more than happy to adopt.

The code I tested the infinity mask is

```
import numpy as np
import tensorflow as tf

a = tf.placeholder(tf.float32, [5])
inf_mask = tf.placeholder(tf.float32, [5])

b = tf.multiply(a, inf_mask)
sf = tf.nn.softmax(b)

loss = (sf[2] - 0)
grad = tf.gradients(loss, a)

sess = tf.Session()

a_np = np.ones([5])
np_mask = np.ones([5]) * 4
np_mask[1] = -np.inf

print sess.run([sf, grad], feed_dict={
    a: a_np,
    inf_mask: np_mask
})

sess.close()
```

The output is `[array([ 0.25,  0.  ,  0.25,  0.25,  0.25], dtype=float32), [array([-0.25,   nan,  0.75, -0.25, -0.25], dtype=float32)]]`

The mask is working but the gradient has a nan, which should have been 0 I think.",0,,5,2017-07-25T17:46:52Z,NONE
11735,"python configure fails on Windows if ""bash on Ubuntu on Windows"" installed",,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10,  with ""bash on Ubuntu on Windows"" installed
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
ec808c9b75af5dcabcb7233b10b72cfd1366fcde
- **Python version**: 
3.5.3
- **Bazel version (if compiling from source)**:
9e62187df84ae425a5d7226b6baf1bef576f0a10
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
bazel --output_base C:\t  clean --expunge
bazel --output_base C:\t build --features generate_pdb_file --action_env=USE_DYNAMIC_CRT=1 --action_env=NO_MSVC_WRAPPER=1 --color=no --compilation_mode fastbuild --verbose_failures --experimental_ui --copt=/Z7 --linkopt=/DEBUG:FASTLINK --copt=/DNDEBUG --host_copt=/DNDEBUG //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
Build tensorflow on windows with bazel may fail because  ""bash on Ubuntu on Windows"" is installed
It may invoke the wrong ""bash"" for executing these commands.

Related: https://github.com/bazelbuild/bazel/issues/3445

### Source code / logs
```
Analyzing: target //tensorflow/tools/pip_package:build_pip_package
ERROR: C:/os/tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': Traceback (most recent call last):
        File ""C:/os/tensorflow/third_party/py/python_configure.bzl"", line 310
                _create_local_python_repository(repository_ctx)
        File ""C:/os/tensorflow/third_party/py/python_configure.bzl"", line 269, in _create_local_python_repository
                _check_python_bin(repository_ctx, python_bin)
        File ""C:/os/tensorflow/third_party/py/python_configure.bzl"", line 225, in _check_python_bin
                _python_configure_fail(""PYTHON_BIN_PATH is not executab..."")
        File ""C:/os/tensorflow/third_party/py/python_configure.bzl"", line 37, in _python_configure_fail
                fail((""%sPython Configuration Error:%...)))
Python Configuration Error: PYTHON_BIN_PATH is not executable.  Is it the python binary?
```",1,,16,2017-07-25T04:44:07Z,CONTRIBUTOR
11726,Error while generating executable from obj file created with XLA aot for CPU,"stat:awaiting tensorflower,type:build/install","Hi,
I m trying to generate executable (currently x86 for testing) using xla aot. I built the test file and generated .o using bazel build. Now I am trying to generate executable using clang (gcc also gives the similar error). I get the following error as undefined reference to **tensorflow::tfcompile::runtime::MallocContiguousBuffers** and
**tensorflow::tfcompile::runtime::FreeContiguous**
```
**clang  ../aot_build/9fb1b9df97c5e4f9c88d55c740dbcaad/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/compiler/aot/tests/_objs/test_graph_binary/tensorflow/compiler/aot/tests/test_graph.o -lstdc++ -v**
clang version 3.8.0 (tags/RELEASE_380/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /pkg/qct/software/llvm/build_tools/llvm38_160329/bin
Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8
Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4
Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9
Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.3
Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8
Candidate multilib: .;@m64
Selected multilib: .;@m64
 ""/usr/bin/ld"" -z relro --hash-style=gnu --build-id --eh-frame-hdr -m elf_x86_64 -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o a.out /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/crt1.o /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/4.8/crtbegin.o -L/usr/lib/gcc/x86_64-linux-gnu/4.8 -L/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu -L/lib/x86_64-linux-gnu -L/lib/../lib64 -L/usr/lib/x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/4.8/../../.. -L/afs/localcell/cm/gv2.6/sysname/pkg.@sys/qct/software/llvm/build_tools/llvm38_160329/bin/../lib -L/lib -L/usr/lib ../aot_build/9fb1b9df97c5e4f9c88d55c740dbcaad/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/compiler/aot/tests/_objs/test_graph_binary/tensorflow/compiler/aot/tests/test_graph.o -lstdc++ -lgcc --as-needed -lgcc_s --no-as-needed -lc -lgcc --as-needed -lgcc_s --no-as-needed /usr/lib/gcc/x86_64-linux-gnu/4.8/crtend.o /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/crtn.o
../aot_build/9fb1b9df97c5e4f9c88d55c740dbcaad/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/compiler/aot/tests/_objs/test_graph_binary/tensorflow/compiler/aot/tests/test_graph.o: In function `main':
test_graph.cc:(.text.startup.main+0xb4): undefined reference to `tensorflow::tfcompile::runtime::MallocContiguousBuffers(long const*, unsigned long, void**, bool)'
test_graph.cc:(.text.startup.main+0xda): undefined reference to `tensorflow::tfcompile::runtime::MallocContiguousBuffers(long const*, unsigned long, void**, bool)'
test_graph.cc:(.text.startup.main+0xf8): undefined reference to `xla::ExecutableRunOptions::set_intra_op_thread_pool(Eigen::ThreadPoolDevice const*)'
test_graph.cc:(.text.startup.main+0x1dc): undefined reference to `__tensorflow_compiler_aot_tests__test_graph_tfmatmul'
test_graph.cc:(.text.startup.main+0x22e): undefined reference to `tensorflow::tfcompile::runtime::FreeContiguous(void*)'
test_graph.cc:(.text.startup.main+0x23a): undefined reference to `tensorflow::tfcompile::runtime::FreeContiguous(void*)'
test_graph.cc:(.text.startup.main+0x289): undefined reference to `tensorflow::tfcompile::runtime::FreeContiguous(void*)'
test_graph.cc:(.text.startup.main+0x295): undefined reference to `tensorflow::tfcompile::runtime::FreeContiguous(void*)'
clang-3.8: error: linker command failed with exit code 1 (use -v to see invocation)

I am running it on  Ubuntu 14.04.5
Tensorflow version: 1.2.1
Installed tensorflow from source with XLA enabled and everything else disabled.
bazel: release 0.5.1
GPU: N/A
Python: 2.7.6 (although I thik it's not applicable here)
clang version 3.8.0

I am following this: https://www.tensorflow.org/performance/xla/tfcompile
Initially I was getting error in build

ERROR: /local/mnt/workspace/ankitac/virtual/tensorflow/tensorflow/compiler/aot/tests/aot_project/BUILD:12:1: undeclared inclusion(s) in rule '//tensorflow/compiler/aot/tests/aot_project:test_graph_binary':
this rule is missing dependency declarations for the following files included by 'tensorflow/compiler/aot/tests/aot_project/test_graph.cc':
  '/local/mnt/workspace/ankitac/virtual/tensorflow/tensorflow/compiler/aot/tests/aot_project/test_graph_tfmatmul.h'.
Target //tensorflow/compiler/aot/tests/aot_project:test_graph_binary failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 5.092s, Critical Path: 1.34s
```
I have BUILD file as:
```
load(""//tensorflow/compiler/aot:tfcompile.bzl"", ""tf_library"")

tf_library(
    name = ""test_graph_tfmatmul"",
    cpp_class = ""foo::MatMulComp"",
    graph = ""test_graph_tfmatmul.pb"",
    config = ""test_graph_tfmatmul.config.pbtxt"",
)

cc_binary(
    name = ""test_graph_binary"",
    srcs = [
        ""test_graph.cc"",  # include test_graph_tfmatmul.h to access the generated header
    ],
    deps = [
        "":test_graph_tfmatmul"",  # link in the generated object file
        ""//third_party/eigen3"",
    ],
    linkopts = [
          ""-lpthread"",
    ]
)
```
Building that using
```
bazel --output_user_root=/local/mnt/workspace/ankitac/virtual/aot_build/ build  //tensorflow/compiler/aot/tests/aot_project:test_graph_binary
```
**For now I resolved this issue by adding my cc_binary to aot/test BUILD and building it from there works. But crating executable is still the issue.**

Any help is highly appreciated!

Thanks & regards


",0,,8,2017-07-24T20:27:55Z,NONE
11724,Importing TensorFlow breaks numpy.linalg.matrix_power(),type:bug/performance,"#10771 
## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: bazel release 0.5.1
- **CUDA/cuDNN version**: CUDA V8.0.61 / 
- **GPU model and memory**: NVIDIA Titan X Fall 2016
- **Exact command to reproduce**:
```python
import numpy as np
import tensorflow as tf
np.random.seed(seed=0)
X = np.random.randn(2000, 2000)
Y = np.linalg.matrix_power(X, 30)
```

### Describe the problem
This seems to be a bug where importing tensorflow breaks numpy.linalg.matrix_power()

The two following code snippets are producing different results on my system when entered directly into the python interpreter. Note, I am restarting the python kernel between running each block.

**This works:**
```python
import numpy as np
np.random.seed(seed=0)
X = np.random.randn(2000, 2000)
Y = np.linalg.matrix_power(X, 30)
>>> X 
array([[ 1.76405235,  0.40015721,  0.97873798, ...,  0.15843385,
        -1.14190142, -1.31097037],
       [-1.53292105, -1.71197016,  0.04613506, ..., -0.03057244,
         1.57708821, -0.8128021 ],
       [ 0.61334917,  1.84369998,  0.27109098, ..., -0.53788475,
         0.39344443,  0.28651827],
       ..., 
       [-0.17117027,  0.57332063, -0.89516715, ..., -0.01409412,
         1.28756456, -0.6953778 ],
       [-1.53627571,  0.57441228, -0.20564476, ...,  0.90499929,
         0.51428298,  0.72148202],
       [ 0.51262101, -0.90758583,  1.78121159, ..., -1.12554283,
         0.95170926, -1.15237806]])
>>> Y
array([[ -1.04752205e+48,   2.10841282e+47,  -4.54826843e+47, ...,
         -7.84526353e+46,  -4.45185369e+47,  -1.96340973e+47],
       [ -5.40802471e+46,   1.12546832e+48,  -1.88764494e+47, ...,
         -3.72182046e+47,   7.97461852e+47,  -5.04546546e+46],
       [ -3.59835691e+47,  -6.90559050e+46,  -8.78538707e+47, ...,
          7.67940928e+47,   2.10052546e+47,   1.75193723e+47],
       ...,
       [  2.20970288e+46,   3.60679821e+47,   5.76631889e+47, ...,
          1.21938369e+48,  -8.61048462e+47,  -3.93610572e+47],
       [ -1.19116636e+48,   2.47318954e+48,   2.65693291e+46, ...,
          9.18513286e+47,   3.91490216e+47,  -7.08113716e+47],
       [ -2.25527724e+47,  -4.94088618e+46,  -2.69359430e+47, ...,
         -4.07174632e+47,   7.38250907e+47,   5.86758288e+46]])
```
**This produces the wrong result:**
```python
import numpy as np
import tensorflow as tf
np.random.seed(seed=0)
X = np.random.randn(2000, 2000)
Y = np.linalg.matrix_power(X, 30)
>>> X
array([[ 1.76405235,  0.40015721,  0.97873798, ...,  0.15843385,
        -1.14190142, -1.31097037],
       [-1.53292105, -1.71197016,  0.04613506, ..., -0.03057244,
         1.57708821, -0.8128021 ],
       [ 0.61334917,  1.84369998,  0.27109098, ..., -0.53788475,
         0.39344443,  0.28651827],
       ..., 
       [-0.17117027,  0.57332063, -0.89516715, ..., -0.01409412,
         1.28756456, -0.6953778 ],
       [-1.53627571,  0.57441228, -0.20564476, ...,  0.90499929,
         0.51428298,  0.72148202],
       [ 0.51262101, -0.90758583,  1.78121159, ..., -1.12554283,
         0.95170926, -1.15237806]])
>>> Y
array([[ -3.40382764e+91,   2.85027458e+91,   1.14039870e+91, ...,
          3.32682992e+91,   6.00166234e+91,   2.33233825e+91],
       [  3.86088264e+91,   1.15500453e+92,   2.83821815e+91, ...,
         -6.16959058e+91,  -1.91501705e+91,  -4.67672849e+91],
       [  5.05026067e+91,   7.72796711e+91,  -4.70112473e+91, ...,
          8.41553063e+90,  -2.66176140e+91,   8.50899233e+90],
       ...,
       [ -2.08592878e+91,   2.28435173e+91,   9.15188619e+90, ...,
         -1.25550051e+91,   1.85247259e+91,  -8.73231986e+90],
       [ -4.73923534e+91,   1.61385540e+92,   1.26364668e+92, ...,
          2.83667716e+91,   5.06236372e+90,  -5.18395025e+91],
       [ -1.52984791e+91,  -5.57421948e+90,   3.27657918e+91, ...,
         -7.08972359e+91,  -1.58912068e+91,  -1.22216698e+91]])
```

The values for X are exactly the same. Interestingly, if you run the first code block, then import tensorflow without restarting the kernel and recompute the matrix power, the correct result is returned.

I haven't been able to find a reference to this anywhere online, and it's a big problem not being able to use tensorflow and numpy in the same script.
",1,,19,2017-07-24T19:38:44Z,NONE
11713,decode_csv is extremely slow,stat:contributions welcome,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
I tested on both MacOS 10, Centos 7, https://pastebin.com/LsADQ89s

- **TensorFlow installed from (source or binary)**:
Tensorflow 1.2.1, also tried with tensorflow compiled from sources

- **TensorFlow version (use command below)**:
('v1.2.0-5-g435cdfc', '1.2.1'), also compiled and tested from master

- **Python version**: 
2.7.13

- **CUDA/cuDNN version**:
no

- **GPU model and memory**:
no

- **Exact command to reproduce**:
see above

### The problem
I noticed that a huge amount of training time CPU is idle. I isolated the problem to the code snippet bellow, where I create a string tensor using tf.constant with N rows each of them contains comma separated list of randomly generated numberical values, then I decode these string tensor to rank2 tensor of floats using 3 different approaches. 


I discovered following:
decoding tfrecords with *tf.parse_example* is quite fast
decoding csv with *decode_csv* is ~20 (4 cores) 60 (16 cores) times slower than parse_example and it utilises only 1 core on my machine
decoding csv with *tf.string_split* + *tf.string_to_number()* is ~20-60 times slower than parse_example. 
It seems *tf.string_to_number()* makes it slow, if I comment out the line with *tf.string_to_number* it is 2-3 times slower than parse example




The code I used for that:
https://pastebin.com/ZR152y5M



### Source code / logs
Running parse_example
Total time: 2.01925897598

Running string_split
Total time: 5.52524709702

Running decode_csv
Total time: 22.6595089436

",0,,8,2017-07-24T09:59:46Z,NONE
11695,Makefile build fails on OSX: -lprotobuf not found,stat:awaiting tensorflower,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No. Using the provided Makefile build system. 

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac OS X 10.12.6

- **TensorFlow installed from (source or binary)**:
Source - r 1.3

- **TensorFlow version (use command below)**:
r1.3

- **Bazel version (if compiling from source)**:
Build label: 0.5.2-homebrew

- **Exact command to reproduce**:
`sh /tensorflow/contrib/makefile/build_all_linux.sh 
`
### Describe the problem
I think there is a bug in the make files when building for OSX. Actually, the build finishes ok but the scripts give a linked error when compiling the provided benchmark program. 
The error given is:

```
ld: library not found for -lprotobuf
clang: error: linker command failed with exit code 1 (use -v to see invocation)

```

### Source code / logs
This is the line where error occurs:
```
gcc --std=c++11 -DIS_SLIM_BUILD -fno-exceptions -DNDEBUG -O3 -march=native -I. -Itf_build/tensorflow/tensorflow/contrib/makefile/downloads/ -Itf_build/tensorflow/tensorflow/contrib/makefile/downloads/eigen -Itf_build/tensorflow/tensorflow/contrib/makefile/downloads/gemmlowp -Itf_build/tensorflow/tensorflow/contrib/makefile/gen/proto/ -Itf_build/tensorflow/tensorflow/contrib/makefile/gen/proto_text/ -Itf_build/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/include -I/usr/local/include \
	-o tf_build/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark tf_build/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/util/reporter.o tf_build/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/tools/benchmark/benchmark_model.o tf_build/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/tools/benchmark/benchmark_model_main.o \
	 tf_build/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a -L/usr/local/lib -all_load -lstdc++ -lprotobuf -lz -lm
```

As you can see towards the end it links against -lprotobuf, however, it does not give the path to the library (It's missing `-L/some-path/tensorflow/contrib/makefile/gen/protobuf-host/lib`). When I manually compile the program, instead of using the makefile, and pass the library path, it works fine. 

It is easy to fix by modifying the lines 186 onwards in the Makefile from:

```
ifeq ($(TARGET),OSX)
	LDFLAGS += -all_load
endif
```
to
```
ifeq ($(TARGET),OSX)
	LDFLAGS += -all_load
ifeq ($(HAS_GEN_HOST_PROTOC),true)
	LIBFLAGS += -L$(MAKEFILE_DIR)/gen/protobuf-host/lib
	export LD_LIBRARY_PATH=$(MAKEFILE_DIR)/gen/protobuf-host/lib
endif
```
Another related issue is that I get a whole bunch of warnings from ranlib about some of the built libraries having no symbol. Any comments on that will also be appreciated:

```
/Library/Developer/CommandLineTools/usr/bin/ranlib: file: /fullpath/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(mkl_layout_pass.o) has no symbols
/Library/Developer/CommandLineTools/usr/bin/ranlib: file: /fullpath/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(mkl_tfconversion_pass.o) has no symbols
/Library/Developer/CommandLineTools/usr/bin/ranlib: file: /fullpath/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(cupti_wrapper.o) has no symbols
/Library/Developer/CommandLineTools/usr/bin/ranlib: file: /fullpath/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(android_armv7a_cpu_utils_helper.o) has no symbols

```

Thanks.",0,,9,2017-07-23T18:58:54Z,NONE
11689,Distributed Tensorflow Authorization,"stat:contributions welcome,type:feature","Could somebody comment on the security design of distributed tensorflow? 
Is there some kind of authorization in place for the grpc calls in distributed tensorflow?
E.g., are the clients validated based on the IP or anything else?

If not, how difficult would it be to add authorization support and what would be the best place in the code to get started?
",0,,4,2017-07-23T12:18:14Z,NONE
11688,Tensorflow v1.2.1 compile error,"stat:community support,type:build/install","I'm, trying to build tensorflow from source. I've followed the tutorial in https://www.tensorflow.org/install/install_sources without success.

The only difference is that I'm trying to use OpenCL with SYCL.

### System information
- **OS Platform and Distribution**: Ubuntu 14.04 64 bits
- **TensorFlow version to be compiled**: v1.2.1
- **Python version**: 2.7.6
- **Bazel version (from repository)**: Build label: 0.5.2
- **GPU model and memory**: Radeon HD 7850

### Problem
I'm trying to compile tensorflow v1.2.1 but I'm having an error about numpy missing dependecies declaration.
It seems there is some workaround because headers are there, but I have no clue about how to do it. My bazel knowledge is low.

**Configuration:**

```
flener@flener-desktop:~/Downloads/tensorflow-src$ uname -a
Linux flener-desktop 3.11.0-14-generic #21-Ubuntu SMP Tue Nov 12 17:04:55 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
flener@flener-desktop:~/Downloads/tensorflow-src$ git checkout v1.2.1
HEAD is now at b4957ff... Merge pull request #11156 from av8ramit/1.2.1
flener@flener-desktop:~/Downloads/tensorflow-src$ git clean -fdx
Removing .bazelrc
Removing .tf_configure.bazelrc
Removing bazel-bin
Removing bazel-genfiles
Removing bazel-out
Removing bazel-tensorflow-src
Removing bazel-testlogs
Removing tensorflow/tools/git/gen/
Removing third_party/eigen3/mkl_include
Removing third_party/mkl/include
Removing third_party/mkl/libdl.so.2
Removing third_party/mkl/libiomp5.so
Removing third_party/mkl/libmklml_intel.so
Removing third_party/mkl/mkl.config
Removing third_party/mkl/mklml_lnx_2018.0.20170425.tgz
Removing third_party/mkl/mklml_lnx_2018.0.20170425/
Removing tools/python_bin_path.sh
flener@flener-desktop:~/Downloads/tensorflow-src$ ./configure
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]
	
Do you wish to build TensorFlow with MKL support? [y/N] y
MKL support will be enabled for TensorFlow
Do you wish to download MKL LIB from the web? [Y/n] y
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] y
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] n
No XLA JIT support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N] y
VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N] y
OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] n
No CUDA support will be enabled for TensorFlow
Please specify which C++ compiler should be used as the host C++ compiler. [Default is ]: /usr/bin/g++-4.9
Please specify which C compiler should be used as the host C compiler. [Default is ]: /usr/bin/gcc-4.9
Please specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]: 
INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.
Configuration finished

```

**Build command:**
`flener@flener-desktop:~/Downloads/tensorflow-src$ bazel build --local_resources 4096,4.0,1.0 --verbose_failures -c opt --config=sycl //tensorflow/tools/pip_package:build_pip_package`

**Error:**
```
ERROR: /home/flener/Downloads/tensorflow-src/tensorflow/python/BUILD:158:1: undeclared inclusion(s) in rule '//tensorflow/python:numpy_lib':
this rule is missing dependency declarations for the following files included by 'tensorflow/python/lib/core/numpy.cc':
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_common.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/numpyconfig.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/_numpyconfig.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_endian.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_cpu.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/utils.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/_neighborhood_iterator_imp.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/__multiarray_api.h'
  '/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_interrupt.h'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

",0,,4,2017-07-23T11:52:10Z,NONE
11674,"ServingInputReceiver passes Estimator model_fn only dictionary of features, but model_fn is allowed to take single tensor feature",type:feature,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, I have written custom code. I have more discussion about the bug in this Jupyter notebook: https://gist.github.com/nkashy1/fc1ec4ee218963216dea3ab5242bf611

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Goobuntu

- **TensorFlow installed from (source or binary)**:
PyPI

- **TensorFlow version (use command below)**:
1.2.1

- **Python version**: 
2.7.6

- **Bazel version (if compiling from source)**:
Not relevant

- **CUDA/cuDNN version**:
Not relevant

- **GPU model and memory**:
Not relevant

- **Exact command to reproduce**:
Check this notebook: https://gist.github.com/nkashy1/fc1ec4ee218963216dea3ab5242bf611

### Describe the problem
The [tf.estimator.Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator) interface allows users to provide a `model_fn` which accepts features either within a single tensor or within a dictionary mapping strings to tensors.

The Estimator `export_savedmodel` method requires a `serving_input_receiver_fn` argument, which is a function of no arguments that produces a [ServingInputReceiver](https://www.tensorflow.org/api_docs/python/tf/estimator/export/ServingInputReceiver). The features tensors from this `ServingInputReceiver` are passed to the `model_fn` for serving.

Upon instantiation, the `ServingInputReceiver` wraps single tensor features into a dictionary. This raises an error for estimators whose `model_fn` expects a single tensor as its `features` argument.

### Source code / logs
Gist: https://gist.github.com/nkashy1/fc1ec4ee218963216dea3ab5242bf611

You can run that notebook to see log messages, etc.

#### Misc
Possibly related to this stackoverflow thread: https://stackoverflow.com/questions/42835809/how-to-export-estimator-model-with-export-savedmodel-function",1,,11,2017-07-21T20:40:04Z,CONTRIBUTOR
11670,Feature Request: Quantized DepthwiseConv2dNative ,"stat:awaiting tensorflower,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: (master as of post) d3edb8c60ed4fd831d62833ed22f5c23486c561c
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
Models, such as MobileNet use _DepthwiseConv2dNative_. I couldn't find a quantized kernel and the quantization pass in _GraphTransform_ doesn't currently support DepthwiseConv2dNative: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/quantize_nodes.cc#L57

Are there plans to provide a quantized version of DepthwiseConv2dNative?

",0,,4,2017-07-21T17:52:36Z,NONE
11651,Feature Request: tf.extract_image_patches gradients operation for variable size inputs,"stat:awaiting response,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Scientific Linux 7.3
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.1.0-rc0-61-g1ec6ed5 1.1.0 GPU
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 8.0.44
- **GPU model and memory**: n/a

### Describe the problem
I'm using the `tf.extract_image_patches` operation to extract a number of overlapping frames from an image with variable size. The current gradient operation fails unless the input image dimensions are fixed.
Specifically, in my case my code fails here 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_grad.py#L690
where `rows_in`, `rows_out` and `cols_out` are all `None`.

For more background: my application is in speech processing and my ""image"" is a spectrogram-like array of features which has a fixed height but can vary in length with the duration of the input audio. I'm trying to split it into overlapping windows dynamically to pass to a classifier downstream.
In my case the input  has shape `(1 x None x 128 x  1)`, where the unknown dimension is typically ~15,000, my image patches are `400x128` and the result has shape `(1 x None x None x 51200)`.

I feel it should be possible to modify the gradient op to accommodate dynamic input dimensions, would this be a reasonable feature addition?
The current gradient implementation was added here: https://github.com/tensorflow/tensorflow/issues/2921
Perhaps this feature request would tie in with https://github.com/tensorflow/tensorflow/issues/6847 ?

### Source code/Logs
I think the information provided explains my problem well enough, let me know if I should provide a more detailed problem description.
An expanded code snippet can also be found here: https://github.com/PaddyT/waveform-asr/blob/master/waveasr/models/wavenet.py#L455#L495
``
extracted = tf.extract_image_patches(images=input_image,
                                                           ksizes=[1, 400, 128, 1],
                                                           strides=[1, 160, 1, 1],
                                                           rates=[1, 1, 1, 1],
                                                           padding='VALID')``


```
 File ""~/diss/waveform-asr/tests/test_graphs/test_wavenet.py"", line 35, in <module>
    alpha=0.5)
  File ""~/diss/waveform-asr/waveasr/models/wavenet.py"", line 321, in __init__
    self.train_op = self.optimizer.minimize(loss=self.objective, global_step=self.global_step)
  File ""~/miniconda2/envs/diss/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 315, in minimize
    grad_loss=grad_loss)
  File ""~/miniconda2/envs/diss/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 386, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""~/miniconda2/envs/diss/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""~/miniconda2/envs/diss/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 368, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""~/miniconda2/envs/diss/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""~/miniconda2/envs/diss/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py"", line 610, in _ExtractImagePatchesGrad
    rows_out = int(ceil((rows_in - ksize_r_eff + 1) / stride_r))
TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'```",0,,9,2017-07-20T18:40:32Z,NONE
11638,Probably wrong implementation for tf.layers.max_pooling1d when data_format='channels_first',"stat:contributions welcome,type:bug/performance","In function ``call`` of class ``_Pooling1D``,  when the input ``data_format='channels_first'``, it should transform input tensor from '**N,C,H**' to '**N,C,H,W**' (batch_size, channels, height, width), meaning that we should expand dimension on the last dimension. 

However, in the code we use ``inputs = array_ops.expand_dims(inputs, 1)``, expanding on the second dimension and transforming from '**N,C,H**' to '**N,1,C,H**'. Then the ``pool_shape`` and ``strides`` are looking at the third dimension, which is not consistant with our ``expand_dims(inputs, 1)`` used before.

I think the code should be changed to ``inputs = array_ops.expand_dims(inputs, -1)`` and ``return array_ops.squeeze(outputs, -1)``. Using **-1** will expand and squeeze on the last dimension, transforming from '**N,C,H**' to **'**N,C,H,1**', and then doing ``pool_shape`` and ``strides`` on the third dimension.

### Source Code
------------------------
````
  def call(self, inputs):
    # There is no TF op for 1D pooling, hence we make the inputs 4D.
    if self.data_format == 'channels_last':
      inputs = array_ops.expand_dims(inputs, 2)
      pool_shape = (1,) + self.pool_size + (1, 1)
      strides = (1,) + self.strides + (1, 1)
      data_format = 'NHWC'
    else:
      inputs = array_ops.expand_dims(inputs, 1)
      pool_shape = (1, 1) + self.pool_size + (1,)
      strides = (1, 1) + self.strides + (1,)
      data_format = 'NCHW'
````

",1,,8,2017-07-20T09:33:38Z,NONE
11626,SparseSoftmaxCrossEntropyWithLogits error while calculating gradient in c++ mode,"stat:awaiting response,type:bug/performance","I'm trying to use the C++ API to train a CNN model. My last layer is using SparseSoftmaxCrossEntropyWithLogits. Here is the python code which generates the prototxt of the model:

```
import tensorflow as tf 
from tensorflow.python.framework import ops 
from tensorflow.python.framework import dtypes

import random  import numpy as np

NUM_CLASSES = 102  IMAGE_HEIGHT = 224  IMAGE_WIDTH = 224  BATCH_SIZE = 25  NUM_CHANNELS = 3  LEARNING_RATE = 0.0001

with tf.Session() as sess:



images_placeholder = tf.placeholder (tf.float32,
                                                shape=(BATCH_SIZE, IMAGE_HEIGHT,
                                                IMAGE_WIDTH, NUM_CHANNELS), name=""input"")   
labels_placeholder = tf.placeholder (tf.float32,
                                                shape=(BATCH_SIZE), name=""label"")

    with tf.name_scope(""conv1_1"") as scope:         
                 kernel = tf.Variable (tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32, stddev=1e-2),
                                                  name=""weights"")         
                 conv = tf.nn.conv2d (images_placeholder, kernel, [1, 1, 1, 1], padding='SAME')      
                 biases = tf.Variable (tf.constant(0.0, shape=[64], dtype=tf.float32),
                                                  trainable=True, name='biases')      
                 out = tf.nn.bias_add (conv, biases)         
                 conv1_1 = tf.nn.relu (out, name=scope)

    pool1 = tf.nn.max_pool (conv1_1,
                            ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1],
                            padding='SAME',
                            name='pool1')

    with tf.name_scope('conv2_1') as scope:         
                 kernel = tf.Variable (tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32, stddev=1e-2),
                                                  name='weights')       
                 conv = tf.nn.conv2d (pool1, kernel, [1, 1, 1, 1], padding='SAME')       
                 biases = tf.Variable (tf.constant(0.0, shape=[128], dtype=tf.float32),
                                                  trainable=True, name='biases')      
                 out = tf.nn.bias_add (conv, biases)         
                 conv2_1 = tf.nn.relu (out, name=scope)

    pool2 = tf.nn.max_pool (conv2_1,
                            ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1],
                            padding='SAME',
                            name='pool2')

    with tf.name_scope('conv3_1') as scope:         
                 kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32, stddev=1e-2),
                                                name='weights')       
                 conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')        
                 biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),
                                                 trainable=True, name='biases')      
                 out = tf.nn.bias_add(conv, biases)      
                 conv3_1 = tf.nn.relu(out, name=scope)

    pool3 = tf.nn.max_pool (conv3_1,
                            ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1],
                            padding='SAME',
                            name='pool3')

    with tf.name_scope('conv4_1') as scope:         
                 kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32, stddev=1e-2),
                                                name='weights')       
                conv = tf.nn.conv2d(pool3, kernel, [1, 1, 1, 1], padding='SAME')        
                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),
                                                trainable=True, name='biases')      
                out = tf.nn.bias_add(conv, biases)      
                conv4_1 = tf.nn.relu(out, name=scope)

    pool4 = tf.nn.max_pool (conv4_1,
                            ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1],
                            padding='SAME',
                            name='pool4')   

    with tf.name_scope('mentee_conv5_1') as scope:      
                 kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32, stddev=1e-2),
                                                name='weights')       
                 conv = tf.nn.conv2d(pool4, kernel, [1, 1, 1, 1], padding='SAME')        
                 biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32), trainable=True,
                                                name='biases')         
                 out = tf.nn.bias_add(conv, biases)      
                 conv5_1 = tf.nn.relu(out, name=scope)

    pool5 = tf.nn.max_pool (conv5_1,
                            ksize=[1, 2, 2, 1],
                            strides=[1, 2, 2, 1],
                            padding='SAME',
                            name='pool5')

    with tf.name_scope('fc1') as scope:         
                 shape = int(np.prod(pool5.get_shape()[1:]))         
                 fc1w = tf.Variable(tf.truncated_normal([shape, 4096], dtype=tf.float32, 
                                             stddev=1e-2), name='weights')       
                 fc1b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),
                                             trainable=True, name='biases')      
                 pool5_flat = tf.reshape(pool5, [-1, shape])         
                 fc1l = tf.nn.bias_add(tf.matmul(pool5_flat, fc1w), fc1b)        
                 fc1 = tf.nn.relu(fc1l)
                 fc1 = tf.nn.dropout(fc1, 0.5)


    labels = tf.to_int64(labels_placeholder)    
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits (labels=labels,
                        logits=fc1, name=""xentropy"")    
    loss = tf.reduce_mean (cross_entropy, name='loss')

    optimizer = tf.train.AdamOptimizer (LEARNING_RATE)  
    global_step = tf.Variable (0, name='global_step', trainable=False)  
    train_op = optimizer.minimize (loss, global_step=global_step, name=""train"")

    init = tf.initialize_variables (tf.all_variables(), name='init_all_vars_op')    
    tf.train.write_graph (sess.graph_def, ""models/"", ""graph.pb"", as_text=False)
```

Unfortunately when I call the c++ code to run the train_op node, it'll throw below error:

`E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: NodeDef mentions attr 'message' not in Op<name=PreventGradient; signature=input:T -> output:T; attr=T:type>; NodeDef: gradients/xentropy/xentropy_grad/PreventGradient = PreventGradient[T=DT_FLOAT, message=""Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\'s interaction with tf.gradients()"", _device=""/job:localhost/replica:0/task:0/cpu:0""](xentropy/xentropy:1)
`
I'm still confused whether the error comes from a bug inside the TF code or not.",0,,9,2017-07-20T00:07:02Z,NONE
11610,Changing batch size changes output for float32 matmuls elementwise by ~1e-8 (at least on CPU),,"While developing a Hierarchical Attention Network, we have discovered that changing the batch size of the input effects the output of dynamic RNNs (while keeping everything else constant). In other words, feeding in [[1,2,3,4,5]] and [[6,7,8,9,10]] individually with batch size 1 will give a different result than feeding in [[1,2,3,4,5],[6,7,8,9,10]] together with batch size 2. We are currently running Bidirectional Dynamic RNNs with GRUs on the CPU-version of Tensorflow 1.2.

While the change in output is small, when a network has many layers of RNNs, the differences become amplified. In our case, changing the batch size from 1 to 10 changes the network accuracy on our test set from 50% to 46%.

System information and shortened sample code below.

### System information
== cat /etc/issue ===============================================
Linux pc93071.ornl.gov 3.10.0-514.26.1.el7.x86_64 #1 SMP Tue Jun 20 01:16:02 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7.3 (Maipo)""
VERSION_ID=""7.3""
REDHAT_BUGZILLA_PRODUCT_VERSION=7.3
REDHAT_SUPPORT_PRODUCT_VERSION=""7.3""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux pc93071.ornl.gov 3.10.0-514.26.1.el7.x86_64 #1 SMP Tue Jun 20 01:16:02 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.1)
numpydoc (0.6.0)
protobuf (3.3.0)
tensorflow (1.2.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

### Source code / logs

```
import numpy as np
import tensorflow as tf
from tensorflow.contrib.rnn import LSTMCell, GRUCell

embeddings = np.random.rand(8000,350).astype(np.float32)
embeddings -= embeddings.mean()
embeddings /= (embeddings.std()*2.5)

#doc input and line count
line = tf.placeholder(tf.int32, shape=[None,10])
num_words = tf.reduce_sum(tf.cast(tf.greater(line,0),tf.int32),1)
word_embeds = tf.nn.embedding_lookup(tf.get_variable('embeddings',
              initializer=embeddings,dtype=tf.float32),line)

[word_outputs_fw,word_outputs_bw],_ = \
        tf.nn.bidirectional_dynamic_rnn(GRUCell(5),GRUCell(5),
        word_embeds,sequence_length=num_words,
        dtype=tf.float32)

word_outputs = tf.concat((word_outputs_fw, word_outputs_bw),2)

init_op = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init_op)

a = np.array([[1,2,3,4,5,0,0,0,0,0]])
b = np.array([[6,7,8,9,10,11,12,13,14,15]])
ab = np.array([[1,2,3,4,5,0,0,0,0,0],[6,7,8,9,10,11,12,13,14,15]])

feed_dict = {line:a}
print sess.run(word_outputs,feed_dict=feed_dict)
feed_dict = {line:b}
print sess.run(word_outputs,feed_dict=feed_dict)
feed_dict = {line:ab}
print sess.run(word_outputs,feed_dict=feed_dict)
```

### Sample Output

Below, the first two matrices are the results of feeding in two inputs one at a time with batch size 1, while the second two matrices are the results of feeding in two inputs together with batch size 2. You can see that the outputs are not exactly the same. While the differences between the two are small, this becomes a major issue when there are multiple layers of RNNs as the differences become more pronounced after each layer.

```
[[[ 0.07946277 -0.09917585  0.01027258 -0.03145921 -0.06281948  0.27924815
   -0.32083094 -0.18930595  0.17904316 -0.09718883]
  [ 0.09456758 -0.06845391 -0.02745478 -0.10440759 -0.07491632  0.27888948
   -0.27896836  0.03206063  0.09979809 -0.00771215]
  [ 0.01643243  0.12345143  0.12964873  0.01598591 -0.18927756  0.37746075
   -0.03456679 -0.01384296  0.03874877  0.06282371]
  [ 0.04219431  0.02407469 -0.1588002   0.1497623  -0.17770161  0.3960323
    0.16187154 -0.04393335 -0.02065297  0.10994863]
  [-0.13827246 -0.07322901 -0.012384    0.12282669  0.07407188 -0.14240782
    0.140168    0.02362901  0.06010906  0.05862212]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]]]
[[[ 0.16048311 -0.02057735  0.18933752 -0.12690066 -0.04377137  0.32376432
    0.13263705 -0.07457904  0.14895026 -0.18088266]
  [ 0.16808736 -0.11579071 -0.11836589 -0.31363881  0.1567639  -0.08804542
    0.1359456  -0.03568897  0.12253968 -0.08998561]
  [ 0.19741508 -0.01034784 -0.03235145 -0.27677989  0.1338885  -0.14571345
    0.08804264 -0.02352159  0.04717591 -0.37237346]
  [ 0.24377933 -0.27160296 -0.11816068 -0.45893419 -0.09967859 -0.04910848
    0.03985181 -0.01856269  0.04410465 -0.21198548]
  [ 0.16746353 -0.20125373 -0.2098352  -0.36264825  0.02557869 -0.06599348
   -0.11331714 -0.17118242 -0.08420456 -0.22979215]
  [-0.09969822 -0.14207448  0.12536064 -0.22236535  0.11328859 -0.09342889
   -0.02536193 -0.28028104 -0.11790876 -0.10144062]
  [-0.09796695 -0.14415297 -0.19729097 -0.25542045 -0.15568495 -0.12689842
   -0.14712927 -0.35488427 -0.06447952 -0.19063833]
  [-0.12240371 -0.07732555 -0.2645728   0.11042064 -0.19387801  0.07324903
   -0.03920996  0.05104404 -0.09357925 -0.13582835]
  [-0.07295815 -0.02809375 -0.24317381  0.04480781 -0.06040902  0.03428879
    0.10196722 -0.06142509 -0.36903486 -0.16991363]
  [-0.01382132 -0.09746805  0.13226555  0.19477166  0.02158988  0.09287433
    0.01845972 -0.16030487 -0.2186746  -0.07543172]]]
[[[ 0.07946277 -0.09917583  0.01027257 -0.03145922 -0.06281949  0.27924818
   -0.32083094 -0.1893059   0.17904317 -0.09718874]
  [ 0.09456757 -0.06845395 -0.02745485 -0.10440758 -0.07491633  0.27888948
   -0.27896842  0.03206065  0.09979802 -0.00771213]
  [ 0.01643244  0.12345135  0.1296487   0.01598606 -0.18927751  0.37746072
   -0.0345668  -0.01384297  0.03874873  0.06282371]
  [ 0.0421943   0.02407462 -0.15880026  0.14976241 -0.17770153  0.39603227
    0.16187152 -0.04393341 -0.02065307  0.10994864]
  [-0.13827249 -0.07322903 -0.01238406  0.12282679  0.07407197 -0.14240779
    0.14016804  0.02362898  0.06010904  0.05862212]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.          0.          0.        ]]

 [[ 0.16048311 -0.02057736  0.18933751 -0.12690073 -0.04377136  0.32376438
    0.13263711 -0.07457898  0.14895013 -0.18088272]
  [ 0.16808733 -0.11579067 -0.11836579 -0.31363881  0.15676391 -0.0880454
    0.13594568 -0.03568894  0.12253958 -0.08998567]
  [ 0.19741504 -0.01034782 -0.0323514  -0.27677989  0.13388851 -0.14571348
    0.08804271 -0.02352155  0.0471758  -0.37237346]
  [ 0.2437793  -0.27160296 -0.11816064 -0.45893413 -0.09967858 -0.04910852
    0.03985184 -0.01856264  0.04410452 -0.21198554]
  [ 0.16746351 -0.20125373 -0.20983508 -0.36264819  0.02557869 -0.06599346
   -0.11331721 -0.17118247 -0.08420463 -0.22979221]
  [-0.09969822 -0.14207451  0.12536073 -0.22236532  0.11328855 -0.09342889
   -0.02536207 -0.28028107 -0.11790879 -0.10144066]
  [-0.09796697 -0.14415301 -0.19729097 -0.25542039 -0.15568499 -0.12689844
   -0.14712939 -0.35488427 -0.06447949 -0.19063836]
  [-0.12240377 -0.07732558 -0.2645728   0.11042073 -0.19387813  0.07324899
   -0.03921008  0.05104404 -0.0935792  -0.13582836]
  [-0.07295817 -0.02809371 -0.24317381  0.04480787 -0.06040911  0.03428881
    0.10196713 -0.06142508 -0.3690348  -0.16991359]
  [-0.0138213  -0.09746802  0.13226555  0.19477174  0.02158987  0.09287442
    0.0184597  -0.16030489 -0.21867451 -0.07543168]]]

```",3,,14,2017-07-19T14:41:54Z,NONE
11604,Unable to compile a quantized graph using XLA AOT?,type:feature,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Master
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: GTX 860M
- **Exact command to reproduce**: 

`bazel build -c opt --cxxopt='-std=c++11' --linkopt='-lm'    --cpu=armeabi-v7a    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --crosstool_top=//external:android/crosstool    //tensorflow/compiler/aot:inception_v3 --verbose_failures`

### Describe the problem
I am currently trying to use `tfcompile` to compile a quantized inception_v3 model for android, following the instructions given in the documentation [here](https://www.tensorflow.org/performance/xla/tfcompile), but I have gotten this error below:

```
INFO: Found 1 target...
ERROR: /home/kwotsin/Android/tensorflow/tensorflow/compiler/aot/BUILD:11:1: Executing genrule //tensorflow/compiler/aot:gen_inception_v3 failed: bash failed: error executing command 
  (cd /home/kwotsin/.cache/bazel/_bazel_kwotsin/655cf5567faa2deb9e3725ec794eb35d/execroot/tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/lib64 \
    PATH=/usr/local/cuda/bin:/usr/local/cuda/bin:/home/kwotsin/bin:/home/kwotsin/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/kwotsin/Android/Sdk/tools:/home/kwotsin/Android/Sdk/platform-tools \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/compiler/aot/tfcompile --graph=tensorflow/compiler/aot/inception_v3.pb --config=tensorflow/compiler/aot/inception_v3.config.pbtxt --entry_point=__tensorflow_compiler_aot__inception_v3 --cpp_class=inception_v3_cpp --target_triple=armv7-none-android --out_header=bazel-out/arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/genfiles/tensorflow/compiler/aot/inception_v3.h --out_object=bazel-out/arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/genfiles/tensorflow/compiler/aot/inception_v3.o '): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 6.
2017-07-19 19:53:26.407268: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-19 19:53:26.407310: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-19 19:53:26.407326: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-19 19:53:26.407330: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-19 19:53:26.407333: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-19 19:53:26.424064: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-07-19 19:53:26.426662: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Not found: No registered 'Const' OpKernel for XLA_CPU_JIT devices compatible with node InceptionV3/Conv2d_1a_3x3/weights/read/_224__cf__224_quantized_const = Const[dtype=DT_QUINT8, value=Tensor<type: quint8 shape: [3,3,3,32] values: [[[97 115 118]]]...>]()
	 (OpKernel was found, but attributes didn't match)
	.  Registered:  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_BOOL]
  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_BOOL]
  device='CPU'

	 [[Node: InceptionV3/Conv2d_1a_3x3/weights/read/_224__cf__224_quantized_const = Const[dtype=DT_QUINT8, value=Tensor<type: quint8 shape: [3,3,3,32] values: [[[97 115 118]]]...>]()]]
2017-07-19 19:53:26.429093: F tensorflow/compiler/aot/tfcompile_main.cc:154] Non-OK-status: status status: Not found: No registered 'Const' OpKernel for XLA_CPU_JIT devices compatible with node InceptionV3/Conv2d_1a_3x3/weights/read/_224__cf__224_quantized_const = Const[dtype=DT_QUINT8, value=Tensor<type: quint8 shape: [3,3,3,32] values: [[[97 115 118]]]...>]()
	 (OpKernel was found, but attributes didn't match)
	.  Registered:  device='XLA_CPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_BOOL]
  device='XLA_GPU_JIT'; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_BOOL]
  device='CPU'

	 [[Node: InceptionV3/Conv2d_1a_3x3/weights/read/_224__cf__224_quantized_const = Const[dtype=DT_QUINT8, value=Tensor<type: quint8 shape: [3,3,3,32] values: [[[97 115 118]]]...>]()]]
/bin/bash: line 1:  6904 Aborted                 (core dumped) bazel-out/host/bin/tensorflow/compiler/aot/tfcompile --graph=tensorflow/compiler/aot/inception_v3.pb --config=tensorflow/compiler/aot/inception_v3.config.pbtxt --entry_point=__tensorflow_compiler_aot__inception_v3 --cpp_class=inception_v3_cpp --target_triple=armv7-none-android --out_header=bazel-out/arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/genfiles/tensorflow/compiler/aot/inception_v3.h --out_object=bazel-out/arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/genfiles/tensorflow/compiler/aot/inception_v3.o
Target //tensorflow/compiler/aot:inception_v3 failed to build
INFO: Elapsed time: 0.339s, Critical Path: 0.18s
```

Despite the ""SSE4.1 etc."" instructions that popped up, I made sure that I configured the tensorflow installation with XLA enabled, so it shouldn't have popped up. 

Also, my quantized graph was created using the Graph Transform Tool with the following command, producing a graph that worked exactly as expected:

```
/home/kwotsin/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=./frozen_model.pb \
--out_graph=./quantized_model.pb \
--inputs='Placeholder_only' \
--outputs='InceptionV3/Predictions/Softmax' \
--transforms='
  add_default_attributes
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  strip_unused_nodes
  sort_by_execution_order'
```

Is XLA AOT compilation of quantized models currently supported? Because when I tried to build with a frozen, non-quantized graph, I got the correct output - a cpp object file and a header file. I thought it would be nice if XLA AOT could be used concurrently with a quantized model to obtain the maximum level of mobile optimization.",1,,8,2017-07-19T12:06:02Z,CONTRIBUTOR
11603,//tensorflow/python:nn_test is failing on ppc64le with AssertionError: False is not true ,stat:community support,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source (v1.2.1)
- **TensorFlow version (use command below)**:
      ('v1.2.1-0-gb4957ff', '1.2.1')
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
       0.4.5-2017-07-13 (@037b9b9)
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
      bazel test //tensorflow/python:nn_test

### Describe the problem
Here  testNaNs is failing , see relevant code-
https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/python/ops/nn_test.py#L835-L841

```
def testNaNs(self):
    # Test that relu(nan) = nan for various sizes.
    for i in range(18):
      x = np.zeros(i) + np.nan
      with self.test_session():
        z = nn_ops.relu(constant_op.constant(x)).eval()
        print(""\n current i value is "", i)
        print(""\n z value is "", z)
        self.assertTrue(np.isnan(z).all())
```
This test is failing ,because nn_ops.relu function returning incorrect results on ppc64le (0 vs expected nan).......(for i = 2 to 18 )

for` i = 0`  :   z value =   []    ............... (ok)
for `i = 1`  :   z value =  [ nan]  ........... (ok)
for `i = 2`  :   z value =  [ 0.  0.]  ...........(not ok on ppc64le, bcz `0. != nan`)

It looks like this is a bug in the nn_ops.relu function for ppc64le, currently I am trying to understand the reason. Please provide comments/suggestions if any. Thanks!
### Source code / logs

```
$ bazel test --test_output=errors //tensorflow/python:nn_test

......................../root/.cache/bazel/_bazel_root/725e77151072daec43bc353cb6fcb26c/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/nn_test.runfiles/org_tensorflow/tensorflow/python/ops/nn_test.py:108: RuntimeWarning: divide by zero encountered in log
  stirling_approx = z * np.log(z) - z + 0.5 * np.log(2. * np.pi * z)
/root/.cache/bazel/_bazel_root/725e77151072daec43bc353cb6fcb26c/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/nn_test.runfiles/org_tensorflow/tensorflow/python/ops/nn_test.py:108: RuntimeWarning: invalid value encountered in multiply
  stirling_approx = z * np.log(z) - z + 0.5 * np.log(2. * np.pi * z)
................F.......
======================================================================
FAIL: testNaNs (__main__.ReluTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/725e77151072daec43bc353cb6fcb26c/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/nn_test.runfiles/org_tensorflow/tensorflow/python/ops/nn_test.py"", line 841, in testNaNs
    self.assertTrue(np.isnan(z).all())
AssertionError: False is not true

----------------------------------------------------------------------
Ran 48 tests in 7.253s

FAILED (failures=1)
0.0208333333333
0.00566666666667
0.0075
0.0208333333333
0.00566666666667
0.0075
0.0208333333333
0.00566666666667
0.0075
L2Loss gradient err = 9.6958e-12
L2Normalize gradient err = 4.2424e-08
L2Normalize gradient err = 5.45829e-07
L2Normalize gradient err = 7.61142e-05
================================================================================

```",0,,17,2017-07-19T11:38:01Z,CONTRIBUTOR
11599,Would you mind not calling the protobuf repository protobuf?,stat:contributions welcome,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:

Source

- **TensorFlow version (use command below)**:

1.1.0

- **Python version**: 

2.7.12

- **Bazel version (if compiling from source)**:

0.5.2
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Currently the protobuf repo in workspace.bzl is called @protobuf. Unfortunately, in github.com/grpc/grpc, the protobuf is bind to @com_github_google_protobuf//:protobuf....So if I have anything that uses the GRPC repository it cannot be built together with Bazel.

I tried rename all @protobuf// to @com_github_google_protobuf//, but it does not work, presumably because the patch file for protobuf get in the way.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,6,2017-07-19T03:32:33Z,NONE
11588,GPU kernel for SVD,"stat:contributions welcome,type:feature","### System information
-Linux Ubuntu 16.04
- TensorFlow installed from (source )
- python v3.5 
- **GPU 8gb**:

### Describe the problem
I tried to run code that used tf.svd on GPU but it gives me an error. Is it correct that tensorflow does not have GPU kernels for SVD?

### Source code / logs
[[Node: Svd = Svd[T=DT_FLOAT, compute_uv=false, full_matrices=false](x)]]
[[Node: map_1/while/nuclear_norm_09660f0e_1 = nuclear_norm_09660f0e[_device=""/job:localhost/replica:0/task:0/gpu:0""](map_1/while/Reshape_1, ^map_1/while/Identity)]]
[[Node: Adagrad_1/update/_64 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_690_Adagrad_1/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0,,8,2017-07-18T20:20:43Z,NONE
11585,Keras API reproducibility,,"If any new option was added to ensure a reproducible results by setting some seed parameter
?
In Keras the issue was discussed [here](https://github.com/fchollet/keras/issues/2743)
According the issue the instability in results is due to weights random initialization.",1,,3,2017-07-18T17:41:48Z,NONE
11569,Why use memory_layer in all cases?,,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2

In current AttentionWrapper, both [BahdanauAttention](https://github.com/tensorflow/tensorflow/blob/c996c7b381a8eb54f9c7d7b298b24b1715645b68/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L416-L417) and [LuongAttention](https://github.com/tensorflow/tensorflow/blob/c996c7b381a8eb54f9c7d7b298b24b1715645b68/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L295-L296) enforce to use a memory_layer. According to my understanding, it is needed only when the depth of memory is not matched with that of query_layer. Is it intended to be in this manner?

@ebrevdo , would you mind having a look at this?",1,,3,2017-07-18T08:42:28Z,CONTRIBUTOR
11564,XLA bugs on training accuracy,type:bug/performance,"-----------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.2.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0 / 6.0
- **GPU model and memory**: NVIDIA TITAN Xp 12GB
- **Exact command to reproduce**:

(At the tensorflow/model/inception directory)
bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/tmp/imagenet_data
bazel-bin/inception/imagenet_eval --checkpoint_dir=/tmp/imagenet_train --eval_dir=/tmp/imagenet_eval

== cat /etc/issue ===============================================
Linux Ares 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Ares 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.1)
protobuf (3.3.0)
tensorflow (1.2.1)
tensorflow-tensorboard (0.1.2)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.1-2-gc996c7b
tf.COMPILER_VERSION = v1.2.1-2-gc996c7b
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda/extras/CUPTI/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Tue Jul 18 09:26:11 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 381.09                 Driver Version: 381.09                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN Xp            Off  | 0000:01:00.0     Off |                  N/A |
| 48%   75C    P2   287W / 250W |  11771MiB / 12189MiB |     54%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1005    G   /usr/lib/xorg/Xorg                              18MiB |
|    0     30938    C   /usr/bin/python                              11737MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7


### Describe the problem
I activated XLA and trained the Inception model.
When I verify the training results, the accuracy is always 0.001.
(It is considered that the training is not performed normally.)

When XLA is disabled, normal accuracy is achieved.

### Source code / logs
I added some codes of model/inception/inception/inception_train.py to enable XLA.
I attached the file.

[inception_train.zip](https://github.com/tensorflow/tensorflow/files/1154355/inception_train.zip)


",0,,12,2017-07-18T00:42:31Z,NONE
11548,Different behavior of tf.extract_image_patches and tf.nn.conv2d for certain padding/stride/filter size combinations,"stat:awaiting tensorflower,type:bug/performance","Hi!

I am trying to implement something using ``tf.extract_image_patches`` and ran into some troubles that made clear ``tf.extract_image_patches`` handles some combinations of padding, filter size and stride differently than ``tf.nn.conv2d``. Since ``tf.extract_image_patches`` is conceptually a ""part"" of a convolution operation, I think this might be unintended behavior. 

Specifically, I implemented a ""manual"" version of a convolution operation using ``tf.extract_image_patches``

```python
def manual_conv(input, filter, strides, padding):
  h_f, w_f, c_in, c_out = filter.get_shape().as_list()
  input_patches = tf.extract_image_patches(input, ksizes=[1, h_f, w_f, 1 ], strides=strides, rates=[1, 1, 1, 1], padding=padding)
  filters_flat = tf.reshape(filter, shape=[h_f*w_f*c_in, c_out])
  return tf.einsum(""ijkl,lm->ijkm"", input_patches, filters_flat)
```

and tested it like this

```python
import unittest
import tensorflow as tf

class TestManualConvToyData(unittest.TestCase):

  def runTest(self):
    m = 32
    c_in = 3
    c_out = 16

    image_sizes = [127, 64]
    filter_sizes = [1, 2, 3, 5, 11]
    strides = [1, 3, 4, 30]
    paddings = [""VALID"", ""SAME""]

    for fs in filter_sizes:
      for stri in strides:
        for imsize in image_sizes: 
          for pad in paddings:
            h = w = imsize
            h_f = w_f = fs
            print ""Testing for"", imsize, fs, stri, pad

            tf.reset_default_graph()
            X = tf.constant(1.0+np.random.rand(m, h, w, c_in), tf.float32)
            W = tf.truncated_normal([h_f, w_f, c_in, c_out])

            Z = tf.nn.conv2d(X, W, strides=[1, stri, stri, 1], padding=pad)
            Z_manual = manual_conv(X, W, strides=[1, stri, stri, 1], padding=pad)

            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            Z_, Z_manual_ = sess.run([Z, Z_manual])
            self.assertEqual(Z_.shape, Z_manual_.shape)
            self.assertTrue(np.allclose(Z_, Z_manual_, rtol=1e-05))
            sess.close()
 ```

This test fails for some combinations of padding, filter size and stride. I think it has to do with the fact that ``tf.extract_image_patches`` tries to center patches if possible, as discussed in [this][1] stackoverflow question.

[1]: https://stackoverflow.com/questions/40731433/understanding-tf-extract-image-patches-for-extracting-patches-from-an-image

------------------------

### System information
- Ubuntu 16.04.
- Python 2.7.12
- tensorflow version 1.2.1 installed via pip (CPU only)",1,,3,2017-07-17T10:16:32Z,NONE
11545,add nodouble option for all cwise ops,"cla: yes,stat:awaiting tensorflower","this is the following patch of ac98d1184008e4 to support nodouble
option for all cwise ops. The macros REGISTER* defined within
__ANDROID_TYPES_SLIM__ should be changed to empty, and it impacts
all the cwise ops, so, all the changes for the cwise ops have to be
in a single patch.

there will be more patches for other ops to support nodouble option.",1,,15,2017-07-17T07:33:14Z,CONTRIBUTOR
11541,tfcompile won't work with graph that has no inputs,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.1 (git version v1.2.0-2140-g85d4102)
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.5.2
- **CUDA/cuDNN version**: 5.1.5
- **GPU model and memory**: GeForce GTX 970 4GB

### Describe the problem

I have been working on a char-rnn like network that is trained on a corpus of text, and then produces similar text as output. I'm trying to compile the graph, but tfcompile asserts that the list of feeds is non-empty. However, since for my network there are no inputs to specify as feeds, tfcompile fails.

### Source code / logs

The configuration I tried to use looks like this:

```
fetch {
  id { node_name: ""predictions"" }
}
```

The error message:
```
INVALID ARGUMENTS: feeds and fetches must be specified
```
which comes from https://github.com/tensorflow/tensorflow/blob/85d4102862c781af2346b4aa568054522e8946ea/tensorflow/compiler/aot/tfcompile_util.cc#L119

I don't really know anything about how the compiler works, but is this check in place because it was assumed that you'd always want to have an input, or because of some other limitation that would cause the compilation to fail with no feeds?",1,,8,2017-07-17T04:09:43Z,NONE
11534,[FeatureRequest] make categorical_x_entropy broadcastable,type:feature,"For example:

```
>>> x = tf.placeholder('float32', [4,5,6])
>>> y = tf.placeholder('float32', [1,5,6])
>>> z = tf.nn.softmax_cross_entropy_with_logits(labels=x, logits=y)
Traceback (most recent call last):
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/home/khaotik/anaconda3/lib/python3.6/contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 1594, in softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 2380, in _softmax_cross_entropy_with_logits
    features=features, labels=labels, name=name)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2508, in create_op
    set_shapes_for_outputs(ret)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1873, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1823, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/home/khaotik/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'SoftmaxCrossEntropyWithLogits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [5,6], [20,6].
```

But, intuitively, I'd like to broadcast `y` into shape `[4,5,6]` in the above code.

It's not too hard to get a workaround such as using `tf.tile`. However it would consume more precious GPU memory.",0,,8,2017-07-16T13:43:37Z,NONE
11521,[go bindings] Printing graph in a text format,type:feature,"I was looking for a function  that allows me (like in python) to print the graph in a readable way.
 
If you open a GitHub issue, here is our policy:

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOs X
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: 
- **Exact command to reproduce**:
In python i can do:

```python
import tensorflow as tf

sess = tf.InteractiveSession()
with tf.gfile.FastGFile(""graphname.pb"", 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    _ = tf.import_graph_def(graph_def, name='')
    
# All operations
sess.graph.get_operations()
```

that prints the operations of my graph

In go i just have the option:

```
graph := tf.NewGraph()
if err := graph.Import(model, """"); err != nil {
		log.Fatal(err)
	}
f, err := os.Create(""logWritter.txt"")
	if err != nil {
		log.Fatal(err)
	}
	graph.WriteTo(f)
```
it prints the binary graph.

### Describe the problem
When using a model, previously trained by somebody else, it is very useful to know the nodes to reference them.  It should be nice to have the same option with go.",1,,7,2017-07-15T19:30:26Z,NONE
11519,import_pb_to_tensorboard.py fails with TypeError,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution**: Mac OSX Sierra 10.12.5
- **TensorFlow installed from**: Source.
- **TensorFlow version**: ('v0.10.0-1727-g484ca8a-dirty', '0.11.0rc0')
- **Python version**: 2.7.6
- **Bazel version**: 0.4.4-homebrew
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
```
python import_pb_to_tensorboard.py --model_dir ~/Code/AndroidTensorFlowMNISTExample/app/src/main/assets/mnist_model_graph.pb --log_dir /tmp/tensorboard/
```

### Describe the problem
I'm trying to use `import_pb_to_tensorboard.py` to import an existing TensorFlow model into TensorBoard.  It appears to always return a TypeError due to line 74:

```
python import_pb_to_tensorboard.py --model_dir ~/Code/AndroidTensorFlowMNISTExample/app/src/main/assets/mnist_model_graph.pb --log_dir /tmp/tensorboard/
Traceback (most recent call last):
  File ""import_pb_to_tensorboard.py"", line 74, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
TypeError: run() got an unexpected keyword argument 'argv'
```

I discovered `import_pb_to_tensorboard.py` in [this Stackoverflow answer](https://stackoverflow.com/a/44955005/112705).",0,,3,2017-07-15T18:38:36Z,CONTRIBUTOR
11514,tf.assign is much slower than tf.assign_add on CPU,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v0.8.0rc0-16474-gac98d11', '1.2.1')
- **Python version**: Python 2.7.13 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**:cuda8.0/cudnn6.0
- **GPU model and memory**:old titan x / 12GB
- **Exact command to reproduce**: a python script

### Describe the problem
`tf.assign` is much slower than `tf.assign_add` on CPU when `intra_op_parallelism_threads` set to 10. Although tensorflow treats these two operations a little different(maybe because `tf.assign` allows uninitialized tensor, accepts more tensor types), they all use a same class in eigen. I find this problem when doing some test about #11411.

### Source code / logs
script is on [gist](https://gist.github.com/suiyuan2009/24315b35915bddbe2d53b764164bb8fb),
```
dtype is <dtype: 'float32'>
use tf.assign: 3480.53776469 MB/s
use tf.assign_add: 10737.1193186 MB/s
```
set `intra_op_parallelism_threads` to 1, 
```
dtype is <dtype: 'float32'>
use tf.assign: 3481.3296105 MB/s
use tf.assign_add: 4244.41816359 MB/s
```
on GPU,
```
dtype is <dtype: 'float32'>
use tf.assign: 120361.172131 MB/s
use tf.assign_add: 77835.7152633 MB/s
```",1,,3,2017-07-15T09:57:32Z,CONTRIBUTOR
11489,import_graph_def input_map not updating all attributes,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Reproducible script below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary/pip
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

```py
import tensorflow as tf
from tensorflow.python.framework import graph_util
from tensorflow.core.framework import graph_pb2

orig_model = ""input_map_orig.pb""
mapped_model = ""input_map_modified.pb""

# Create a graph with uint8 placeholder that gets
# cast to float32 before going through image whitening
tf.reset_default_graph()
img = tf.placeholder(tf.uint8, shape=(1, None, None, 3), name=""input_tensor"")
float_img = tf.cast(img, tf.float32, ""ToFloat"")
whiten_fn = lambda img: tf.image.per_image_standardization(img)
whitened = tf.map_fn(whiten_fn, float_img, name='image_whitening')
identity = tf.identity(whitened, name=""id"")

# Write graph
output_names = [""id""]
with tf.Session() as sess:
  input_graph_def = sess.graph_def
  output_graph_def = graph_util.convert_variables_to_constants(sess,
                                                               input_graph_def,
                                                               output_names)
  tf.train.write_graph(output_graph_def, ""./"", orig_model, False)

# Load the graph again
tf.reset_default_graph()
graph_def = graph_pb2.GraphDef()
with open(orig_model, ""rb"") as f:
  graph_def.ParseFromString(f.read())

# Rewire the graph with a float32 placeholder directly
img = tf.placeholder(tf.float32, shape=(1, None, None, 3), name=""input"")
input_map = {
  ""ToFloat"": img,
  }
tf.import_graph_def(graph_def, input_map=input_map, name="""")

# Write the modified graph
graph = tf.get_default_graph()
output_names = [""id""]
with tf.Session(graph=graph) as sess:
  graph = tf.get_default_graph()
  input_graph_def = graph.as_graph_def()
  output_graph_def = graph_util.convert_variables_to_constants(sess,
                                                               input_graph_def,
                                                               output_names)
  tf.train.write_graph(output_graph_def, ""./"", mapped_model, False)

# Try to load the modified graph
tf.reset_default_graph()
graph_def = graph_pb2.GraphDef()
with open(mapped_model, ""rb"") as f:
  graph_def.ParseFromString(f.read())

g = tf.import_graph_def(graph_def)
```

### Describe the problem
I noticed this issue trying to modify (via input_map) an object detection model (from [tf/models/object_detection](https://github.com/tensorflow/models/tree/master/object_detection)) to directly accept float32 instead of uint8. I have managed to reproduce the using the above minimal example. It seems like one of the attributes of one of the operations doesn't get fully updated. Possibly related to  https://github.com/tensorflow/tensorflow/issues/9925 .

### Source code / logs
Traceback:
```
Traceback (most recent call last):
  File ""input_map_bug.py"", line 71, in <module>
    g = tf.import_graph_def(graph_def)
  File ""/home/s.antol/cv/py3virtualenvs/tf1.2/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 331, in import_graph_def
    op_to_bind_to, node.name))
ValueError: Specified colocation to an op that does not exist during import: ToFloat in image_whitening/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3
```

Looking through the protobuf text version, the node below has `s: ""loc:@ToFloat""` instead of (what I think should be) `s:""loc:@input""`:
```
node {
  name: ""image_whitening/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3""
  op: ""TensorArrayScatterV3""
  input: ""image_whitening/TensorArray""
  input: ""image_whitening/TensorArrayUnstack/range""
  input: ""input""
  input: ""image_whitening/TensorArray:1""
  attr {
    key: ""T""
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@ToFloat""
      }
    }
  }
}
```
",1,,6,2017-07-13T21:13:34Z,NONE
11463,Copyright on first line of LICENSE (Apache 2) is incorrect,"stat:awaiting tensorflower,type:support","
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
N/A
- **TensorFlow installed from (source or binary)**:
N/A
- **TensorFlow version (use command below)**:
N/A
- **Python version**: 
N/A
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
N/A

### Describe the problem
The LICENSE file in the tensorflow github repository has an incorrect copyright assignment.
The first line of the file reads:
Copyright 2017 The TensorFlow Authors.  All rights reserved.

This is incorrect.  ""The TensorFlow Authors"" are not the copyright holders for the Apache 2.0 license.
This line should be removed.  It makes a legal claim which is expressly false.

A separate issue is whether the line in the LICENSE file which provides an example of how to attribute
the copyright for new code in the TensorFlow project (which also includes a line assigning copyright
to ""The TensorFlow Authors"") is incorrect as well.

In general I can't see how the copyright assignment works in the project.  Yuan Tang was recently
added to the AUTHORS file.  Does that person now have full copyright over the entire TensorFlow
work?  The Contributor agreement only grants a copyright *license* to Google and the downstream
recipients of the code.  It does not grant copyright to the contributed code.

### Source code / logs
N/A
",0,,4,2017-07-12T21:09:32Z,NONE
11447,Feature Request: sparse matrix triangular solver,stat:awaiting tensorflower,"I have just written about this in stack overflow,
but I just realized it would be more relevant if be put here.

I think it would be very helpful if we could do solve linear equation Ax = b,
where A has a sparse matrix representation, for example,
containing lower triangular entries for a banded symmetric-matrix.

Because, AFAIK, in this case, we need to convert the sparse matrix A
with the `tf.sparse_to_dense()`, to run the `tf.matrix_triangular_solve()`.

But, if the dimension of A is very large, e.g., about 16000x16000,
and with very sparse entries, e.g., about 46000 non-zeros (0.018%),
it would take a huge amount of memory.

Or maybe there is another way to do it in Tensorflow?",0,,6,2017-07-12T09:08:57Z,NONE
11440,Linear Model Tutorial: How to extract prediction? ,stat:contributions welcome,"Similar to this issue: https://github.com/tensorflow/tensorflow/issues/97 

For the ""[TensorFlow Linear Model Tutorial](https://www.tensorflow.org/tutorials/wide)"", the project implies that it will end with a program that, based on input data, outputs a 0 or 1: 

> Given census data about a person such as age, gender, education and occupation (the features), we will try to predict whether or not the person earns more than 50,000 dollars a year (the target label). We will train a logistic regression model, **and given an individual's information our model will output a number between 0 and 1, which can be interpreted as the probability that the individual has an annual income of over 50,000 dollars.**

However, it seems that the tutorial is incomplete. The last steps have you calculate the accuracy of the trained model: 

> The first line of the output should be something like accuracy: 0.83557522, which means the accuracy is 83.6%. Feel free to try more features and transformations and see if you can do even better!

And then point you in the direction of the full example code: 

> If you'd like to see a working end-to-end example, you can download our [example code.](https://www.github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/learn/wide_n_deep_tutorial.py) and set the model_type flag to wide. 

When I run the final program, my output looks like this: 

> `accuracy: 0.989583`
> `accuracy/baseline_label_mean: 0.364583`
> `accuracy/threshold_0.500000_mean: 0.989583`
> `auc: 1.0`
> `auc_precision_recall: 1.0`
> `global_step: 3000`
> `labels/actual_label_mean: 0.364583`
> `labels/prediction_mean: 0.369466`
> `loss: 0.0242721`
> `precision/positive_threshold_0.500000_mean: 0.972222`
> `recall/positive_threshold_0.500000_mean: 1.0`

Only `accuracy` is explained in the instructions, and it doesn't seem that there are final steps to complete the tutorial: to take a set of given values, and predict `income_bracket.` Can someone provide a code example, or point to documentation on how to extract final predictions after training the model?

Thanks! ",1,,10,2017-07-12T01:22:30Z,NONE
11414,TensorFlow needs a mascot,type:feature,"Every open source project deserves a mascot. Here's Teensy the TensorFlow Pony, and he's ready to serve:

![img_20170710_073626](https://user-images.githubusercontent.com/161459/28030840-3a882240-655a-11e7-99ae-4469eec0a58a.jpg)
",1,,8,2017-07-10T17:27:43Z,MEMBER
11411,Fetching data in Distributed Tensorflow has too much latency ,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

https://gist.github.com/ahaider3/ae4f6d2d790d963a93b346bb0138a41d

The above is a simple benchmark which tests the overhead of distributed TF. It fetches a configurable sized variable from the parameter server and does a matmul on the worker. It also does a matmul from a locally stored variable on the worker. The time difference between these two operations would be the overhead I am measuring. 

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Redhat  
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
tensorflow 1.2 
- **Python version**: 
python 2.7.7



- **Exact command to reproduce**:

python matmul_benchmark.py --num_features=256 --batch_size=128 --num_hidden=64 --job_name=ps &

python matmul_benchmark.py --num_features=256 --batch_size=128 --num_hidden=64 --job_name=worker

By increasing batch_size, the timing difference between local/remote computation eventually becomes negligible. 
However, for small batch sizes the overhead can become 2x/3x:

For example, here are two runs for different model/dataset sizes:

> 128 features, batch size of 32, hidden layer size of 256  returns:
Local GEMM Time:  0.0002624  Network Fetch GEMM Time: 0.0006798

> 256 features, batch size of 128, hidden layer size of 128  returns:
Local GEMM Time: 0.0002995 Network Fetch GEMM Time: 0.0006124

### Describe the problem
Distributed tensorflow introduces overhead due to its communication stack. By overhead I mean the additional time required for workers to receive data from parameter servers when compared to doing the same computation without fetching any remote data. 

This is a problem because due to this overhead I have to use 2/3 nodes to just provide performance on-par with non-distributed (single process) tensorflow. The number of nodes required to be on-par with single process TF increases further when I use gpus. 


Fetching small variables provides a constant overhead which limits scaling and efficiency . 
This overhead creates two issues in Distributed Tensorflow:
1) I have to add several workers just to equal the performance of a single process. 
2) The overhead of fetching model parameters doesn't scale but the amount of computation does 
decrease as I add more workers. Thus, once I get to a moderately small batch size for each worker I can't scale because the constant overhead of fetching remote model parameters. 

There have been several issues posted with distributed tensorflow. #6116 is an improvement to large tensor transfer while this problem exists for small tensors. #4498 might have been caused by CPU performance bottleneck and not network. However for my problem, network transfer is definitely the bottleneck. I have tried using RDMA and have seen minimal benefit. 

### Source code / logs
https://gist.github.com/ahaider3/ae4f6d2d790d963a93b346bb0138a41d



",1,,27,2017-07-10T15:50:23Z,NONE
11399,Let string_split support splitting utf-8 characters,type:feature,"### Describe the problem

Type of issue: feature request

The [string_split](https://www.tensorflow.org/versions/r0.12/api_docs/python/string_ops/splitting) function has (mostly) good behavior when splitting utf-8 strings by single-character delimiter, but fails to do it properly on null-width delimiter because of its documented behavior:

> If delimiter is an empty string, each element of the source is split into individual strings, each containing one byte. (This includes splitting multibyte sequences of UTF-8.)

For models like seq2seq one needs a split function that can split utf-8 strings into individual characters that can be processed by model as units, also embeddings having properly of being easily joined as utf-8 strings.

Could tensorflow provide alternative implementation of string_split that is utf-8 - aware?",1,,8,2017-07-09T19:39:32Z,NONE
11396,RecordInput blocks if buffer_size is larger than the amount of files in tfrecords.,,"If the `buffer_size` keyword argument in `data_flow_ops.RecordInput(file_pattern, .. buffer_size=buffer_size)` is larger than the amount of files inside of `file_pattern`, the op will block forever.

This is slightly related to #11372, another case where `RecordInput` blocks forever.

Not sure how difficult/possible it would be to check for this or throw an error when this occurs. Feel free to mark this as closed if this is intended behaviour.",1,,4,2017-07-09T16:47:02Z,NONE
11395,Gradients are not registered,stat:community support,"(System information probably is not relevant to the issue, so I moved it below)

## The Problem

It seems that the code, generated by macros `REGISTER_GRADIENT_OP` in [math_grad.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/gradients/math_grad.cc) is never executed:
`static bool unused_ret_val_123 = ::tensorflow::ops::GradOpRegistry::Global()->Register(name, fn);`

My `BUILD` file:
```
cc_binary(
    name = ""bitwise_operations"",
    srcs = [
       ""main.cpp""
    ],
    deps = [
        ""//tensorflow/cc:grad_ops"",
        ""//tensorflow/cc:cc_ops"",
        ""//tensorflow/cc:client_session"",
        ""//tensorflow/core:tensorflow"",
        ""//tensorflow/cc/DimanNe/tensorflow_utils:tensorflow_utils"",
    ],
)
```

## The cause

`Bazel` generates such `tensorflow/bazel-out/local-dbg/bin/tensorflow/cc/DimanNe/bitwise_operations/bitwise_operations-2.params` that instructs linker to put `math_grad.pic.o` in separate static library, here is how it looks in the params file containing linking instructions:
```
--start-lib
bazel-out/local-dbg/bin/tensorflow/cc/_objs/real_math_grad/tensorflow/cc/gradients/real_math_grad.pic.o
--end-lib
```
And [here1](https://www.google.ru/search?q=global+symbols+in+static+libraries&oq=global+symbols+in+static+libraries&aqs=chrome..69i57.7343j0j7&client=ubuntu&sourceid=chrome&ie=UTF-8#newwindow=1&q=global+initializer+in+static+libraries)/[here2](https://stackoverflow.com/questions/9459980/c-global-variable-not-initialized-when-linked-through-static-libraries-but-ok) you can find a lot of complaints about static global variables not being initialized, being linked as static libraries.


## The solution
Add `alwayslink = 1,` to `math_grad` library in `tensorflow/cc/BUILD` (and actually any *_grad library, since all of them use the same mechanism of registration of gradients).
Exactly the same has already been done here - `tensorflow/core/BUILD`.

It the solution is OK, I can make a pull-request.

## System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Kubuntu 17.04
- **TensorFlow installed from (source or binary)**:
Compiled from sources
- **TensorFlow version (use command below)**:
`remotes/origin/r1.2`
- **Python version**: 
Do not use it
- **Bazel version (if compiling from source)**:
$ bazel version
Build label: 0.5.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jun 6 10:34:11 2017 (1496745251)
Build timestamp: 1496745251
Build timestamp as int: 1496745251
- **CUDA/cuDNN version**:
no cude
- **GPU model and memory**:
01:00.0 VGA compatible controller: NVIDIA Corporation GK106 [GeForce GTX 650 Ti Boost] (rev a1)
- **Exact command to reproduce**:",0,,1,2017-07-09T15:45:25Z,CONTRIBUTOR
11389,CUDA_ERROR_LAUNCH_FAILED,stat:awaiting tensorflower,"I'm useing CNN like Tutorials
tensorflow-gpu 1.2.1
CUDA Toolkit 8.0
cuDNN 5.1
python 3.5.2
windows10
![image](https://user-images.githubusercontent.com/15059661/27991248-2b1ca360-64a3-11e7-802e-d50dd64acc64.png)
when it run :
> 2017-07-09 11:51:59.107178: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.107569: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.107982: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.108244: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.108549: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.109679: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 11:51:59.408255: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.721
pciBusID 0000:01:00.0
Total memory: 11.00GiB
Free memory: 9.12GiB
2017-07-09 11:51:59.408712: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:961] DMA: 0 
2017-07-09 11:51:59.408892: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:971] 0:   Y 
2017-07-09 11:51:59.409056: I c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)
3153
2017-07-09 11:52:04.245057: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_driver.cc:1068] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED
2017-07-09 11:52:04.245474: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_timer.cc:54] Internal: error destroying CUDA event in context 000001A873C64B60: CUDA_ERROR_LAUNCH_FAILED
2017-07-09 11:52:04.245791: E c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_timer.cc:59] Internal: error destroying CUDA event in context 000001A873C64B60: CUDA_ERROR_LAUNCH_FAILED
2017-07-09 11:52:04.246154: F c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\stream_executor\cuda\cuda_dnn.cc:1961] failed to enqueue convolution on stream: CUDNN_STATUS_MAPPING_ERROR
[Finished in 19.7s]

if i use tensorflow without gpu, it's ok
",0,,12,2017-07-09T04:48:27Z,NONE
11370,Feature Request: Include Depthwise Convolution in graph_transforms fold_batch_norms,stat:contributions welcome,"Hi!

Currently, the graph_transforms tool includes only `Conv2D` and `MatMul` ops when folding batch normalization scaling/multiplication into its weights, as in `fold_batch_norms.cc`. Google's Mobilenet example uses depthwise convolution extensively, so it would be nice to include this feature for the `DepthwiseConv2dNative` operation. The problem here is that weights are ordered differently for this operation and contain the `channel_muliplier` which would need to be checked when trying to bake subsequent multiplications. 
",1,,5,2017-07-08T08:10:43Z,NONE
11366,Problems with AOT-Compiled Inception V3 model (runtime crash / nonsense output),"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.5
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: bazel release 0.5.1-homebrew
- **CUDA/cuDNN version**: n/a (CPU only build)
- **GPU model and memory**: n/a
- **Exact command to reproduce**: See description below.

### Describe the problem
I've successfully built the AOT compiler and all its tests pass fine. I'm trying to do the analogous thing as in the matmul example to build an AOT-compiled library for a frozen Inception V3 graph: specifically, `inception_v3_2016_08_28_frozen.pb`, which I hope to incorporate into my larger C++ project.

The bazel build goes fine, and I get a (large) library and header file. I can successfully compile and link that into my larger project. When I `Run()` it, however, I get a `EXC_BAD_ACCESS` on this line of disassembly:
```
0x10143f55f <+143>: movq   (%rax), %rax
```
with this stack trace from a call to `Run()`:
```
#0	0x000000010143f55f in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 8, 4, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()
#7	0x00000001012ff70b in __tensorflow_aot_test__aot_test ()
```

Furthermore, when I write my own simple binary, separate from my larger project, along the lines of the matmul test example for AOT, I can build and run it without the above crash, but no matter what input I feed in, I get the same output: the 1001-element results vector is all zeros except entry 429, which is exactly 1.0. My guess was that the image data I'm feeding in was somehow garbage, but I've verified (?) that I can read in the same binary blob of pre-processed image data in Matlab and it looks reasonable. (Pre-processing here includes resizing the image to the required size (299x299), dividing each element by 255, and storing as floats.)

Is something going wrong in AOT-compiling the graph here, or am I doing something wrong or missing something totally stupid? Is there something used in the Inception architecture that's not supported? Should I be trying with another frozen graph? Note that I'm on the `r1.2` branch, but may try switching to master next to see if it's something that's been changed/fixed since `r1.2`. See below for source. 

### Source code / logs

`BUILD` file for my `aot_test` library and a simple binary to run it:
```
load(""//tensorflow/compiler/aot:tfcompile.bzl"", ""tf_library"")

tf_library(
    name = ""aot_test"",
    cpp_class = ""TF_TestAOT"",
    graph = ""inception_v3_2016_08_28_frozen.pb"",
    config = ""aot_test.config.pbtxt"",
)

cc_binary(
    name = ""my_binary"",
    srcs = [
        ""my_binary.cc"", 
    ],
    deps = [
        "":aot_test"",  
        ""//third_party/eigen3"",
    ],
    # I've tried with or without this
    #linkopts = [
    #      ""-lpthread"",
    #]
)
```

Contents of `aot_test.config.pbtxt` referenced above:
```
feed {
  id { node_name: ""input"" }
  shape {
    dim { size: 1   }
    dim { size: 299 }
    dim { size: 299 }
    dim { size: 3   }
  }
}

fetch {
  id { node_name: ""InceptionV3/Predictions/Reshape_1"" }
}
```

Contents of `my_binary.cc` referenced above:
```
#define EIGEN_USE_THREADS
#define EIGEN_USE_CUSTOM_THREAD_POOL

#include <cstdlib>
#include <iostream>
#include ""third_party/eigen3/unsupported/Eigen/CXX11/Tensor""
#include ""tensorflow/aot_test/aot_test.h"" // generated

int main(int argc, char** argv) {
  Eigen::ThreadPool tp(1);  // Size the thread pool as appropriate. (I've tried various options here)
  Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());

  TF_TestAOT test;
  test.set_thread_pool(&device);

  // Set up args and run the computation. 
  // Printing out the data shows it is valid. I've also tried random input data and multiple images.
  FILE* file = fopen(""/tmp/img_norm.bin"", ""rb"");
  const size_t n = fread(test.arg0_data(), sizeof(float), 299*299*3, file); 
  fclose(file);
  std::cout << ""Read "" << n << "" floats"" << std::endl;
  
  test.Run();

  std::cout << ""Status: "" << test.error_msg() << std::endl;
  
  // Check result
  const float* output_data = test.result0_data();
  float maxScore = -1.f;
  int maxIndex = -1;
  for(int i=0; i<1001; ++i)
  {
     // If I print this, i'll see all zeros except entry 429, which is one
    //std::cout << ""Score["" << i << ""]="" << output_data[i] << std::endl;
    if(output_data[i] > maxScore)
    {
      maxScore = output_data[i];
      maxIndex = i;
    }
  }

  std::cout << ""Max score = "" << maxScore << "" at index "" << maxIndex << std::endl;

  return 0;
}
```

",0,,9,2017-07-08T03:29:11Z,NONE
11361,Feature Request: Change REGISTER_OP macro to facilitate customization on static initialization sequence,"stat:awaiting tensorflower,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: iOS
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.0
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: iPhone series
- **Exact command to reproduce**: N/A

### `REGISTER_OP` current syntax is not friendly for customization

`REGISTER_OP` in its current implementation, which leverages C++ macro trick to do method-chaining is not friendly for customization. For example, a typical `REGISTER_OP` macro call looks like this:

```
REGISTER_OP(""DynamicPartition"")
    .Input(""data: T"")
    .Input(""partitions: int32"")
    .Output(""outputs: num_partitions * T"")
    .Attr(""num_partitions: int"")
    .Attr(""T: type"")
    ....;
```

When implementing lazy initialization, this macro, comparing with others from TensorFlow (`REGISTER_KERNEL_BUILDER` for example) is more difficult to customize. The reason is that the macro doesn't capture subsequent method calls, therefore, cannot scope these method calls into a function unit. But, this is easy to solve if we change the `REGISTER_OP` syntax a bit:

```
REGISTER_OP(Op(""DynamicPartition"")
    .Input(""data: T"")
    .Input(""partitions: int32"")
    .Output(""outputs: num_partitions * T"")
    .Attr(""num_partitions: int"")
    .Attr(""T: type"")
    ....);
```
The above example is very close to how `REGISTER_KERNEL_BUILDER` works:
```
REGISTER_KERNEL_BUILDER(Name(""NoOp"").Device(DEVICE_CPU), NoOp);
```
so we have some consistencies there.

A hypothetic change to the `REGISTER_OP` macro could look like this:
```
static inline OpDefBuilderWrapper<true> Op(const char name[]) {
    return OpDefBuilderWrapper<true>(name);
}
}  // namespace register_op

#define REGISTER_OP(op) REGISTER_OP_UNIQ_HELPER(__COUNTER__, op)
#define REGISTER_OP_UNIQ_HELPER(ctr, op) REGISTER_OP_UNIQ(ctr, op)
#define REGISTER_OP_UNIQ(ctr, op)                                            \
  static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr    \
      TF_ATTRIBUTE_UNUSED =                                                  \
          ::tensorflow::register_op::op;
```

More importantly, this small change enabled some lazy initialization opportunities regarding ops registration, you can imagine a platform-specific change (not likely to get upstreamed) to this macro:

```
#define REGISTER_OP_UNIQ(ctr, op)                                            \
__attribute__((used)) static void register_op_init##ctr(void) {              \
  static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr    \
      TF_ATTRIBUTE_UNUSED =                                                  \
          ::tensorflow::register_op::op;                                     \
}                                                                            \
__attribute__((used)) __attribute__((section (""__DATA,tf_reg_op""))) static void *register_op_func##ctr = (void *)&register_op_init##ctr
```

Which put the static initializers into a function and a lazy initializer can call op registrations by scanning the data section and invoke these functions one by one.

Please let me know if this will violate some core assumptions TensorFlow is making and your concerns.",0,,9,2017-07-07T18:21:50Z,NONE
11351,transform_graph quantize_weights doesn't compile on windows,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

I'm executing a command from documentation, and I don't think that my custom model is part of the issue.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Windows Server 2012 R2 64-bit

- **TensorFlow installed from (source or binary)**:

Latest master (7/7/2017) compiled with bazel and msvc

- **TensorFlow version (use command below)**:

commit 1e037850f1a (July 6 21:55:34 2017 -0400)

- **Python version**: 

3.5.3 Anaconda 64-bit

- **Bazel version (if compiling from source)**:

0.5.1

- **CUDA/cuDNN version**:

CPU Only

- **GPU model and memory**:

CPU Only (CPU is dual socket Xeon E5-2687W v2)

- **Exact command to reproduce**:
```
$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights'
```

### Describe the problem

I originally asked this question on StackOverflow and I was recommended to file a bug report:

https://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights

The `transform_graph` program in tensorflow does not include the `quantize_weights` transform. If I execute the command above without the `quantize_weights` transform it works correctly.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights'
```
```
2017-07-06 13:21:10.361492: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_constants
2017-07-06 13:21:10.476001: W C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-06 13:21:13.241688: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_batch_norms
2017-07-06 13:21:16.088969: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_old_batch_norms
2017-07-06 13:21:16.650913: E C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:209] Transform 'quantize_weights' not recognized.
2017-07-06 13:21:16.650934: E C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:210] usage: C:\Users\name\git-repos\tensorflow\bazel-bin\tensorflow\tools\graph_transforms\transform_graph.exe
Flags:
        --in_graph=""""                           string  input graph file name
        --out_graph=""""                          string  output graph file name
        --inputs=""""                             string  inputs
        --outputs=""""                            string  outputs
        --transforms=""""                         string  list of transforms
        --output_as_text=false                  bool    whether to write the graph in text protobuf format

Transforms are:
add_default_attributes
backport_concatv2
backport_tensor_array_v3
fold_batch_norms
fold_constants
fold_old_batch_norms
freeze_requantization_ranges
fuse_pad_and_conv
fuse_resize_and_conv
fuse_resize_pad_and_conv
insert_logging
obfuscate_names
remove_attribute
remove_device
remove_nodes
rename_attribute
rename_op
set_device
sort_by_execution_order
sparsify_gather
strip_unused_nodes
```
",1,,5,2017-07-07T14:06:34Z,NONE
11350,MonitoredTrainingSession to have accessible summary writer.,"stat:contributions welcome,type:feature","**Tensorflow version: 1.2.1**

I am using `MonitoredTrainingSession` extensively to train models, and for the most part does exactly what I want it to do. However, I would like to be able to extract (or pass in) a `FileWriter` object so I can report other summaries from inside my evaluation routines. This is because only one` FileWriter` can write to the events log:

At the moment, this is the best workaround I can do:

```python
sess = tf.train.MonitoredTrainingSession(
       ...
    )

# HACK: this is so we use the same summary writer obj for both summaries, only way to do it.
summary_writer = sess._hooks[1]._summary_writer
```

Then I can use the `summary_writer` to manually report summaries in the evaluation part of my code:

```python
mean_test_loss = ...
summary = tf.Summary(value=[
    tf.Summary.Value(tag='mean_test_loss', simple_value=mean_test_loss)
])
summary_writer.add_summary(summary, current_step)

```

It would be nice to have a non-hacky way to get the `summary_writer` from the session so only one `FileWriter` writes to the events file.

One thought I had is to have a `FileWriter` object as part of the `Scaffold` that is used to build the session. That way anyone can get hold of the scaffold and use the one `summary_writer` designated to write to the events log.

I would be happy to help implementing this if other people are interested.

",0,,2,2017-07-07T12:52:00Z,NONE
11348,The order in which tensorflow libraries are loaded leads to segmentation fault,"stat:community support,type:build/install","I have a simple java code below.Running this code produces a core dump.
i am running this on debian/8 jessie system. I use tensorflow 1.2.1.
The same code works fine in mac osx but has problems when we run the same  in Linux.
When the code is changed to load tensorflow libraries before rocksdb library it works fine on all platforms.

package com.test.tensorflow;

import org.rocksdb.RocksDB;
import org.rocksdb.RocksDBException;
import org.tensorflow.SavedModelBundle;
import org.tensorflow.Session;
import org.tensorflow.Tensor;

public class TestTensorFlow {

	public static void main(String[] args){
		
		 System.out.println(""before loading.."" + System.getProperty(""java.io.tmpdir""));
		
		
		 RocksDB.loadLibrary();
		 try {
			RocksDB db =RocksDB.open(""/tmp/rocksdelete"");
			db.close();
		} catch (RocksDBException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		 
		 SavedModelBundle smb = SavedModelBundle.load(""test-model"", ""serve"");
		 Session tfSession = smb.session();
		 System.out.println(""loaded"");

	}
}
",0,,1,2017-07-07T11:49:46Z,NONE
11345,//tensorflow/python:nn_test is failing on Windows,stat:awaiting tensorflower,"https://ci.tensorflow.org/job/tf-master-win-bzl/1218/consoleFull
```
18:54:32 INFO: From Testing //py_test_dir/tensorflow/python:nn_test:
18:54:32 ==================== Test output for //py_test_dir/tensorflow/python:nn_test:
18:54:32 ......................................F...........
18:54:32 ======================================================================
18:54:32 FAIL: testOutput4DInput123 (__main__.MomentsTest)
18:54:32 ----------------------------------------------------------------------
18:54:32 Traceback (most recent call last):
18:54:32   File ""\\?\c:\temp\Bazel.runfiles_nwtmklpc\runfiles\org_tensorflow\py_test_dir\tensorflow\python\ops\nn_test.py"", line 878, in testOutput4DInput123
18:54:32     self.doOutputTest((10, 10, 10, 30), (1, 2, 3))
18:54:32   File ""\\?\c:\temp\Bazel.runfiles_nwtmklpc\runfiles\org_tensorflow\py_test_dir\tensorflow\python\ops\nn_test.py"", line 854, in doOutputTest
18:54:32     self.assertAllClose(variance, expected_var, rtol=tol, atol=tol)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 660, in assertAllClose
18:54:32     self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 630, in _assertArrayLikeAllClose
18:54:32     np.testing.assert_allclose(b, a, rtol=rtol, atol=atol, err_msg=msg)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 1411, in assert_allclose
18:54:32     verbose=verbose, header=header, equal_nan=equal_nan)
18:54:32   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 796, in assert_array_compare
18:54:32     raise AssertionError(msg)
18:54:32 AssertionError: 
18:54:32 Not equal to tolerance rtol=0.0001, atol=0.0001
18:54:32 None
18:54:32 (mismatch 100.0%)
18:54:32  x: array([[[[ 0.000834]]],
18:54:32 
18:54:32 ...
18:54:32  y: array([[[[ 0.001117]]],
18:54:32 
18:54:32 ...
```",0,,5,2017-07-07T08:08:39Z,MEMBER
11337,get error in tensorflow 1.2 but the code works on tensorflow 1.0,stat:awaiting tensorflower,"Hi,

I have the following code. I can run it successfully in tf v1.0 but it failed in tf v1.2. The error is from the (inputs, state) in the GRUCell. Can you help me understand why the errors come from?

Thank you.


```python
import tensorflow as tf
from  tensorflow.contrib.learn.python.learn.estimators.dnn  import DNNClassifier
from tensorflow.contrib.layers import real_valued_column
from tensorflow.contrib.layers.python.layers.initializers import xavier_initializer

dropout=0.2
hidden_1_size = 1000
hidden_2_size = 250
NUM_EPOCHS=100
BATCH_SIZE=50
lr=0.0001

num_features = 2328
RNN_HIDDEN_SIZE=100
FIRST_LAYER_SIZE=1000
SECOND_LAYER_SIZE=250
NUM_LAYERS=2
BATCH_SIZE=50
NUM_EPOCHS=200
lr=0.0003
ATTN_LENGTH=30
beta=0


class RNNModel():
    def __init__(self):
        global_step = tf.contrib.framework.get_or_create_global_step()
        self.input_data = tf.placeholder(dtype=tf.float32,shape=[BATCH_SIZE,num_features])
        self.target_data = tf.placeholder(dtype=tf.int32,shape=[BATCH_SIZE])
        self.dropout_prob = tf.placeholder(dtype=tf.float32,shape=[])
        
        def makeGRUCells():
            base_cell = tf.contrib.rnn.GRUCell(num_units=RNN_HIDDEN_SIZE,) 
            layered_cell = tf.contrib.rnn.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False) 
            attn_cell =tf.contrib.rnn.AttentionCellWrapper(cell=layered_cell,attn_length=ATTN_LENGTH,state_is_tuple=False)
            return attn_cell
        
        self.gru_cell = makeGRUCells()
        self.zero_state = self.gru_cell.zero_state(1, tf.float32)
        
        self.start_state = tf.placeholder(dtype=tf.float32,shape=[1,self.gru_cell.state_size])
        print((self.start_state))
        
        

        with tf.variable_scope(""fff"",initializer=xavier_initializer(uniform=False), reuse = None):
            droped_input = tf.nn.dropout(self.input_data,keep_prob=self.dropout_prob)
            
            layer_1 = tf.contrib.layers.fully_connected(
                num_outputs=FIRST_LAYER_SIZE,
                inputs=droped_input,
            )
            layer_2 = tf.contrib.layers.fully_connected(
                num_outputs=RNN_HIDDEN_SIZE,
                inputs=layer_1,
            )
            
        
        split_inputs = tf.reshape(droped_input,shape=[1,BATCH_SIZE,num_features],name=""reshape_l1"") # Each item in the batch is a time step, iterate through them
        #print(split_inputs.shape)
        split_inputs = tf.unstack(split_inputs,axis=1,name=""unpack_l1"")
        #print(""lentgh is "" + str(len(split_inputs)))
        states =[]
        outputs =[]
        with tf.variable_scope(""rnn"",initializer=xavier_initializer(uniform=False), reuse = None) as scope:
            state = self.start_state
            for i, inp in enumerate(split_inputs):
                if i >0:
                    scope.reuse_variables()
                print((state))
                print((inp))
                print(""this is for "" + str(i))
                output, state = self.gru_cell(inputs = inp, state = state)
                states.append(state)
                outputs.append(output)
        self.end_state = states[-1]
        outputs = tf.stack(outputs,axis=1) # Pack them back into a single tensor
        outputs = tf.reshape(outputs,shape=[BATCH_SIZE,RNN_HIDDEN_SIZE])
        self.logits = tf.contrib.layers.fully_connected(
            num_outputs=num_classes,
            inputs=outputs,
            activation_fn=None
        )

            
        with tf.variable_scope(""loss"", reuse = None):
            self.penalties =    tf.reduce_sum([beta*tf.nn.l2_loss(var) for var in tf.trainable_variables()])

            
            self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits,labels = self.target_data)
            self.loss = tf.reduce_sum(self.losses + beta*self.penalties)
        
        with tf.name_scope(""train_step""):
            opt = tf.train.AdamOptimizer(lr)
            gvs = opt.compute_gradients(self.loss)
            self.train_op = opt.apply_gradients(gvs, global_step=global_step)
        
        with tf.name_scope(""predictions""):
            probs = tf.nn.softmax(self.logits)
            self.predictions = tf.argmax(probs, 1)
            correct_pred = tf.cast(tf.equal(self.predictions, tf.cast(self.target_data,tf.int64)),tf.float64)
            self.accuracy = tf.reduce_mean(correct_pred)

         
with tf.Graph().as_default():
    model = RNNModel()
```


```python

WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x0000000038EB4CC0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
Tensor(""Placeholder_3:0"", shape=(1, 3300), dtype=float32)
Tensor(""Placeholder_3:0"", shape=(1, 3300), dtype=float32)
Tensor(""unpack_l1:0"", shape=(1, 2328), dtype=float32)
this is for 0




---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-20-2249079aecbe> in <module>()
      1 with tf.Graph().as_default():
----> 2     model = RNNModel()

<ipython-input-19-58646adfd4d3> in __init__(self)
     48                 print((inp))
     49                 print(""this is for "" + str(i))
---> 50                 output, state = self.gru_cell(inputs = inp, state = state)
     51                 states.append(state)
     52                 outputs.append(output)

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\contrib\rnn\python\ops\rnn_cell.py in call(self, inputs, state)
   1111       input_size = inputs.get_shape().as_list()[1]
   1112     inputs = _linear([inputs, attns], input_size, True)
-> 1113     lstm_output, new_state = self._cell(inputs, state)
   1114     if self._state_is_tuple:
   1115       new_state_cat = array_ops.concat(nest.flatten(new_state), 1)

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in call(self, inputs, state)
    914                                       [-1, cell.state_size])
    915           cur_state_pos += cell.state_size
--> 916         cur_inp, new_state = cell(cur_inp, cur_state)
    917         new_states.append(new_state)
    918 

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in call(self, inputs, state)
    293       value = math_ops.sigmoid(
    294           _linear([inputs, state], 2 * self._num_units, True, bias_ones,
--> 295                   self._kernel_initializer))
    296       r, u = array_ops.split(value=value, num_or_size_splits=2, axis=1)
    297     with vs.variable_scope(""candidate""):

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _linear(args, output_size, bias, bias_initializer, kernel_initializer)
   1015         _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size],
   1016         dtype=dtype,
-> 1017         initializer=kernel_initializer)
   1018     if len(args) == 1:
   1019       res = math_ops.matmul(args[0], weights)

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
   1063       collections=collections, caching_device=caching_device,
   1064       partitioner=partitioner, validate_shape=validate_shape,
-> 1065       use_resource=use_resource, custom_getter=custom_getter)
   1066 get_variable_or_local_docstring = (
   1067     """"""%s

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    960           collections=collections, caching_device=caching_device,
    961           partitioner=partitioner, validate_shape=validate_shape,
--> 962           use_resource=use_resource, custom_getter=custom_getter)
    963 
    964   def _get_partitioned_variable(self,

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    358           reuse=reuse, trainable=trainable, collections=collections,
    359           caching_device=caching_device, partitioner=partitioner,
--> 360           validate_shape=validate_shape, use_resource=use_resource)
    361     else:
    362       return _true_getter(

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in wrapped_custom_getter(getter, *args, **kwargs)
   1403     return custom_getter(
   1404         functools.partial(old_getter, getter),
-> 1405         *args, **kwargs)
   1406   return wrapped_custom_getter
   1407 

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in wrapped_custom_getter(getter, *args, **kwargs)
   1403     return custom_getter(
   1404         functools.partial(old_getter, getter),
-> 1405         *args, **kwargs)
   1406   return wrapped_custom_getter
   1407 

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)
    350           trainable=trainable, collections=collections,
    351           caching_device=caching_device, validate_shape=validate_shape,
--> 352           use_resource=use_resource)
    353 
    354     if custom_getter is not None:

C:\Users\hsong01\AppData\Local\Continuum\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)
    667         raise ValueError(""Trying to share variable %s, but specified shape %s""
    668                          "" and found shape %s."" % (name, shape,
--> 669                                                    found_var.get_shape()))
    670       if not dtype.is_compatible_with(found_var.dtype):
    671         dtype_str = dtype.name

ValueError: Trying to share variable rnn/attention_cell_wrapper/multi_rnn_cell/cell_0/gru_cell/gates/kernel, but specified shape (200, 200) and found shape (2428, 200).
```
",0,,7,2017-07-06T22:00:47Z,NONE
11336,TF 1.2 vs 1.1: Keras K.set_learning_phase(False) not working in 1.2 but works in 1.1,,"Hi all,

Works fine in 1.1 but in 1.2: 
```
from tensorflow.contrib.keras.python.keras import backend as K
from tensorflow.contrib.keras.python.keras.models import load_model
K.set_learning_phase(False)
model = load_model(MODEL_PATH)
```
```
model.uses_learning_phase <-- returns TRUE
```

This does not happen in 1.1. What may have changed that cause this in 1.2? 

Thank you in advance.
Best regards,
Dylan Randle

",0,,9,2017-07-06T21:47:48Z,NONE
11334,Memory Overhead/Leak in Android lib,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Nexus 6p, Android v7.1.2
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:  1.2.0-rc2
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**: 0.4.5-homebrew
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**:
- **Exact command to reproduce**: 
-- Selective Headers: ` bazel build -c opt --copt=""-DSELECTIVE_REGISTRATION"" --copt=""-DSUPPORT_SELECTIVE_REGISTRATION"" //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a `
-- Added `tensorflow/core/kernels/random_shuffle_queue_op.cc` and `tensorflow/core/kernels/random_shuffle_op.cc` to `tf_op_files.txt` file
-- Removed unused nodes: `bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=model.pb \
--out_graph=optimized_model.pb \
--inputs='input' \
--outputs='output' \
--transforms='
  strip_unused_nodes(type=float, shape=""1,299,299,3"")'`

### Describe the problem
The Tensorflow Android library is using a lot more memory than I expected. It almost seems like it's maintaining a reference to all input arrays, as memory usage balloons the longer the model is used. 
Here is an example of the memory usage with feed/run/fetch commented out (source code below):

![no_tensorflow](https://user-images.githubusercontent.com/4616968/27930636-3342a548-624c-11e7-91ed-3f4f56b7cf5f.png)

Here is the same timeframe, with the only difference being that feed/run/fetch is enabled:

![tensorflow](https://user-images.githubusercontent.com/4616968/27930738-954e125e-624c-11e7-82f2-cc21e67bc5d3.png)

Memory usage is over three times worse. The longer I leave the model running, the more memory usage increases (it eventually gets to 110 mb).

The below method is being called at a rate of 4.419011933 per sec (i.e. it's processing 4.412 input arrays per second), where each input array is of size 96\*96\*3 (27648).

This is being run on a Nexus 6p, running stock 7.1.2. The model is a conv net with inception, batch norm and dropout, trained using tensorflow slim. 

### Source code / logs
Commented out:
```java
public float[] runInference(float[] pixels) {
        assertRightSize(pixels);
        final float[] outputArray = new float[128];
        // Simulate some sort of output
        Arrays.fill(outputArray, new Random().nextInt(1000)/new Random().nextFloat());
//     inferenceInterface.feed(""phase_train"", new bool[]{false});
//     inferenceInterface.feed(""input"", pixels, 1, 96, 96, 3);
//     inferenceInterface.run(new String[]{""output""});
        // Copy the output Tensor back into the output array.
//     inferenceInterface.fetch(""output"", outputArray);

        return outputArray;
    }
```
Enabled:

```java
public float[] runInference(float[] pixels) {
        assertRightSize(pixels);
        final float[] outputArray = new float[128];
        inferenceInterface.feed(""phase_train"", new bool[]{false});
        inferenceInterface.feed(""input"", pixels, 1, 96, 96, 3);
        inferenceInterface.run(new String[]{""output""});
        // Copy the output Tensor back into the output array.
        inferenceInterface.fetch(""output"", outputArray);

        return outputArray;
    }
```

where `float[] pixels` is a float array of size `27648`, denoting the pixels in an image of size 96x96.

The custom code is an update to the InferenceInterface to accept boolean types during feeding: 

```java
public void feed(String inputName, boolean[] src, long... dims) {
        byte[] b = new byte[src.length];
        for (int i = 0; i < src.length; ++i) {
            b[i] = (byte) (src[i] ? 1 : 0);
        }
        addFeed(inputName, Tensor.create(DataType.BOOL, dims, ByteBuffer.wrap(b)));
    }
```

Please let me know if there's any other information I can provide.",0,,21,2017-07-06T20:31:54Z,NONE
11303,Catch keyboard interrupt in session run,stat:contributions welcome,"Right now, Ctrl+c does not abort a long session run.",0,,2,2017-07-05T17:05:44Z,MEMBER
11301,Blas SGEMM launch failed,stat:community support,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I am using Resnet code from tensorflow models with some modifications.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 24
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 2.7
- **CUDA/cuDNN version**: cuda_8.0.61-cudnnv5
- **GPU model and memory**: Nvidia Titan X, 12 GB

I am training a Resnet model on my own data from scratch. After successfully running for 65700 steps, it crashed with the following error:

2017-06-30 16:27:50.302438: E tensorflow/stream_executor/cuda/cuda_blas.cc:543] failed to run cuBLAS routine cublasSgemm_v2: CUBLAS_STATUS_EXECUTION_FAILED
Traceback (most recent call last):
  File ""resnet_main.py"", line 178, in <module>
    if z%100 == 0:
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""resnet_main.py"", line 171, in main
    tf.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)
  File ""resnet_main.py"", line 90, in train
    mon_sess.run(model.train_op)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 505, in run
    run_metadata=run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 842, in run
    run_metadata=run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 798, in run
    return self._sess.run(*args, **kwargs)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    run_metadata=run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 798, in run
    return self._sess.run(*args, **kwargs)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=12544, n=1024, k=256
	 [[Node: unit_3_2/sub3/conv3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](unit_3_2/sub3/leaky_relu, unit_3_2/sub3/conv3/DW/read)]]
	 [[Node: train_step/update/_6858 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_15509_train_step/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'unit_3_2/sub3/conv3/Conv2D', defined at:
  File ""resnet_main.py"", line 178, in <module>
    if z%100 == 0:
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""resnet_main.py"", line 171, in main
    tf.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)
  File ""resnet_main.py"", line 31, in train
    model.build_graph()
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 42, in build_graph
    self._build_model()
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 95, in _build_model
    x = res_func(x, filters[3], filters[3], self._stride_arr(1), False)
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 245, in _bottleneck_residual
    x = self._conv('conv3', x, 1, out_filter / 4, out_filter, [1, 1, 1, 1])
  File ""/s/chopin/l/grad/prady/PycharmProjects/GestureRecognition/frame/resnet_model.py"", line 273, in _conv
    return tf.nn.conv2d(x, kernel, strides, padding='SAME')
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 399, in conv2d
    data_format=data_format, name=name)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/s/chopin/l/grad/prady/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Blas SGEMM launch failed : m=12544, n=1024, k=256
	 [[Node: unit_3_2/sub3/conv3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](unit_3_2/sub3/leaky_relu, unit_3_2/sub3/conv3/DW/read)]]
	 [[Node: train_step/update/_6858 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_15509_train_step/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

2017-06-30 16:27:55.680213: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x564291240800: CUDA_ERROR_MISALIGNED_ADDRESS

On another machine with exact configuration, it is still running successfully (425,000 steps as of now). I don't understand why it crashed on one machine after running for 65,700 steps.",0,,4,2017-07-05T16:15:15Z,NONE
11294,Feature request : Add more Scipy Optimizer,"stat:contributions welcome,type:feature","Hi,

Could it be possible to wrap the [scipy.optimize.basinhopping](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.basinhopping.html) and [scipy.optimize.anneal](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.optimize.anneal.html) the same way the [tf.contrib.opt.ScipyOptimizerInterface](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/opt/python/training/external_optimizer.py) allow us to use method as LBFGS with Tensorflow to minimize a function ?

Thanks",0,,1,2017-07-05T12:59:18Z,NONE
11290,Restoring SavedModel in //tensorflow/c:c_api_test fails ,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version**: 'v1.2.1-0-gb4957ff', '1.2.1'
- **Python version**: 2.7.12
- **Bazel version**: 0.4.5
- **CUDA/cuDNN version**: No GPU
- **GPU model and memory**: No GPU
- **Exact command to reproduce**: bazel test //tensorflow/c:c_api_test

### The problem:
While executing c_api_test from c module on a big endian machine, it fails while restoring SavedModel(tensorflow/cc/saved_model/testdata/half_plus_two/00000123). There is a warning displayed `Reading a bundle with different endianness from the reader`. 

Similarly, other tests from cc, java module which read this SavedModel from testdata also fail due to endianness mismatch.

What would be appropriate way to handle this failure on big endian?
Is there a way to convert the above SavedModel to Big Endian while reading it in the tests?

### Test Logs:
```
[ RUN      ] CAPI.SavedModel
2017-06-29 09:04:33.999662: I tensorflow/cc/saved_model/loader.cc:226] Loading SavedModel from: <HOME>/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/c/c_api_test.runfiles/org_tensorflow/tensorflow/cc/saved_model/testdata/half_plus_two/00000123
2017-06-29 09:04:34.039733: I tensorflow/cc/saved_model/loader.cc:145] Restoring SavedModel bundle.
2017-06-29 09:04:34.079006: W tensorflow/core/framework/op_kernel.cc:1158] Unimplemented: Reading a bundle with different endianness from the reader
2017-06-29 09:04:34.079311: W tensorflow/core/framework/op_kernel.cc:1158] Unimplemented: Reading a bundle with different endianness from the reader
2017-06-29 09:04:34.079363: W tensorflow/core/framework/op_kernel.cc:1158] Unimplemented: Reading a bundle with different endianness from the reader
2017-06-29 09:04:34.079708: I tensorflow/cc/saved_model/loader.cc:274] Loading SavedModel: fail. Took 136931 microseconds.
tensorflow/c/c_api_test.cc:1198: Failure
      Expected: TF_OK
      Which is: 0
To be equal to: TF_GetCode(s)
      Which is: 12
Reading a bundle with different endianness from the reader
         [[Node: save/RestoreV2 = RestoreV2[_output_shapes=[[]], dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save/Const_0_1, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
```",0,,13,2017-07-05T09:20:57Z,CONTRIBUTOR
11275,tfcompile with tf.nn.dynamic_rnn crashes,stat:awaiting tensorflower,"Trying to build a C++ binary with tfcompile crashes with `INVALID ARGUMENTS: Mising Exit successor to rnn/while/Switch` if the graph contains `tf.nn.dynamic_rnn`, but it works with `tf.nn.static_rnn`. Why is this?",2,,29,2017-07-04T15:43:30Z,CONTRIBUTOR
11269,Build failure for r1.2  & master (r1.1 builds fine),"stat:community support,type:build/install","### System information
== cat /etc/issue ===============================================
Linux Lounge 4.11.8-200.fc25.x86_64 #1 SMP Thu Jun 29 16:13:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""25 (Workstation Edition)""
VERSION_ID=25
REDHAT_BUGZILLA_PRODUCT_VERSION=25
REDHAT_SUPPORT_PRODUCT_VERSION=25

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 6.3.1 20161221 (Red Hat 6.3.1-1)
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Lounge 4.11.8-200.fc25.x86_64 #1 SMP Thu Jun 29 16:13:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.2.1)
tensorflow-tensorboard (0.1.2)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-1709-g679bb02
tf.COMPILER_VERSION = v1.2.0-1709-g679bb02
Sanity check: array([1], dtype=int32)
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda::/usr/local/cuda-7.5/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Tue Jul  4 21:42:35 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 750 Ti  Off  | 0000:01:00.0      On |                  N/A |
|  6%   36C    P8     1W /  38W |    243MiB /  2000MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1490    G   /usr/bin/gnome-shell                           118MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudart_static.a

### Describe the problem
I've managed to compile tf r1.1 with CUDA support with no problems. Howwever r1.2 and master throw an error at the final link stage (I think). I call the build process from a script (below).

The error is pasted below the calling script. The error message says to recompile with -fPIC, so I added that to the --copt and --cxxopt bazel command, but it makes no difference.

And issue  #9149 is affecting me as well, although it doesn't affect build success.

Thanks to all the wonderful TF hackers! You're making the world a better place.

## Script used to build TF
#! /bin/sh
cd ~/Downloads/Software/tensorflow
export CUDA_TOOLKIT_PATH=/usr/local/cuda
export CUDNN_INSTALL_PATH=/lib64
export GCC_HOST_COMPILER_PATH=/usr/bin/gcc53
export LD_LIBRARY_PATH=/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda-8.0/lib64
export PATH=/home/john/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/local/sbin:/usr/bin
export PYTHON_BIN_PATH=/usr/bin/python
export PYTHON_LIB_PATH=/usr/lib64/python2.7/site-packages
export TF_CUDA_CLANG=0
export TF_CUDA_COMPUTE_CAPABILITIES=5.2
export TF_CUDA_VERSION='8' 
export TF_CUDNN_VERSION='6'
export TF_NEED_CUDA=1
export TF_NEED_OPENCL=0 
export CC=/usr/bin/gcc53
export CXX=/usr/bin/g++-53

rm -fr ~/.cache/bazel/_bazel_john/189563267da147eb81f91b14c734315c/
bazel clean
\#git checkout r1.1
./configure
bazel build --config=opt --copt=-O2 ---copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --cxxopt=-O2 --copt=-w --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures 

## Error at final (?) linking
2017-07-04 22:01:21.178045: W tensorflow/core/framework/op_gen_lib.cc:194] Squeeze can't find input squeeze_dims to rename
ERROR: /home/john/Downloads/Software/tensorflow/tensorflow/python/BUILD:2638:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command 
  (cd /home/john/.cache/bazel/_bazel_john/189563267da147eb81f91b14c734315c/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/lib64 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc53 \
    LD_LIBRARY_PATH=/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda-8.0/lib64 \
    PATH=/home/john/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/local/sbin:/usr/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/bin/python \
    PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \
    TF_CUDA_VERSION='' \
    TF_CUDNN_VERSION='' \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL=0 \
  external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Wl,--version-script tensorflow/tf_version_script.lds -Wl,-z,muldefs -Wl,-z,muldefs -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -pthread -Wl,-no-as-needed -B/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/bin/ld: /usr/lib/gcc/x86_64-redhat-linux/5.3.1/libgomp.a(critical.o): relocation R_X86_64_32 against `.bss' can not be used when making a shared object; recompile with -fPIC
/usr/lib/gcc/x86_64-redhat-linux/5.3.1/libgomp.a: error adding symbols: Bad value
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1865.691s, Critical Path: 223.61s

",0,,5,2017-07-04T10:06:13Z,NONE
11247,Standalone Embedding Projector does not load bookmarks,stat:awaiting tensorflower,"The standalone[ Embedding Projector](http://projector.tensorflow.org/) does not open the _Load bookmarks_ window for me all of a sudden. _Save bookmarks_ and everything else still works though. 

I am on Windows 7 (Enterprise) using Chrome (Google Chrome	59.0.3071.115 (Official Build) (64-bit) (cohort: Stable)).

",0,,8,2017-07-03T15:12:21Z,NONE
11241,[Feature request] add checkpoint_convert.py script to pip package,"stat:contributions welcome,type:feature","In the TensorFlow 1.2.0 pip package (at least for Linux), [checkpoint_convert.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py) is not included. Because of #11168, 92da8abfd35b93488ed7a55308b8f589ee23b622, 157370e5916b85c65958ed8383ae31d727228ed7, it might be useful. Esp., in our framework, I would like to add some automatic handling at runtime when a checkpoint file is loaded and some variables are not found, to automatically try to load variables under different names according to `_RNN_NAME_REPLACEMENTS`. Thus, extending to adding `checkpoint_convert.py` to the pip package, it would also be nice to make `_RNN_NAME_REPLACEMENTS` public (remove the leading underscore).
",0,,4,2017-07-03T09:37:49Z,NONE
11238,Dendrite morphological neural networks,"stat:contributions welcome,type:feature","Can you guys also provide an implementation for Dendrite morphological neural networks in tensorflow. 

http://www.sciencedirect.com/science/article/pii/S0925231213010916",0,,3,2017-07-03T08:44:34Z,NONE
11228,GPU kernel for segment_sum?,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.2.0-5-g435cdfc', '1.2.1')
- **Python version**: 2.7.12
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: GTK1070/ 8105MB

^^ I don't think system information is hugely relevant in this case, but writing them down anyways.

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

This is a feature request. I was running *tf.unsorted_segment_sum* on an unsorted list of segments, and thought that I might be able to get a performance gain if the segment ids are sorted (as that is usually the case).
However, to my surprise, I discovered that there are no supported GPU kernels for vanilla segment_sum, forcing tensorflow to copy memory over to the CPU and thereby slowing down the operation greatly.
Would it be possible to support an optimized GPU version of segment_sum that takes advantage of the fact that the segments are sorted?

### Source code / logs

(Device Placement)
UnsortedSegmentSum: (UnsortedSegmentSum)/job:localhost/replica:0/task:0/gpu:0
softmax/ops/SegmentSum: (SegmentSum)/job:localhost/replica:0/task:0/cpu:0

(Profiling)
[Unsorted Segment Sum] : Took 1.979 Seconds
[Segment Sum] : Took 2.704 Seconds",0,,3,2017-07-02T21:27:50Z,NONE
11187,TF Slim - allow soft placement for devices with train_image_classifier,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.5
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**: git tag 1.2
- **Python version**: 2.7 system install
- **Bazel version (if compiling from source)**: home-brew 0.4.5
- **CUDA/cuDNN version**: NA
- **GPU model and memory**:  NA
- **Exact command to reproduce**: 

train Mobilenet_v1 on CPU like so:

 python train_image_classifier.py     --train_dir=${TRAIN_DIR}     --dataset_dir=${DATASET_DIR}     --dataset_name=Framing     --dataset_split_name=train     --model_name=mobilenet_v1     --checkpoint_path=${CHECKPOINT_PATH}     --checkpoint_exclude_scopes=MobilenetV1/Logits/Conv2d_1c_1x1/biases,MobilenetV1/Logits/Conv2d_1c_1x1/weights 

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Tensorflow 1.2 has no GPU support for macOS. Thus training/retraining can only happen on CPU.
TF Slim doesnt appear to have an out of the box way to specify soft placement of nodes - therefore I can't appear to train a mobile net checkpoint?


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


`INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
INFO:tensorflow:Fine-tuning from /Volumes/MediaArchive/datasets/SynopsisCinemaNet/model/mobilenet_v1_1.0_224_2017_06_14/mobilenet_v1_1.0_224.ckpt.index
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Cannot assign a device for operation 'MobilenetV1/Logits/Conv2d_1c_1x1/biases/RMSProp_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.
	 [[Node: MobilenetV1/Logits/Conv2d_1c_1x1/biases/RMSProp_1 = VariableV2[_class=[""loc:@MobilenetV1/Logits/Conv2d_1c_1x1/biases""], container="""", dtype=DT_FLOAT, shape=[5], shared_name="""", _device=""/device:GPU:0""]()]]
`",0,,5,2017-06-30T17:57:01Z,CONTRIBUTOR
11186,tf.copy() as alternative to tf.identity(),"stat:contributions welcome,type:feature","`tf.identity(tensor)` does or does not create a copy of the tensor based on whether it's on the same device. This can lead to bugs that are hard to find. The current way of ensuring a copy is to perform an arithmetic/logic operation that doesn't change the value, such as `tensor + 0`, `1 * tensor`, or `tf.equal(tensor, True)`. Needless to say, this makes code hard to read. Moreover, different treatment is needed for different tensor types. Can we have a `tf.copy(tensor)` that does this for us?",0,,9,2017-06-30T17:46:32Z,MEMBER
11184,"TF Slim scripts iterate invisible files, don't appear to handle paths with spaces?","stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2 release (tagged from git)
- **Python version**: system 2.7 from Mac OS X 10.12
- **Bazel version (if compiling from source)**: home-brew 0.4.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:  TF Slim scripts such as train_image_classifier and their installed components, and download_and_convert.py 

### Describe the problem
Hello. Apologies, this seems rather trivial and potentially an oversight on my part, but I think its worth mentioning. 

i'm attempting to follow the TF Slim models readme to get Mobilenet_v1 trained on a custom data set. In looking through the download_and_convert.py scripts and TFRecord creation scripts, I've noticed that:

• conversion functions will iterate over a directory and attempt to load invisible files on macOS such as .DS_Store files as jpegs and cause exceptions in image decode functions
• train_image_classifier does not appear to handle spaces in directory path names, and also attempts to iterate over invisible items such as .DocumentRevisions-V100 (which of course is only an issue if Volume paths with spaces are used).

Im likely missing some basic python understanding, or perhaps some of my issue is an interplay with the nuances of OS X, the OS X installed Python and testing not happening on OS X - but its definitely an issue for folks trying to do work on OS X setting up inference and tuning / retraining end portions of graphs.

### Source code / logs

I don't think I need to include any source, but will try to oblige should anything be requested. Hopefully this isn't an embarrassingly obvious oversight on my part! 

Thank you in advance for taking the time to look this over.",0,,5,2017-06-30T17:24:29Z,CONTRIBUTOR
11182,Quantize weights causes accuracy to plunge when run in mobile but not in computers?,"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
```
/home/kwotsin/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=./frozen_inception_resnet_v2_for_mobile.pb \
--out_graph=./quantized_inception_resnet_v2_for_mobile_NEW.pb \
--inputs='Placeholder_only' \
--outputs='InceptionResnetV2/Logits/Predictions' \
--transforms='
  add_default_attributes
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  strip_unused_nodes
  sort_by_execution_order'
```

### Describe the problem
Using the above quantization method, the quantization tool works so well that there is hardly a noticeable difference in accuracy drop (less than 0.5%) for a model like inception v3, with a 1/4 size reduction and slightly faster speed. However, when using the exact same files to be run on mobile, the performance gets so poor that there's more than 70-80% accuracy decrease. I'm unsure whether the issue lies with the quantization not getting optimized on mobile architectures (ARM instead of the usual desktop amd architecture), or whether there is a problem in the operations for the tensorflow mobile library.

Note that `quantize_nodes` is totally unusable. When used to quantize the model, the model size increases a little and then causes the app to crash instantly. The error log produced when using quantize_nodes is this:

```
07-01 00:07:01.760 28272-28357/com.mindorks.tensorflowexample E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)
07-01 00:07:03.508 28272-28357/com.mindorks.tensorflowexample A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 28357 (pool-1-thread-1)
```

Also, for almost every model I ran, the following error appeared:
`No implementation found for long org.tensorflow.contrib.android.RunStats.allocate()`
What does this mean and how could I resolve it?

FYI: Not sure if it makes a difference, but when I built my lib_tensorflow_inference.so file and the JAR file for using the TF library on mobile, the tensorflow version was cloned from the master branch and not git checked out. Would this make a difference?

Further weird phenomenon:

Although I built my TF from source and bazel built the graph transform tool, the following warnings still appear:

```
2017-07-01 00:05:19.612228: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612262: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612278: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612282: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-01 00:05:19.612290: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
```

Thank you.",1,,25,2017-06-30T16:09:20Z,CONTRIBUTOR
11171, [Feature] Node mirroring for GPU-memory reduction,"stat:awaiting response,type:feature","In the paper [Training Deep Nets with Sublinear Memory Cost](https://arxiv.org/abs/1604.06174) Chen et al. introduced a very good idea to greatly reduce GPU memory requirements. 

The idea bowls down to discarding the output of some nodes during the forward pass and recompute those values when they are needed again in the backward pass. Only the output of some key ops is kept in memory. During back-prop all forward computation from those key nodes are redone. They also describe how this can be implemented in a graph based computation model by mirroring non-key ops. This is depicted in figure 3 (see below).

Performing this kind of graph manipulation in [MxNet](https://github.com/dmlc/mxnet) is quite easy and I have played around with this myself. I am able to reduce the memory cost of a SotA segmentation model from `13504 MB` to `3382 MB` for the cost of about ~40% increase in computational time. (Given that we have plenty 1080 TI and view P100 GPUs, I am very happy to pay this cost).

For me as deep learning researcher this is a totally awesome killer feature. In most of my experiments I am limited by the amount of available GPU memory. Doing node mirroring allows me to try a whole bunch of new stuff, I was always wanting to do. 

1. Is anything like this planned to be implemented in Tensorflow any time soon?
2. In the current API, is there already a way to build and / or manipulate the computational graph to perform node mirroring (like in figure 3)?

![](https://i.imgur.com/CnkUzwJ.png)

Regarding question two, I don't mind if it gets messy. Copying some nodes inside the graph is possible in tensorflow. Gradient flow can also be stopped for the first copy. What is missing is to utilize the second node for gradient computation. I don't know how I can archive this using the python API in tensorflow. Any ideas with this?

",0,,22,2017-06-30T11:24:18Z,NONE
11165,"[feature-request] Multi-arity elems in fold{l,r}","stat:contributions welcome,type:feature","The functions ```fold{l,r}``` that are part of ```tensorflow.python.ops.functional_ops``` currently only allow single-arity arguments for ```elems```. This makes it inconvenient for writing operations that involve dynamic concatenation of tensors differing in the dimension along a particular axis without padding (this also means one can't use ```tf.map_fn``` for accomplishing this task).

This scenario is present in cases like object detection where a different number of boxes are emitted for each image in the batch. Currently, the implementation in tensorflow/models (```tensorflow-models:object_detection/core/post_processing.py```) gets around this by fixing the batch size and using ```tf.split``` during graph compilation time. The requested op would make such scenarios dynamic; it would also be the way forward in making ```tf.dynamic_partition``` ..erm, more dynamic (without introducing a List into Tensorflow's semantics).

I currently resort to something like the following,
``` python
zeroq = tf.constant(0) - tf.constant(0)
nkeeps_0 = tf.zeros([zeroq], dtype=tf.int32); keeps_0 = tf.zeros([zeroq], dtype=tf.int32)  
def _compute(ii, nkeeps_r, keeps_r):
  keep_ii = <function that spits a varying tensor of shape [M_ii]>
  return (ii + 1, tf.concat([nkeeps_r, tf.stack([tf.shape(keep_ii)[0]])], axis=0), tf.concat([keeps_r, keep_ii], axis=0))
_, *ret = control_flow_ops.while_loop(lambda ii, *_: ii < bsize, _compute, [tf.constant(0), nkeeps_0, keeps_0], back_prop=False)
```
I'm not sure how this will play with ```back_prop=True```, or as to how this would fit in with the larger goals for the project.",0,,1,2017-06-30T05:20:51Z,NONE
11164,Expose reader.read_up_to in slim parallel reader,"stat:contributions welcome,type:feature","When reading small records (in my case, one example is a a floatlist of about 150 floats), the DataSetProvider from slim is very slow. I found out that things get much faster if I write a custom input pipeline that leverages reader.read_up_to 

```python
def ReadTFRecord(filename_queue):
  num_tfrecords_at_once = 1024 
  reader = tf.TFRecordReader()
  _, queue_batch = reader.read_up_to(filename_queue, num_tfrecords_at_once)
  return [queue_batch]
```
the returned value is then fed to `tf.train.shuffle_batch` with enqueue_many set to true. 

As far as I understand, this behavior is currently not exposed in slim.ParallelReader, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/parallel_reader.py#L132. Are there any plans for adding it?",0,,5,2017-06-30T04:19:10Z,CONTRIBUTOR
11157,TypeError: can't pickle _thread.lock objects,stat:awaiting tensorflower,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, using stock examples
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.2.1
- **Python version**: 3.6.1 (Anaconda 4.4.0 64-bit)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: I'm running the seq2seq example in models/tutorials/rnn/translate, verbatim.

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

Collecting system information...
2017-06-29 18:35:16.672194: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 18:35:16.672242: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 18:35:16.672250: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Wrote environment to tf_env.txt. You can review the contents of that file.
and use it to populate the fields in the github issue template.

cat tf_env.txt

== cat /etc/issue ===============================================
Linux GCRGDL171 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux GCRGDL171 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.3.0)
tensorflow (1.2.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda:/usr/local/cuda/lib64:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Jun 29 18:35:19 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K40m          Off  | 0000:27:00.0     Off |                    0 |
| N/A   27C    P8    21W / 235W |      0MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I get exception: TypeError: can't pickle _thread.lock objects. It happens on different machines with the same python version. Just running your example code verbatim. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Traceback (most recent call last):
  File ""translate.py"", line 322, in <module>
    tf.app.run()
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""translate.py"", line 319, in main
    train()
  File ""translate.py"", line 178, in train
    model = create_model(sess, False)
  File ""translate.py"", line 136, in create_model
    dtype=dtype)
  File ""/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py"", line 179, in __init__
    softmax_loss_function=softmax_loss_function)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py"", line 1206, in model_with_buckets
    decoder_inputs[:bucket[1]])
  File ""/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py"", line 178, in <lambda>
    lambda x, y: seq2seq_f(x, y, False),
  File ""/home/t-mabruc/models/tutorials/rnn/translate/seq2seq_model.py"", line 142, in seq2seq_f
    dtype=dtype)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py"", line 848, in embedding_attention_seq2seq
    encoder_cell = copy.deepcopy(cell)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 161, in deepcopy
    y = copier(memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 476, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 215, in _deepcopy_list
    append(deepcopy(a, memo))
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/home/t-mabruc/anaconda3/lib/python3.6/copy.py"", line 169, in deepcopy
    rv = reductor(4)
TypeError: can't pickle _thread.lock objects",0,,37,2017-06-30T01:38:11Z,NONE
11155,head.py still uses scalar_summary,"stat:contributions welcome,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.5
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.2.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
head.py still uses `logging_ops.scalar_summary` despite the method being a depreciated, leading to warnings. The problem seems to start from `estimator.fit` and `estimator.evaluate`

### Source code
```
import tensorflow as tf
# NumPy is often used to load, manipulate and preprocess data.
import numpy as np

# Declare list of features. We only have one real-valued feature. There are many
# other types of columns that are more complicated and useful.
features = [tf.contrib.layers.real_valued_column(""x"", dimension=1)]

# An estimator is the front end to invoke training (fitting) and evaluation
# (inference). There are many predefined types like linear regression,
# logistic regression, linear classification, logistic classification, and
# many neural network classifiers and regressors. The following code
# provides an estimator that does linear regression.
estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)

# TensorFlow provides many helper methods to read and set up data sets.
# Here we use two data sets: one for training and one for evaluation
# We have to tell the function how many batches
# of data (num_epochs) we want and how big each batch should be.
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x_train}, y_train,
                                              batch_size=4,
                                              num_epochs=1000)
eval_input_fn = tf.contrib.learn.io.numpy_input_fn(
    {""x"":x_eval}, y_eval, batch_size=4, num_epochs=1000)

# We can invoke 1000 training steps by invoking the  method and passing the
# training data set.
estimator.fit(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did.
train_loss = estimator.evaluate(input_fn=input_fn)

eval_loss = estimator.evaluate(input_fn=eval_input_fn)

print ""train loss: %r""% train_loss
print ""eval loss: %r""% eval_loss
```

### Logs
```
WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1l/v82bx7_s5zvf7z8wlgjz4j_06gd09g/T/tmpQRR2VF
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
2017-06-29 16:53:02.952908: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952925: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952930: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952934: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
train metrics: {'loss': 9.803332e-07, 'global_step': 1000}
eval metrics: {'loss': 0.0026192721, 'global_step': 1000}
```
",0,,1,2017-06-29T23:58:32Z,CONTRIBUTOR
11149,Self-contained source code package of tensorflow,"stat:contributions welcome,type:build/install","Dear TensorFlow development team,
    Government regularization on medical software requires software to be compiled from fully controllable source code. Downloading from outside of the manufacture is not permitted. This literally implies that medical software should be able to compile without Internet connection. Currently, the bazel compilation procedure download from Internet. We post this request for a self-contained package of tensorflow.

",0,,2,2017-06-29T21:07:15Z,NONE
11148,TFDBG Crashing on Windows 10; 'Causality Violated in Timing Relations of Debug Dumps',,"I started using TensorFlow and wrote a simple Siamese neural net. I wrote a small script to test the network, and got NaNs for loss, so I decided to learn how to use tfgbd. 

But when I run tfgbd, it crashes with the error 'Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]'

------------------------

-Windows 10, up to date
-Python 3.5
-TensorFlow 1.2.0, compiled in CPU-only mode

Source Code:
I have one script to define the network and one to run the actual test. I will include both.

sameDiffNet:

```
import tensorflow as tf

class SameDiffNet:
	# class is a siamese FC network for classifying vectors as same/different
	
	def __init__(self,inputLen):
		# settings
		self.NUM_BRANCHES = 2
		self.LAYER_SIZES = [100,100]
		self.DATA_TYPE = tf.float32
		
		# input
		self.inputs = []
		for branch in range(self.NUM_BRANCHES):
			self.inputs.append(tf.placeholder(self.DATA_TYPE,[None,inputLen]))

		# network branches
		self.branches = []
		self.branchWeights = self.branch_weights(inputLen)
		for branch in range(self.NUM_BRANCHES):
			self.branches.append(self.network_branch(branch))
				
		# combination layer and loss
		self.out = self.distance_layer_euclidean()
		self.target = tf.placeholder(self.DATA_TYPE,None)
		self.loss = self.cross_entropy_loss()
		
	def branch_weights(self,inputLen):
		# weights are shared, so they are computed once and re-used to make multiple graphs
		# They are stored as a dictionary of arrays for flexible layer shapes and sizes
		netWeights = {""weights"": [], ""bias"": []}
		netWeights[""weights""].append(tf.Variable(tf.random_normal([inputLen,self.LAYER_SIZES[1]]),name=""weights""))
		netWeights[""bias""].append(tf.Variable(tf.zeros([self.LAYER_SIZES[0]]),name=""bias""))
		
		for layer in range(1,len(self.LAYER_SIZES)):
			netWeights[""weights""].append(tf.Variable(tf.random_normal([self.LAYER_SIZES[layer-1],self.LAYER_SIZES[layer]]),name=""weights""))
			netWeights[""bias""].append(tf.Variable(tf.zeros([self.LAYER_SIZES[layer]]),name=""bias""))
		
		return netWeights
		
	def network_branch(self,branch):
		fc = self.inputs[branch]
		for layer in range(len(self.LAYER_SIZES)):
			fc = tf.nn.relu(tf.nn.bias_add(tf.matmul(fc,self.branchWeights[""weights""][layer]), self.branchWeights[""bias""][layer]))
		return fc
			
	def distance_layer_euclidean(self):
		assert self.NUM_BRANCHES == 2
		dist = tf.subtract(1.0,tf.nn.sigmoid(tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.branches[0],self.branches[1]),2),1))))
		return dist
		
	def cross_entropy_loss(self):
		loss = tf.add(tf.multiply(self.target,tf.log(self.out)),tf.multiply(1-self.target,tf.log(1-self.out)))
		return loss`
```

toyTestTraining:
```
''' A simple test where we train our siamese network on toy examples
Our training data consists of a pair of 0's and 1's, and our truth output will
simply be the XOR of these two values'''

import numpy as np
import tensorflow as tf
from tensorflow.python import debug as tf_debug
from sameDiffNet import SameDiffNet

numTraining = 1000
numIter = 1000

sess = tf.InteractiveSession()
sess = tf_debug.LocalCLIDebugWrapperSession(sess)
sess.add_tensor_filter(""has_inf_or_nan"", tf_debug.has_inf_or_nan)
network = SameDiffNet(2)
optimizer = tf.train.AdamOptimizer().minimize(network.loss)

data = np.random.randint(0,2,(numTraining,2))
truth = data[:,0] == data[:,1]
truth = [float(not truth[b]) for b in range(numTraining)]
data = data.astype(float)

init = tf.global_variables_initializer().run()
for iter in range(numIter):
	permutationL = np.random.permutation(numTraining)
	permutationR = np.random.permutation(numTraining)
	target = [float(truth[permutationL[i]] == truth[permutationR[i]]) for i in range(numTraining)]

	totalLoss = 0.0
	for v in range(numTraining):
		_, loss = sess.run([optimizer,network.loss], feed_dict={
						network.inputs[0]:[data[permutationL[v],:]],
						network.inputs[1]:[data[permutationR[v],:]],
						network.target: target[v]})
		totalLoss += loss
		
	if np.isnan(totalLoss):
		print('Model diverged with loss = NaN')
		quit()

	if iter % 10 == 0:
		print ('step %d: loss %.3f' % (iter, totalLoss/numTraining))
```


import toyTestTraining opens tfgbd. I enter 'run' at the first pause, and get the following error dump:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Computer Vision\Siamese Same-Different Network\toyTestTraining.py"", line 35, in <module>
    network.target: target[v]})
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\wrappers\framework.py"", line 495, in run
    run_end_resp = self.on_run_end(run_end_req)
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\wrappers\local_cli_wrapper.py"", line 312, in on_run_end
    self._dump_root, partition_graphs=partition_graphs)
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\lib\debug_data.py"", line 551, in __init__
    self._load_partition_graphs(partition_graphs, validate)
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\lib\debug_data.py"", line 809, in _load_partition_graphs
    self._validate_dump_with_graphs()
  File ""C:\Users\Christopher\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\lib\debug_data.py"", line 985, in _validate_dump_with_graphs
    (node, datum.timestamp, repr(pending_inputs[node])))
ValueError: Causality violated in timing relations of debug dumps: gradients/sub_1_grad/Shape_1 (1498762743063952): these input(s) are not satisfied: [('Sub_1', 0)]


This error happens 100% of the time I run these commands.
I apologize in advance if I'm overlooking something obvious. Thank you.",1,,4,2017-06-29T19:20:06Z,NONE
11144,MultiRNNCell cannot stack PhasedLSTMCell,type:feature,"### System information
 **TensorFlow version (use command below)**: 1.2

### Describe the problem
tf.contrib.rnn.PhasedLSTMCell takes a tuple of tensors as inputs (time and features).

but the tf.nn.rnn_cell.MultiRNNCell reuse the output of a cell to feed the next one:

`cur_inp, new_state = cell(cur_inp, cur_state)`

### Source code / logs

Something like that works.

[https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn_cell_impl.py](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn_cell_impl.py)

```
902c902,903
<     cur_inp = inputs
---
>     times = inputs[0]
>     cur_inp = inputs[1]
916c917
<         cur_inp, new_state = cell(cur_inp, cur_state)
---
>         cur_inp, new_state = cell((times, cur_inp), cur_state)
```

Not sure whether it is a bug report or a feature request (for a dedicated MultiPhasedLSTMCell) though...",1,,19,2017-06-29T17:11:29Z,NONE
11138,Hang when fitting tensorflow learn model which contains crossed sparse_column_with_* columns and the data is loaded with pandas_input_fn,type:bug/performance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Run on Databricks GPU cluster (Ubuntu 16.04.1 LTS)
- **TensorFlow installed from (source or binary)**: pip installed tensorflow-gpu
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: CUDA: Version 8.0, cuDNN: Version 5.1 for CUDA 8.0
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

When building Linear models with the tensorflow learn libraries the program hangs if the pandas input function (tensorflow.estimator.inputs.pandas_input_fn) is used and a crossed_column (tensorflow.contrib.layers.crossed_column) is constructed from a sparse_column_with_\*. This issue is not seen in the tensorflow tutorials as they use constant tensor's to input the data which does not scale to large datasets. This also only occurs if crossing sparse_column_with_\* columns, bucketized continuous columns do not cause a hang.

The final line of output before the code hangs is: `INFO:tensorflow:Create CheckpointSaverHook.`

### Source code / logs

Minimum working example of bug (with example of code that works and code that breaks):

```python
import pandas as pd
import tensorflow as tf

# Some sample data
df = pd.DataFrame({'label' : [0,1,1,0], 'con1' : [10,20,30,40], 'con2' : [1,4,9,16], 'cat1' : ['a','a','b','b'], 'cat2' : ['c','d','c','d']})

# Sparse base columns
from tensorflow.contrib.layers import sparse_column_with_keys, sparse_column_with_hash_bucket
sparse_cat1 = sparse_column_with_keys('cat1', keys=['a','b'])
sparse_cat2 = sparse_column_with_hash_bucket('cat2', hash_bucket_size=10)

# Bucketised columns
from tensorflow.contrib.layers import real_valued_column, bucketized_column
bucket_con1 = bucketized_column(real_valued_column('con1'), boundaries=[5,15,25,35])
bucket_con2 = bucketized_column(real_valued_column('con2'), boundaries=[5,15,25,35])

# Crossed columns
from tensorflow.contrib.layers import crossed_column
# This works with both inputs:
cross_bb = crossed_column([bucket_con1, bucket_con2], hash_bucket_size=100)
# Both these hang with pandas input:
cross_cc = crossed_column([sparse_cat1, sparse_cat2], hash_bucket_size=100)
cross_bc = crossed_column([bucket_con1, sparse_cat1], hash_bucket_size=100)

feature_columns = [sparse_cat1, sparse_cat2, cross_bb, cross_cc, cross_bc]
model = tf.contrib.learn.LinearClassifier(feature_columns=feature_columns)

# Use pandas input - doesn't work
train_gen_fun = tf.estimator.inputs.pandas_input_fn(df, batch_size=len(df), num_epochs=None, shuffle=True)
# Split out the label from the features
def input_fn1(gen) :
  features = gen()
  target = features.pop('label')
  return features, target

# Use constant input - does work
def input_fn2(df):
  feature_cols = {
    'con1' : tf.constant(df['con1'].values),
    'con2' : tf.constant(df['con2'].values),
    'cat1' : tf.SparseTensor(indices=[[i, 0] for i in range(df['cat1'].size)],
                             values=df['cat1'].values, dense_shape=[df['cat1'].size, 1]),
    'cat2' : tf.SparseTensor(indices=[[i, 0] for i in range(df['cat2'].size)],
                             values=df['cat2'].values, dense_shape=[df['cat2'].size, 1]),
  }
  label = tf.constant(df['label'].values)
  return feature_cols, label

# This hangs
model.fit(input_fn=lambda:input_fn1(train_gen_fun), steps=10)

# This works
model.fit(input_fn=lambda:input_fn2(df), steps=10)
```
",1,,7,2017-06-29T11:56:41Z,NONE
11113,Add cosine annealing for learning rate decay,"stat:contributions welcome,type:feature","[SGDR: Stochastic Gradient Descent With Warm Restarts](https://openreview.net/pdf?id=Skq89Scxx), proposes decaying the learning rate according to

![image](https://user-images.githubusercontent.com/2202312/27641761-1bf302c8-5c1d-11e7-8d4b-15988701ff3f.png)


where ![image](https://user-images.githubusercontent.com/2202312/27641775-28b4e0a8-5c1d-11e7-8adc-1dcaea55d77c.png) is the minimum step length, ![image](https://user-images.githubusercontent.com/2202312/27641798-3be6a80a-5c1d-11e7-9b41-d3c25b0b2b96.png) is the maximum step length, ![image](https://user-images.githubusercontent.com/2202312/27641818-4686daf0-5c1d-11e7-8991-533ce8710e8f.png) is the global step and ![image](https://user-images.githubusercontent.com/2202312/27641841-5594f2ac-5c1d-11e7-9f54-e3cc8ccd1566.png) is the maximum number of iterations.

I've personally found this strategy to  be easy to use given that the number of hyperparameters is relatively small and results are good.

Is this something we want added to tensorflow? Would you accept submissions?



",0,,6,2017-06-28T14:19:58Z,NONE
11101,Negative indices support for tf.gather,stat:awaiting response,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.06
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.2.0
- **Bazel version (if compiling from source)**: 5.2
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

`tf.gather` does not support negative indices yet. I have implemented this feature. If you are okay with this feature, then can I create a pull request?",1,,5,2017-06-28T08:36:50Z,CONTRIBUTOR
11095,Symbol not found with adding new op,stat:awaiting tensorflower,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac Sierra
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**:
- **Exact command to reproduce**: python test.py

### Describe the problem
Created a custom op, but cannot import it from python. Error at command line:

```
tensorflow.python.framework.errors_impl.NotFoundError: dlopen(src/./ops/build/preprocessing.so, 6): Symbol not found: __ZN10tensorflow14AugmentFunctorIN5Eigen9GpuDeviceEEclERKS2_iiiiiiiPKfPfS7_
  Referenced from: src/./ops/build/preprocessing.so
  Expected in: flat namespace
 in src/./ops/build/preprocessing.so

```

### Source code / logs
Makefile
```
TF_INC = `python -c ""import tensorflow; print(tensorflow.sysconfig.get_include())""`

ifndef CUDA_HOME
    CUDA_HOME := /usr/local/cuda
endif

CC        = gcc -O2 -pthread
CXX       = g++
GPUCC     = nvcc
CFLAGS    = -std=c++11 -I$(TF_INC) -I""$(CUDA_HOME)/include"" -DGOOGLE_CUDA=1
GPUCFLAGS = -c
LFLAGS    = -pthread -shared -fPIC
GPULFLAGS = -x cu -Xcompiler -fPIC
CGPUFLAGS = -L$(CUDA_HOME)/lib -L$(CUDA_HOME)/lib64 -lcudart -undefined dynamic_lookup

OUT_DIR   = src/ops/build
PREPROCESSING_SRC = ""src/ops/preprocessing/preprocessing.cc"" ""src/ops/preprocessing/kernels/data_augmentation.cc""
GPU_SRC_DATA_AUG  	= ""src/ops/preprocessing/kernels/data_augmentation.cu.cc""
GPU_PROD_DATA_AUG 	= $(OUT_DIR)/data_augmentation.o
PREPROCESSING_PROD	= $(OUT_DIR)/preprocessing.so

preprocessing:
	$(GPUCC) -g $(CFLAGS) $(GPUCFLAGS) $(GPU_SRC_DATA_AUG) $(GPULFLAGS) $(GPUDEF) -o $(GPU_PROD_DATA_AUG)
	$(CXX) -g $(CFLAGS)  $(PREPROCESSING_SRC) $(GPU_PROD_DATA_AUG) $(LFLAGS) $(CGPUFLAGS) -o $(PREPROCESSING_PROD)

```

test.py
```
import tensorflow as tf
_preprocessing_ops = tf.load_op_library(
    tf.resource_loader.get_path_to_datafile(""./ops/build/preprocessing.so""))
```

data_augmentation.h
```
#ifndef FLOWNET_DATA_AUGMENTATION_H_
#define FLOWNET_DATA_AUGMENTATION_H_

namespace tensorflow {
template<typename Device>
struct AugmentFunctor {
  void operator()(const Device& d);
};
} // namespace tensorflow
#endif // FLOWNET_DATA_AUGMENTATION_H_
```

data_augmentation.cc
```
#define EIGEN_USE_THREADS

#include ""data_augmentation.h""
#include ""tensorflow/core/framework/op_kernel.h""

namespace tensorflow {
typedef Eigen::ThreadPoolDevice CPUDevice;
typedef Eigen::GpuDevice        GPUDevice;

template<>
struct AugmentFunctor<CPUDevice>{
  void operator()(const CPUDevice& d) {
    // CPU implementation here
  }
};

template<typename Device>
class DataAugmentation : public OpKernel {
  public:
    explicit DataAugmentation(OpKernelConstruction *ctx) : OpKernel(ctx) {}

    void Compute(OpKernelContext *ctx) override {
      // Perform augmentation either on CPU or GPU
      AugmentFunctor<Device>()(ctx->eigen_device<Device>());
    }
};

REGISTER_KERNEL_BUILDER(Name(""DataAugmentation"")
                        .Device(DEVICE_CPU),
                        DataAugmentation<CPUDevice>)

#if GOOGLE_CUDA

REGISTER_KERNEL_BUILDER(Name(""DataAugmentation"")
                        .Device(DEVICE_GPU),
                        DataAugmentation<GPUDevice>)
#endif // GOOGLE_CUDA
} // namespace tensorflow
```
data_augmentation.cu.cc
```
#if GOOGLE_CUDA

#define EIGEN_USE_GPU

#include ""augmentation_base.h""
#include ""data_augmentation.h""
#include ""tensorflow/core/util/cuda_kernel_helper.h""

namespace tensorflow {
__global__ void SpatialAugmentation() {
   // CUDA kernel code goes here
}

template<>
struct AugmentFunctor<GPUDevice>{
  void operator()(const GPUDevice& d) {
    // GPU implementation goes here
    CudaLaunchConfig config = GetCudaLaunchConfig(10, d);
    SpatialAugmentation<<<config.block_count, config.thread_per_block, 0, d.stream()>>>(config.virtual_thread_count);
  }
};

typedef Eigen::GpuDevice GPUDevice;
template struct AugmentFunctor<GPUDevice>;
} // namespace tensorflow
```",0,,3,2017-06-28T02:49:59Z,NONE
11092,"conv2d on CPU does not pass numerical gradient check, possibly because the forward has an offset but the backward not when padding values are negative.",,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
conv2d (CPU version) gradient function does not pass my gradient check tests when performing 'SAME' convolution in some special cases.
See my code below for details.

TensorFlow uses eigen_spatial_convolution.h and eigen_backward_spatial_convolution.h for performaing conv2d on CPU.
The possible reason is that in this case the padding will be negative. During forward the eigen function SpatialConvolution will apply this negative padding as an offset. However, in backward, it does not apply this offset -- the forward and backward are inconsistent. 

### Source code / logs
```python
import tensorflow as tf
import numpy as np
bH = 4 
bW = 4 
H = 2 
W = 2    
in_c = 2 
out_c = 3 

stride = 4 
batch_size = 2 
batch_data  = np.ones([batch_size, bH, bW, in_c])
for n in range(batch_size):
  for c in range(in_c):
    for h in range(bH):
      for w in range(bW):
        batch_data[n, h, w, c] = n*0.001 + c*0.002 + h*0.003 + w*0.004   
    
batch = tf.placeholder(tf.float32, [2, bH, bW, 2]) 
f = tf.placeholder(tf.float32, [H, W, in_c, out_c])
output = tf.nn.conv2d(batch, f, strides = [1, stride, stride, 1], padding = 'SAME')
s = tf.reduce_sum(output)
grad_y = tf.gradients(s, f)
init = tf.global_variables_initializer()

alpha = 5e-4 
with tf.Session() as sess:
  sess.run(init)
  filters = np.ones([H, W, in_c, out_c], dtype = float)
  result, grads = sess.run([s, grad_y], feed_dict = {batch: batch_data, f: filters})
  print(result)
  for n in range(out_c):
    for c in range(in_c):
      for h in range(H):
        for w in range(W):
          old = filters[h, w, c, n]
          filters[h, w, c, n] = old - alpha
          [result_left] = sess.run([s], feed_dict = {batch: batch_data, f: filters}) 
          filters[h, w, c, n] = old + alpha
          [result_right] = sess.run([s], feed_dict = {batch: batch_data, f: filters})
          filters[h, w, c, n] = old 
          grad_est = (result_right - result_left) / (2 * alpha)
          grad_act = grads[0][h, w, c, n]
          print(""(%d,%d,%d,%d): %f, %f"" % (n, c, h, w, grad_act, grad_est))
```
```
2017-06-27 18:16:36.858424: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858460: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858464: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858468: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-27 18:16:36.858472: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
0.576
(0,0,0,0): 0.001000, 0.014961
(0,0,0,1): 0.009000, 0.023007
(0,0,1,0): 0.007000, 0.020981
(0,0,1,1): 0.015000, 0.028968
(0,1,0,0): 0.005000, 0.018954
(0,1,0,1): 0.013000, 0.027061
(0,1,1,0): 0.011000, 0.024974
(0,1,1,1): 0.019000, 0.033021
(1,0,0,0): 0.001000, 0.014961
(1,0,0,1): 0.009000, 0.023007
(1,0,1,0): 0.007000, 0.020981
(1,0,1,1): 0.015000, 0.028968
(1,1,0,0): 0.005000, 0.018954
(1,1,0,1): 0.013000, 0.027001
(1,1,1,0): 0.011000, 0.024974
(1,1,1,1): 0.019000, 0.033021
(2,0,0,0): 0.001000, 0.014961
(2,0,0,1): 0.009000, 0.023007
(2,0,1,0): 0.007000, 0.020981
(2,0,1,1): 0.015000, 0.028968
(2,1,0,0): 0.005000, 0.018954
(2,1,0,1): 0.013000, 0.027001
(2,1,1,0): 0.011000, 0.024974
(2,1,1,1): 0.019000, 0.033021
```

",1,,8,2017-06-27T22:19:39Z,NONE
11087,[feature] Option to Selectively Disable Certain Graph Optimizations,"stat:contributions welcome,type:feature","repost from: https://github.com/tensorflow/tensorflow/commit/999b794c137d12d73adbf41dcbe9383a0cd94769#commitcomment-22789669 (CC @petewarden).

On iOS when using a graph that has been ""memory mapped"", you want to disable constant folding to prevent the optimization pass from copying all of the weight data. The current way to do so is to set optimization [level `L0` which disables all optimizations](https://github.com/tensorflow/tensorflow/blob/12f033df4c8fa3feb88ce936eb1581eaa92b303e/tensorflow/core/protobuf/config.proto#L101-L102). Ideally there is a way to keep Common subexpression elimination and function inlining, but prevent constant folding.",0,,1,2017-06-27T18:35:37Z,CONTRIBUTOR
11085,Tensorflow - Metal Support for Mac OS,"stat:contributions welcome,type:feature","Hello!
I have seen and read some requests for OpenCL support and GPU support on Mac OS, this seems to have been abandoned, am I correct?
But it also seems like Apple is really trying to make Metal big, is this something you have thought of implementing? I understand its not just made by thinking of it, but I would just like to know if any progress is made with GPU support for Mac OS?

- Konrad",0,,18,2017-06-27T16:20:47Z,NONE
11076,"Is it possible to add a feature to tf.Print , so that it will be capable to save tensor value to file?","stat:contributions welcome,type:feature","Since the while_loop operation is hard to debug, usually we use `tf.Print` to visual tensors in the loop. but `tf.Print` only print a summarization of a tensor. Sometimes I need to get all the value in a tensor, and it is not possible to use `sess.run()` to eval the intermediate tensor value in a loop unless use `TensorArray`. any body would add a **save-to-file** option in `tf.Print` .",0,,3,2017-06-27T06:37:20Z,CONTRIBUTOR
11071,non-chief worker stuck in distributed SYNC mode for graph with two optimizers,stat:awaiting tensorflower,"Seems distributed tensorflow cannot train graph with two optimizers in sync mode (one for local update, the other for ps update)

There are three parts in my graph: 
1. each worker has its own copy of vars as the ps server, but are defined with local variable `collections=[tf.GraphKeys.LOCAL_VARIABLES]`, each worker has its own forward-backward loop based on the local vars and its own optimizer
2. (local variable - ps variable) as the gradient and apply to ps variable with SyncReplicasOptimizer.apply_gradients
3. broadcast the ps variable to the local variable

The three parts are run in this way: run subgraph 1 several times, then run subgraph 2 in distributed sync mode to update ps params and then run subgraph 3

### Source code / logs
```
    if args.job_name == 'ps':
        server.join()
    elif args.job_name == 'worker':
        is_chief = (args.task_index == 0)
        num_gpus = len(worker_spec)

        ps_device = '/job:ps/cpu:0'
        worker_device = '/job:worker/task:%d/gpu:0' % args.task_index
        with tf.device(
                tf.train.replica_device_setter(cluster=cluster, ps_device=ps_device, worker_device=worker_device)):
            global_step = tf.Variable(args.start_step, name='global_step', trainable=False)

            print 'building ps params'
            ps_tparams = init_tparams()

            print 'building local params'
            with tf.device(worker_device):
                worker_tparams = init_tparams(is_local=True)  # define variable in collection tf.GraphKeys.LOCAL_VARIABLES

            print 'building graph'

            print '-- local update'
            x, x_mask, y, y_mask, cost = build_graph(worker_tparams, config)
            opt = tf.train.MomentumOptimizer(config.lr, config.mr)
            updates = worker_tparams
            grads = tf.gradients(cost, updates, colocate_gradients_with_ops=True)
            clipped_grads, _ = tf.clip_by_global_norm(grads, config.clip_grads)
            train_op = opt.apply_gradients(zip(clipped_grads, updates))

            print '-- reduce average'
            ps_updates = ps_tparams
            avg_grads = [tf.sub(var, ps_var) for var, ps_var in zip(updates, ps_updates)]
            bopt = tf.train.MomentumOptimizer(config.blr, config.bmr, use_nesterov=True)
            bopt = tf.train.SyncReplicasOptimizerV2(bopt, replicas_to_aggregate=num_gpus, total_num_replicas=num_gpus)
            update_op = bopt.apply_gradients(zip(avg_grads, ps_updates), global_step=global_step)

            print '-- broadcast'
            broadcast_ops = []
            for kk, pp in ps_tparams.items():
                broadcast_ops.append(worker_tparams[kk].assign(pp).op)

            # Others related to sync mode
            chief_queue_runner = bopt.get_chief_queue_runner()
            sync_init_op = bopt.get_init_tokens_op()

            sv = tf.train.Supervisor(
                is_chief=is_chief,
                logdir=config.ckp,
                init_op=tf.global_variables_initializer(),
                local_init_op=tf.local_variables_initializer(),
                global_step=global_step)

            if is_chief:
                print('Worker %d: Initializing session' % args.task_index)
            else:
                print('Worker %d: Waiting for session to be initialized' % args.task_index)

            sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False,
                                         device_filters=['/job:ps', '/job:worker/task:%d' % args.task_index])
            with sv.managed_session(server.target, config=sess_config) as sess:
                print('Worker %d: Session initialization completed' % args.task_index)

                if is_chief:
                    # Chief worker will start the chief queue runner and call the init op
                    sess.run(sync_init_op)
                    sv.start_queue_runners(sess, [chief_queue_runner])
```
The non-chief works stuck at `sv.managed_session` and showing below message again and again:
`I tensorflow/core/distributed_runtime/master_session.cc:993] Start master session a4de1cec7011a62d with config:`
The code can run successfully when there is no local optimizer.

### System information
- Linux Ubuntu 14.04
- CUDA 8.0
- tf 0.12.0-rc1
- GPU: GeForce GTX 1080",1,,12,2017-06-27T02:36:57Z,NONE
11070,deadloop on replaying kernel when profiling DL network with nvprof ,type:build/install,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, use models from Keras ,e.g. VGG16
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0/5.1
- **GPU model and memory**:
Nvidia K40, 10G
- **Exact command to reproduce**:
nvprof -metrics flop_sp_efficiency python train_vgg
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The profiling process will end with a deadloop in replaying some kernels with prompt:
""Replaying kernel ""cgemm_sm35_ldg_tn_64x8x64x16x16""

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",1,,6,2017-06-27T01:39:42Z,NONE
11058,terminate called after throwing an instance of 'std::out_of_range' error when call made to tf.contrib.tensor_forest.random_forest.TensorForestEstimator.predict(),"stat:community support,type:support","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Installed with pip install tensorflow-gpu
- **TensorFlow version (use command below)**:
('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Bazel version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
5.1.10 for CUDA 8.0
- **GPU model and memory**:
name: GeForce GTX 1050 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.493
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.46GiB
- **Exact command to reproduce**:
python RandomForestTrainer.py ?? I'd be happy to upload my code
You can collect some of this information using our environment capture script:
Collecting system information...
2017-06-26 02:27:23.087673: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.087713: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.087720: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.087727: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-26 02:27:23.394076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1050 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.493
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.46GiB
2017-06-26 02:27:23.394119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-26 02:27:23.394126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-26 02:27:23.394144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0)
Wrote environment to tf_env.txt. You can review the contents of that file.
and use it to populate the fields in the github issue template.

cat tf_env.txt

== cat /etc/issue ===============================================
Linux Desktop 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Desktop 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
protobuf (3.3.0)
tensorflow-gpu (1.2.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.0
tf.GIT_VERSION = v1.2.0-rc2-21-g12f033d
tf.COMPILER_VERSION = v1.2.0-rc2-21-g12f033d
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/lib64/
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Mon Jun 26 02:27:24 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 105...  Off  | 0000:01:00.0      On |                  N/A |
|  0%   45C    P0    36W / 120W |    448MiB /  4031MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1164    G   /usr/lib/xorg/Xorg                             258MiB |
|    0     15045    G   ...el-token=7CE624E5F1863243374CB7B5F4C7B81C    72MiB |
|    0     20044    G   /usr/lib/xorg/Xorg                              41MiB |
|    0     25088    G   compiz                                          38MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7

### Describe the problem
I created and trained a classifier with the tf.contrib.tensor_forest.random_forest.TensorForestEstimator class, but when I try to use the predict() method I get the following error:

2017-06-26 02:30:13.003812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0)
terminate called after throwing an instance of 'std::out_of_range'
terminate called recursively
terminate called recursively
Aborted (core dumped)




",0,,1,2017-06-26T07:34:42Z,NONE
11055,Keras load model raises ValueError when loading optimizer weights,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I extended models_test.py to reproduce the bug
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 8.8
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.2.0-1106-g1f82b7a', '1.2.0')
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: nvidia Tesla K-80 / 11.17gb
- **Exact command to reproduce**: See test in PR

### Describe the problem
Upon calling keras.models.load_model(fn) against a file generated by keras.models.save_model() a ValueError is raised. I believe it could be related to using padding='same' in the Conv2D layer.

Traceback (most recent call last):
  File ""models_test.py"", line 166, in test_saving_cnn
    model = keras.models.load_model(fname)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/models.py"", line 316, in load_model
    model.optimizer.set_weights(optimizer_weight_values)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/optimizers.py"", line 95, in set_weights
    'provided weight shape ' + str(w.shape))
ValueError: Optimizer weight shape (512,) not compatible with provided weight shape (64,)

### Source code / logs
Please see PR below.
",1,,4,2017-06-26T03:18:08Z,NONE
11037,installation failed with Virtualenv ERROR:The executable is not functioning tensorflow,"stat:awaiting tensorflower,type:docs","Operating System: macOS Sierra 10.12.3
The version of virtualenv is 15.1.0 
issue like these:
`admindeMacBook-Air:~ admin$ virtualenv --system-site-packages ~/tensorflow`
`Using base prefix '//anaconda'`
`New python executable in /Users/admin/tensorflow/bin/python`
`dyld: Library not loaded: @loader_path/../lib/libpython3.5m.dylib`
`  Referenced from: /Users/admin/tensorflow/bin/python`
`  Reason: image not found`
`ERROR: The executable /Users/admin/tensorflow/bin/python is not functioning`
`ERROR: It thinks sys.prefix is '/Users/admin' (should be '/Users/admin/tensorflow')`
`ERROR: virtualenv is not compatible with this system or executable`

I have tried many ways like homebrew, upgrade py, but it does not work at all.
",0,,15,2017-06-24T23:29:19Z,NONE
11034,There should be tf.fill_like,"stat:contributions welcome,type:feature",,0,,3,2017-06-24T15:50:37Z,NONE
11000,Upgrade to jemalloc 5.0.0,"stat:contributions welcome,type:feature",Contributions welcome! (I won't have bandwidth to do this in the short-term.),0,,4,2017-06-23T01:13:17Z,OWNER
10984,Building Tensorflow on Windows with AVX2 enable not compiling,"stat:contributions welcome,type:feature","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorflow/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10. Intel Core i7-6600U
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**:1.2.0-rc0
- **Bazel version (if compiling from source)**:No
- **CUDA/cuDNN version**:No
- **GPU model and memory**:No
- **Exact command to reproduce**:

1. Set up toolchain for for 64-bit:
` vcvarsall amd64`
2. Invoked CMAKE
 `C:\Projects\tensorflow\tensorflow\contrib\cmake\build>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35\libs\python35.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2`
3. To build the PIP package
`MSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj`

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I'm opening a new issue as suggested in [issue 10199](https://github.com/tensorflow/tensorflow/issues/10199) to track AVX2 support on Windows.

I followed the instructions to built tensorflow on Windows using [CMAKE](https://github.com/tensorflow/tensorflow/tree/r0.12/tensorflow/contrib/cmake) and wanted to enable AVX2, but when it was time to build with MSBuild it returned 550 errors all similar to this:

`""C:\Projects\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj"" (default target) (7) -> (ClCompile target) -> c:\projects\tensorflow\third_party\eigen3\unsupported\eigen\cxx11\src\fixedpoint\packetmathavx2.h(274): error C3861: '_mm256_extract_epi16': identifier not found (compiling source file C:\Projects\tensorflow\tensorflow\core\framework\allocator_registry.cc) [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj] c:\projects\tensorflow\third_party\eigen3\unsupported\eigen\cxx11\src\fixedpoint\packetmathavx2.h(278): error C3861: '_mm256_extract_epi8': identifier not found (compiling source file C:\Projects\tensorflow\tensorflow\core\framework\allocator_registry.cc) [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj]`

All errors with the same code `C3861: identifier not found` regarding ` _mm256_extract_epi16` and `_mm256_extract_epi8`  
I do have` immintrin.h` in C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include but `_mm256_extract_epi8` and `_mm256_extract_epi16` are not defined in that file.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,2,2017-06-22T13:09:52Z,NONE
10982,python mnist_softmax_xla.py run failure,type:build/install,"Hi,
I run python mnist_softmax_xla.py and got below failure:

linux-swfm:~/workarea/test> python3 mnist_softmax_xla.py   
...
2017-06-22 20:02:52.685534: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (1): Tesla K40m, Compute Capability 3.5
2017-06-22 20:02:57.741927: F tensorflow/compiler/xla/service/algebraic_simplifier.cc:768] Check failed: user->operand(reshape_or_broadcast_operand_index) == reshape_or_broadcast (0x7f30cc012550 vs. 0x7f30cc021490)
Aborted

my tensorflow version is tensorflow-1.1.0
cuda sdk: 7.5
 ",1,,12,2017-06-22T12:09:14Z,NONE
10972,Tensorflow 1.2: FileWriter needs to be created after tf.text.summary ops?,type:bug/performance,"The following works and creates a tf.text.summary which I can find via tensorboard:

```
import tensorflow as tf
sess = tf.InteractiveSession()
summary_op = tf.summary.text('config/config', tf.convert_to_tensor('hello world'))
summary_writer = tf.summary.FileWriter('/tmp/tensorboard', sess.graph)
text = sess.run(summary_op)
summary_writer.add_summary(text, 0)
summary_writer.add_summary(text, 100)
summary_writer.add_summary(text, 200)
summary_writer.flush()
summary_writer.close()
```

![image](https://user-images.githubusercontent.com/6200749/27425155-c4a1199a-5737-11e7-89f8-9ae3bd4159b4.png)

If we change the order of the FileWriter and the summary_op above it does not log anything:

```
import tensorflow as tf
sess = tf.InteractiveSession()
summary_writer = tf.summary.FileWriter('/tmp/tensorboard', sess.graph)
summary_op = tf.summary.text('config/config', tf.convert_to_tensor('hello world'))
text = sess.run(summary_op)
summary_writer.add_summary(text, 0)
summary_writer.add_summary(text, 100)
summary_writer.add_summary(text, 200)
summary_writer.flush()
summary_writer.close()
```

![image](https://user-images.githubusercontent.com/6200749/27425124-a2af2926-5737-11e7-9daa-53cda286cc67.png)
",1,,15,2017-06-22T08:45:16Z,CONTRIBUTOR
10867,C++ api in Debug x64 mode not building for VS2015,stat:community support,"Hi,

I'm not sure if this is expected behaviour or a problem with the solution file generated by CMake, so my apologies if I'm writing in the wrong place.

I'm trying to build Tensorflow C++ API on Windows using VS2015, and so far I didn't have problems to build Release x64 binaries, which just required me to ensure that the toolset for 64 bits is in use when creating the def file (dump bin.exe and undname.exe in particular).

I could verify that the build works as expected, being able to load models saved in Python and perform inference successfully.

However, when building the debug x64 version of the .dll, I'm being blocked by the following error:

```
104>  tensorflow_static.vcxproj -> D:\out\Debug\tensorflow_static.lib
104>  symbols=1016688, taken=140782, dupes=3472
105>------ Build started: Project: tensorflow, Configuration: Debug x64 ------
105>  Building Custom Rule D:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt
105>  CMake does not need to re-run because D:/out/CMakeFiles/generate.stamp is up-to-date.
105>LINK : fatal error LNK1189: library limit of 65535 objects exceeded
========== Build: 104 succeeded, 1 failed, 1 up-to-date, 0 skipped ==========
```

Is there any workaround for this issue? Has anyone managed to build the debug version of the library? Is it possible at all?

From what I could google around, this linker issue is not easy to overcome, so feedback is most welcome.",0,,15,2017-06-20T20:35:36Z,NONE
10862,Bug: MultiRNNCell.state_size is a tuple,type:feature,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: 1080 Ti
- **Exact command to reproduce**: see below

### Describe the problem

Version 1:

The follow code will return LSTMStateTuple with `h` and `c`:

```python

        enc_cell = tf.contrib.rnn.LSTMCell(hidden_dim)

        enc_inp_len = np.array([seq_length_in for _ in range(batch_size)])

        ((encoder_fw_outputs,
          encoder_bw_outputs),
         (encoder_fw_final_state,
          encoder_bw_final_state)) = (
            tf.nn.bidirectional_dynamic_rnn(cell_fw=enc_cell,
                                            cell_bw=enc_cell,
                                            inputs=enc_inp,
                                            sequence_length=enc_inp_len,
                                            dtype=tf.float32)
            )
        encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)

        encoder_final_state_c = tf.concat(
            (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)

        encoder_final_state_h = tf.concat(
            (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)

        encoder_final_state = tf.contrib.rnn.LSTMStateTuple(
            c=encoder_final_state_c,
            h=encoder_final_state_h
        )
```

However, if I run the following MultiCellRNN:

```python
        enc_cells = []
        for i in range(0, encoder_depth):
            with tf.variable_scope('enc_RNN_{}'.format(i)):
                cell = tf.contrib.rnn.GRUCell(hidden_dim)  # Or LSTMCell(hidden_dim)
                cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)
                enc_cells.append(cell)
        enc_cell = tf.contrib.rnn.MultiRNNCell(enc_cells)

        ((encoder_fw_outputs,
          encoder_bw_outputs),
         (encoder_fw_final_state,
          encoder_bw_final_state)) = (
            tf.nn.bidirectional_dynamic_rnn(cell_fw=enc_cell,
                                            cell_bw=enc_cell,
                                            inputs=enc_inp,
                                            sequence_length=enc_inp_len,
                                            dtype=tf.float32)
            )

        # encoder_fw_final_state is a Tensor from the .c part of LSTMStateTuple
```

It will return state tensor(just the `c` part, not the `h` activation)",0,,10,2017-06-20T18:06:26Z,NONE
10842,Feature request: add more options to Luong attention,type:feature,"Currently, the best results of the Luong attention paper [(Minh-Thang Luong, Hieu Pham, Christopher D. Manning. ""Effective Approaches to Attention-based Neural Machine Translation."" EMNLP 2015.)](https://arxiv.org/abs/1508.04025) cannot be reproduced with the implementation of `tf.contrib.seq2seq.LuongAttention`. Features that are missing:

- **Local attention**: attend to a window of time steps, rather than to all of the time steps of the encoder output (global attention). The window size should be a hyperparameter that the user can tune.
- **Different scoring functions**: currently, the scoring function is limited to a dot products between each encoder output and the decoder output. The paper shows better results with ""general"" scoring (all of the encoder outputs are multiplied by one learnable matrix) and also explores the option of using Bahdanau-like scoring (concatenate and multiply by a learnable matrix, then apply tanh and take a dot product with a learnable vector).
- **Predictive alignments**: while the probability function can be replaced, it would be nice to add predictive alignment as a function, and make the implementation of both monotonic and predictive alignments behave well with local attention limited to a time window (changes shape of learnables).
- **Input-feeding approach**: (please correct me in this one if I am mistaken) the current implementation is missing the final step that computes a prediction by concatenating the context vector with the decoder output, weights them and applies tanh (let this be `s_t=tanh(W [c_t; h_t])`). Passing `s_t` through a softmax layer gives the prediction distribution, but passing it as is to the next input improved performance in the paper.

On a sidenote: it also seems to be that there is no difference in the key and query vectors between the Bahdanau and Luong attention mechanisms, when there should be. Bahdanau attention has a computation pathway starting from the previous decoder output `h_{t-1} -> a_t -> c_t -> h_t`, while Luong attention starts from the current output `h_t -> a_t -> c_t -> s_t`.",2,,7,2017-06-20T08:32:56Z,NONE
10837,Feature Request: Placeholder support for being set from an Op,stat:awaiting tensorflower,"Update: I thought on this some more, and perhaps if tf.Variable could directly support being set from an op with the transfer happening entirely on the C++ side that might cleanly and simply solve the problem.

Often it is not known immediately what kind of Op will be needed for input, but it would be preferable to specify that detail later without the overhead associated with transporting data in python. 

For example, it would be ideal to be able to define a full model for a task like ImageNet labeling with a LazyOp defined for the Input and Labels. Then later on the output of a `Dataset`, `RecordInput`, or `tf.placeholder` could be supplied to finalize the necessary connection.

This request is based on the comments of @fchollet at https://github.com/fchollet/keras/pull/6928#issuecomment-309552423.

",0,,10,2017-06-19T23:29:58Z,NONE
10827,version 1.2 doesn't show CUDA and cuDNN information,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **CUDA/cuDNN version**: CUDA 8.0, cuDNN 5.1
- **GPU model and memory**: GTX 970M, 3GB

### Describe the problem
In previous version, after importing tensorflow like `import tensorflow as tf` following output will be shown:
```
>>> import tensorflow as tf;
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.7.5 locally
```
However, after I installed CUDA and cuDNN, and then installed Tensorflow v1.2, I found there is NO output for `import tensorflow as tf` in python. And I cannot check whether gpu successfully uses CUDA or cuDNN.
I have checked my GPU as follows and GPU works well. I have tried the method in #566 to adjust `TF_CPP_MIN_LOG_LEVEL`, but it seems have no effect.
I suggest it would be great to include CUDA and cuDNN info when importing tensorflow.

```
>>> import tensorflow as tf
>>> sess = tf.Session()
2017-06-20 00:24:38.111017: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111060: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111074: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111086: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.111097: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 00:24:38.215890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-20 00:24:38.216159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 970M
major: 5 minor: 2 memoryClockRate (GHz) 1.038
pciBusID 0000:01:00.0
Total memory: 2.95GiB
Free memory: 2.63GiB
2017-06-20 00:24:38.216174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-20 00:24:38.216180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-20 00:24:38.216191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
```
",0,,23,2017-06-19T14:32:30Z,NONE
10824,Constant operator is not appropriate for variable initialize,"stat:contributions welcome,type:bug/performance","Tensorflow uses const tensor to initialize variables(for example ones_initializer, zeros_initializer and some optimizer slot creation), this will prevent `AssignOp `to transfer ownership from rhs to lhs and waster a lot of memory when variable shape is very large(for example sparse model). see #9823 #9742",0,,4,2017-06-19T12:20:35Z,CONTRIBUTOR
10804,Not possible to use tf.contrib.training.stratified_sample with a SparseTensor,"stat:awaiting tensorflower,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.2.0-rc2-21-g12f033d 1.2.0
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: - 
- **GPU model and memory**: -
- **Exact command to reproduce**: -

### Describe the problem
**Context**:
I set up an input pipeline that reads `tf.train.SequenceExample`. My dataset is quite unbalanced, so I used `tf.contrib.training.stratified_sample` to resample examples. 

**Problem**:
`tf.contrib.training.stratified_sample` works well with `tf.FixedLenFeature` (context_features) but it raises a `TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. ...` when applied to `tf.VarLenFeature` of sequence_features. 
Using `tf.sparse_tensor_to_dense()` is not applicable either, as it raises `ValueError: All shapes must be fully defined: ...`

**Statement**:
If it is not an intended behaviour, then I'd like to report a bug, as I don't see why `tf.SparseTensor` shouldn't be supported.
If `tf.contrib.training.stratified_sample` works as intended, then I'd like to request a feature of `tf.SparseTensor` support in online data resampling ops.
",0,,6,2017-06-18T02:37:58Z,CONTRIBUTOR
10788,Where is ios_examples?,,"Hi,

I'm trying to follow your iOS guide in the README, which tells me to use: tensorflow/contrib/ios_examples. 

But this folder is completely missing.

Can anyone advise? ",1,,4,2017-06-17T01:32:31Z,NONE
10785,Feature Request-Randomized Hashing,"stat:community support,type:feature","This is feature request to see if randomized hashing can be implemented to relevant part of the library to allow the option to be utilized for better computational resource utilization:

https://arxiv.org/abs/1602.08194",0,,4,2017-06-16T23:31:45Z,NONE
10768,Undefined Symbol Import error ,"stat:community support,type:build/install","Hi,

SO: Linux Mint 17 x64
Version 1.1
Compiling from source
Options: sycl (Opencl)
Python 2.7

_Using TensorFlow backend.
Traceback (most recent call last):
  File ""/home/kafka/PycharmProjects/Test1/Test1.py"", line 1, in <module>
    from keras.models import Sequential
  File ""/usr/local/lib/python2.7/dist-packages/keras/__init__.py"", line 3, in <module>
    from . import activations
  File ""/usr/local/lib/python2.7/dist-packages/keras/activations.py"", line 4, in <module>
    from . import backend as K
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/__init__.py"", line 73, in <module>
    from .tensorflow_backend import *
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 1, in <module>
    import tensorflow as tf
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN2cl4sycl7program30create_program_for_kernel_implESsPKhiPKPKcSt10shared_ptrINS0_6detail7contextEE


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help._




",0,,4,2017-06-16T15:31:37Z,NONE
10767,[Feature Request] Exclude ties in function in_top_k,"stat:contributions welcome,type:feature","This is a feature request related to #10489 (tie handling in function in_top_k)

Would it be possible to add an option/argument specifying whether ties should be included or excluded?
In other words, make it possible for ties to return False instead of True.

Thanks!",0,,7,2017-06-16T14:33:15Z,NONE
10765,[Performance] contirb.seq2seq.attention_wrapper slower due to using matmul instead of reduce_sum,type:bug/performance,"tf version '1.2.0-rc0' contirb.seq2seq.attention_wrapper is great, it make using attention much easier.
However I found using attention_wrapper will be much slower then tf version 1.0.
After some experiment I found it is due to using matmul instead of reduce_sum.

from attetntion_wrapper.py 731
      
      expanded_alignments = array_ops.expand_dims(alignments, 1)
      attention_mechanism_values = self._attention_mechanism.values
      context = math_ops.matmul(expanded_alignments, attention_mechanism_values)
      context = array_ops.squeeze(context, [1])

Using above code for one of my application got 2.2 batch/s, after changing to use reduce_sum(as tf version 1.0 did), the speed is 3.4 batch/s, improve a lot.

      expanded_alignments = array_ops.expand_dims(alignments, 2)
      attention_mechanism_values = self._attention_mechanism.values
      context = math_ops.reduce_sum(expanded_alignments * attention_mechanism_values, [1])",1,,3,2017-06-16T13:52:17Z,NONE
10764,"There is QuantizedInstanceNorm operation registered, But I could not find InstanceNorm operation anywhere.","stat:awaiting tensorflower,type:feature","OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b
HEXAGON SDK: 3.1

There is **QuantizedInstanceNorm** operation registered, But I could not find **InstanceNorm** operation anywhere.

I am not sure why Quantized form is added without its original instance form, Maybe to convert graphs trained using other nets into pb and quantize them. Well this is my assumption.

Could anyone tell how can I get **instancenorm** operation.


thanks",0,,3,2017-06-16T13:41:43Z,NONE
10763,What is the possible op substitute for set of OPerations on CPU to DSP Hexagon,type:feature,"OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b
HEXAGON SDK: 3.1
nnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib

I am trying to build a graph to run on hexagon,
it uses few op's which hexagon doesn't support.

native : graph_transferer.cc:109 Failed to transfer graph Invalid argument: Mean has not been implemented yet.

OP's details are as below:-

 {""Mean"", SupportedOpType::**??**},
 {""RealDiv"", SupportedOpType::**??**},
 {""Pow"", SupportedOpType::**??**},
 {""Conv2DBackpropInput"", SupportedOpType::**??**},
 {""Square"", SupportedOpType::**??**},
 {""SquaredDifference"", SupportedOpType::**??**},
 {""StopGradient"", SupportedOpType::**??**},
 {""Reciprocal"", SupportedOpType::**??**},

Is there any possible substitute for the operation types Mean, Pow, Conv2DBackpropInput etc.. for hexagon.

thanks in advance.",1,,7,2017-06-16T13:36:49Z,NONE
10761,Feature Request : Tensor Roll,"stat:contributions welcome,type:feature","Could you add an equivalent to [Numpy roll](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.roll.html) on Tensor in tensorflow in order to allow the user to roll a Tensor along one of the axis of the tensor ?
",0,,7,2017-06-16T11:16:52Z,NONE
10749,Numpy.fft.fft2() gives different result than tf.fft2d(),"stat:awaiting response,type:bug/performance","as mentioned in the issue #6401, the tf.fft2d() gives different result compared to np.fft.fft2(). Is there a reason for this ?

Note : numpy gives proper fourier transform after np.fft.fftshift(), and I have taken care of that in my code.
The differences are not visible here, but the mean squared error is significant.

![image1](https://user-images.githubusercontent.com/18488880/27207200-84637a88-5202-11e7-9d49-d22cf9a8057d.png)![image2](https://user-images.githubusercontent.com/18488880/27207198-8462f2b6-5202-11e7-88c2-7114b36c696a.png)    ![image3](https://user-images.githubusercontent.com/18488880/27207199-8462fe50-5202-11e7-8d7b-bca01bba063b.png)   ![image4](https://user-images.githubusercontent.com/18488880/27207631-f2a41284-5205-11e7-91a6-336d75755787.png)

Second image is the fft using tensorflow, and third one is using numpy. You can see the difference in the corners. The fourth image is the difference between the two images times 10.

 (tf has some features while numpy does not)

I am working on an application which uses fft in backpropagation and thus it is of absolute importance that the fft in numpy are same as fft by tf.

My question is - Why is there a difference and how can I get the same fft as numpy ?


",0,,15,2017-06-16T00:45:28Z,NONE
10747,Striding behaviour different between caffe and tensorflow,type:bug/performance,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Binary (pip install)
- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Tesla P100-SXM2 16MB
- **Exact command to reproduce**: python caffe_to_tf_test.py

### Describe the problem
Caffe convolution produce different results then tensorflow with the same parameters.   This has something to do with striding - the attached test fails with striding equal to 2, and succeeds with striding equal to 1.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

[x.zip](https://github.com/tensorflow/tensorflow/files/1079200/x.zip)

",1,,10,2017-06-15T22:56:28Z,NONE
10739,Quantized graph using graph transform fails to work,"stat:awaiting tensorflower,type:build/install","**System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.1
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce:**

I am using a quantized graph created using following command:

bazel-bin/tensorflow/tools/graph_transforms/transform_graph 
--in_graph=./frozen_model_inception_resnet_v2.pb 
--out_graph=./quantized_weights_and_nodes_inception_resnet_v2.pb 
--inputs='InputImage:0' 
--outputs='InceptionResnetV2/Logits/Predictions' 
--transforms='
add_default_attributes
strip_unused_nodes(type=float, shape=""1,299,299,3"")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights
quantize_nodes
strip_unused_nodes
sort_by_execution_order'

I try to use the graph in a program as below:

graph_def = tf.GraphDef()
    with open(os.path.join(FLAGS.model_dir, GRAPH_FILE), ""rb"") as f:
        model_str = f.read()
        graph_def.ParseFromString(model_str)
        tf.import_graph_def(graph_def, name='')

However, I get error ""ValueError: No op named QuantizedAdd in defined operations"" now when tf.import_graph_def(graph_def, name='') is called.

I also tried to use :         dir(tf.contrib) as explained in one of the issues : https://github.com/tensorflow/tensorflow/issues/10130

graph_def = tf.GraphDef()
    with open(os.path.join(FLAGS.model_dir, GRAPH_FILE), ""rb"") as f:
        model_str = f.read()
        graph_def.ParseFromString(model_str)
        dir(tf.contrib)
        tf.import_graph_def(graph_def, name='')

but this did not solve the problem for me, I still get same error.",0,,10,2017-06-15T17:45:34Z,NONE
10737,[feature] tf.contrib.image.invert,"stat:contributions welcome,type:feature","/CC @ringw 

Along the lines of the other utility functions in [`tf.contrib.image`](https://www.tensorflow.org/api_docs/python/tf/contrib/image), would be great to have a `tf.contrib.image.invert` that takes a transform and returns the inverse transform.",0,,11,2017-06-15T17:08:00Z,CONTRIBUTOR
10731,scope reuse problem variable not exist for using Dense(in contirb.seq2seq.attention_wrapper),stat:awaiting response,"tf version '1.2.0-rc0' 
in attention_wrapper.py(contirb.seq2seq.attention_wrapper), it use below
      
    from tensorflow.python.layers import core as layers_core 
    memory_layer = layers_core.Dense(10, name=""memory_layer"", use_bias=False)  #line 416

but this usage will cause un expected result when trying to reuse memory_layer, see below

    input = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)
    with tf.variable_scope('main') as scope:
        memory_layer = layers_core.Dense(10, name=""memory_layer"", use_bias=False)
        x = memory_layer(input)
        scope.reuse_variables()
        memory_layer = layers_core.Dense(10, name=""memory_layer"", use_bias=False)
        y = memory_layer(input)

ValueError: Variable main/memory_layer_1/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?

One workaround is to change name=""memory_layer"" to _scope=""memory_layer""

    with tf.variable_scope('main') as scope:
        memory_layer = layers_core.Dense(10, _scope=""memory_layer"", use_bias=False)
        x = memory_layer(input)
        scope.reuse_variables()
        memory_layer = layers_core.Dense(10, _scope=""memory_layer"", use_bias=False)
        y = memory_layer(input)

I think this is a bug for atttention_wrapper.py ? since we can not reuse memory_layer, then we can not train/evaluate in one graph when using attention cell wrapper.
",0,,6,2017-06-15T12:26:18Z,NONE
10728,tensorflow.contrib.keras.python.keras.models throwing errors for a valid keras code,type:bug/performance,"### System information
== cat /etc/issue ===============================================
Linux parikshit-XPS-L322X 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux parikshit-XPS-L322X 4.4.0-79-generic #100-Ubuntu SMP Wed May 17 19:58:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow (1.2.0rc1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.0-rc1
tf.GIT_VERSION = v1.2.0-rc0-24-g94484aa
tf.COMPILER_VERSION = v1.2.0-rc0-24-g94484aa
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

Keras version 2.0.5 with Tensorflow backend

Using PyCharm Community edition 2017.1.3 as editor 

### Describe the problem
I was trying to implement a toy example for One Shot Siamese paper (Gregory Koch etc.) using Keras and found difference in behaviour (errors) between tensorflow.contrib.keras.python.keras.models (i.e using Tensorflow's contrib library for Keras) and keras.models (i.e Keras library with tensorflow backend). Here we have to train two separate CNNs with tied weights and tensorflow contrib library for keras is throwing errors for valid Keras code. Please refer to the code below for difference in behaviour / error

### Source code (using tensorflow contrib lib for keras)
```python
from __future__ import absolute_import, print_function, division
from tensorflow.contrib.keras.python.keras.layers import LSTM, Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D
from tensorflow.contrib.keras.python.keras.models import Model, Sequential
from tensorflow.contrib.keras.python.keras.regularizers import l2
from tensorflow.contrib.keras.python.keras import backend as K
from tensorflow.contrib.keras.python.keras.optimizers import SGD
from tensorflow.contrib.keras.python.keras.initializers import RandomNormal

input_shape = (105, 105, 1)
left_input = Input(input_shape)
right_input = Input(input_shape)

w_init = RandomNormal(mean=0, stddev=1e-2)
b_init = RandomNormal(mean=0.5, stddev=1e-2)

convnet = Sequential()
convnet.add(Conv2D(64, (10, 10), activation='relu', input_shape=input_shape,
                   kernel_initializer=w_init, kernel_regularizer=l2(2e-4)))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (7, 7), activation='relu',
                   kernel_regularizer=l2(2e-4), kernel_initializer=w_init,
                   bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(256, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(Flatten())
convnet.add(Dense(4096, activation=""sigmoid"", kernel_regularizer=l2(1e-3),
                  kernel_initializer=w_init, bias_initializer=b_init))

l_side = convnet(left_input)
r_side = convnet(right_input)
```
### Output/Error (tensorflow contrib lib for keras)
```
Traceback (most recent call last):
  File ""/home/parikshit/PycharmProjects/Toy_example/one_shot.py"", line 53, in <module>
    l_side = convnet(left_input)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/engine/topology.py"", line 432, in __call__
    output = super(Layer, self).__call__(inputs, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 439, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/models.py"", line 560, in call
    return self.model.call(inputs, mask)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/engine/topology.py"", line 1743, in call
    output_tensors, _, _ = self.run_internal_graph(inputs, masks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/keras/python/keras/engine/topology.py"", line 1957, in run_internal_graph
    self.add_loss(layer.get_losses_for(None), None)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 254, in add_loss
    self._losses += losses
AttributeError: 'Model' object has no attribute '_losses'
```
### Source code (using Keras library with tensorflow backend)
```python
from __future__ import absolute_import, print_function, division
from keras.layers import LSTM, Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D
from keras.models import Model, Sequential
from keras.regularizers import l2
from keras import backend as K
from keras.optimizers import SGD
from keras.initializers import RandomNormal

input_shape = (105, 105, 1)
left_input = Input(input_shape)
right_input = Input(input_shape)

w_init = RandomNormal(mean=0, stddev=1e-2)
b_init = RandomNormal(mean=0.5, stddev=1e-2)

convnet = Sequential()
convnet.add(Conv2D(64, (10, 10), activation='relu', input_shape=input_shape,
                   kernel_initializer=w_init, kernel_regularizer=l2(2e-4)))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (7, 7), activation='relu',
                   kernel_regularizer=l2(2e-4), kernel_initializer=w_init,
                   bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(128, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(MaxPooling2D())
convnet.add(Conv2D(256, (4, 4), activation='relu', kernel_initializer=w_init,
                   kernel_regularizer=l2(2e-4), bias_initializer=b_init))
convnet.add(Flatten())
convnet.add(Dense(4096, activation=""sigmoid"", kernel_regularizer=l2(1e-3),
                  kernel_initializer=w_init, bias_initializer=b_init))

l_side = convnet(left_input)
r_side = convnet(right_input)
```
### Output/Error (Keras library with tensorflow backend)
```
Using TensorFlow backend.

Process finished with exit code 0
```",1,,5,2017-06-15T10:02:24Z,NONE
10703,Bazel bring up for ROCm,"stat:awaiting tensorflower,type:build/install","Hi,
I am trying to add new backend to tensorflow. As a first step, I started changing bazel files around [(Commit here)](https://github.com/ROCmSoftwarePlatform/tensorflow/commit/b75ea3f499a5f63f2580066ae132c93e2b03d0ad). When I enable XLA + ROCM during configure, and run `bazel build -s --config=opt --config=rocm //tensorflow/tools/pip_package:build_pip_package `, I am getting the following error:
```
ERROR: no such package '@local_config_rocm//': error loading package 'external': The repository named 'local_config_rocm' could not be resolved.
INFO: Elapsed time: 0.227s
```

It would be great if someone can parse the commit mentioned and suggest changes. 
Thank you!",0,,18,2017-06-14T14:17:34Z,NONE
10685,Darwin support for MKL build / configure script,"type:bug/performance,type:feature","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac OS X 10.12.4, Darwin
- **TensorFlow installed from (source or binary)**:
Source, git tag 1.2.0 RC 2
- **TensorFlow version (use command below)**:
1.2 RC 2
- **Bazel version (if compiling from source)**:
bazel version
..............
Build label: 0.4.3-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 22 15:20:15 2016 (1482420015)
Build timestamp: 1482420015
Build timestamp as int: 1482420015
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
./configure 
Please specify the location of python. [Default is /usr/bin/python]: 
Found possible Python library paths:
  /Library/Python/2.7/site-packages
Please input the desired Python library path to use.  Default is [/Library/Python/2.7/site-packages]

Using python library path: /Library/Python/2.7/site-packages
Do you wish to build TensorFlow with MKL support? [y/N] y
MKL support will be enabled for TensorFlow
Do you wish to download MKL LIB from the web? [Y/n] Y
Darwin is unsupported yet

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
N/A
You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Darwin / Mac OS X support for Intel's optional MKL optimizations. MKL appears to have darwin support, so I am unsure why it is not supported in Tensorflow. I imagine this is on a to-do, but a publicly tracked feature request might be helpful. Thank you.

### Source code / logs
N/A",2,,42,2017-06-13T17:07:25Z,CONTRIBUTOR
10680,tf.estimator generator_input_fn no padding queue?,type:feature,"Hello again! 
While I was examining TF source code for [10597 issue](https://github.com/tensorflow/tensorflow/issues/10597) solution, I found another bug or lack of important feature, such as `PaddingFIFOQueue` for all of `tf.estimator` input pipelines. Such option is very important for seq2seq tasks with dynamic shapes.

As a solution I found a hacky way to generate `[1, batch_size, time]` batches and squeeze them to `[batch_size, time]` in the model. Source code: [tensorflow](https://github.com/Scitator/tensorflow), [model](https://github.com/Scitator/TF-seq2seq/tree/tf_master_seq2seq), [notebook](https://gist.github.com/Scitator/d72cef607d23200074dfbbc1cbce3b55).

As you can understand, I am not very happy with such solution, that's why I am asking for help to solve it in more correct and tensorflow way. Any suggestions?",1,,6,2017-06-13T13:28:54Z,CONTRIBUTOR
10679,recovery_wait_secs feature for tf.train.MonitoredTrainingSession() similar to the one present in tf.train.SessionManager(),"stat:contributions welcome,type:feature","I ran the distributed model for a small data set and for very few epochs for some test run.

The chief worker started normally and finished training (training time was less than 30 seconds) but the other workers did not start.

Below log message has been displayed in all the workers other than chief:
`Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: <list_of_variables >`

Then I found the reason behind this in [this](https://stackoverflow.com/questions/42986653/distributed-tensorflow-not-running-some-workers/43007657#43007657) Stackoverflow answer.

A `recover_wait_secs` feature would make it easier rather handling that timeout period manually.",1,,6,2017-06-13T12:53:52Z,NONE
10675,Inner tf.device inherits device index when using wildcard index,type:bug/performance,"TF version: v1.2.0-rc0-735-gf48673b (about one week ago)

```python
with tf.device('gpu:7'):
    with tf.device('cpu:*'):
        print(tf.constant(0).device) # /device:CPU:7
```

workaround:

```python
with tf.device('gpu:7'):
    with tf.device(None), tf.device('cpu:*'):
        print(tf.constant(0).device) # /device:CPU:*
```",1,,6,2017-06-13T11:03:21Z,CONTRIBUTOR
10672,Strange performance: sparse tensor matmul in kernel_test,"stat:awaiting tensorflower,type:bug/performance","Sorry for the previous issue 
According to the document [HERE](https://www.tensorflow.org/api_docs/python/tf/sparse_tensor_dense_matmul)

> tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks
A sparse [m, k] with % nonzero values between 1% and 80%
B dense [k, n]

When I run [sparse_tensor_dense_matmul_op_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test.py) with large n,m,k
I get:
```
% nnz 	 n 	 gpu 	 m 	 k 	 dt(dense) 	 dt(sparse) 	 dt(sparse)/dt(dense)
0.5 	 512 	 True 	 1822 	 4608 	 0.0222946 	 0.0130646 	 0.585998
0.5 	 512 	 True 	 1821 	 4608 	 0.0224976 	 0.0130761 	 0.581222
0.5 	 512 	 True 	 1820 	 4608 	 0.022529 	 0.79513 	 35.2936
0.5 	 512 	 True 	 1819 	 4608 	 0.0217343 	 0.795709 	 36.6107
```
It is strange that `dt(sparse)/dt(dense)` are very different when m=1821 -> 1820
BTY, I set the iterations to 10 for time saving...
```
delta_dense = _timer(sess, ops_fn, 10)
delta_sparse = _timer(sess, ops_fn, 10)
```

Here's some information:
OS: Ubuntu 14.04
tf-version: 1.1.0  installed from source
GPU: NVIDIA K80, 4 kernels (only '/gpu:0' is used)
CUDA: 8.0
cudnn: 5.1.5

You can run sparse_tensor_dense_matmul_op_test.py with my settings
```
  for thresh in (0.5,):
    for n in (512,):
      for use_gpu in (True,):
        for m in (1822, 1821, 1820, 1819):
          for k in (9*512,):
            sparse_tensor_dense_vs_dense_matmul_benchmark(
                thresh, m, k, n, False, False, use_gpu=use_gpu)
```
",0,,4,2017-06-13T09:24:43Z,NONE
10649,Implement architecture-independent fallback in tensorflow/workspace.bzl,"stat:contributions welcome,type:build/install","Archictecture-dependent binaries such as `nodejs` limits portability to different targets (namely, I'm interested in Tensorflow ppc64le builds). I tried replacing x64 binaries with ppc64 in the cached dirs and managed to compile Tensorflow (see https://github.com/tensorflow/tensorflow/issues/10306).

This issue is similar to https://github.com/bazelbuild/rules_closure/issues/207.
",0,,3,2017-06-12T13:49:22Z,CONTRIBUTOR
10641,bug: BeamSearchDecoder should not assume that  when time > 0 beam will be full,type:bug/performance,"```
  scores_flat = control_flow_ops.cond(
      time > 0,
      lambda: array_ops.reshape(scores, [batch_size, -1]),
      lambda: scores[:, 0])
  num_available_beam = control_flow_ops.cond(
      time > 0,
      lambda: math_ops.reduce_prod(scores_shape[1:]),
      lambda: math_ops.reduce_prod(scores_shape[2:]))

  # Pick the next beams according to the specified successors function
  next_beam_size = math_ops.minimum(
      ops.convert_to_tensor(
          beam_width, dtype=dtypes.int32, name=""beam_width""),
      num_available_beam)
  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=next_beam_size)
  next_beam_scores.set_shape([static_batch_size, beam_width])
  word_indices.set_shape([static_batch_size, beam_width])
``` 
code start from
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L510

Correct me if I am wrong, but I think this code is assuming that, when time > 0 the beam will be full. It is true when the vocabulary is big such as is the case in machine translation. but if the vocabulary is small, the beam might won't be full when time > 0 and might pose a problem.  the value of `next_beam_size ` in the code seems must be `beam_width` or it will raise an error since `next_beam_scores.set_shape([static_batch_size, beam_width])`, which make ` next_beam_size = math_ops.minimum` useless.

I am trying to write a Pointer Network BeamSearch Decoder by modifying this source file. And the vocabulary is usually small, so there is a possibility that when time == 1 the beam won't be fully filled. 

I appreciate finally some one wrote a general BeamSeach decoder, that will make my life easier.

",1,,6,2017-06-12T02:16:00Z,CONTRIBUTOR
10631,i get an error when i build tensorflow by bazel on windows,stat:community support,"PS C:\WINDOWS\system32> cd tensorflow
PS C:\WINDOWS\system32\tensorflow> bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --cop
t=-msse4.2 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 //tensorflow/tools/pip_package:build_pip_package
>>
.....................
ERROR: C:/windows/system32/tensorflow/tensorflow/tools/pip_package/BUILD:27:1: error loading package 'tensorflow/core':
Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Traceback (most recent cal
l last):
        File ""C:/windows/system32/tensorflow/tensorflow/workspace.bzl"", line 117
                _apply_patch(repo_ctx, repo_ctx.attr.patch_file)
        File ""C:/windows/system32/tensorflow/tensorflow/workspace.bzl"", line 108, in _apply_patch
                _execute_and_check_ret_code(repo_ctx, cmd)
        File ""C:/windows/system32/tensorflow/tensorflow/workspace.bzl"", line 92, in _execute_and_check_ret_code
                fail(""Non-zero return code({1}) when ..., <2 more arguments>))
Non-zero return code(127) when executing 'C:\tools\msys64\usr\bin\bash.exe -c patch -p1 -d C:/users/godw/appdata/local/t
emp/_bazel_godw/nseddbsr/external/protobuf -i C:/windows/system32/tensorflow/third_party/protobuf/add_noinlines.patch':
Stdout:
Stderr: /usr/bin/bash: patch: command not found
 and referenced by '//tensorflow/tools/pip_package:included_headers_gather'.",0,,4,2017-06-11T12:46:03Z,NONE
10622,RecordInput Documentation in API doc site,type:docs,"[RecordInput is in the tf 1.2 code](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/data_flow_ops.py#L1602) but I don't see it in the [tf 1.2 API docs](https://www.tensorflow.org/versions/r1.2/api_docs/python/). Should it be present?
",3,,17,2017-06-11T02:50:23Z,NONE
10607,functional add_n: compose a new (differentiable) op from a list of ops without memory footprint,"stat:contributions welcome,type:feature","### Describe the problem

It is a feature request, and should be very related to the current high memory cost of tensorflow. 

In my case, I am building a graph which I should be able to compute gradients. In this graph, I heavily use the `add_n` op which returns a tensor from a list of tensors. I want to remark that this is very inefficient for two reasons:

1. Memory wise, it requires to cache all input tensors in the list before it actually aggregates. Technically, such process can be replaced by `accumulate_n` if one does not care computing its gradient. In facts, I have been tried with `add_n` with input list size goes to tens or a hundred, it quickly fills up the memory of GPUs. 

2. Besides high memory footprint, it also prohibits the use of multi-thread framework of tensorflow, ultimately affecting the efficiency. This is because the idea of `add_n` actually introduces an extra layer of tensors whose controlled dependency prevents deallocating any of these tensors computed in time. Consider the following example:

```python
a=tf.Variable(0.2)
b=tf.Variable(0.1)

c=[tf.sin(a), tf.cos(a), tf.sin(b)]
d=[tf.sin(a), tf.cos(b)]

e=add_n(c)
f=add_n(d)
# ... initialization 
sess.run([e, f])
```
In the above example, suppose given variables `a` and `b` what we really need is tensors `e` and `f`, but the introduction of tensor list `c` and `d` occupies what I consider as redundant memory. Note that the computation of tensors in `c` and `d` can be made multi-threaded / parallel if we have infinite memory. But the real situation is if the caching tensors in `c` already eat up all memory, no tenors in `d` will be executed simultaneously until `e` is complete (at which time `c` is released). 

In fact, one can calculate `e` and its gradients `de/da`, `de/db` without explicitly storing any tensors in `c`. This trick is by introducing a functional which takes a set of ops and their inputs, and return a global summed-up tensor, which may look like:

```python

a=tf.Variable(0.2)
b=tf.Variable(0.1)

e_func=add_n_functional([tf.sin, tf.cos, tf.sin])
e=e_func([a, a, b])
f_func=add_n_functional([tf.sin, tf.cos])
f=f_fun([a, b])

# ... initialization 
sess.run([e, f])
```
Note `add_n_functional` returns a new op from a list of given ops. With this new functional, we can avoid buffering a lot intermediate tensors. At the same time, `e_func` and `f_func` are still differentiable.

I was thinking how to implement this idea at python level, but it seems to only be feasible via rewriting some C++ parts. I will appreciate if this feature is added to tensorflow in the near future.   



",0,,8,2017-06-10T05:36:44Z,NONE
10605,tensorflow/tools/git script breaks when git repo has packed references,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Not applicable to bug
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source build
- **TensorFlow version (use command below)**:
tip of tree
- **Bazel version (if compiling from source)**:
0.5.1
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:
```
git pack-refs
git gc
bazel clean
configure
bazel build -c opt --copt=-g --copt=-mavx --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package
```

- **Results**:
```
ERROR: /local/chip/git/tensorflow-knureon/tensorflow/core/BUILD:1404:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /local/chip/git/tensorflow-knureon/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
```


The problem is due to the fact that the link in tensorflow/tools/git/gen/branch_ref is supposed to point to a valid file in my .git directory: .git/refs/heads/tf-tip.  However, I have been doing some reorganizing of our tree structure, and in the process of removing deprecated branches my calls to git caused this file to be deleted.  So the .git/refs/heads directory is empty and the hash is found in .git/packed-refs:

rdubielzig@swpl-000224:/local/chip/git/tensorflow-knureon/.git$ grep tf-tip packed-refs 
504965336d1432ee96b4f0e9b78f65ee201e9be5 refs/heads/tf-tip


WORKAROUND:
Recreate the missing ref file by writing  'tf-tip' in .git/refs/heads with the contents consisting of the hash above.",1,,5,2017-06-09T21:59:27Z,NONE
10597,tf.estimator generator_input_fn multi thread bug ,"stat:contributions welcome,type:bug/performance","I would like to use python generators as input pipeline for tf.estimator's. Finally I found generator_input_fn (announced [here](https://youtu.be/5DknTFbcGVM?t=12m30s)).

Nevertheless, when I start first experiments, I found I bug with learning curve. After some experiments I found the purpose of it - all blows up if you set `num_threads` > 1 in generator_input_fn.

For example, here is loss plot with python generator and `num_threads=1`:
![tf_py_generator_1_thread](https://user-images.githubusercontent.com/7606451/26978620-d58faec2-4d34-11e7-8f8b-14e4e50f6844.png)

And with `num_threads=2`:
![tf_py_generator_2_threads](https://user-images.githubusercontent.com/7606451/26978619-d58a9e3c-4d34-11e7-8f1b-8bab67a957aa.png)

**But** if I use `tf.estimator.inputs.numpy_input_fn` with 4 thread all work pretty well:
![tf_numpy_generator_4_threads](https://user-images.githubusercontent.com/7606451/26978621-d591c11c-4d34-11e7-85ce-2340bd2ed01c.png)
Except the fact, that I cannot save all my data in one numpy array (GBs of data).

Any suggestions why so? Or I need just wait for TF 1.2 with working `tf.estimators.inputs.generator_input_fn`?

Jupyter notebook with my experiments [here](https://gist.github.com/Scitator/184c8d676f36a9b7c04fb504d9088590).",0,,6,2017-06-09T14:03:15Z,CONTRIBUTOR
10585,Run convert_graphdef_memmapped_format fail,"stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    OS X EI Caption 10.11.6
- **TensorFlow installed from (source or binary)**:
    binary (pip install)
- **TensorFlow version (use command below)**:
    TensorFlow 1.2.0-rc1 CPU Only
- **Bazel version (if compiling from source)**:
    Build label: 0.4.5-homebrew
    Build target: bazel-out/local-
    opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
    Build time: Thu Mar 16 13:37:54 2017 (1489671474)
    Build timestamp: 1489671474
    Build timestamp as int: 1489671474
- **CUDA/cuDNN version**:
    CPU Only

### Describe the problem
Because the buffers holding the model weight values are 77MB in size, the memory needed to load these into the app can crash in Android, even before the model is run. So I want to run `convert_graphdef_memmapped_format` to map them into memory.So I build it.When I run it ,it get me a error`tensorflow/contrib/util/convert_graphdef_memmapped_format.cc:61] Unknown argument –-in_graph=/Users/liba/Desktop/OptimizeCTNModel.pb
`

### Source code / logs
log:
``` 
ZHANGSH7-MP:tensorflow liba$ bazel-bin/tensorflow/contrib/util/convert_graphdef_memmapped_format –-in_graph=/Users/liba/Desktop/OptimizeCTNModel.pb –-out_graph=/Users/liba/Desktop/MemmappedCTNModel.pb
2017-06-09 14:59:12.633589: E tensorflow/contrib/util/convert_graphdef_memmapped_format.cc:61] Unknown argument –-in_graph=/Users/liba/Desktop/OptimizeCTNModel.pb
usage: bazel-bin/tensorflow/contrib/util/convert_graphdef_memmapped_format
Flags:
	--in_graph=""""                    	string	input graph
	--out_graph=""""                   	string	output graph
	--min_conversion_tensor_size=10000	int32	constants with tensors that have less than this number elements won't be converted into ImmutableConst (be memmapped)

```
",0,,4,2017-06-09T07:39:51Z,NONE
10535,tf.nn.conv3d_transpose really slow on i7 CPU with 100+G free memory,"stat:awaiting response,type:bug/performance","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: virtualenv pip
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: on CPU
- **Exact command to reproduce**:

### Describe the problem
It takes about 10 mins to do the tf.nn.conv3d_transpose computation.
The input size is [1, 97, 128, 256, 32], kernel size is 3*3*3, strides is [1, 2, 2, 2, 1], and the output size is [1, 193, 256, 512, 1].

At first my model runs with normal speed. Before this layer, there is several tf.nn.conv3d and tf.nn.conv3d_transpose computation.
After this step's computation, it seems the computation become really slow down.

But my model runs smoothly on 12G GPU, if using 4 GPUs, 1.8 examples/sec.

I notice a similar issue #3128. That issue also reports some problem on CPU, but not on GPU. Is that issue resolved?

### Source code / logs
Since I am training a large model on a large dataset. I will only include the model's code. If is needed, I will include more codes. 

The computationally cost layer is the last layer in the variable_scope learning_regularization, right before the scope soft_argmin in `def _build_model`.

For more details, I am reimplementing https://arxiv.org/pdf/1703.04309.pdf.

```python
from collections import namedtuple

import numpy as np
import tensorflow as tf
import six

from tensorflow.python.training import moving_averages

# If a model is trained using multiple GPUs, prefix all Op names with tower_name
# to differentiate the operations. Note that this prefix is removed from the
# names of the summaries when visualizing a model.
TOWER_NAME = 'tower'

# Batch normalization. Constant governing the exponential moving average of
# the 'global' mean and variance for all activations.
BATCHNORM_MOVING_AVERAGE_DECAY = 0.9997

# The decay to use for the moving average.
MOVING_AVERAGE_DECAY = 0.9999


HParams = namedtuple('HParams',
                     ['batch_size', 'lrn_rate',
                     'weight_decay_rate',
                     'relu_leakiness', 'optimizer', 'max_disparity'])


class GCNet(object):
  """"""GCNet model.""""""

  def __init__(self, hps, left_images, right_images, gt_disparity, mask, mode): 
    """"""ResNet constructor.

    Args:
      hps: Hyperparameters.
      images: Batches of images. [batch_size, image_size, image_size, 3]
      labels: Batches of labels. [batch_size, num_classes]
      mode: One of 'train', 'eval' and 'predict'.
    """"""
    self.hps = hps
    self._left_images = left_images
    self._right_images = right_images
    self.gt_disparity = gt_disparity
    self.mask = mask
    self.mode = mode
    self.debug_op_list = []  

    self._extra_train_ops = []
    
  def build_graph_to_loss(self):
    self._build_model()
    self._build_loss_op()

  def _stride_arr(self, stride):
    """"""Map a stride scalar to the stride array for tf.nn.conv2d.""""""
    return [1, stride, stride, 1]
    
  def _stride_3d_arr(self, stride):
    """"""Map a stride scalar to the stride array for tf.nn.conv2d.""""""
    return [1, stride, stride, stride, 1]

  def _build_model(self):
    """"""Build the core model within the graph.""""""

    layer_idx = 1
    with tf.variable_scope('unary_features', reuse=False):
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        left_x = self._left_images
        left_x = self._conv('conv', left_x, 5, 3, 32, self._stride_arr(2))
        left_x = self._relu(left_x, self.hps.relu_leakiness)
        left_x = self._batch_norm('bn', left_x)
      tf.add_to_collection('shapes', tf.shape(left_x))
        
      for i in six.moves.range(8):
        left_x, layer_idx = self._unary_feat_residual(left_x, 3, 32, 32, self._stride_arr(1), layer_idx)
        tf.add_to_collection('shapes', tf.shape(left_x))
    
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        left_x = self._conv('conv', left_x, 3, 32, 32, self._stride_arr(1))
      tf.add_to_collection('shapes', tf.shape(left_x))
    
    layer_idx = 1    
    with tf.variable_scope('unary_features', reuse=True):
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        right_x = self._left_images
        right_x = self._conv('conv', right_x, 5, 3, 32, self._stride_arr(2))
        right_x = self._relu(right_x, self.hps.relu_leakiness)
        right_x = self._batch_norm('bn', right_x)
        
      for i in six.moves.range(8):
        right_x, layer_idx = self._unary_feat_residual(right_x, 3, 32, 32, self._stride_arr(1), layer_idx)

      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        right_x = self._conv('conv', right_x, 3, 32, 32, self._stride_arr(1))
      
    with tf.variable_scope('cost_volumn'):
      left_cost_volume = tf.stack([tf.identity(left_x)] * (self.hps.max_disparity/2+1), axis=1, name='left_stack')
      right_cost_volume = []
      cur_width = tf.shape(right_x)[2]

      for depth in six.moves.range(self.hps.max_disparity/2+1):
        right_cost_volume.append(tf.pad(tf.slice(right_x, [0, 0, 0, 0], [-1, -1, cur_width - depth, -1], name='right_slice_'+str(depth)),
                                        [[0, 0], [0, 0], [depth, 0], [0, 0]],
                                        name='right_pad_'+str(depth)
                                        ))
      right_cost_volume = tf.stack(right_cost_volume, axis=1, name='right_stack')
      x = tf.concat([left_cost_volume, right_cost_volume], 4)
      tf.add_to_collection('shapes', tf.shape(x))
      
          
    with tf.variable_scope('learning_regularization'):
      stored_features = []

      in_filters = [64, 64, 64, 64]
      out_filters = [32, 64, 64, 64]
      in_filters_stride_2 = [64, 64, 64, 64]
      out_filters_stride_2 = [64, 64, 64, 128]
      for i in six.moves.range(4):
        tmp_x, layer_idx = self._regularization_subsample(x, 3, in_filters[i], out_filters[i], self._stride_3d_arr(1), layer_idx)
        tf.add_to_collection('shapes', tf.shape(tmp_x))
        stored_features.append(tmp_x)
        
        with tf.variable_scope('layer_'+str(layer_idx)):
          layer_idx += 1
          x = self._conv3d('conv3d', x, 3, in_filters_stride_2[i], out_filters_stride_2[i], self._stride_3d_arr(2))
          x = self._relu(x, self.hps.relu_leakiness)
          x = self._batch_norm('bn', x)
          tf.add_to_collection('shapes', tf.shape(x))

      
      assert stored_features[0] is not stored_features[1]

      for i in six.moves.range(2):
        with tf.variable_scope('layer_'+str(layer_idx)):
          layer_idx += 1
          x = self._conv3d('conv3d', x, 3, 128, 128, self._stride_3d_arr(1))
          x = self._relu(x, self.hps.relu_leakiness)
          x = self._batch_norm('bn', x)
          tf.add_to_collection('shapes', tf.shape(x))

      transposed_in_filters = [128, 64, 64, 64]
      transposed_out_filters = [64, 64, 64, 32]
      
      for i in six.moves.range(4):
        x, layer_idx = self._regularization_upsample(x, stored_features[-i-1], 3, transposed_in_filters[i], transposed_out_filters[i], self._stride_3d_arr(2), layer_idx)
        tf.add_to_collection('shapes', tf.shape(x))
      
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        input_shape = tf.shape(self.gt_disparity)
        x = self._conv3d_trans('conv_trans', x, 3, 32, 1, self._stride_3d_arr(2), [input_shape[0], self.hps.max_disparity+1, input_shape[1], input_shape[2], 1])
        tf.add_to_collection('shapes', tf.shape(x))
        self.debug_op_list.append(tf.shape(x))

    
    with tf.variable_scope('soft_argmin'):
        x = tf.squeeze(x, squeeze_dims=[4], name='squeeze')
        tf.add_to_collection('shapes', tf.shape(x))
        x = tf.transpose(x, perm=[0, 2, 3, 1], name='transpose')
        tf.add_to_collection('shapes', tf.shape(x))
        x = tf.nn.softmax(x, dim=-1, name='softmax')
        tf.add_to_collection('shapes', tf.shape(x))

        multiplier = tf.range(0, self.hps.max_disparity+1, dtype=tf.float32, name='depth_range')
        x = tf.multiply(x, multiplier, name='softmax_mul_depth')
        tf.add_to_collection('shapes', tf.shape(x))
        self.predicted_disparity = tf.reduce_sum(x, axis=3, name='reduce_sum')       
        tf.add_to_collection('shapes', tf.shape(self.predicted_disparity))
    self.shapes = tf.get_collection('shapes')
    self.debug_op_list.append(self.shapes)

  def _build_loss_op(self):
    with tf.variable_scope('loss'):
      self.abs_loss = tf.reduce_mean(tf.abs((self.gt_disparity - self.predicted_disparity) * self.mask), name='abs_loss')
      self.total_loss = self.abs_loss + self._decay()

      
  def _add_loss_summaries(self):
    """"""Add summaries for losses in CIFAR-10 model.

    Generates moving average for all losses and associated summaries for
    visualizing the performance of the network.

    Args:
      total_loss: Total loss from loss().
    Returns:
      loss_averages_op: op for generating moving averages of losses.
    """"""
    # Compute the moving average of all individual losses and the total loss.
    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='loss_avg')
    self.loss_averages_op = loss_averages.apply([self.abs_loss, self.total_loss])

    # Attach a scalar summary to all individual losses and the total loss; do the
    # same for the averaged version of the losses.
    for l in [self.abs_loss, self.total_loss]:
      # Name each loss as '(raw)' and name the moving average version of the loss
      # as the original loss name.
      tf.summary.scalar(l.op.name + ' (raw)', l)
      tf.summary.scalar(l.op.name, loss_averages.average(l))
    
  def _build_train_op(self, global_step):
    """"""Build training specific ops for the graph.""""""
    self.lrn_rate = tf.constant(self.hps.lrn_rate, tf.float32)
    tf.summary.scalar('learning_rate', self.lrn_rate)

    loss_averages_op = self._add_loss_summaries()
    
    with tf.control_dependencies([loss_averages_op]):
      if self.hps.optimizer == 'sgd':
        optimizer = tf.train.GradientDescentOptimizer(self.lrn_rate)
      elif self.hps.optimizer == 'mom':
        optimizer = tf.train.MomentumOptimizer(self.lrn_rate, 0.9)
      elif self.hps.optimizer == 'RMSProp':
        optimizer = tf.train.RMSPropOptimizer(self.lrn_rate, decay=0.9, momentum=0.9, epsilon=1)
        
        trainable_variables = tf.trainable_variables()
        grads = optimizer.compute_gradients(self.total_loss, trainable_variables)


    apply_op = optimizer.apply_gradients(
        grads,
        global_step=global_step, 
        name='train_step')
        
    # Track the moving averages of all trainable variables.
    variable_averages = tf.train.ExponentialMovingAverage(
        MOVING_AVERAGE_DECAY, global_step)
    variables_averages_op = variable_averages.apply(tf.trainable_variables())

    with tf.control_dependencies([apply_op, variables_averages_op]):
      self.train_op = tf.no_op(name='train')

  def _regularization_upsample(self, x, feature, filter_size, in_filter, out_filter, stride, layer_idx):
    with tf.variable_scope('layer_'+str(layer_idx)):
      layer_idx += 1
      x = self._conv3d_trans('conv_trans', x, filter_size, in_filter, out_filter, stride, tf.shape(feature))
      x = self._relu(x, self.hps.relu_leakiness)
      x = self._batch_norm('bn', x)
      
    with tf.variable_scope('residual_after_'+str(layer_idx-1)):
      x += feature

    tf.logging.debug('image after unit %s', x.get_shape())
    return x, layer_idx

  def _regularization_subsample(self, x, filter_size, in_filter, out_filter, stride, layer_idx):

    with tf.variable_scope('layer_'+str(layer_idx)):
      layer_idx += 1
      x = self._conv3d('conv3d', x, filter_size, in_filter, out_filter, stride)
      x = self._relu(x, self.hps.relu_leakiness)
      x = self._batch_norm('bn', x)

    with tf.variable_scope('layer_'+str(layer_idx)):
      layer_idx += 1
      x = self._conv3d('conv3d', x, filter_size, out_filter, out_filter, stride)
      x = self._relu(x, self.hps.relu_leakiness)
      x = self._batch_norm('bn', x)
      
    tf.logging.debug('image after unit %s', x.get_shape())
    return x, layer_idx

  def _unary_feat_residual(self, x, filter_size, in_filter, out_filter, stride, layer_idx):
    orig_x = x
    orig_layer_idx = layer_idx - 1
    
    for i in six.moves.range(2):
      with tf.variable_scope('layer_'+str(layer_idx)):
        layer_idx += 1
        x = self._conv('conv', x, 3, in_filter, out_filter, stride)
        x = self._relu(x, self.hps.relu_leakiness)
        x = self._batch_norm('bn', x)
          
    with tf.variable_scope('residual_btw_'+str(layer_idx-1)+'_'+str(orig_layer_idx)):
      x += orig_x

    tf.logging.debug('image after unit %s', x.get_shape())
    return x, layer_idx


  def _decay(self):
    """"""L2 weight decay loss.""""""
    costs = []
    for var in tf.trainable_variables():
      if var.op.name.find(r'DW') > 0:
        costs.append(tf.nn.l2_loss(var))
        # tf.summary.histogram(var.op.name, var)

    return tf.multiply(self.hps.weight_decay_rate, tf.add_n(costs))

  def _conv(self, name, x, filter_size, in_filters, out_filters, strides):
    """"""Convolution.""""""
    with tf.variable_scope(name):
      n = filter_size * filter_size * out_filters
      kernel = self._variable_on_cpu(
          'DW', [filter_size, filter_size, in_filters, out_filters],
          initializer=tf.random_normal_initializer(
              stddev=np.sqrt(2.0/n)))
      return tf.nn.conv2d(x, kernel, strides, padding='SAME')
      
  def _conv3d(self, name, x, filter_size, in_filters, out_filters, strides):
    """"""Convolution.""""""
    with tf.variable_scope(name):
      n = filter_size * filter_size * filter_size * out_filters
      kernel = self._variable_on_cpu(
          'DW', [filter_size, filter_size, filter_size, in_filters, out_filters],
           initializer=tf.random_normal_initializer(
              stddev=np.sqrt(2.0/n)))
      return tf.nn.conv3d(x, kernel, strides, padding='SAME')
      
  def _conv3d_trans(self, name, x, filter_size, in_filters, out_filters, strides, output_shape):
    """"""Convolution.""""""
    with tf.variable_scope(name):
      n = filter_size * filter_size * filter_size * out_filters
      kernel = self._variable_on_cpu(
          'DW', [filter_size, filter_size, filter_size, out_filters, in_filters],
            initializer=tf.random_normal_initializer(
              stddev=np.sqrt(2.0/n)))
      x_shape = tf.shape(x)
      self.debug_op_list.append(tf.shape(kernel))
      return tf.nn.conv3d_transpose(
                x, 
                kernel, 
                output_shape,
                strides, 
                padding='SAME')

  def _relu(self, x, leakiness=0.0):
    """"""Relu, with optional leaky support.""""""
    return tf.where(tf.less(x, 0.0), leakiness * x, x, name='leaky_relu')

  # TODO(xpan): Consider batch_norm in contrib/layers/python/layers/layers.py
  def _batch_norm(self, name, x):
    """"""Batch normalization.""""""
    with tf.variable_scope(name):
      params_shape = [x.get_shape()[-1]]

      beta = self._variable_on_cpu(
          'beta', params_shape,
          initializer=tf.constant_initializer(0.0, tf.float32))
      gamma = self._variable_on_cpu(
          'gamma', params_shape,
          initializer=tf.constant_initializer(1.0, tf.float32))

      if self.mode == 'train':
        mean, variance = tf.nn.moments(x, range(len(x.get_shape())-1), name='moments')

        moving_mean = self._variable_on_cpu(
            'moving_mean', params_shape,
            initializer=tf.constant_initializer(0.0, tf.float32),
            trainable=False)
        moving_variance = self._variable_on_cpu(
            'moving_variance', params_shape,
            initializer=tf.constant_initializer(1.0, tf.float32),
            trainable=False)

        self._extra_train_ops.append(moving_averages.assign_moving_average(
            moving_mean, mean, BATCHNORM_MOVING_AVERAGE_DECAY))
        self._extra_train_ops.append(moving_averages.assign_moving_average(
            moving_variance, variance, BATCHNORM_MOVING_AVERAGE_DECAY))
      else:
        mean = self._variable_on_cpu(
            'moving_mean', params_shape,
            initializer=tf.constant_initializer(0.0, tf.float32),
            trainable=False)
        variance = self._variable_on_cpu(
            'moving_variance', params_shape,
            initializer=tf.constant_initializer(1.0, tf.float32),
            trainable=False)
      y = tf.nn.batch_normalization(
          x, mean, variance, beta, gamma, 0.001)
      y.set_shape(x.get_shape())
      return y

  def _variable_on_cpu(self, name, shape, initializer, dtype=tf.float32, trainable=True):
    """"""Helper to create a Variable stored on CPU memory.

    Args:
      name: name of the variable
      shape: list of ints
      initializer: initializer for Variable

    Returns:
      Variable Tensor
    """"""
    with tf.device('/cpu:0'):
      var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype, trainable=trainable)
    return var
```",0,,11,2017-06-08T13:50:49Z,NONE
10520,tf.layers.conv3d_transpose() gives error,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04.2 LTS (Xenial Xerus)
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.2.0-rc2
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8/5.1.10
- **GPU model and memory**:
GeForce GTX 1080
- **Exact command to reproduce**:
```
import tensorflow as tf
x_3d = tf.placeholder(tf.float32,shape=[None,5,5,5,1])
conv_t = tf.layers.conv3d_transpose(x_3d,20,[3,3,3])
```

### Describe the problem
I am getting a TypeError when I use a placeholder with batch size as None as inputs to the conv3d_transpose. This problem does not happen with the tf.layers.conv2d_transpose()

### Source code / logs
```
import tensorflow as tf
x_2d = tf.placeholder(tf.float32,shape=[None,5,5,1])
conv2d_t = tf.layers.conv2d_transpose(x_2d,20,[3,3])
x_3d = tf.placeholder(tf.float32,shape=[None,5,5,5,1])
conv_t = tf.layers.conv3d_transpose(x_3d,20,[3,3,3])
```

> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-3-94e71945bcae> in <module>()
>       4 
>       5 x_3d = tf.placeholder(tf.float32,shape=[None,5,5,5,1])
> ----> 6 conv_t = tf.layers.conv3d_transpose(x_3d,20,[3,3,3])
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/convolutional.pyc in conv3d_transpose(inputs, filters, kernel_size, strides, padding, data_format, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, trainable, name, reuse)
>    1538       _reuse=reuse,
>    1539       _scope=name)
> -> 1540   return layer.apply(inputs)
>    1541 
>    1542 
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.pyc in apply(self, inputs, *args, **kwargs)
>     490       Output tensor(s).
>     491     """"""
> --> 492     return self.__call__(inputs, *args, **kwargs)
>     493 
>     494   def _assert_input_compatibility(self, inputs):
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.pyc in __call__(self, inputs, *args, **kwargs)
>     439         # Check input assumptions set after layer building, e.g. input shape.
>     440         self._assert_input_compatibility(inputs)
> --> 441         outputs = self.call(inputs, *args, **kwargs)
>     442 
>     443         # Apply activity regularization.
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/convolutional.pyc in call(self, inputs)
>    1456         outputs_4d = array_ops.reshape(outputs, [
>    1457             outputs_shape[0], outputs_shape[1] * outputs_shape[2],
> -> 1458             outputs_shape[3], outputs_shape[4]
>    1459         ])
>    1460       outputs_4d = nn.bias_add(
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.pyc in reshape(tensor, shape, name)
>    2449   """"""
>    2450   result = _op_def_lib.apply_op(""Reshape"", tensor=tensor, shape=shape,
> -> 2451                                 name=name)
>    2452   return result
>    2453 
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
>     491           except TypeError as err:
>     492             if dtype is None:
> --> 493               raise err
>     494             else:
>     495               raise TypeError(
> 
> TypeError: Failed to convert object of type <type 'list'> to Tensor. Contents: [None, 49, 7, 20]. Consider casting elements to a supported type.
> 
> ",1,,7,2017-06-08T04:00:34Z,NONE
10488,Changing the cache_size in Gemmlowp/meta/single_thread_gemm.h cause random error in Requantize nodes,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux ubuntu 16.04

- **TensorFlow installed from (source or binary)**:

source, NDK built Android ARM64 binary

- **TensorFlow version (use command below)**:

commit id: f48673b5054b474fa1e51823edd075088cd16d5f
Author: Luke Iwanski <luke@codeplay.com>

- **Bazel version (if compiling from source)**:
0.4.5

- **CUDA/cuDNN version**:
no

- **GPU model and memory**:
no

- **Exact command to reproduce**:
1. bazel --output_base=../out/armv8_benchmark_model/ build -s -c opt --jobs=1 --crosstool_top=//external:android/crosstool --cpu=arm64-v8a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain  tensorflow/tools/benchmark:benchmark_model 2>&1 |tee log.txt
2.adb push benchmark_model /data/local/tmp/
 
3. run_vgg1 on Nexus5X6P phone:
script:
time ./$1 --graph=$2   --input_layer=""images:0""   --input_layer_shape=""1,224,224,3""   --input_layer_type=""float""   --output_layer=""prob:0"" --num_runs=1

The final command line that I use:
./run_vgg1.sh benchmark_model vgg16.8bit.weightsnodes.model

### My problem
When I change the cache_size from 256*1024 to 128*1024 in the Gemmlowp/meta/single_thread_gemm.h, the benchmark_model randomly failed on the 8 bit quantized both node and weights vgg16 model.

### Source code / logs
My Tensorflow commit-id:
commit f48673b5054b474fa1e51823edd075088cd16d5f

My modify for the Gemmlowp:
in file  gemmlowp/meta/single_thread_gemm.h:
change all the ""int cache_size = 256 * 1024"" to ""int cache_size = 128 * 1024"".

The error log is :
native : benchmark_model.cc:381 Graph: [vgg16.8bit.weightsnodes.model]
native : benchmark_model.cc:382 Input layers: [images:0]
native : benchmark_model.cc:383 Input shapes: [1,224,224,3]
native : benchmark_model.cc:384 Input types: [float]
native : benchmark_model.cc:385 Output layers: [prob:0]
native : benchmark_model.cc:386 Num runs: [1]
native : benchmark_model.cc:387 Inter-run delay (seconds): [-1.0]
native : benchmark_model.cc:388 Num threads: [-1]
native : benchmark_model.cc:389 Benchmark name: []
native : benchmark_model.cc:390 Output prefix: []
native : benchmark_model.cc:391 Show sizes: [0]
native : benchmark_model.cc:392 Warmup runs: [2]
native : benchmark_model.cc:52 Loading TensorFlow.
native : benchmark_model.cc:59 Got config, 0 devices
can't determine number of CPU cores: assuming 4
can't determine number of CPU cores: assuming 4
native : benchmark_model.cc:257 Running benchmark for 2 iterations without detailed stat logging:
native : benchmark_model.cc:233 Error during inference: Invalid argument: requested_output_max must be >= requested_output_min, but got nan and 0
	 [[Node: fc8/BiasAdd/eightbit/requantize = Requantize[Tinput=DT_QINT32, out_type=DT_QUINT8, _device=""/job:localhost/replica:0/task:0/cpu:0""](fc8/BiasAdd/eightbit, fc8/BiasAdd/eightbit:1, fc8/BiasAdd/eightbit:2, fc8/BiasAdd/eightbit/requant_range, fc8/BiasAdd/eightbit/requant_range:1)]]
native : benchmark_model.cc:268 Failed on run 0
native : benchmark_model.cc:451 Timing failed with Invalid argument: requested_output_max must be >= requested_output_min, but got nan and 0
	 [[Node: fc8/BiasAdd/eightbit/requantize = Requantize[Tinput=DT_QINT32, out_type=DT_QUINT8, _device=""/job:localhost/replica:0/task:0/cpu:0""](fc8/BiasAdd/eightbit, fc8/BiasAdd/eightbit:1, fc8/BiasAdd/eightbit:2, fc8/BiasAdd/eightbit/requant_range, fc8/BiasAdd/eightbit/requant_range:1)]]
    0m11.12s real     0m27.55s user     0m01.87s system



",0,,11,2017-06-07T10:32:03Z,CONTRIBUTOR
10487,"Variable ""weights"" does not exist with BasicLSTMcell or LSTMBlockCell ",,"### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: via pip with GPU support
- **TensorFlow version (use command below)**: 1.1
- **GPU model and memory**: GPU Titan X

### Describtion of the problem

I am trying to use LSTM cell, but when I make the __call__ to it, I receive an ValueError message saying that the variable weights is does not exist or not created with get_variable().

I looked into the tensorflow source code of the BasicLSTMCell or LSTMBlockCell and we can see that the weights matrix is getted by a call to tf.get_variable()... So it seems to be a bug, right ? 
Does someone can tell me if I made a mistake of if it is a bug ?

NB: Note that i tried several other solution with variable_scope instead of name_scope, with reuse = True, of False , with no success ... 

### Source code / logs : 
**here is the source code of BasicLSTMCell and LSTMBlockCell**
the call to get_variable into LSTMBlockCell __call_ funtion
```
w = vs.get_variable(self._names[""W""], [input_size + self._num_units,
                                             self._num_units * 4])
```
and into the _linear function used by BasicLSTMCell
```
weights = vs.get_variable(
_WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)
```

**here is my source code**
```
lstm_cell = tf.contrib.rnn.LSTMBlockCell(num_units=self._state_size)
for t in range(self._rnn_step):
    with tf.name_scope('lstm'):
    _, (c, h) = lstm_cell(lstm_input, [c, h], scope=tf.get_variable_scope())
```

**here is the error message**
```
  File ""/home/toto/workspace/model.py"", line 441, in _rnn
    _, (c, h) = lstm_cell(lstm_input, [c, h], scope=tf.get_variable_scope())
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py"", line 382, in __call__
    self._num_units * 4])
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1049, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 948, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 356, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 341, in _true_getter
    use_resource=use_resource)
  File ""/home/toto/PythonEnv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 671, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
```",1,,3,2017-06-07T09:30:48Z,NONE
10479,Possible bug: LSTMCell with use_peephole=True breaks when using initializer=tf.orthogonal_initializer,stat:awaiting response,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX Sierra
- **TensorFlow installed from (source or binary)**: binary - pip
- **TensorFlow version (use command below)**: 1.2rc0
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:
```

class ToyModel(object):
	def __init__(self):
		x = tf.get_variable(""x"", shape=[5, 3, 7],
							initializer=tf.random_normal_initializer(),
							trainable=False)
		cell = tf.contrib.rnn.LSTMCell(7, use_peepholes=True, initializer=tf.orthogonal_initializer)
		self.rnn_out, self.final_state = tf.nn.dynamic_rnn(cell=cell,
														   inputs=x,
														   parallel_iterations=8,
														   time_major=True,
														   dtype=tf.float32)


graph_context = tf.Graph()
with graph_context.as_default():
	m1 = ToyModel()

	tf_init = tf.global_variables_initializer()
	save_dir = ""/Users/delkind/Desktop/whd/tf_checkpoints/unit_test""

	sv = tf.train.Supervisor(logdir=save_dir)
	with sv.managed_session() as sess:
		y1 = m1.rnn_out.eval(session=sess)

		print(y1)
```
### Describe the problem
I believe this is a bug. When using this code, the following error is raised.
```

Traceback (most recent call last):
  File ""src/tensorflow_unit_tests.py"", line 84, in <module>
    m1 = ToyModel()
  File ""src/tensorflow_unit_tests.py"", line 79, in __init__
    dtype=tf.float32)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 566, in dynamic_rnn
    dtype=dtype)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 729, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2766, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2595, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2545, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 712, in _time_step
    skip_conditionals=True)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 198, in _rnn_step
    new_output, new_state = call_cell()
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 700, in <lambda>
    call_cell = lambda: cell(input_t, state)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 685, in __call__
    output, new_state = self._cell(inputs, state, scope)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 165, in __call__
    return super(_RNNCell, self).__call__(inputs, state)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 439, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 376, in call
    ""w_f_diag"", shape=[self._num_units], dtype=dtype)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1065, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 962, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 360, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 168, in _rnn_get_variable
    variable = getter(*args, **kwargs)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 352, in _true_getter
    use_resource=use_resource)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 725, in _get_single_variable
    validate_shape=validate_shape)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 200, in __init__
    expected_shape=expected_shape)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 278, in _init_from_args
    initial_value(), name=""initial_value"", dtype=dtype)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 701, in <lambda>
    shape.as_list(), dtype=dtype, partition_info=partition_info)
  File ""/Users/delkind/Desktop/whd/venv_tf_1.2rc0/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 481, in __call__
    raise ValueError(""The tensor to initialize must be ""
ValueError: The tensor to initialize must be at least two-dimensional

```
This is unexpected behavior. If you omit either of ```initializer=tf.orthogonal_initializer``` or ```use_peephole=True```, the graph can be built and evaluated as expected. I'm not aware of a mathematical reason the weights in this model cannot be orthogonal.

",1,,10,2017-06-07T03:23:42Z,NONE
10478,tfdbg error when stepping through a graph that uses tf.train.shuffle_batch,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.2.0-rc1-24-gce1d6ec 1.2.0-rc2
(I also got the same error with tf 1.1.0)
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 8.0, cuDNN 5.1
- **GPU model and memory**: Nvidia GTX 1060
- **Exact command to reproduce**:
The following code will start a tfdbg session. Inside this session, enter these commands to get the error:
tfdbg> invoke_stepper
tfdbg> s
tfdbg> s
tfdbg> s
```
import tensorflow as tf
from tensorflow.python import debug as tf_debug

def read_records(filename_queue, enqueue_many_size=1024):
    reader = tf.TFRecordReader()
    _, queue_batch = reader.read_up_to(filename_queue, enqueue_many_size)
    return queue_batch

def input_batch(filenames, batch_size, num_epochs, min_after_dequeue=128, num_threads=8):
    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs)
    queue_batch = read_records(filename_queue)

    capacity = min_after_dequeue + (num_threads + 3) * batch_size
    batch_serialized_example = tf.train.shuffle_batch(
        [queue_batch],
        batch_size=batch_size,
        num_threads=num_threads,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue,
        enqueue_many=True)

    return batch_serialized_example

b = input_batch(['test_filename'], 32, 5)
sess = tf_debug.LocalCLIDebugWrapperSession(tf.Session())
sess.run(b)
```

### Describe the problem
tfdbg seemingly cannot step through a graph that uses tf.train.shuffle_batch. I cannot work around it by ""stepping over"" the node using step -t either.

### Source code / logs
Running the code provided above and stepping through the graph produces this stack trace. In a real graph, the error stops me from stepping any further. I worked out from looking at types_pb2.py that the value 20 is DT_RESOURCE. It seems like the error is triggered when tfdbg tries to convert this datatype to a numpy array.

```
--- Node Stepper: run #1: 1 fetch (shuffle_batch:0); 0 feeds ------
| <-- --> | s
Error occurred during handling of command: step :
<class 'KeyError'>: 20                                                                                                                                                                                    UP

Traceback (most recent call last):
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py"", line 664, in dispatch_command
    output = handler(argv, screen_info=screen_info)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/cli/stepper_cli.py"", line 487, in step
    screen_output = self.cont([self._sorted_nodes[self._next]], screen_info)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/cli/stepper_cli.py"", line 397, in cont
    restore_variable_values=parsed.restore_variable_values)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/debug/lib/stepper.py"", line 679, in cont
    options=run_options)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 952, in _run
    subfeed_dtype = subfeed_t.dtype.as_numpy_dtype
  File ""/home/ed/.pyenv/versions/neda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py"", line 122, in as_numpy_dtype
    return _TF_TO_NP[self._type_enum]
KeyError: 20
```
",1,,11,2017-06-07T03:14:35Z,NONE
10468,[feature] Use Core ML on iOS,type:feature,"Apple announced [Core ML](https://developer.apple.com/documentation/coreml) which may be useful for abstracting away the complexities of the hardware platform:

![image](https://user-images.githubusercontent.com/51059/26841383-5226ef0c-4ab7-11e7-9ce9-61849a3c0cc9.png)

Related:
* https://github.com/tensorflow/tensorflow/issues/7958 (MPS)
* https://github.com/tensorflow/tensorflow/issues/3001 (BNNS)",1,,15,2017-06-06T16:55:30Z,CONTRIBUTOR
10458,Transform_graph android error ,,"Hi,
One month back I generated my custom TF model (output_graph.pb ) using Tensor Flow 1.0.1. It was working fine after optimization it using optimize_for_interface.

Now I plan to reduce its size and improve execution speed, I downloaded Tensor Flow 1.2.0.  I used transform_graph as 
 bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=./output_graph.pb \
--out_graph=./transformed_graph.pb \
--inputs='Mul' \
--outputs='final_result' \
--transforms='
  add_default_attributes
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  quantize_nodes
  strip_unused_nodes
  sort_by_execution_order'

I built the APK and ran on a Lenovo Yoga 3 tablet.
It generated a run time error:

W/native  (24951): op_kernel.cc:1165 Invalid argument: computed output size would be negative
E/TensorFlowInferenceInterface(24951): Failed to run TensorFlow inference with inputs:[Mul], outputs:[final_result]
--------- beginning of crash
E/AndroidRuntime(24951): FATAL EXCEPTION: inference
E/AndroidRuntime(24951): Process: org.tensorflow.demo, PID: 24951
E/AndroidRuntime(24951): java.lang.IllegalArgumentException: computed output size would be negative
E/AndroidRuntime(24951): 	 [[Node: pool_3/eightbit = QuantizedAvgPool[T=DT_QUINT8, ksize=[1, 8, 8, 1], padding=""VALID"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](mixed_10/join/eightbit, mixed_10/join/eightbit:1, mixed_10/join/eightbit:2)]]
E/AndroidRuntime(24951): 	at org.tensorflow.Session.run(Native Method)
E/AndroidRuntime(24951): 	at org.tensorflow.Session.access$100(Session.java:48)

In both the cases, the Bazel version is 0.4.5
Any help to solve this? 



",1,,12,2017-06-06T12:28:08Z,NONE
10449,[Feature]Adding automatic model average parallelism support in TF,"awaiting review,stat:awaiting tensorflower","Model Average is a common paradigm for distributed DL training, also there are several papers regarding to it and its variants:

(https://arxiv.org/pdf/1410.7455v8.pdf)
(http://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/0005880.pdf)

Do we have any plan to bring this support into TF? Actually we have already implemented model average support and benchmarked it on several in-house models, the speed up is good, about 3X(4 cards) to 9X(16 cards) convergence speed-up. Also we are working on making the model average mechanism as automatic as possible, so modeling guys could easily leverage this nice feature.

If TF community is fine with this feature/enhancement, we will be happy to merge our code into community.

Thanks.

",0,,9,2017-06-06T05:33:29Z,NONE
10439,Different timelines on QueueDequeManyV2 in cpu and gpu installations,,"OS Platform and Distribution: Ubuntu 14.04
TensorFlow version: 
    cpu: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
    gpu:  ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')

CUDA/cuDNN: 8.0/5.0

env: https://pastebin.com/f70fQ9Mw

I'm trying to fill queue of input data in additional thread in python, but obtain very strange timings for this operation, different for cpu and gpu version in 20 times. as you can see in full script, i forced device to cpu 

full script i'm using to fill queue: https://pastebin.com/Ny1QVZh2

key part:
```
    enqueue_op = queue.enqueue_many([queue_input_data, queue_input_target])
    dequeue_op = queue.dequeue()
 
    data_batch, target_batch = tf.train.batch(dequeue_op, batch_size=batch_size, capacity=10 * batch_size)
 
    def enqueue(sess):
        while True:
            sess.run(enqueue_op, feed_dict={queue_input_data: data, queue_input_target: target})

...

    run_options = tf.RunOptions(timeout_in_ms=4000, trace_level=tf.RunOptions.FULL_TRACE)
    run_metadata = tf.RunMetadata()
    sess.run(
        target_batch,
        options=run_options,
        run_metadata=run_metadata)
 
    tl = timeline.Timeline(run_metadata.step_stats)
    ctf = tl.generate_chrome_trace_format()
    with open('timeline.json', 'w') as f:
        f.write(ctf)
```
Steps to reproduce:
```
# cpu only version
pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.1.0-cp27-none-linux_x86_64.whl
python read_feed_dict.py
mv timeline.json timeline_cpu_version.json

pip uninstall tensorflow

# gpu version
pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.1.0-cp27-none-linux_x86_64.whl
python read_feed_dict.py
mv timeline.json timeline_gpu_version.json
```
cpu timeline:
![cpu](https://cloud.githubusercontent.com/assets/1593310/26796368/f636b37e-4a31-11e7-8851-863e74643697.png)

gpu timeline:
![gpu](https://cloud.githubusercontent.com/assets/1593310/26796369/f640d688-4a31-11e7-989d-197a7f2499e7.png)




",1,,4,2017-06-05T18:04:17Z,NONE
10419,[Feature Request] A guide for creating custom DeepDream models,"stat:awaiting tensorflower,type:docs","The current DeepDream guide located [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/deepdream), uses the inception5h model. From what I can tell, it does not appear very straightforward in terms of how to fine tune the model in order to create different DeepDream hallucinations from a custom data set. It also does not appear to be relatively easy to change the model that the guide uses. 

I think that an additional guide which shows individuals how to fine tune a model for the purposes of DeepDream would be useful for those trying to explore the artistic and visual aspects of TensorFlow models. I haven't been able to find any guide for creating custom DeepDream models in Tensorflow, so I am not sure where to start.


",0,,5,2017-06-03T20:41:17Z,NONE
10408,Memory leak ,type:bug/performance,"I have a memory leak with TensorFlow. I refered to https://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session to address my issue, and I followed the advices of the answer, that seemed to have solved the problem. However it does not work here. 

In order to recreate the memory leak, I have created a simple example. First, I use this function (that I got here : https://stackoverflow.com/questions/276052/how-to-get-current-cpu-and-ram-usage-in-python) to check the memory use of the python process : 

    def memory():
        import os
        import psutil
        pid = os.getpid()
        py = psutil.Process(pid)
        memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think
        print('memory use:', memoryUse)

Then, everytime I call the `build_model` function, the use of memory increases.

Here is the `build_model` function that has a memory leak : 
 
    def build_model():

        '''Model'''

        tf.reset_default_graph()


        with tf.Graph().as_default(), tf.Session() as sess:
            tf.contrib.keras.backend.set_session(sess)

            labels = tf.placeholder(tf.float32, shape=(None, 1))
            input = tf.placeholder(tf.float32, shape=(None, 1))

            x = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense1')(input)
            x1 = tf.contrib.keras.layers.Dropout(0.5)(x)
            x2 = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense2')(x1)
            y = tf.contrib.keras.layers.Dense(1, activation='sigmoid', name='dense3')(x2)


            loss = tf.reduce_mean(tf.contrib.keras.losses.binary_crossentropy(labels, y))

            train_step = tf.train.AdamOptimizer(0.004).minimize(loss)

            #Initialize all variables
            init_op = tf.global_variables_initializer()
            sess.run(init_op)

            sess.close()

        tf.reset_default_graph()

        return 

 I would have thought that using the block ` with tf.Graph().as_default(), tf.Session() as sess: ` and then **closing the session** and **calling `tf.reset_default_graph`** would clear all the memory used by TensorFlow. Apparently it does not.

The memory leak can be recreated as following : 

    memory()
    build_model()
    memory()
    build_model()
    memory()

The output of this is (for my computer) :

    memory use: 0.1794891357421875
    memory use: 0.184417724609375
    memory use: 0.18923568725585938

Clearly we can see that all the memory used by TensorFlow is not freed afterwards. Why?

I hope I made myself clear.",1,,22,2017-06-02T21:55:39Z,NONE
10389,slim.conv2d Error: Input has undefined `axis` dimension.,,"Here is my code:
```
import tensorflow as tf
slim = tf.contrib.slim
data_format='NCHW'

input = tf.placeholder(dtype=tf.float32, shape=[2, 4, None, None])
with slim.arg_scope([slim.batch_norm], data_format=data_format):
    net = slim.conv2d(input, 4, kernel_size=3, stride=1, padding='SAME', rate=2,
                      data_format=data_format, normalizer_fn=slim.batch_norm)
```

Here is the logs:
```
Traceback (most recent call last):
  File ""/home/zzy/workspace/tf-models/mind_slim/examples/test.py"", line 9, in <module>
    net = slim.conv2d(input, 4, kernel_size=3, stride=1, padding='SAME', rate=2, data_format=data_format, normalizer_fn=slim.batch_norm)
  File ""/home/zzy/anaconda2/envs/tf-gpu-py27-source/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/home/zzy/anaconda2/envs/tf-gpu-py27-source/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 927, in convolution
    outputs = normalizer_fn(outputs, **normalizer_params)
  File ""/home/zzy/anaconda2/envs/tf-gpu-py27-source/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/home/zzy/anaconda2/envs/tf-gpu-py27-source/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 528, in batch_norm
    outputs = layer.apply(inputs, training=is_training)
  File ""/home/zzy/anaconda2/envs/tf-gpu-py27-source/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 320, in apply
    return self.__call__(inputs, **kwargs)
  File ""/home/zzy/anaconda2/envs/tf-gpu-py27-source/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 286, in __call__
    self.build(input_shapes[0])
  File ""/home/zzy/anaconda2/envs/tf-gpu-py27-source/lib/python2.7/site-packages/tensorflow/python/layers/normalization.py"", line 118, in build
    input_shape)
ValueError: ('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(2), Dimension(None), Dimension(None), Dimension(None)]))
```

When I change the rate to 1
Or I change the data_format to 'NHWC' and input to [2, None, None, 4]
It works without any error.
My tensorflow version: 1.1",1,,7,2017-06-02T08:41:20Z,NONE
10375,[Feature] sparse_tensor_dense_matmul with two SparseTensor,stat:awaiting tensorflower,"Would it be possible to implement matrix multiplication between two `SparseTensor`? 

Currently, it's possible to multiply two dense `Tensor` with many zeros using the `X_is_sparse` parameter of `tf.matmul`, and a `SparseTensor` with a `Tensor` using `tf.sparse_tensor_dense_matmul`. 

However, with some datasets it is impossible to store dense matrices in memory and it would be great if we could have the option of fully sparse multiplication.

Thanks,
Daniele
",0,,10,2017-06-01T15:39:20Z,NONE
10370,Bug: ProtoBuf tokenizer crashes when loading single_image_random_dot_stereograms OP,type:bug/performance,"### System information
- No custom code
- Ubuntu 17.04 (also confirmed on 16.04)
- TensorFlow installed from source
- TensorFlow version: v1.2.0-rc0-486-g95d90ab2e 1.2.0-rc1
- Bazel version: 0.5.0
- Python version: 3.5.3 (also confirmed on 2.7.12):
- Not tested with GPU support:

Reproduction
------------------

    import tensorflow as tf
    regressor = tf.contrib.learn.LinearRegressor(feature_columns=[])

Alternative:

    import keras

Reference: [Stackoverflow](https://stackoverflow.com/questions/44291072/google-protobuf-text-format-parseerror-when-instantiating-a-tensorflow-model-wit)

Manifestation of the error
---------------------------------

The first method to reproduce should cause an assert due to the empty `feature_columns`.
Instead, the protobuf tokenizer crashes with:

> Traceback (most recent call last):
>  File ""<stdin>"", line 1, in <module>
>  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py"", line 53, in __getattr__
>    module = self._load()
>  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/lazy_loader.py"", line 42, in _load
>    module = importlib.import_module(self.__name__)
>  File ""/usr/lib/python3.5/importlib/__init__.py"", line 126, in import_module
>    return _bootstrap._gcd_import(name[level:], package, level)
>  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
>  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
>  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
>  File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked
>  File ""<frozen importlib._bootstrap_external>"", line 673, in exec_module
>  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
>  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/__init__.py"", line 35, in <module>
>    from tensorflow.contrib import image
>  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/__init__.py"", line 40, in <module>
>    from tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms
>  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py"", line 26, in <module>
>    ""_single_image_random_dot_stereograms.so""))
>  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/util/loader.py"", line 55, in load_op_library
>    ret = load_library.load_op_library(path)
>  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/load_library.py"", line 84, in load_op_library
>    exec(wrappers, module.__dict__)
>  File ""<string>"", line 248, in <module>
>  File ""<string>"", line 114, in _InitOpDefLibrary
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 481, in Merge
>    descriptor_pool=descriptor_pool)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 535, in MergeLines
>    return parser.MergeLines(lines, message)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 568, in MergeLines
>    self._ParseOrMerge(lines, message)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 583, in _ParseOrMerge
>    self._MergeField(tokenizer, message)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 684, in _MergeField
>    merger(tokenizer, message, field)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 773, in _MergeMessageField
>    self._MergeField(tokenizer, sub_message)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 684, in _MergeField
>    merger(tokenizer, message, field)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 773, in _MergeMessageField
>    self._MergeField(tokenizer, sub_message)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 684, in _MergeField
>    merger(tokenizer, message, field)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 773, in _MergeMessageField
>    self._MergeField(tokenizer, sub_message)
>  File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 652, in _MergeField
>    (message_descriptor.full_name, name))
>google.protobuf.text_format.ParseError: 48:12 : Message type ""tensorflow.AttrValue"" has no field named ""5"".

What causes this exception?
--------------------------------------

The problem is the information extracted from the `_single_image_random_dot_stereograms.so` library file from `/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/image/python/ops/`
This file contains encoded information passed to protobuf.

The problem occurs when a line with a `float` default is parsed.

In this case, it is the sequence

    eye_separation: float = 2.5

at offset *0xa3b4* in `emphasized _single_image_random_dot_stereograms.so`

Somehow, the parser replaces decimal points with commas. In the end, this is created:

    attr {\n'
      name: ""eye_separation""\n'
      type: ""float""\n'
      default_value {\n'
        f: 2,5\n'
      }\n'
    }\n'

The tokenizer (at `google/protobuf/text_format.py`) gets confused by the `,` in the default value and thinks that `5` is a separate field.

Root of the error
---------------------

The error occurs during the execution of [load_library.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/load_library.py#L72).

    op_list_str = py_tf.TF_GetOpList(lib_handle)
    op_list = op_def_pb2.OpList()
    op_list.ParseFromString(compat.as_bytes(op_list_str))
    wrappers = py_tf.GetPythonWrappers(op_list_str)

`op_list` contains the correct default value of `2.5`, whereas `wrappers`, the wrapped list returned from [python_op_gen.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/python_op_gen.cc#L762) contains a `2,5`.

This is what `GetPythonWrappers` does:

    string GetPythonWrappers(const char* op_list_buf, size_t op_list_len) {
      string op_list_str(op_list_buf, op_list_len);
      OpList ops;
      ops.ParseFromString(op_list_str);
      return GetPythonOps(ops, {}, false);
    }

The appended files include the contents of the `op_list` and the `wrappers` variable:
[op_list.txt](https://github.com/tensorflow/tensorflow/files/1044775/op_list.txt)
[wrapper.txt](https://github.com/tensorflow/tensorflow/files/1044777/wrapper.txt)

",1,,10,2017-06-01T12:55:17Z,NONE
10352,Feature request: Update OpDef proto to ease 1-based indexing,type:docs,"It would be nice if the `OpDef` proto included information on which inputs and attributes are indices, so that TensorFlow bindings for index-from-1 languages (like Julia) could automatically subtract 1 from the parameters of client calls that refer to those parameters. 

Currently, the Julia binding has to rely on [rough heuristics](https://github.com/malmaud/TensorFlow.jl/blob/40d963f010bd394258d4a950069db85401430050/src/ops.jl#L232), like checking if the operation's input's type attribute is called ""Tidx"", to provide the conversion. ",1,,6,2017-05-31T18:59:52Z,CONTRIBUTOR
10338,tensorflow.Session() crashes if executed after importing scipy.optimize and pytorch,stat:awaiting tensorflower,"### Configuration

Python version: 3.5.2 (same for Python 3.6)
SciPy version: 0.19.0
PyTorch version: 0.1.12_2
TensorFlow version: 1.1.0
Host system: Ubuntu 16.04

### Dockerfile to reproduce my setup:

```
FROM nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04

RUN apt-get update -qq \
 && apt-get install -yq -qq --no-install-recommends \
    python3 \
    python3-dev \
    curl \
    ca-certificates
RUN curl -O https://bootstrap.pypa.io/get-pip.py && python3 get-pip.py && rm get-pip.py
RUN pip3 install numpy scipy
RUN pip3 install --no-cache-dir tensorflow-gpu
RUN pip3 install --no-cache-dir http://download.pytorch.org/whl/cu80/torch-0.1.12.post2-cp35-cp35m-linux_x86_64.whl
```

### Describe the problem

```
Python 3.5.2 (default, Nov 17 2016, 17:05:23) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import scipy.optimize
>>> import torch
>>> import tensorflow
>>> tensorflow.Session()
*** Error in `python3': free(): invalid pointer: 0x00007f28329efac0 ***
```

### Output

The above error message is followed by a huge backtrace that starts like this ...

```
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f28796ed7e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x7fe0a)[0x7f28796f5e0a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f28796f998c]
/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_ZNSt15basic_stringbufIcSt11char_traitsIcESaIcEE8overflowEi+0x181)[0x7f28377aefa1]
/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_ZNSt15basic_streambufIcSt11char_traitsIcEE6xsputnEPKcl+0x89)[0x7f2837805e79]
/usr/local/lib/python3.5/dist-packages/torch/lib/libshm.so(_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l+0x1c5)[0x7f2832764235]
/usr/local/lib/python3.5/dist-packages/torch/lib/libshm.so(_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc+0x27)[0x7f28327644f7]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow20BaseGPUDeviceFactory17GetValidDeviceIdsERKSsPSt6vectorIiSaIiEE+0x7c7)[0x7f27fb0a8127]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow20BaseGPUDeviceFactory13CreateDevicesERKNS_14SessionOptionsERKSsPSt6vectorIPNS_6DeviceESaIS8_EE+0x15a)[0x7f27fb0a9dca]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow13DeviceFactory10AddDevicesERKNS_14SessionOptionsERKSsPSt6vectorIPNS_6DeviceESaIS8_EE+0x17d)[0x7f27fb0d2bad]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow20DirectSessionFactory10NewSessionERKNS_14SessionOptionsE+0x98)[0x7f27fb0904c8]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow10NewSessionERKNS_14SessionOptionsEPPNS_7SessionE+0x127)[0x7f27fb103c07]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x114c081)[0x7f27f968e081]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0xe8670b)[0x7f27f93c870b]
python3(PyCFunction_Call+0x4f)[0x4e9b9f]
python3(PyEval_EvalFrameEx+0x614)[0x524414]
python3[0x52d2e3]
python3(PyEval_EvalFrameEx+0x50ee)[0x528eee]
python3(PyEval_EvalCodeEx+0x88a)[0x52e87a]
python3[0x4ebd38]
python3(PyObject_Call+0x47)[0x5b7167]
python3[0x4f413e]

...
```

and ends like this

```
7f2879cf3000-7f2879cf4000 rw-s cfdf2000 00:2e 14                         /dev/nvidia0
7f2879cf4000-7f2879cf5000 rw-s 18da776000 00:2e 12                       /dev/nvidiactl
7f2879cf5000-7f2879e7a000 rw-p 00000000 00:00 0 
7f2879e7a000-7f2879e7b000 rw-s cfdf2000 00:2e 14                         /dev/nvidia0
7f2879e7b000-7f2879e7c000 rw-s 1ec635d000 00:2e 12                       /dev/nvidiactl
7f2879e7c000-7f2879e7d000 rw-s cfdf2000 00:2e 14                         /dev/nvidia0
7f2879e7d000-7f2879e7e000 rw-s 1ffafd3000 00:2e 12                       /dev/nvidiactl
7f2879e7e000-7f2879e7f000 rwxp 00000000 00:00 0 
7f2879e7f000-7f2879e81000 rw-p 00000000 00:00 0 
7f2879e81000-7f2879e82000 r--p 00025000 08:01 3973057                    /lib/x86_64-linux-gnu/ld-2.23.so
7f2879e82000-7f2879e83000 rw-p 00026000 08:01 3973057                    /lib/x86_64-linux-gnu/ld-2.23.so
7f2879e83000-7f2879e84000 rw-p 00000000 00:00 0 
7ffe1932c000-7ffe1934d000 rw-p 00000000 00:00 0                          [stack]
7ffe193bf000-7ffe193c1000 r--p 00000000 00:00 0                          [vvar]
7ffe193c1000-7ffe193c3000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
Aborted (core dumped)
```",0,,8,2017-05-31T16:41:27Z,CONTRIBUTOR
10306,Build fails on ppc64le,stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 359d6f9716c0bb9bd8201ce600da98b0481a8049
- **Bazel version (if compiling from source)**:  0.4.5-2017-05-25 (@255953740)
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: `bazel build --verbose_failures --show_package_location  //tensorflow/tools/pip_package:build_pip_package`

### Describe the problem
On a ppc64le machine running Ubuntu 17.04 I am not able to build tensorflow.

### Source code / logs
```
ERROR: /home/brosa/.cache/bazel/_bazel_brosa/141a2b9f209d04ad1bc4d9433836a54c/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/BUILD:54:1: Generating SOY v2 Java files @io_bazel_rules_closure//java/io/bazel/rules/closure/webfiles/server:listing_files failed: bash failed: error executing command
  (cd /home/brosa/.cache/bazel/_bazel_brosa/141a2b9f209d04ad1bc4d9433836a54c/execroot/org_tensorflow && \
  exec env - \
    PATH=/home/brosa/bazel/output:/home/brosa/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/com_google_template_soy/SoyParseInfoGenerator --outputDirectory=bazel-out/host/genfiles/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server --javaPackage=io.bazel.rules.closure.webfiles.server --javaClassNameSource=filename --allowExternalCalls=1 $(cat bazel-out/host/genfiles/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/listing_files__srcs) $(cat bazel-out/host/genfiles/external/io_bazel_rules_closure/java/io/bazel/rules/closure/webfiles/server/listing_files__deps)'): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Unrecognized option: -client
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
Target //tensorflow/tools/pip_package:build_pip_package failed to build


```",0,,9,2017-05-30T23:11:11Z,CONTRIBUTOR
10299,document how to use selective_registration and the use of __ANDROID_FULL_TYPE__,stat:awaiting tensorflower,"Every developer wants to use his own model. 
Most app built for Mobile will crash at runtime, because those model won't just use the sparse subset of ops shipped with the aar available from jcenter 

Which means, that mobile developers need a way to easily and painlessly cross compile tenserflow with the right ops for their custom models. 

The print_header_for_selecrtive_registration.py  script is a good step in the right direction for this but it is not documented. 

The documentation is completely lacking. Please document how to cross-compile tenserflow for mobile with the right types, and the right ops. With want command ? what files should we modify, where ? 

I spent days looking at the tensorflow code/build files trying things and I still could not build a binary that would make that annoying ""Op wasn't registered issue"" away

Fix this ! This is not an individual problem, look at the amount of questions and issues about ""tenserflow and Op wasn't registered"" on the internet.

btw, the tensorflow aar from jcenter is completely useless as it can only be used to build the demo app.
It would be better to put the demo apk on Google play, it would not mislead developers into thinking they can easily build apps with it
 

",0,,6,2017-05-30T20:21:19Z,NONE
10296,Test CMake entries against filetree,stat:contributions welcome,There were some invalid entries in `tensorflow/contrib/cmake/tf_python.cmake` which are removed as of #10294 and which were discovered alongside #10264 @drpngx where I proposed extracting all file glob entries from all CMake files for better management as well as automated testing for their validity to keep things safe and sound.,0,,16,2017-05-30T18:00:39Z,CONTRIBUTOR
10287,Windows 8.1 Anaconda Tensorflow GPU -- BLACKSCREEN,stat:community support,"Followed instructions on https://www.tensorflow.org/install/install_windows
When I get to

activate tensorflow-gpu 
 $ python
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
Screen goes Black. When I move the cursor it moves, and then resets to the center every 10 seconds or so and disappears into the blackness, and doesnt go back to normal screen.

### System information
- Windows 8.1 Pro
used
- pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl 

- Cuda toolkit 8.0 
- Cudnn 5.1
- 4G NVidia GT 750M:

 python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
b'unkown' 1.1.0


Let me know what else I should provide
",0,,4,2017-05-30T14:30:36Z,NONE
10277,Android demo app crash on x86 device(libavcodec.so text relocations),stat:contributions welcome,"The app start then,  complain about libavcodec.so text relocations
![screenshot_20170529-122626](https://cloud.githubusercontent.com/assets/4120796/26559275/f5468b90-446b-11e7-85bb-fb1eadcbf691.png)
here is the log:

`05-29 12:33:36.787 12014-12014/org.tensorflow.demo E/WindowManager: android.view.WindowLeaked: Activity org.tensorflow.demo.ClassifierActivity has leaked window DecorView@34ca6d3[] that was originally added here
                                                                        at android.view.ViewRootImpl.<init>(ViewRootImpl.java:418)
                                                                        at android.view.WindowManagerGlobal.addView(WindowManagerGlobal.java:331)
                                                                        at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:94)
                                                                        at android.app.Dialog.show(Dialog.java:329)
                                                                        at android.app.AlertDialog$Builder.show(AlertDialog.java:1112)
                                                                        at android.app.Activity.performStart(Activity.java:6723)
                                                                        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2662)
                                                                        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2766)
                                                                        at android.app.ActivityThread.-wrap12(ActivityThread.java)
                                                                        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1507)
                                                                        at android.os.Handler.dispatchMessage(Handler.java:102)
                                                                        at android.os.Looper.loop(Looper.java:154)
                                                                        at android.app.ActivityThread.main(ActivityThread.java:6236)
                                                                        at java.lang.reflect.Method.invoke(Native Method)
                                                                        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:891)
                                                                        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:781)
05-29 12:33:36.864 12014-12014/org.tensorflow.demo E/Surface: dequeueBuffer failed (No such device)
05-29 12:33:36.865 12014-12014/org.tensorflow.demo E/ViewRootImpl[ClassifierActivity]: Could not lock surface
                                                                                       java.lang.IllegalArgumentException
                                                                                           at android.view.Surface.nativeLockCanvas(Native Method)
                                                                                           at android.view.Surface.lockCanvas(Surface.java:310)
                                                                                           at android.view.ViewRootImpl.drawSoftware(ViewRootImpl.java:2853)
                                                                                           at android.view.ViewRootImpl.draw(ViewRootImpl.java:2827)
                                                                                           at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:2608)
                                                                                           at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2215)
                                                                                           at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1254)
                                                                                           at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6344)
                                                                                           at android.view.Choreographer$CallbackRecord.run(Choreographer.java:874)
                                                                                           at android.view.Choreographer.doCallbacks(Choreographer.java:686)
                                                                                           at android.view.Choreographer.doFrame(Choreographer.java:621)
                                                                                           at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:860)
                                                                                           at android.os.Handler.handleCallback(Handler.java:751)
                                                                                           at android.os.Handler.dispatchMessage(Handler.java:95)
                                                                                           at android.os.Looper.loop(Looper.java:154)
                                                                                           at android.app.ActivityThread.main(ActivityThread.java:6236)
                                                                                           at java.lang.reflect.Method.invoke(Native Method)
                                                                                           at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:891)
                                                                                           at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:781)
`

The device is an Zenfone 2 with an intel atom processor, is it supported?",0,,6,2017-05-29T18:44:50Z,CONTRIBUTOR
10270,Performance degradation with large lookup tables - optimizer._apply_sparse_duplicate_indices  (TF V1.0.1),,"Hi,

I ran into this performance issue while trying to upgrade tensorflow from version 0.12.1  to 1.X.

We ran a network with large embedding lookup tables:
- 100K X 32 (for example, word embedding -  with 100K unique words)
- 300K X 128 (for example, categorical feature with cardinality of 300K unique items)

 After upgrading TF version to 1.0.1,  GPU usage dropped in from 60% to 30%.
Training time went up in 50%-200% (depends on how big is the embedding lookup table). 


This is the commit that caused the performance degradation:
https://github.com/tensorflow/tensorflow/commit/f9f56f9dc7fe41ef1128290a77ac88e889ea5229

The handling of unique indexes is very slow and does not run in parallel with others operations. 
Please note the big unique blocks in the middle.
![trace_unique](https://cloud.githubusercontent.com/assets/8734262/26542969/ab0f3740-4464-11e7-9dcb-f3ccd58dfc8a.png)

Here is a work around (not handling unique indexes ):
```
class MyOptimizer(tf.train.AdamOptimizer):
        def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8,
               use_locking=False, name=""Adam""):
                super(MyOptimizer,self).__init__(learning_rate,beta1, beta2, epsilon, use_locking,name)

        def _apply_sparse_duplicate_indices(self, grad, var):
                return self._apply_sparse(grad, var)
```


Thanks,
Erez
",1,,15,2017-05-29T08:56:55Z,NONE
10250,Error on importing metagraph that uses unbound input multiple times,,"If I export a scoped metagraph which has multiple references to a tensor which will be unbound after exporting, I cannot re-import the metagraph. This problem can be reproduced with the following MWE.

```python
import tensorflow as tf

graph = tf.Graph()

with graph.as_default():
    inputs = tf.placeholder(shape=[], dtype=tf.float32, name=""inputs"")

    with tf.name_scope(""scope""):
        output = inputs + inputs

    tf.train.export_meta_graph(""./mwe.meta"",
                               export_scope=""scope"",
                               as_text=True)

graph = tf.Graph()

with graph.as_default():
    inputs = tf.constant(shape=[], value=1.0)

    tf.train.import_meta_graph(""./mwe.meta"",
                               import_scope=""scope"",
                               input_map={
                                   ""$unbound_inputs_inputs"": inputs
                               })

```
Running this code results in the following error.
```
Traceback (most recent call last):
  File ""<snip>\metagraph_bug_mwe.py"", line 23, in <module>
    ""$unbound_inputs_inputs"": inputs
  File ""<snip>\Python35\lib\site-packages\tensorflow\python\training\saver.py"", line 1595, in import_meta_graph
    **kwargs)
  File ""<snip>\Python35\lib\site-packages\tensorflow\python\framework\meta_graph.py"", line 479, in import_scoped_meta_graph
    "","".join([compat.as_str(v) for v in field.value
ValueError: Graph contains unbound inputs: $unbound_inputs_inputs,$unbound_inputs_inputs. Must provide these inputs through input_map.
```
Upon inspection of the generated metagraph file (see [mwe.meta](https://github.com/tensorflow/tensorflow/files/1033570/mwe.meta.txt), lines 67 - 75), I noticed that the `inputs` tensor actually has two entries in the `unbound_inputs` collection. Since the `import_scoped_meta_graph` function compares the full collection read from the proto to the `input_map` parameter, they do not match and the error is raised.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see above
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0/5.1.10
- **GPU model and memory**: Nvidia GeForce GTX 860M with 2GB VRAM + 4GB shared
- **Exact command to reproduce**: See MWE above

",0,,5,2017-05-27T14:14:45Z,NONE
10241,C++ Online Documentation codeblocks not formatting,type:docs,"There are some codeblocks in C++ documentation , written with github-style fenced markdown, 
that are not rendering as `<code>`.

Eg: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/depth-to-space

![screenshot of a page with docs not formatted as code](https://cloud.githubusercontent.com/assets/5127634/26518496/5c312d9e-42e4-11e7-856a-972268bcf757.png)

It looks like something is going wrong with the site generation,
that when translating markdown, it does not pickup these blocks.

In the pages I quickly checked it seems to occur in the Summary sections, eg in:

- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/depth-to-space
- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space
- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space-n-d

",2,,10,2017-05-27T06:03:05Z,CONTRIBUTOR
10240,wide&deep tutorial for large data.,type:support,"When i apply the wide&deep tutorial  code to much larger dataset with millions of rows, I received 

[libprotobuf ERROR google/protobuf/io/zero_copy_stream_impl_lite.cc:173] Cannot allocate buffer larger than kint32max for StringOutputStream.

or sometimes


ValueError: GraphDef cannot be larger than 2GB.

Any simple fix?  I pretty much want to apply the combined classifier in the tutorial.",1,,12,2017-05-27T05:50:06Z,NONE
10220,Tensorflow crashes on build on Ubuntu 16.04,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: building from source
- **TensorFlow version (use command below)**:  5ae244e
- **Bazel version (if compiling from source)**:  0.4.5
- **CUDA/cuDNN version**: CUDA 8.0.61, cudnn 6.0.21 (tried also 5.1)
- **GPU model and memory**: 2x Tesla P100-PCIE-12GB
- **Exact command to reproduce**: building
- **Additional information**: Intel(R) Xeon(R) CPU E7-4860 v2 @ 2.60GHz, gcc version 5.4.1 20170519 (Ubuntu 5.4.1-11ubuntu2~16.04)


### Describe the problem
On the regular rebuild of Tensorflow, the build crashes with bunch of `error: argument of type ""const void *"" is incompatible with parameter of type ""const something *""`

### Source code / logs
Crash log:
```
INFO: From Compiling tensorflow/core/kernels/scatter_functor_gpu.cu.cc:
/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9218): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9229): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9242): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9253): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9266): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9277): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9290): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9301): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9314): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9325): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9338): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9350): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9363): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9374): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9387): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9399): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9408): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9417): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9426): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9435): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9443): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9452): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9461): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9470): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9479): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9488): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9497): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9506): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9515): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9524): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9533): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9542): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(54): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(62): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(70): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(78): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(86): error: argument of type ""void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(95): error: argument of type ""void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(104): error: argument of type ""void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(112): error: argument of type ""void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(120): error: argument of type ""void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(129): error: argument of type ""void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(138): error: argument of type ""void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(146): error: argument of type ""void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10223): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10235): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10247): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10259): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10271): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10283): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10295): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10307): error: argument of type ""const void *"" is incompatible with parameter of type ""const double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10319): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10331): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10343): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10355): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10367): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10379): error: argument of type ""const void *"" is incompatible with parameter of type ""const int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10391): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10403): error: argument of type ""const void *"" is incompatible with parameter of type ""const long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10413): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10424): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10433): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10444): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10453): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10464): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10473): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10484): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10493): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10504): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10513): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10524): error: argument of type ""void *"" is incompatible with parameter of type ""float *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10533): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10544): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10553): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10564): error: argument of type ""void *"" is incompatible with parameter of type ""double *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10573): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10584): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10593): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10604): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10613): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10624): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10633): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10644): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10653): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10664): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10673): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10684): error: argument of type ""void *"" is incompatible with parameter of type ""int *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10693): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10704): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10713): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10724): error: argument of type ""void *"" is incompatible with parameter of type ""long long *""

92 errors detected in the compilation of ""/tmp/tmpxft_00008f12_00000000-7_scatter_functor_gpu.cu.cpp1.ii"".
ERROR: /scratch/chaimb/tensorflow/tensorflow/core/kernels/BUILD:1140:1: output 'tensorflow/core/kernels/_objs/scatter_functor_gpu/tensorflow/core/kernels/scatter_functor_gpu.cu.pic.o' was not created.
ERROR: /scratch/chaimb/tensorflow/tensorflow/core/kernels/BUILD:1140:1: not all outputs were created or valid.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 147.888s, Critical Path: 69.54s
```


I've tried disabling most of the options (MKL, architecture optimizations, computability) but the crash happens even with full-default (except CUDA and XLA) configuration.",1,,20,2017-05-26T14:25:45Z,NONE
10215,Feature request: Keras CRF layer,"stat:awaiting tensorflower,type:feature","It will be great if in the `contrib.keras` in the nearest future [linear CRF layer](https://github.com/phipleg/keras/blob/crf/keras/layers/crf.py) (inside the Keras wrapper) will be added.

I think a lot of people will find this very [useful](https://github.com/fchollet/keras/issues/4090).",0,,7,2017-05-26T11:33:09Z,NONE
10200,Docker.gpu build fail: http 404,stat:contributions welcome,"------------------------

### System information
- Only change: in Docker.gpu I added `apt-get python-tk`
- Linux 14.04
- Docker
- Tesla k80
-  what causes problem: ` sudo nvidia-docker build -t with_tk -f Dockerfile.gpu . `

### Describe the problem
When editing the dockerfile to simply add python-tk the build says:
```
Collecting tensorflow-gpu==0.0.0 from http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl
  HTTP error 404 while getting http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl
  Could not install requirement tensorflow-gpu==0.0.0 from http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl because of error 404 Client Error: Not Found for url: http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl
Could not install requirement tensorflow-gpu==0.0.0 from http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl because of HTTP error 404 Client Error: Not Found for url: http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl for URL http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl
The command '/bin/sh -c pip --no-cache-dir install     http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl' returned a non-zero code: 1
```

To fix I simply declared gpu-1.0.0 instead of 0.0.0, but I am not supposed to write in those lines!

",1,,7,2017-05-25T20:25:56Z,NONE
10195,Use freeze_graph only with an input checkpoint,"stat:contributions welcome,type:feature","### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.0-rc0

`freeze_graph` method from `tensorflow.python.tools` should be able to work just with an input checkpoint, it needn't a graph definition from a protobuf file. Just restoring the metagraph and using the graph from the session lets you get rid of the graph def file.

Also, as you have provided from 1.2.0-rc0 a method to freeze from code without loading the files ([`freeze_graph_with_def_protos`](https://github.com/tensorflow/tensorflow/blob/v1.2.0-rc0/tensorflow/python/tools/freeze_graph.py#L58)), it should be able to work without a checkpoint but just with a session.

These will make freezing way simpler.",0,,5,2017-05-25T15:20:44Z,CONTRIBUTOR
10192,How to know what commands and types are supported in iOS build?,"stat:awaiting tensorflower,type:docs","According to this [comment](https://github.com/tensorflow/tensorflow/issues/9934#issuecomment-302817142)  and other related issues currently there is some commands and types that iOS users can't load from `frozen.pb` graph. So we could use any TF API in python but not in iOS. It is hard to guess what python API will not been supported in iOS. So is there any documentation or instructions of how to write solution using python API and what functions and types could be used to make `frozen.pb` graph be fully supported by iOS API?

",0,,5,2017-05-25T13:06:56Z,NONE
10155,Estimator should be able to partially load checkpoints,"stat:awaiting tensorflower,type:feature","### Describe the problem
When training neural networks and experimenting with different architectures or simply adapting a model to a new number of classes, it is crucial to be able to reuse an existing trained model as far as possible. For example, if I want to use the inception-v4 architecture and train it on 700 instead of 1000 classes, I need to be able to load all layers but the logit ones.

Unfortunately, this is not possible (at least I wasn't able to find a way) with the Estimator API. Whenever the size of a variable in my model changes or I add or remove a variable, the Estimator cannot load an existing checkpoint any more. This is a major drawback making the Estimator basically unusable for developing a new architecture or adapting an existing one by iteratively adapting the model.

### Requested features
* It should be possible to tell the Estimator that it's ok if some variables aren't found in the checkpoint. Those should simply be initialized as if no checkpoint would be loaded.
* It should be possible to specify scopes that should not be loaded from the checkpoint or to specify a flag that says something like ""just don't load variables that have a different shape / that you can't load"".
* Be able to load an existing checkpoint from a different path than the Estimator's `model_dir` when there is no checkpoint in the `model_dir` yet. This is helpful to start training from a different checkpoint without manully having to copy those model's checkpoints into the new `model_dir`

### Inspiration
This request has been inspired by the parameters you can specify to the [train_image_classifier.py](https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py) script from the tensorflow-models/slim directory. There you have the parameters `--checkpoint_exclude_scopes`, `--ignore_missing_vars` and `--checkpoint_path`.

Of course, one could say it's possible to implement this manually. But I think these are basic functionalities for everyone doing a bit more deeplearning than only the tutorial. That's why I think this should be part of the otherwise easy to use Estimator API. ",0,,12,2017-05-24T10:14:33Z,CONTRIBUTOR
10125,Feature request: weight normalization,"stat:contributions welcome,type:feature","Is it possible to incorporate Weight Normalization (https://arxiv.org/abs/1602.07868) into tensorflow itself?

https://github.com/openai/weightnorm/tree/master/tensorflow",0,,7,2017-05-23T04:13:36Z,NONE
10110,Python bindings to CTC Beam Search do not allow a dictionary to be specified,stat:awaiting tensorflower,"In the underlying C++ code, tested here:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_beam_search_test.cc#L103

a dictionary can be used.  However, the python bindings do not expose the ability to specify a dictionary scorer at all.  See here:

https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/ops/ctc_ops.py#L219",1,,4,2017-05-22T18:29:01Z,NONE
10094,compile contrib/hvx failed.,,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.2.0-rc0
- **Bazel version (if compiling from source)**:

- **CUDA/cuDNN version**:
not used 
- **GPU model and memory**:
not used
- **Exact command to reproduce**:
I follow the commands in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/hvx 
to build tensorflow that running hvx.

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
 I have tryed ndk-r13b,r10d,r14d. All of them produce the errors as follows:

checking whether to enable maintainer-specific portions of Makefiles... yes
checking build system type... x86_64-unknown-linux-gnu
checking host system type... arm-unknown-linux-androideabi
checking target system type... arm-unknown-linux-androideabi
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for arm-linux-androideabi-strip... no
checking for strip... strip
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether UID '1000' is supported by ustar format... yes
checking whether GID '1000' is supported by ustar format... yes
checking how to create a ustar tar archive... gnutar
checking for arm-linux-androideabi-gcc...  arm-linux-androideabi-gcc --sysroot ../Qualcomm/Hexagon_SDK/3.0/tools/android-ndk-r10d/platforms/android-21/arch-arm
checking whether the C compiler works... no
configure: error: in `/home/zhouzhan/tensorflow/tensorflow/contrib/makefile/downloads/protobuf':
configure: error: C compiler cannot create executables
See `config.log' for more details

Config.log is:
[config_log.txt](https://github.com/tensorflow/tensorflow/files/1018354/config_log.txt)


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,6,2017-05-22T09:44:30Z,NONE
10083,"Nullptr check failed, when using TensorArray in combination with while_loop and swap_memory",,"Environment: TensorFlow-gpu r1.1 build from source on Windows 10

I am using the python API of TensorFlow to train a variant of an LSTM.
For that purpose I use the `tf.while_loop` function to iterate over the time steps
With `swap_memory=True` and not limiting devices to cpu I get the following failure:

`...tensorflow/tensorflow/core/framework/tensor.cc:885] Check failed: nullptr != b.buf_ (nullptr vs. 00...)`

With `swap_memory=False` or limiting devices to cpu this does not happen.

The part of my code, that causes this failure (when commenting it out, it works) is in the body of the while loop:

    ...
    h_gathered = h_ta.gather(tf.range(time))
    h_gathered = tf.transpose(h_gathered, [1, 0, 2])
    syn_t = self.syntactic_weights_ta.read(time)[:, :time]
    syn_t = tf.expand_dims(syn_t, 1)
    syn_state_t = tf.squeeze(tf.tanh(tf.matmul(syn_t, h_gathered)), 1)
    ...

where `time` is zero based and incremented after each step, `h_ta` is a TensorArray

    h_ta = tf.TensorArray(
            dtype=dtype,
            size=max_seq_len,
            clear_after_read=False,
            element_shape=[batch_size, num_hidden],
            tensor_array_name=""fw_output"")
and `self.syntactic_weights_ta` is also a TensorArray

    self.syntactic_weights_ta = tf.TensorArray(
            dtype=dtype,
            size=max_seq_len,
            tensor_array_name=""fw_syntactic_weights"")
    self.syntactic_weights_ta = self.syntactic_weights_ta.unstack(syntactic_weights)

What I am trying to achieve in the code snippet is basically a weighted sum over the past outputs, stored in `h_ta`.
In the end I train the network with `tf.train.AdamOptimizer`.

The forward propagation seems to work, as inserting `tf.Print` commands in the sensitive part of the code works.
But I guess the backward propagation 

Unfortunately I could not find out which tensor's buffer points to nullptr.
",1,,7,2017-05-21T18:41:27Z,NONE
10080,compilation errors due to missing op classes when using selective registration (cmake windows build),stat:contributions welcome,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 7
- **TensorFlow installed from (source or binary)**:
From source
- **TensorFlow version (use command below)**:
commit 280374
- **Bazel version (if compiling from source)**:
n/a, using cmake build
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:

cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DCMAKE_INCLUDE_CURRENT_DIR:BOOL=ON -DCMAKE_CXX_FLAGS=-DSELECTIVE_REGISTRATION -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX -Dtensorflow_BUILD_PYTHON_BINDINGS:BOOL=OFF -Dtensorflow_BUILD_CONTRIB_KERNELS:BOOL=OFF -Dtensorflow_BUILD_SHARED_LIB:BOOL=ON 

MSBuild /p:Configuration=Release tensorflow.vcxproj

### Describe the problem

I'm building with cmake on Windows, using selective registration.  I've put ops_to_register.h in my build dir and specified -DCMAKE_INCLUDE_CURRENT_DIR=ON in my cmake command so that it would be added to the include path.

Due (I'm assuming) to selective registration, the generated code omits many classes which would otherwise be generated in a full build.

When compiling non-generated code, e.g. tensorflow\cc\gradients\array_grad.cc, there are compile errors wherever it references the classes that were not generated due to selective registration, for example:

array_grad.cc(51): error C2653: 'Unstack': is not a class or namespace name [...omitted...\tensorflow\tensorflow\contrib\cmake\build\tf_cc.vcxproj]

There are many of these errors for various referenced classes, in various other source files such as:
tensorflow\cc\gradients\math_grad.cc
tensorflow\cc\gradients\nn_grad.cc
tensorflow\cc\framework\gradients.cc

When using selective registration, what's the right approach to avoid these errors?
",0,,1,2017-05-21T16:07:19Z,NONE
10071,Cannot build jemalloc support using CMake on Linux (fails trying to include <windows.h>),"stat:contributions welcome,type:build/install","I am using the provided cmake build project files to compile tensorflow because I have a custom clang binary built with additional optimization passes of my own.

The build works fine without Jemalloc

    cmake -DCMAKE_BUILD_TYPE=Release ../tensorflow/contrib/cmake/  
    make -j4   # compiles O.K.

but when I add the jemalloc option it fails. 

    cmake -Dtensorflow_ENABLE_JEMALLOC_SUPPORT=ON -DCMAKE_BUILD_TYPE=Release ../tensorflow/contrib/cmake/  
    make 

    [  5%] Performing configure step for 'jemalloc'
    -- CMAKE_C_COMPILER_ID: Clang
    -- void* size is 8
    -- int size is 4
    -- long size is 8
    -- long long size is 8
    -- intmax_t size is 8
    -- CMAKE_SYSTEM_NAME: Linux
    -- whether pause instruction is compilable ... yes
    CMake Error at Utilities.cmake:755 (message):
      GetSystemPageSize failed compilation see
      cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.log
    Call Stack (most recent call first):
      CMakeLists.txt:464 (GetSystemPageSize)


Looking at cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.log there is

    Building C object CMakeFiles/cmTC_129ba.dir/getpagesize.c.o
    clang     -o CMakeFiles/cmTC_129ba.dir/getpagesize.c.o   -c  tensorflow-github/build-cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.c
    tensorflow-github/build-cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.c:1:10: fatal error: 'windows.h' file not found
    #include <windows.h>
                 ^~~~~~~~~~~
    1 error generated.

By looking at getpagesize.c it is clear it is a windows-only source file that should not have been compiled on Linux.

I went further investigating why jemalloc is trying to compile a windows source under Linux but I got nowhere after an hour or so. I lack understanding of the jemalloc build and I will continue to look into this but if you have someone on your side with a more prompt answer, that would save me time, thank you. 
",0,,8,2017-05-21T04:38:28Z,NONE
10062,C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed,stat:community support,"I got the following error when installing tensorflow v1.1.0 from source:

> ERROR: /home/software/tensorflow-1.1.0/tensorflow/stream_executor/BUILD:39:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 121 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.

My OS is centos7 with cuda 8.0 and cudnn 5.",0,,2,2017-05-20T09:06:18Z,NONE
10036,Document functional differences between tf.stack and tf.parallel_stack,stat:contributions welcome,"What if `tf.stack` had the API:

```
tf.stack(
    values,
    axis=0,
    name='stack',
    algorithm='sequential'
)
```

Options for algorithm could be `sequential`, `parallel` to start. This could apply broadly to many ops and ops like `parallel_stack` could be deprecated. 

Any ideas for a better parameter name than `algorithm`?",0,,12,2017-05-19T17:29:38Z,NONE
10021,Class weighting in tf.losses.softmax_cross_entropy,"stat:contributions welcome,type:feature","Feature request

In `tf.losses.softmax_cross_entropy` there's an optional field `weights`. I assumed this field was used for assigning a different weight to each class, but it actually is used to assign a weight to each sample in the batch. In my use case i have a `batch_size` of `128` and `30` classes, so I was passing a `[1, 30]` tensor and got this error:

```
InvalidArgumentError (see above for traceback): Incompatible shapes: [128] vs. [30]
	 [[Node: optimizer/gradients/cross_entropy/softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](optimizer/gradients/cross_entropy/softmax_cross_entropy_loss/Mul_grad/Shape, optimizer/gradients/cross_entropy/softmax_cross_entropy_loss/Mul_grad/Shape_1)]]
```

I looked at the implementation, confirmed that the function expects `batch_size` as the dimension of thensor and realized that my expected behavior cannot be achieved easily as `tf.nn.softmax_cross_entropy_with_logits` doesn't have a weight parameter.

My current workaround solution is to re-implement this function calculating the loss for each class and then multiplying for the weight vector that I pass, but that's inefficient compared to the optimized implementation of `tf.nn.softmax_cross_entropy_with_logits`.

So my request is:
- provide an optimized `tf.nn.softmax_cross_entropy_with_logits` that also accepts `weights` for each class as a parameter
- use it inside `tf.losses.softmax_cross_entropy` so that one can pass weights as a scalar, a `[batch_size, 1]` tensor, a `[1, num_classes]` tensor or a `[batch_size, num_classes]` tensor (the same dimension of  `onehot_labels`)",0,,11,2017-05-19T02:55:16Z,NONE
10012,Session vs DeprecatedSession,,"Hi,

I'm wondering as to the main differences between the new sessions in the C API and the deprecated sessions. I noticed that [the Python API is using the deprecated sessions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L562) and since I am using the new sessions, I want to make sure I understand the differences correctly. I list here the differences I believe exist and I hope that someone could verify and/or correct my thoughts:
- `TF_ExtendGraph` is not necessary with the new sessions. The session will always be aware of changes in the underlying graph.
- `TF_Reset` still makes sense with the new sessions and has the same functionality. If that is indeed the case, maybe it should be moved outside the deprecated session API region of the C API header file.
- Most of the `TF_SessionOptions` still apply, but some of them do not make sense anymore (e.g., the `ConfigProto.graph_options.infer_shapes` option). Could someone please provide a list of which options have been deprecated?
- I do not really understand the whole dealing with session handles. I believe it's not necessary to deal with them with the new session API as the partial run handle is not provided as a feed/fetch value, but as a separate argument. Is that true? If so, should I completely ignore them when dealing with the sessions? That would mean that I never need to use the ops defined in `session_ops`. Is that correct?

Thank you,
Anthony",1,,8,2017-05-18T18:25:01Z,CONTRIBUTOR
10004,"In reader.py, line 17 throws error on python 3.5. The decode phrase should be removed, and then it works","stat:contributions welcome,type:bug/performance","In reader.py, line 17 throws error on python 3.5. The decode phrase should be removed, and then it works",0,,9,2017-05-18T12:27:28Z,NONE
9996,Convolution_transpose layer now gives an error (Tensorflow 1.0.0). ,"stat:contributions welcome,type:bug/performance","I am implementing an architecture with conv and conv_transpose layers and this is what I am giving the convolution transpose layer: 
```
    ('convolution_transpose', dict(num_outputs=96, kernel_size=[41, 11],
                                     stride=[2, 1], padding=""SAME"", scope='dec_block_1'))
```

and this is what I get 


```
/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    175       current_args = current_scope[key_func].copy()
    176       current_args.update(kwargs)
--> 177     return func(*args, **current_args)
    178   _add_op(func)
    179   setattr(func_with_args, '_key_op', _key_op(func))

/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in convolution2d_transpose(inputs, num_outputs, kernel_size, stride, padding, data_format, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)
   1123         _scope=sc,
   1124         _reuse=reuse)
-> 1125     outputs = layer.apply(inputs)
   1126 
   1127     # Add variables to collections.

/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)
    301       Output tensor(s).
    302     """"""
--> 303     return self.__call__(inputs, **kwargs)
    304 
    305 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)
    267           input_shapes = [x.get_shape() for x in input_list]
    268           if len(input_shapes) == 1:
--> 269             self.build(input_shapes[0])
    270           else:
    271             self.build(input_shapes)

/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py in build(self, input_shape)
   1048                                   regularizer=self.bias_regularizer,
   1049                                   trainable=True,
-> 1050                                   dtype=self.dtype)
   1051     else:
   1052       self.bias = None

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)
    986       collections=collections, caching_device=caching_device,
    987       partitioner=partitioner, validate_shape=validate_shape,
--> 988       custom_getter=custom_getter)
    989 get_variable_or_local_docstring = (
    990     """"""%s

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)
    888           collections=collections, caching_device=caching_device,
    889           partitioner=partitioner, validate_shape=validate_shape,
--> 890           custom_getter=custom_getter)
    891 
    892   def _get_partitioned_variable(self,

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)
    339           reuse=reuse, trainable=trainable, collections=collections,
    340           caching_device=caching_device, partitioner=partitioner,
--> 341           validate_shape=validate_shape)
    342     else:
    343       return _true_getter(

/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, **kwargs)
    256           name, shape, initializer=initializer, regularizer=regularizer,
    257           dtype=dtype, trainable=trainable,
--> 258           variable_getter=functools.partial(getter, **kwargs))
    259 
    260     # Build (if necessary) and call the layer, inside a variable scope.

/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in _add_variable(self, name, shape, dtype, initializer, regularizer, trainable, variable_getter)
    206                                initializer=initializer,
    207                                dtype=dtype,
--> 208                                trainable=trainable and self.trainable)
    209     # TODO(sguada) fix name = variable.op.name
    210     if variable in existing_variables:

/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in layer_variable_getter(getter, *args, **kwargs)
   1308       getter = functools.partial(current_custom_getter, getter)
   1309     kwargs['rename'] = rename
-> 1310     return _model_variable_getter(getter, *args, **kwargs)
   1311   return layer_variable_getter
   1312 

/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in _model_variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, **_)
   1297       regularizer=regularizer, collections=collections, trainable=trainable,
   1298       caching_device=caching_device, partitioner=partitioner,
-> 1299       custom_getter=getter)
   1300 
   1301 

/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    175       current_args = current_scope[key_func].copy()
    176       current_args.update(kwargs)
--> 177     return func(*args, **current_args)
    178   _add_op(func)
    179   setattr(func_with_args, '_key_op', _key_op(func))

/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in model_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter)
    266                  trainable=trainable, collections=collections,
    267                  caching_device=caching_device, device=device,
--> 268                  partitioner=partitioner, custom_getter=custom_getter)
    269   return var
    270 

/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    175       current_args = current_scope[key_func].copy()
    176       current_args.update(kwargs)
--> 177     return func(*args, **current_args)
    178   _add_op(func)
    179   setattr(func_with_args, '_key_op', _key_op(func))

/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter)
    223                   collections=collections,
    224                   caching_device=caching_device,
--> 225                   partitioner=partitioner)
    226 
    227 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)
    331           initializer=initializer, regularizer=regularizer, reuse=reuse,
    332           trainable=trainable, collections=collections,
--> 333           caching_device=caching_device, validate_shape=validate_shape)
    334 
    335     if custom_getter is not None:

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape)
    682         caching_device=caching_device,
    683         dtype=variable_dtype,
--> 684         validate_shape=validate_shape)
    685     self._vars[name] = v
    686     logging.vlog(1, ""Created variable %s with shape %s and init %s"", v.name,

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope)
    224           name=name,
    225           dtype=dtype,
--> 226           expected_shape=expected_shape)
    227 
    228   def __str__(self):

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape)
    301             with ops.name_scope(""Initializer""),  ops.device(None):
    302               self._initial_value = ops.convert_to_tensor(
--> 303                   initial_value(), name=""initial_value"", dtype=dtype)
    304               shape = (self._initial_value.get_shape()
    305                        if validate_shape else tensor_shape.unknown_shape())

/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>()
    671       else:
    672         init_val = lambda: initializer(
--> 673             shape.as_list(), dtype=dtype, partition_info=partition_info)
    674         variable_dtype = dtype.base_dtype
    675 

TypeError: __init__() got multiple values for argument 'dtype'

```

The same code worked on Tensorflow 0.12. ",0,,6,2017-05-18T09:27:51Z,NONE
9988,[feature] Support Lanczos method in tf.image.resize_images,"stat:contributions welcome,type:feature","Add support for a `Lanczos` (a truncated sinc) mode in `tf.image.resize_images`. Currently this mode is not offered.

[Pillow supports `LANCZOS`](http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters) (aka `ANTIALIAS`) as a resampling method and stipulates this method has the [highest quality for down sampling](http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters-comparison-table) ([default for `thumbnail` for example](http://pillow.readthedocs.io/en/3.4.x/reference/Image.html#PIL.Image.Image.thumbnail)).
![image](https://cloud.githubusercontent.com/assets/51059/26181858/91e9471e-3b41-11e7-8653-4fa7277e98a6.png)
",0,,7,2017-05-18T00:44:46Z,CONTRIBUTOR
9978,graph_editor.copy_with_input_replacements crashes for some orderings of inputs,"stat:contributions welcome,type:bug/performance","Graph editor copy_with_input_replacements  visits nodes in order provided, and assumes that op referenced by ""op._original_op"" has already already been visited. When this assumption is false, it fails with KeyError inside transform.py

Reproducible case

```
import tensorflow as tf
import numpy as np
import tensorflow.contrib.graph_editor as ge

if __name__=='__main__':
  params = tf.Variable(1, dtype=np.float32, name=""params"")
  temp = tf.reduce_sum(params, name=""sum_temp"")
  cost1 = tf.square(temp, name=""cost1"")
  gradients1 = tf.gradients([cost1], [params])
  ops = tf.get_default_graph().get_operations()
  ops = list(sorted(ops, key=lambda op: op.name))
  copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops), {})
```
It fails with following error

```
Traceback (most recent call last):
  File ""graph_editor_test.py"", line 13, in <module>
    copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops), {})
  File ""/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py"", line 620, in copy_with_input_replacements
    sgv, dst_graph, dst_scope, src_scope, reuse_dst_scope=reuse_dst_scope)
  File ""/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py"", line 436, in __call__
    self._copy_ops(info)
  File ""/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py"", line 450, in _copy_ops
    op_, op_outputs_ = self.transform_op_handler(info, op)
  File ""/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py"", line 173, in copy_op_handler
    original_op = info.transform_original_op_handler(info, op._original_op)
  File ""/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py"", line 125, in transform_op_if_inside_handler
    return info.transformed_ops[op]
KeyError: <tf.Operation 'sum_temp' type=Sum>
```

A work-around is to clear `_original_op` entries for all ops

```
def clear_original_ops(ops):
  for op in ops:
    op._original_op = None
```

@purpledog ",0,,8,2017-05-17T18:07:30Z,CONTRIBUTOR
9968,ValueError: Refusing to perform an overparameterized separable convolution,"stat:contributions welcome,type:docs","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1rc
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**: No CUDA
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

I am using tensorflow function tf.nn.separable_conv2d. I want to understand why  channel_multiplier * in_channels > out_channels is not allowed. It was not clear anywhere from the documentation.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,3,2017-05-17T12:38:44Z,NONE
9961,[CMAKE] Unresolved external symbol rdft,type:build/install,"

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 (Visual studio 2015)
- **TensorFlow installed from (source or binary)**: via cmake and includes into c++ project as static lib.(tensorflor_static.lib file).

### Describe the problem
After successful building Release version I tried to add tensorflow_static.lib and dependencies into c++ project. Then linker threw an error:

> Severity	Code	Description	Project	File	Line	Suppression State
> Error	LNK2001	unresolved external symbol rdft	MyLib	C:\path\to\release\tensorflow_static.lib(spectrogram.obj)	1	
",1,,12,2017-05-17T08:55:14Z,NONE
9958,Android demo app crashes when using quantized model obtained from graph_transform tool?,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
Only edited `ClassifierActivity.java` to suit a custom model
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Android smartphone / host machine: Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.1
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: GTX 860M

### Describe the problem
I am currently following the guide in: http://nilhcem.com/android/custom-tensorflow-classifier

to train a custom classifier. However, I am using my own frozen graph that I obtained from my own training. What I noticed was when I used the quantized graph obtained through the `graph_transform` method, the app simply crashes without even running. In the guide, it is recommended to run this command on the inference graph:

```
bazel-bin/tensorflow/python/tools/optimize_for_inference \
  --input=/tf_files/retrained_graph.pb \
  --output=/tf_files/retrained_graph_optimized.pb \
  --input_names=Mul \
  --output_names=final_result
```

While I think it may be in conflict with the quantized graph transformations, I ran this command to test, and the app did crash. Here are the observations for all 4 permutations I tested:

1. quantization + optimize_for_inference = **app crash**
2. quantization only = **app crash**
3. optimize_for_inference on frozen graph = **app works**
4. frozen_graph only = **app works**

So my conclusion is the quantization operations within the quantized graph caused the app to fail. 

Here is the quantization command I ran:

```
/home/kwotsin/tensorflow-android/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=./frozen_model_mobilenet.pb \
--out_graph=./quantized_model_mobilenet.pb \
--inputs='Placeholder_only' \
--outputs='MobileNet/Predictions/Softmax' \
--transforms='
  add_default_attributes
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  quantize_nodes
  strip_unused_nodes
  sort_by_execution_order'
```

And the java file I edited to build my APK:

```
  private static final int INPUT_SIZE = 224;
  private static final int IMAGE_MEAN = 128;
  private static final float IMAGE_STD = 128;
  private static final String INPUT_NAME = ""Placeholder_only"";
  private static final String OUTPUT_NAME = ""MobileNet/Predictions/Softmax"";

  private static final String MODEL_FILE = ""file:///android_asset/quantized_model_mobilenet.pb"";
  private static final String LABEL_FILE =
      ""file:///android_asset/mobilenet_labels.txt"";
```

Other than these edit, every other file is the same. I then imported this project in Android Studio, and ran the `build apk` option located on the top toolbar of Android Studio.

So far, existing tutorials I've seen (e.g. those from Pete Warden) use the `quantize_graph` method to run on mobile devices. Is `graph_transform` compatible for quantizing models for mobile devices yet?",1,,25,2017-05-17T07:26:14Z,CONTRIBUTOR
9951,Would you please accomodate for building tensorflow with a custom clang (4.0.0) and libc++ instead of stdlibc++? ,"stat:contributions welcome,type:build/install","I have a custom clang with additional optimization passes but I cant get TS compiled with it. 

$ bazel build --cxxopt=-std=c++11 --cxxopt=-stdlib=libc++ tensorflow:libtensorflow.so
INFO: Found 1 target...
INFO: From Compiling external/protobuf/src/google/protobuf/compiler/js/embed.cc [for host]:
external/protobuf/src/google/protobuf/compiler/js/embed.cc:37:12: warning: unused variable 'output_file' [-Wunused-const-variable]
const char output_file[] = ""well_known_types_embed.cc"";
           ^
1 warning generated.
ERROR: /home/hbucher/.cache/bazel/_bazel_hbucher/ad427c7fddd5b68de5e1cfaa7cd8c8cc/external/com_googlesource_code_re2/BUILD:11:1: undeclared inclusion(s) in rule '@com_googlesource_code_re2//:re2':
this rule is missing dependency declarations for the following files included by 'external/com_googlesource_code_re2/re2/bitstate.cc':
  '/home/hbucher/install/include/c++/v1/stddef.h'
  '/home/hbucher/install/include/c++/v1/__config'",0,,1,2017-05-17T02:02:35Z,NONE
9946,StatSummarizer logs error messages for graph with a while loop,,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see Python script below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Built from source
- **TensorFlow version (use command below)**: From command below: ""b'unknown' 1.1.0-rc2"", commit: 69433c1f1adef96fde2074b05d3362e88d8587de
- **Bazel version (if compiling from source)**: Used CMake 3.6.3
- **CUDA/cuDNN version**: Built without GPU support
- **GPU model and memory**: Built without GPU support
- **Exact command to reproduce**:
```
  <create graph.pb with Python script below>
  <path to build output>/benchmark_model.exe --graph=""graph.pb"" --input_layer="""" --input_layer_shape="""" --input_layer_type=""""
```



You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
**Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.**

When running a graph containing a while loop with benchmark_model.exe, StatSummarizer reports numerous errors like this:

E c:\source\tensorflow\tensorflow\core\util\stat_summarizer.cc:146] Bad output slot '1' for 'loop_op/Switch'

It looks like StatSummarizer determines that something about the step stats produced for the Switch node in this case is invalid. This is reproducible with the simple graph in the Python script below, which does not seem like it should be an invalid graph.

### Source code / logs
**Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.**

Python script:

```
import tensorflow as tf

initial_value = tf.constant(1)
loop_cond = lambda i: tf.less(i, 10)
loop_body = lambda i: tf.add(i, 1)
loop_op = tf.while_loop(loop_cond, loop_body, [initial_value], name=""loop_op"")
output = tf.identity(loop_op, name=""output"")

with tf.Session() as sess:
  tf.train.write_graph(sess.graph, ""."", ""graph.pb"", as_text=False)
```",1,,6,2017-05-16T22:45:35Z,NONE
9933,Multiplicative Integration Recurrent Neural Networks,"cla: yes,stat:awaiting response","This is the same PR as #9286(closed) after I
   - resolved conflicts
   - modified __init__.py
   - solved cla:no problem(I hope)

I implemented Multiplicative Integration variants of recurrent neural networks
(RNN, GRU and LSTM) proposed in

Yuhuai Wu, Saizheng Zhang, Ying Zhang, Yoshua Bengio, Ruslan Salakhutdinov,
On Multiplicative Integration with Recurrent Neural Networks. NIPS, 2016.
https://arxiv.org/abs/1606.06630

The RNNs proposed in the paper are implemented as:

    MultiplicativeIntegrationRNNCell
    MultiplicativeIntegrationGRUCell
    MultiplicativeIntegrationLSTMCell
    _multiplicative_integration as a helper function
in
    tensorflow/contrib/rnn/python/ops/rnn_cell.py
    tensorflow/contrib/rnn/__init__.py

Test codes:
    tensorflow/contrib/rnn/python/kernel_tests/rnn_cell_test.py",1,,13,2017-05-16T13:04:24Z,NONE
9927,Some small problems with the RNN and seq2seq implementations,"stat:contributions welcome,type:feature","1. In the class `AttentionCellWrapper` , https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L1116  , maybe the `lstm_output` should be replaced by some other token, since the wrapper is not specified for LSTM.

2.  In the class `Decoder`, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/decoder.py#L90 , I think the `step()` method should not return an output as an instance of `BasicDecoderOutput`. From an object-oriented-programming view, the `BasicDecoder` is an inheritance of `Decoder`, the basic class should not have access to something designed for the inherited class, the same problem exists in the `dynamic_decode` method.",0,,4,2017-05-16T04:42:56Z,NONE
9926,Issues with RoCE support,stat:community support,"When rendezvous_mgr->RecvLocalAsync fails, grpc responds with the Status, while grpc+verbs does not. Should we consider this situation ? @junshi15 ",0,,38,2017-05-16T02:21:49Z,NONE
9925,graph_editor copy_with_input_replacements doesn't update colocation constraints,"stat:contributions welcome,type:bug/performance","It seems if you try to use graph_editor to make copy of a model to place on another device, the new graph will still refer to old version inside colocation constraints. 

This causes errors like below when trying to run resulting graph.
`tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot colocate nodes 'gradients/Max_1_1_grad/mul' and 'gradients/AddN_13: Cannot merge devices with incompatible ids: '/GPU:0' and '/GPU:1'
`

More natural might be to update colocation constraints to point to newly created copies of ops.

Test case
```
  import tensorflow.contrib.graph_editor as ge
  tf.reset_default_graph()
  with tf.device('/cpu:0'):
    a = tf.ones((), name='a')
    with tf.get_default_graph().colocate_with(a):
      b = tf.add(a, 1, name='b')
  g = tf.get_default_graph()
  ops = g.get_operations()
  copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops),
                                                       {})
  print(tf.get_default_graph().as_graph_def())
```

You will see that newly created `b_1` op will refer to old op `a`

```
node {
  name: ""b/y_1""
  op: ""Const""
  device: ""/device:CPU:0""
  attr {
    key: ""_class""
    value {
      list {
        s: ""loc:@a""
      }
    }
  }
```

@purpledog ",0,,5,2017-05-16T01:49:41Z,CONTRIBUTOR
9924,Quantize conv2d transpose,"cla: yes,stat:awaiting tensorflower","This PR creates a new quantized kernel called `QuantizedDeconv2D`, which performs a deconvolution computation (also known as `conv2d_transpose` in TensorFlow) in a quantized mode.

The current progress of this new kernel includes:

1. A reference implementation of deconvolution
2. Two unit tests with small dimensions and different strides
3. Only `VALID` padding is allowed

Further guidance on this work is welcomed!",1,,14,2017-05-15T23:31:00Z,CONTRIBUTOR
9920,Freezing graphs with custom ops,type:feature,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 and MacOS Sierra
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master (quite recent)
- **Bazel version (if compiling from source)**: 0.4.5
- **Exact command to reproduce**: freeze_graph

### Describe the problem
I've asked my question on StackOverflow here:
http://stackoverflow.com/questions/43880729/using-new-op-while-importing-graph-in-tensorflow
I'm trying to freeze a model which contains a custom op. But `freeze_graph` gives the following error: 
```
Traceback (most recent call last):
  File ""<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 202, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 134, in main
    FLAGS.variable_names_blacklist)
  File ""<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 99, in freeze_graph
    _ = importer.import_graph_def(input_graph_def, name="""")
  File ""<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/importer.py"", line 260, in import_graph_def
    raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named RoiPool in defined operations.
```
I was suggested on StackOverflow to build `freeze_graph` with my custom op as a dependency. I did that, but `freeze_graph` still gives the same error. 

It was also suggested for me to open a **feature request** to make an easier-to-use interface for using freeze_graph with custom ops.

### Source code / logs
Here is the freeze_graph command I'm using: 
`bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=<local path>/data/graph_vgg.pb --input_checkpoint=<local path>/data/VGGnet_fast_rcnn_iter_70000.ckpt --output_node_names=""cls_prob,bbox_pred"" --output_graph=<local path>/graph_frozen.pb`",0,,5,2017-05-15T20:57:25Z,NONE
9918,preserving specific checkpoints,"stat:contributions welcome,type:feature","Savers automatically clean up checkpoints and that's lovely.  But there are special points during training that I want to be sure to save (e.g. transitioning from a pre-training phrase to full training), which I can't ensure with the current options (unless I just keep everything, by making ```max_to_keep``` & ```keep_checkpoint_every_n_hours``` huge).

Two possible approaches:

1)  ```saver.save(..., preserve=True)```
Never clean up this checkpoint.

2)  ```max_to_keep``` is defined **per** ```save_path```
i.e. Whenever I change the ```save_path``` argument to ```save()``` in the middle of the session, don't clean up the checkpoints with the previous ```save_path```.

This is related to #8658 (with a little book-keeping on the client, you could do #8658 yourself).",0,,2,2017-05-15T17:43:28Z,NONE
9917,Feature request: tf.nn.depthwise_conv2d_transpose,"stat:contributions welcome,type:feature","### System information
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.1.0-0-g1ec6ed5', '1.1.0')
- **Bazel version (if compiling from source)**: 0.4.5- (@non-git)
- **CUDA/cuDNN version**: 7.5/5.1
- **GPU model and memory**: NVIDIA M40, 12GB

### Describe the problem
I would like to apply a `tf.nn.conv2d_transpose` operation to each channel of a feature image independently. There is no `tf.nn.depthwise_conv2d_transpose` operation.

I tried using `tf.nn.depthwise_conv2d_native_backprop_input` however, when I try to optimize a function that involves one of these operations, it results in an error because there is no gradient operation defined:

```
LookupError: No gradient defined for operation 'DepthwiseConv2dNativeBackpropInput_1' (op type: DepthwiseConv2dNativeBackpropInput)
```

This is related to https://github.com/tensorflow/tensorflow/issues/7934

It is possible to achieve this functionality using `conv2d_transpose` by constructing a large filter with many coefficients set to zero. However, it is relatively inefficient, especially for a large number of channels.",0,,5,2017-05-15T16:59:18Z,NONE
9916,tf.self_adjoint_eig doesn't behave the same way with float32 and float64,"stat:contributions welcome,type:feature","Here is an example to reproduce the problem

```
l = tf.constant([[10., -4., -4., -2.],
                  [-4., 10., -2., -4.],
                  [-4., -2., 6., 0.],
                  [-2., -4., 0., 6.]], dtype=tf.float64)
e, v = tf.self_adjoint_eig(tf.expand_dims(l, 0))
```

When I set `dtype=tf.float64` the output is

```
// Eigen values
[[ -2.31986627e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]]

// Eigen vectors
[[-0.5        -0.16245985  0.5        -0.68819096]
 [-0.5         0.16245985  0.5         0.68819096]
 [-0.5        -0.68819096 -0.5         0.16245985]
 [-0.5         0.68819096 -0.5        -0.16245985]]
```

When `dtype=tf.float32` the output is

```
// Eigen values
[[ -1.02379988e-06   5.52786446e+00   1.20000019e+01   1.44721375e+01]]

// Eigen vectors
[[ 0.49999985  0.16245979  0.49999985 -0.68819106]
 [ 0.5        -0.16246006  0.50000018  0.68819082]
 [ 0.5         0.68819106 -0.49999988  0.16246004]
 [ 0.49999991 -0.68819088 -0.50000012 -0.16245979]]
```
In this case the sign of the second eigen vector changed.

The numpy equivalent of this code always give the same result (in float or float32) and is similar to the result I got with the tf.float64 version

```
L = np.array([[10., -4., -4., -2.],
                  [-4., 10., -2., -4.],
                  [-4., -2., 6., 0.],
                  [-2., -4., 0., 6.]])
D, V =np.linalg.eigh(L)
```


```
// numpy eigen values
[  1.11716192e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]

// numpy eigen vectors
[[ 0.5        -0.16245985  0.5        -0.68819096]
 [ 0.5         0.16245985  0.5         0.68819096]
 [ 0.5        -0.68819096 -0.5         0.16245985]
 [ 0.5         0.68819096 -0.5        -0.16245985]]
```

",0,,5,2017-05-15T16:31:50Z,NONE
9904,BeamSearchDecoder cell state never changed ,,"tf version '1.1.0-rc2'
It looks BeamSearchDecoder never used next_cell_state, but always using the inital cell state.
In beam_search_decoder.py 423
        next_cell_state = nest.map_structure(
            self._maybe_split_batch_beams,
            next_cell_state, self._cell.state_size)
But next_cell_state is never used later, since just pass   state to _beam_search_step function where state.cell_state is never changed 
    beam_search_output, beam_search_state = _beam_search_step(
          time=time,
          logits=cell_outputs,
          beam_state=state,
          batch_size=batch_size,
          beam_width=beam_width,
          end_token=end_token,
          length_penalty_weight=length_penalty_weight)",1,,10,2017-05-15T04:29:19Z,NONE
9901,tf.gradients runtime scales suboptimally with size of the graph,"stat:contributions welcome,type:bug/performance","`tf.gradients` can be inefficient on large graphs and it runtime increases with size of the graph, even when the amount of work it needs to do is constant. This inefficiency is apparent when trying to differentiate small parts of large graph many times.

Discovered when trying to scale to 8 GPUs using data parallelism using 8 identical copies of model -- time spent inside gradients grows for each new replica even though replicas are identical and independent. We are calling `tf.gradients` many times (calling tf.gradients on parts of model in order to do memory saving gradients [trick](https://arxiv.org/abs/1604.06174)), our largest models spend >2 hours inside `tf.gradients`.

I've profiled the runs and saw that most of the time is spent inside

`_MarkReachedOps(from_ops, reached_ops)` inside `gradients_impl.py`

It's called as follows

```
  reached_ops = [False] * (graph._last_id + 1)
  for op in to_ops:
    reached_ops[op._id] = True
```
You can see that it's using Python list initialized with the size of the entire graph so this initialization step would grow with size of the graph.

![screenshot 2017-05-14 15 35 58](https://cloud.githubusercontent.com/assets/23068/26038340/102545da-38bb-11e7-873b-b57bc628ae7c.png)


Profile of the `_MarkReachedOps` when calling when calling tf gradients 560 times, with each gradient call adding 35 nodes on average, and total size of the graph being 200k nodes

```
Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   101                                           @profile
   102                                           def _MarkReachedOps(from_ops, reached_ops):
   103                                             """"""Mark all ops reached from ""from_ops"".
   104                                           
   105                                             Args:
   106                                               from_ops: list of Operations.
   107                                               reached_ops: list of booleans, indexed by operation id.
   108                                             """"""
   109       568         1967      3.5      0.0    queue = collections.deque()
   110       568         4835      8.5      0.0    queue.extend(from_ops)
   111  39912648     14661885      0.4      8.4    while queue:
   112  39912080     17079278      0.4      9.8      op = queue.popleft()
   113  39912080     41203709      1.0     23.7      if not reached_ops[op._id]:
   114  28997056     21267924      0.7     12.2        reached_ops[op._id] = True
   115  58483932     42196549      0.7     24.2        for output in op.outputs:
   116  29486876     37595214      1.3     21.6          queue.extend(output.consumers())
```

Possible solutions could be a more efficient implementation of `_PendingCount`, or a different algorithm for `tf.gradients` which is more efficient for large graphs",0,,12,2017-05-14T22:37:07Z,CONTRIBUTOR
9871,errors in ipython sessions cause core dump or segfault,"stat:community support,type:feature","------------------------

### System information

Python 2.7.13 :: Anaconda custom (64-bit)
ipython :: 5.3.0
linux :: 3.16.0-4-amd64


https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh gives:

== cat /etc/issue ===============================================
Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux
VERSION_ID=""8""
VERSION=""8 (jessie)""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Debian 4.9.2-10) 4.9.2
Copyright (C) 2014 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux

== check pips ===================================================
msgpack-numpy (0.3.9)
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.2.0)
tensorflow-gpu (1.0.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.0.1
tf.GIT_VERSION = v1.0.0-65-g4763edf-dirty
tf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally

== env ==========================================================
LD_LIBRARY_PATH /Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Fri May 12 19:38:18 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1050    Off  | 0000:05:00.0      On |                  N/A |
| 61%   67C    P0    36W /  75W |    145MiB /  1998MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN X (Pascal)    Off  | 0000:06:00.0     Off |                  N/A |
| 54%   84C    P2    68W / 250W |  11530MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  TITAN X (Pascal)    Off  | 0000:09:00.0     Off |                  N/A |
| 45%   78C    P2    85W / 250W |  11820MiB / 12189MiB |     35%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1518    G   /usr/bin/X                                     141MiB |
|    1     20850    C   python                                       11527MiB |
|    2     18363    C   python                                       11817MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7
/usr/local/cuda-7.5/doc/man/man7/libcudart.7
/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib64/libcudart_static.a
/usr/local/cuda-7.5/lib/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a

== cat /etc/issue ===============================================
Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux
VERSION_ID=""8""
VERSION=""8 (jessie)""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Debian 4.9.2-10) 4.9.2
Copyright (C) 2014 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux

== check pips ===================================================
msgpack-numpy (0.3.9)
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.2.0)
tensorflow-gpu (1.0.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.0.1
tf.GIT_VERSION = v1.0.0-65-g4763edf-dirty
tf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally

== env ==========================================================
LD_LIBRARY_PATH /Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Fri May 12 19:38:27 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1050    Off  | 0000:05:00.0      On |                  N/A |
| 61%   67C    P0    36W /  75W |    145MiB /  1998MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN X (Pascal)    Off  | 0000:06:00.0     Off |                  N/A |
| 54%   84C    P2    68W / 250W |  11530MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  TITAN X (Pascal)    Off  | 0000:09:00.0     Off |                  N/A |
| 46%   78C    P2   155W / 250W |  11820MiB / 12189MiB |     38%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1518    G   /usr/bin/X                                     141MiB |
|    1     20850    C   python                                       11527MiB |
|    2     18363    C   python                                       11817MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7
/usr/local/cuda-7.5/doc/man/man7/libcudart.7
/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib64/libcudart_static.a
/usr/local/cuda-7.5/lib/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a

== cat /etc/issue ===============================================
Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux
VERSION_ID=""8""
VERSION=""8 (jessie)""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Debian 4.9.2-10) 4.9.2
Copyright (C) 2014 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux

== check pips ===================================================
msgpack-numpy (0.3.9)
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.2.0)
tensorflow-gpu (1.0.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.0.1
tf.GIT_VERSION = v1.0.0-65-g4763edf-dirty
tf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally

== env ==========================================================
LD_LIBRARY_PATH /Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Fri May 12 19:40:02 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.44                 Driver Version: 367.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  Off  | 0000:02:00.0     Off |                  N/A |
| 22%   46C    P8    18W / 250W |      1MiB / 12206MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-7.5/lib/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib/libcudart_static.a
/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib64/libcudart_static.a
/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7
/usr/local/cuda-7.5/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7

== cat /etc/issue ===============================================
Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux
VERSION_ID=""8""
VERSION=""8 (jessie)""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Debian 4.9.2-10) 4.9.2
Copyright (C) 2014 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux

== check pips ===================================================
msgpack-numpy (0.3.9)
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.2.0)
tensorflow-gpu (1.0.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.0.1
tf.GIT_VERSION = v1.0.0-65-g4763edf-dirty
tf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally

== env ==========================================================
LD_LIBRARY_PATH /Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Fri May 12 19:40:54 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.44                 Driver Version: 367.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  Off  | 0000:02:00.0     Off |                  N/A |
| 22%   47C    P8    18W / 250W |      1MiB / 12206MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-7.5/lib/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib/libcudart_static.a
/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib64/libcudart_static.a
/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7
/usr/local/cuda-7.5/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7




python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"" gives
('v1.0.0-65-g4763edf-dirty', '1.0.1')



### Describe the problem
When I run tensorflow code (e.g. keras's mnist_cnn.py) in ipython, errors and Ctrl+C often crashes the interactive ipython session with a core dump or segfault, e.g....


### Source code / logs

In [1]: run mnist_cnn.py 
Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
x_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
/u/kruegerd/python_modules/keras/keras/backend/tensorflow_backend.py:2252: UserWarning: Expected no kwargs, you passed 1
kwargs passed to function are ignored with Tensorflow backend
  warnings.warn('\n'.join(msg))
Train on 60000 samples, validate on 10000 samples
Epoch 1/12
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:02:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)
23680/60000 [==========>...................] - ETA: 10s - loss: 0.5787 - acc: 0.8213^C---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
/u/kruegerd/python_modules/keras/examples/mnist_cnn.py in <module>()
     65           epochs=epochs,
     66           verbose=1,
---> 67           validation_data=(x_test, y_test))
     68 score = model.evaluate(x_test, y_test, verbose=0)
     69 print('Test loss:', score[0])

/u/kruegerd/python_modules/keras/keras/models.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)
    863                               class_weight=class_weight,
    864                               sample_weight=sample_weight,
--> 865                               initial_epoch=initial_epoch)
    866 
    867     def evaluate(self, x, y, batch_size=32, verbose=1,

/u/kruegerd/python_modules/keras/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)
   1499                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,
   1500                               callback_metrics=callback_metrics,
-> 1501                               initial_epoch=initial_epoch)
   1502 
   1503     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):

/u/kruegerd/python_modules/keras/keras/engine/training.pyc in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)
   1153                 batch_logs['size'] = len(batch_ids)
   1154                 callbacks.on_batch_begin(batch_index, batch_logs)
-> 1155                 outs = f(ins_batch)
   1156                 if not isinstance(outs, list):
   1157                     outs = [outs]

/u/kruegerd/python_modules/keras/keras/backend/tensorflow_backend.pyc in __call__(self, inputs)
   2229         session = get_session()
   2230         updated = session.run(self.outputs + [self.updates_op],
-> 2231                               feed_dict=feed_dict)
   2232         return updated[:len(self.outputs)]
   2233 

/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    765     try:
    766       result = self._run(None, fetches, feed_dict, options_ptr,
--> 767                          run_metadata_ptr)
    768       if run_metadata:
    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    963     if final_fetches or final_targets:
    964       results = self._do_run(handle, final_targets, final_fetches,
--> 965                              feed_dict_string, options, run_metadata)
    966     else:
    967       results = []

/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1013     if handle is None:
   1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1015                            target_list, options, run_metadata)
   1016     else:
   1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1020   def _do_call(self, fn, *args):
   1021     try:
-> 1022       return fn(*args)
   1023     except errors.OpError as e:
   1024       message = compat.as_text(e.message)

/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1002         return tf_session.TF_Run(session, options,
   1003                                  feed_dict, fetch_list, target_list,
-> 1004                                  status, run_metadata)
   1005 
   1006     def _prun_fn(session, handle, feed_dict, fetch_list):

KeyboardInterrupt: 

Fatal Python error: GC object already tracked
Aborted (core dumped)

",0,,1,2017-05-12T23:55:52Z,NONE
9868,Chrome timeline for Keras?,"stat:contributions welcome,type:feature","I've been looking at the chrome timeline to profile my Keras models, but have been unable to find any documentation on how I could use it with my Keras models.
I am running keras with a tf backend, and my sequential models are all built in keras. For instance, this is how my model is being built:


    'model.fit_generator( \
				generator= data_gen(args, 1), \
			 	steps_per_epoch=tr_steps, \
			 	epochs=args.epochs, \
			 	validation_data=data_gen(args, 2), \
			 	validation_steps=val_steps, \
			 	verbose=1, \
			 	callbacks=[checkpointer])`


 


I am at a loss for how I would try to generate a timeline trace for this model, and wanted to know if there is any related documentation for how I can do this?",0,,9,2017-05-12T18:39:06Z,NONE
9849,Building failure on KNL,"stat:awaiting tensorflower,type:build/install","Build with
Current master branch source code from github

> ~/tensorflow$ ./configure 
> Please specify the location of python. [Default is /usr/bin/python]: 
> Found possible Python library paths:
>   /usr/local/lib/python2.7/dist-packages
>   /usr/lib/python2.7/dist-packages
> Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]
> Using python library path: /usr/local/lib/python2.7/dist-packages
> Do you wish to build TensorFlow with MKL support? [y/N] y
> MKL support will be enabled for TensorFlow
> Do you wish to download MKL LIB from the web? [Y/n] 
> Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
> Do you wish to use jemalloc as the malloc implementation? [Y/n] 
> jemalloc enabled
> Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] 
> No Google Cloud Platform support will be enabled for TensorFlow
> Do you wish to build TensorFlow with Hadoop File System support? [y/N] 
> No Hadoop File System support will be enabled for TensorFlow
> Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] 
> No XLA support will be enabled for TensorFlow
> Do you wish to build TensorFlow with VERBS support? [y/N] 
> No VERBS support will be enabled for TensorFlow
> Do you wish to build TensorFlow with OpenCL support? [y/N] 
> No OpenCL support will be enabled for TensorFlow
> Do you wish to build TensorFlow with CUDA support? [y/N] 
> No CUDA support will be enabled for TensorFlow
> Warning: ignoring http_proxy in environment.
> INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.
> Configuration finished

Command
`bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures`

The error only part of build log
[Build Log.txt](https://github.com/tensorflow/tensorflow/files/994830/Build.Log.txt)

The Env collected by tf_env_collect.sh
[Env.txt](https://github.com/tensorflow/tensorflow/files/994893/Env.txt)


Bazel
> $ bazel version
> Warning: ignoring http_proxy in environment.
> Build label: 0.4.5
> Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
> Build time: Thu Mar 16 12:19:38 2017 (1489666778)
> Build timestamp: 1489666778
> Build timestamp as int: 1489666778

Xeon Phi Platform(KNL)
No GPU

One thing to notice is that with my experiments,
The changes in
[Fix TensorFlow compilation errors with KNL optimization flags](https://github.com/tensorflow/tensorflow/commit/51331365b60dd042ebc0849ea4e1ab6a396b60fd)
fixed the building issue. Although I don't know whether it is functioning correctly.

Then the code is rolled back in
[FIxed merge issues ](https://github.com/tensorflow/tensorflow/commit/bbdd4a7f6508c32042dcff10025fd39aeba72cdc)

Could you please look into this.
Thank you.",0,,9,2017-05-12T01:48:53Z,NONE
9837,Optimizers in the C++ API,"stat:contributions welcome,type:feature","There is currently no Optimizer in the [C++ API](https://www.tensorflow.org/api_docs/cc/) compared as the ones that we can find in the [Python API](https://www.tensorflow.org/api_docs/python/).

It means, when using only the C++ API that we have to manually collect the gradients and apply them.

Don't you think it should be a convenient add? Retrieving the gradients and applying them is kind of hard and error prone. If yes, I could work on it and create an Optimizer + GradientDescentOptimizer in the C++ API.

I maybe missed something.",0,,25,2017-05-11T12:06:08Z,CONTRIBUTOR
9836,Unable to run model in iOS: dtype() == expected_dtype (9 vs. 4),,"### System information
- **iOS emulator**
- **TensorFlow version v1.1.0rc2**
- compiler flag: -O3, `-D__ANDROID_TYPES_SLIM__` replaced by `-D__ANDROID_TYPES_FULL__` inside `tensorflow/contrib/makefile/Makefile` in order to fix a issue of missing kernel
- modification made: `tensorflow/core/kernels/cwise_op_floor_mod.cc` added to `tensorflow/contrib/makefile/tf_op_files.txt b/tensorflow/contrib/makefile/tf_op_files.txt` in order to fix another issue of missing kernel

### Describe the problem

I am trying to run the [deeplab image segmentation](https://github.com/DrSleep/tensorflow-deeplab-resnet) on iOS.  I have freezed the model, which can then be run on a python shell.  But when I put it on to iOS, it crashes.  Please see the log from xcode below.  I am sure my build of tensorflow is working because I can run another model.

### Source code / logs

The log comes from running a quantized model.  running a non-quantized version lead to the same problem.
```
2017-05-11 18:57:16.053474: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-11 18:57:16.053595: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-11 18:57:16.053717: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-11 18:57:16.053830: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-11 18:57:16.053889: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-11 18:57:16.054 tf_ios_makefile_example[10355:45103643] Graph created.
[libprotobuf INFO google/protobuf/io/coded_stream.cc:610] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 45491214
2017-05-11 18:57:16.094 tf_ios_makefile_example[10355:45103643] Creating session.
2017-05-11 18:57:17.110386: F tensorflow/core/framework/tensor.cc:487] Check failed: dtype() == expected_dtype (9 vs. 4)
```

Thanks in advance.
",0,,7,2017-05-11T11:47:10Z,NONE
9823,Tensorflow consumes much more memory than expected,"stat:awaiting tensorflower,type:bug/performance","My model has four CPU variables:
[500M, 3] tf.int32
[500M] tf.float32
[500M] tf.float32 (FTRL accumulate slot)
[500M] tf.float32 (FTRL linear slot)
expected memory consumption should be (500M * 6) * 4 = 12G, however tensorflow used 20G memory.

When I increased 500M to 1B, total memory usage is 40G, seems tensorflow do allocate much more memory than needed, any idea? By the way I am not using any tcmalloc stuff.
I also used timeline show_memory to print allocated tensor size, everything is consistent with my calculating.",0,,19,2017-05-11T01:18:51Z,CONTRIBUTOR
9779,memory leak when implement rnn attention decoder,type:bug/performance,"### System information

== cat /etc/issue ===============================================
Linux quad 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04 LTS (Xenial Xerus)""
VERSION_ID=""16.04""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux quad 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
protobuf (3.3.0)
tensorflow-gpu (1.1.0)

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Tue May  9 12:16:54 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  Off  | 0000:05:00.0     Off |                  N/A |
| 22%   47C    P0    76W / 250W |      0MiB / 12205MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |
| 22%   60C    P2   129W / 250W |  11713MiB / 12207MiB |     80%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |
| 22%   49C    P0    83W / 250W |      0MiB / 12207MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |
| 24%   63C    P2   117W / 250W |  11713MiB / 12207MiB |     70%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    1     21558    C   python3                                      11709MiB |
|    3     21346    C   python3                                      11709MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-7.5/doc/man/man7/libcudart.7
/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7
/usr/local/cuda-7.5/lib64/libcudart_static.a
/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
/usr/local/cuda-7.5/lib/libcudart_static.a
/usr/local/cuda-7.5/lib/libcudart.so.7.5.18
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.27


### Describe the problem
When we try to implement a complex network which contain a rnn attention decoder, It will consume all the memory after several days. I extract the decoder in a test file, the memory still grow in a slower speed. also found that if change softmax to sigmoid, memory doesn't leak.

### Source code / logs
test code:
```
# __author__ = ""liusiye""
# -*- coding: utf-8 -*-
import tensorflow as tf
from tensorflow.contrib.rnn import GRUCell, MultiRNNCell
from os import getpid
import psutil
import gc
import tensorflow as tf
import numpy as np


process = psutil.Process(getpid())
B, T, H = 20, 60, 256
layer_num = 4

def apply_attention(encoding, rnn_output):
    ''' encoding: [t, b, h1]
        rnn_output: [b, h2]
    '''
    T, B, H1 = encoding.get_shape().as_list()
    _, H2 = rnn_output.get_shape().as_list()
    with tf.variable_scope('attention'):
        w_encoder = tf.get_variable(
            name='W_encoder',
            shape=[H1, H1],
            initializer=tf.random_uniform_initializer(-0.01, 0.01))
        w_decoder = tf.get_variable(
            name='W_decoder',
            shape=[H2, H1],
            initializer=tf.random_uniform_initializer(-0.01, 0.01))
        w_attention = tf.get_variable(
            name='W_attention',
            shape=[H1, 1],
            initializer=tf.random_uniform_initializer(-0.01, 0.01))
    r_decoder = tf.matmul(rnn_output, w_decoder)  # [b, h1]

    r_encoder = tf.matmul(tf.reshape(encoding, [-1, H1]), w_encoder)
    r_encoder = tf.reshape(r_encoder, [T, B, H1])
    # [t, b, h] -> [t * b, h] -> [t, b, h]

    r_attention = tf.tanh(r_encoder + r_decoder)  # [t, b, h1]
    attention = tf.matmul(tf.reshape(r_attention, [-1, H1]), w_attention)
    attention = tf.nn.softmax(tf.reshape(attention, [T, B]), dim=0)
    #attention = tf.nn.sigmoid(tf.reshape(attention, [T, B]))
    encoding = tf.transpose(encoding, perm=[2, 0, 1])  # [t, b, h1]->[h1, t, b]

    context = tf.reduce_sum(encoding * attention, axis=1)  # [h1, b]
    return tf.transpose(context)  # [b, h1]

def rnn_attention_decoder_test():
    encoding = tf.get_variable(name='encoding', shape=[T, B, H], dtype=tf.float32)
    rnn_outputs = []  # t * [b, h]
    scope = tf.get_variable_scope()

    zero_input = tf.constant(0, shape=[B, H], dtype=tf.float32)
    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(H) for i in range(layer_num)], state_is_tuple=True)
    state = cell.zero_state(B, tf.float32)
    with tf.variable_scope(scope) as outer_scope:
        for t in range(T):#T):
            attention_input = zero_input
            rnn_input = apply_attention(encoding, attention_input)
            rnn_output, state = cell(rnn_input, state)
            rnn_outputs.append(rnn_output)
            outer_scope.reuse_variables()
    return tf.stack(rnn_outputs, axis=1), state  # t * [b, h] -> [b, t, h]

with tf.Session() as sess, tf.variable_scope('model'):
    with tf.variable_scope('model', reuse=None):
        tensor_lists_test = rnn_attention_decoder_test()
    init_op = tf.group(
        tf.global_variables_initializer(),
        tf.local_variables_initializer()
    )
    sess.run(init_op)
    sess.graph.finalize()
    for step in range(100000):
        after = process.memory_percent()
        if step > 0:
            print(""MEMORY CHANGE %.7f -> %.7f"" % (before, after))
        before = process.memory_percent()
        sess.run(tensor_lists_test)
        gc.collect()
```

log:
```
2017-05-09 09:27:55.435870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-09 09:27:55.435903: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-09 09:27:55.435909: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-09 09:27:55.435913: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-09 09:27:55.435916: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-09 09:27:55.732204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.2405
pciBusID 0000:09:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
2017-05-09 09:27:55.732232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-05-09 09:27:55.732238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-05-09 09:27:55.732247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
MEMORY CHANGE 1.1297021 -> 1.3666840
MEMORY CHANGE 1.3666840 -> 1.3666840
MEMORY CHANGE 1.3666840 -> 1.3697929
MEMORY CHANGE 1.3697929 -> 1.3697929
MEMORY CHANGE 1.3697929 -> 1.3729200
MEMORY CHANGE 1.3729200 -> 1.3733208
MEMORY CHANGE 1.3733208 -> 1.3733208
MEMORY CHANGE 1.3733208 -> 1.3737215
MEMORY CHANGE 1.3737215 -> 1.3768487
MEMORY CHANGE 1.3768487 -> 1.3799758
MEMORY CHANGE 1.3799758 -> 1.3803644
MEMORY CHANGE 1.3803644 -> 1.3834976
MEMORY CHANGE 1.3834976 -> 1.3834976
MEMORY CHANGE 1.3834976 -> 1.3838862
MEMORY CHANGE 1.3838862 -> 1.3838862
MEMORY CHANGE 1.3838862 -> 1.3842870
MEMORY CHANGE 1.3842870 -> 1.3846878
MEMORY CHANGE 1.3846878 -> 1.3850885
MEMORY CHANGE 1.3850885 -> 1.3850885
MEMORY CHANGE 1.3850885 -> 1.3850885
MEMORY CHANGE 1.3850885 -> 1.3850885
MEMORY CHANGE 1.3850885 -> 1.3850885
MEMORY CHANGE 1.3850885 -> 1.3854771
MEMORY CHANGE 1.3854771 -> 1.3854771
MEMORY CHANGE 1.3854771 -> 1.3854771
MEMORY CHANGE 1.3854771 -> 1.3858779
MEMORY CHANGE 1.3858779 -> 1.3858779
MEMORY CHANGE 1.3858779 -> 1.3858779
MEMORY CHANGE 1.3858779 -> 1.3858779
MEMORY CHANGE 1.3858779 -> 1.3858779
MEMORY CHANGE 1.3858779 -> 1.3858779
MEMORY CHANGE 1.3858779 -> 1.3862665
MEMORY CHANGE 1.3862665 -> 1.3866673
MEMORY CHANGE 1.3866673 -> 1.3866673
MEMORY CHANGE 1.3866673 -> 1.3870680
MEMORY CHANGE 1.3870680 -> 1.3870680
MEMORY CHANGE 1.3870680 -> 1.3870680
MEMORY CHANGE 1.3870680 -> 1.3870680
MEMORY CHANGE 1.3870680 -> 1.3870680
MEMORY CHANGE 1.3870680 -> 1.3870680
MEMORY CHANGE 1.3870680 -> 1.3870680
MEMORY CHANGE 1.3870680 -> 1.3874688
MEMORY CHANGE 1.3874688 -> 1.3874688
MEMORY CHANGE 1.3874688 -> 1.3878695
MEMORY CHANGE 1.3878695 -> 1.3878695
MEMORY CHANGE 1.3878695 -> 1.3882581
MEMORY CHANGE 1.3882581 -> 1.3882581
MEMORY CHANGE 1.3882581 -> 1.3886589
MEMORY CHANGE 1.3886589 -> 1.3886589
MEMORY CHANGE 1.3886589 -> 1.3890597
MEMORY CHANGE 1.3890597 -> 1.3894604
MEMORY CHANGE 1.3894604 -> 1.3894604
MEMORY CHANGE 1.3894604 -> 1.3898612
MEMORY CHANGE 1.3898612 -> 1.3898612
MEMORY CHANGE 1.3898612 -> 1.3902619
MEMORY CHANGE 1.3902619 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3906627
MEMORY CHANGE 1.3906627 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3937898
MEMORY CHANGE 1.3937898 -> 1.3941906
MEMORY CHANGE 1.3941906 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3945913
MEMORY CHANGE 1.3945913 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3949921
MEMORY CHANGE 1.3949921 -> 1.3953929
MEMORY CHANGE 1.3953929 -> 1.3953929
MEMORY CHANGE 1.3953929 -> 1.3953929
MEMORY CHANGE 1.3953929 -> 1.3953929
MEMORY CHANGE 1.3953929 -> 1.3953929
MEMORY CHANGE 1.3953929 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3957936
MEMORY CHANGE 1.3957936 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3961944
MEMORY CHANGE 1.3961944 -> 1.3965951
MEMORY CHANGE 1.3965951 -> 1.3965951
MEMORY CHANGE 1.3965951 -> 1.3965951
MEMORY CHANGE 1.3965951 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3969959
MEMORY CHANGE 1.3969959 -> 1.3973967
MEMORY CHANGE 1.3973967 -> 1.3973967
MEMORY CHANGE 1.3973967 -> 1.3973967
MEMORY CHANGE 1.3973967 -> 1.3973967
MEMORY CHANGE 1.3973967 -> 1.3977974
MEMORY CHANGE 1.3977974 -> 1.3977974
```",1,,6,2017-05-09T04:42:12Z,NONE
9775,"Feature Request: ""training"" argument for contrib.rnn.DropoutWrapper like the one in tf.layers.dropout","stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.0.4
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.1.0


### Feature Request: ""training"" argument for contrib.rnn.DropoutWrapper for applying dropout depending on train/inference phase.

In [`tf.layers.dropout`](https://www.tensorflow.org/api_docs/python/tf/layers/dropout), the `training` parameter is a handy setting that lets you apply dropout depending on whether the model is training or doing inference. It's very convenient to be able to pass a boolean to the model placeholder and have it automatically do the right thing when it comes to dropout.

Unfortunately, [`tf.contrib.rnn.DropoutWrapper`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper) does not have this same parameter, and I think it would greatly benefit from it. This is a feature request for it.

I tried implementing it myself with `tf.cond` and either returning the dropped-out outputs/states or the untouched ones, but I couldn't figure out how to share the variables between them in the cond.
",0,,5,2017-05-09T02:29:09Z,CONTRIBUTOR
9747,'Tensor' object has no attribute 'initializer' after import from meta graph,"stat:awaiting tensorflower,type:bug/performance","------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution**: Darwin Austins-MBP 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.4
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:v1.1.0-rc0-61-g1ec6ed5 1.1.0
- **Bazel version (if compiling from source)**:0.4.5
- **CUDA/cuDNN version**:None
- **GPU model and memory**:None
- **Exact command to reproduce**: Ref to Codes

### tensorflow import 
    tf.VERSION = 1.1.0
    tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
    tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
    Sanity check: array([1], dtype=int32)



### Describe the problem
After export and import a meta graph with uninitialized local variables,
You can not inittialize them with sess.run(tf. local_variables_initializer()), cause
TF do not register variable's proto function with key 'LOCAL_VARIABLES' and when 
export meta graph to protobuf, source code can not find to_proto function from repository.


### Source code / logs
```python
import tensorflow as tf

graph = tf.Graph()
with graph.as_default():
    x = tf.Variable(1, collections=[tf.GraphKeys.LOCAL_VARIABLES])
    y = tf.Variable(1)
    z = x + y
origin_meta_graph = tf.train.export_meta_graph(graph=graph)
new_graph = tf.Graph()
with new_graph.as_default():
    tf.train.import_meta_graph(origin_meta_graph)
    init = tf.local_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
```

```bash
Traceback (most recent call last):
  File ""/Users/austin/workspace/aip/3rd/tensorflow/tensorflow/test.py"", line 12, in <module>
    init = tf.local_variables_initializer()
  File ""/Users/austin/workspace/aip/3rd/tensorflow/venv/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1184, in local_variables_initializer
    return variables_initializer(local_variables())
  File ""/Users/austin/workspace/aip/3rd/tensorflow/venv/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1149, in variables_initializer
    return control_flow_ops.group(*[v.initializer for v in var_list], name=name)
  File ""/Users/austin/workspace/aip/3rd/tensorflow/venv/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1149, in <listcomp>
    return control_flow_ops.group(*[v.initializer for v in var_list], name=name)
AttributeError: 'Tensor' object has no attribute 'initializer'
```

```python
import tensorflow as tf

graph = tf.Graph()
with graph.as_default():
    x = tf.Variable(1, collections=[tf.GraphKeys.LOCAL_VARIABLES])
    y = tf.Variable(1)
    z = x + y
origin_meta_graph = tf.train.export_meta_graph(graph=graph)
new_graph = tf.Graph()
with new_graph.as_default():
    tf.train.import_meta_graph(origin_meta_graph)
print(graph.get_collection(tf.GraphKeys.LOCAL_VARIABLES))
print(new_graph.get_collection(tf.GraphKeys.LOCAL_VARIABLES))
```

```bash
[<tf.Variable 'Variable:0' shape=() dtype=int32_ref>]
[<tf.Tensor 'Variable:0' shape=() dtype=int32_ref>]
```
As it show above, in origin graph local_variable collection is a list of **tf.Variable**
but in the new graph, is a list of **tf.Tensor**

### Work around
Add following registration in your model core
OR Ref to this [PR](https://github.com/tensorflow/tensorflow/pull/9674)

```python
from tensorflow.core.framework import variable_pb2
from tensorflow.python.framework import ops
from tensorflow.python.ops import variables
from tensorflow.python.framework.ops import register_proto_function

register_proto_function(
    ops.GraphKeys.LOCAL_VARIABLES,
    proto_type=variable_pb2.VariableDef,
    to_proto=variables.Variable.to_proto,
    from_proto=variables.Variable.from_proto)
```",0,,17,2017-05-08T06:10:31Z,NONE
9738,OpenCL support for Window,stat:community support,"Scheduled to be compatible with OpenCL for Window
Currently bazel and cmake can not build on OpenCL on Windows
Is there no plan to support OpenCL on Windows?
If so, when will the period be?",0,,4,2017-05-07T09:44:20Z,NONE
9712,Resize image for nd,"stat:contributions welcome,type:feature","Is there a functionality of resize image for n-d where n > 2? It seems currently tensorflow only support resize images for 2d images (4D tensor). Could you add the functionality? 
",0,,1,2017-05-06T03:10:15Z,NONE
9705,atrous_conv2d does not support NCHW format,stat:contributions welcome,"Any plans to support NCHW format for atrous_conv2d?  As per the performance guidelines on TensorFlow website,  ops using NCHW format is faster than NHWC format for GPUs.",0,,3,2017-05-05T22:07:31Z,NONE
9690,Make EIGEN_MAX_ALIGN_BYTES available from Python,type:feature,"Removing unnecessary memcpys when feeding a Numpy array with a feed_dict is a [recurring feature request](https://github.com/tensorflow/tensorflow/issues/7951) that has large performance implications.

From what I can tell, @alextp [implemented changes](https://github.com/tensorflow/tensorflow/commit/0ffa40ee3d5fae4ff14b75c2525edcaa2f01ece7) that avoid the memcpy if the input array is ``EIGEN_MAX_ALIGN_BYTES`` aligned. For a user to definitely avoid memcpy's on feeding, they would need to make sure their arrays are aligned to ``EIGEN_MAX_ALIGN_BYTES``. Currently, there is no way to access ``EIGEN_MAX_ALIGN_BYTES`` from Python, so the user can't be sure what alignment is required. 

It would be nice if there was a C API call (and a corresponding Python one) to make ``EIGEN_MAX_ALIGN_BYTES`` available. This isn't a critical feature as the user can currently be very pessimistic on alignment requirements and (probably safely) 64-byte align their inputs.",1,,13,2017-05-05T16:14:21Z,NONE
9683,"tf.avg_pool fails for data format ""NCHW"" on ppc64le",stat:community support,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04 ppc64le
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
'v1.0.1-0-ge895d5c-dirty'
- **Bazel version (if compiling from source)**:
Build label: 0.4.4-2017-04-13 (@80a07b5)
- **CUDA/cuDNN version**:
No GPU
- **GPU model and memory**:
No GPU
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm trying to run tf.nn.avg_pool (https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool) by passing in NCHW as the data format on a CPU (no GPU) but see the error: 

"" Executor failed to create kernel. Invalid argument: Default AvgPoolingOp only supports NHWC.""

The API documentation mentions both NHWC and NCHW are supported. Please see logs below for complete details

**Query: Does avg_pool support NCHW for CPUs?**
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Note: Below, NHWCToNCHW defined standard func to convert from one form to another (but not shown in this snippet)

>>> x
array([[[[  1.,   2.,   3.],
         [  4.,   5.,   6.],
         [  7.,   8.,   9.]],

        [[ 10.,  11.,  12.],
         [ 13.,  14.,  15.],
         [ 16.,  17.,  18.]]]], dtype=float32)
>>> t = tf.placeholder(tf.float32)
>>> t = NHWCToNCHW(t)
>>> t = tf.nn.avg_pool(t,ksize=[1,2,2,1],strides=[1,2,2,1],padding=""SAME"",data_format=""NCHW"")
>>> actual = sess.run(t, {inputs: x})
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: Default AvgPoolingOp only supports NHWC.
         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 2, 2, 1], padding=""SAME"", strides=[1, 2, 2, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](AvgPool)]]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Default AvgPoolingOp only supports NHWC.
         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 2, 2, 1], padding=""SAME"", strides=[1, 2, 2, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](AvgPool)]]

Caused by op u'AvgPool_1', defined at:
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1765, in avg_pool
    name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 50, in _avg_pool
    data_format=data_format, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Default AvgPoolingOp only supports NHWC.
         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 2, 2, 1], padding=""SAME"", strides=[1, 2, 2, 1], _device=""/job:localhost/replica:0/task:0/cpu:0""](AvgPool)]]

",0,,2,2017-05-05T11:07:12Z,CONTRIBUTOR
9664,Run half-precision models on Android,"stat:contributions welcome,type:feature","Is it possible to run half-precision (float16) graphs on Android (arm64-v8a/AArch64 supports half-precision)? If so, what would be the approach to do that? Trying to run a float16 graph gives an exception saying that only INT32 and Float32 ops are supported.

Thank you in advance,",0,,8,2017-05-04T14:35:42Z,NONE
9661,[feature] Support Cross Compiling with tfcompile,"stat:contributions welcome,type:feature","Tensorflow (using XLA) is able to AOT compile a graph using `tfcompile`. There does not seem to be a way to, or it it not documented, cross compile the graph (ie compile on OS X for deployment on iOS). (Related [SO](http://stackoverflow.com/questions/43508105/using-tfcompile-to-aot-compile-tensorflow-graph-for-ios) question).

I suggest adding a means of performing this cross compilation.",0,,14,2017-05-04T14:00:42Z,CONTRIBUTOR
9645,Gather/Slice/StridedSlice Gradients Support in the C++ API,"stat:contributions welcome,type:feature","Hi,

I noticed that there is currently no gradient support in the C++ API for the gather, slice, and strided slice ops. Would it be too difficult to add support for those gradient ops? I am asking because they are ops very frequently used in the context of machine learning models and without them building ML models can be unnecessarily complicated.

Thank you!

P.S. I have noticed that the Python API implementation of the gather op gradient uses indexed slices, but I am not sure if that is entirely necessary and can thus probably also be supported in the C++ API.",0,,3,2017-05-03T23:43:20Z,CONTRIBUTOR
9638,Seg fault on session run when built with CMake and optimize for native arch enabled,,"**System info: Ubuntu 16.04 64 bit, gcc 5.4.0, Intel i5 CPU**

Segmentation fault occurs in Eigen when a certain AVX instruction is performed (see stack trace below). This occurs during session run of several convolutional neural network graphs.

Tensorflow (checked out from the master branch today) is built using CMake with tensorflow_BUILD_SHARED_LIB enabled which generates a libtensorflow.so library file. This library file is linked to another C++ application which simply loads a graph and executes it.

Disabling the CMake option tensorflow_OPTIMIZE_FOR_NATIVE_ARCH removes the error, but probably also reduce performance.

Below is a nasty long stack trace, if you need any other info please let me know.

Stack trace:
```
#0 0x00007fffee19021b in _mm256_store_ps (__A=..., __P=0x7fff7c110cd0) at /usr/lib/gcc/x86_64-linux-gnu/5/include/avxintrin.h:854
#1 Eigen::internal::pstore<float, float __vector(8)>(float*, float __vector(8) const&) (to=0x7fff7c110cd0, from=...)
  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX/PacketMath.h:260
#2 0x00007fffefd255b5 in Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>::operator() (
  this=0x7fff98fd4a67, blockA=0x7fff7c110cd0, lhs=..., depth=9, rows=8, stride=0, offset=0)
  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/products/GeneralBlockPanelKernel.h:1767
#3 0x00007fffeff65692 in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::pack_lhs (
  this=0x7fff937fbbd0, m=1, k=0) at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h:495
#4 0x00007fffeff63758 in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper (this=0x7fff937fbbd0, start=1, end=2, k=0, rhs=false) at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h:624
#5 0x00007fffeff6369d in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1}::operator()() const (__closure=0x7fff7c1aaca0)
  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h:628
#6 0x00007fffeff73cca in std::_Bind<Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1} ()>::__call<void>(std::tuple<>&&, std::_Index_tuple<>) (this=0x7fff7c1aaca0,
  __args=<unknown type in /home/smistad/workspace/FAST/build_Release/lib/libtensorflow.so, CU 0xf277508, DIE 0xf39a603>) at /usr/include/c++/5/functional:1074
#7 0x00007fffeff71a5d in std::_Bind<Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1} ()>::operator()<, void>() (this=0x7fff7c1aaca0) at /usr/include/c++/5/functional:1133
#8 0x00007fffeff6d3ac in std::_Function_handler<void (), std::_Bind<Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::M---Type <return> to continue, or q <return> to quit---
akePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1} ()> >::_M_invoke(std::_Any_data const&) (__functor=...) at /usr/include/c++/5/functional:1871
#9 0x00007fffedeba4c8 in std::function<void ()>::operator()() const (this=0x7fff7c1aace0) at /usr/include/c++/5/functional:2267
#10 0x00007fffedeb9da7 in tensorflow::thread::EigenEnvironment::ExecuteTask (this=0x21bd7a8, t=...) at /home/smistad/workspace/FAST/build_Release/external/tensorflow/src/tensorflow/tensorflow/core/lib/core/threadpool.cc:81
#11 0x00007fffedebca71 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop (this=0x21bd7a0, thread_id=3)
  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:232
#12 0x00007fffedebade0 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment)::{lambda()#1}::operator()() const ()
  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:65
#13 0x00007fffedebe462 in std::_Function_handler<void (), Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment)::{lambda()#1}>::_M_invoke(std::_Any_data const&) (__functor=...) at /usr/include/c++/5/functional:1871
#14 0x00007fffedeba4c8 in std::function<void ()>::operator()() const (this=0x3333350) at /usr/include/c++/5/functional:2267
#15 0x00007fffedeb9aec in tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}::operator()() const (__closure=0x3333350)
  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/src/tensorflow/tensorflow/core/lib/core/threadpool.cc:56
#16 0x00007fffedebbcb1 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) (__functor=...)
  at /usr/include/c++/5/functional:1871
#17 0x00007fffedeba4c8 in std::function<void ()>::operator()() const (this=0x3346398) at /usr/include/c++/5/functional:2267
#18 0x00007fffedef50ca in std::_Bind_simple<std::function<void ()> ()>::_M_invoke<>(std::_Index_tuple<>) (this=0x3346398) at /usr/include/c++/5/functional:1531
#19 0x00007fffedef5020 in std::_Bind_simple<std::function<void ()> ()>::operator()() (this=0x3346398) at /usr/include/c++/5/functional:1520
#20 0x00007fffedef4fb0 in std::thread::_Impl<std::_Bind_simple<std::function<void ()> ()> >::_M_run() (this=0x3346380) at /usr/include/c++/5/thread:115
#21 0x00007ffff6201c80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#22 0x00007ffff5d1d6ba in start_thread (arg=0x7fff98fd5700) at pthread_create.c:333
#23 0x00007ffff5a5382d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109
```
",1,,6,2017-05-03T17:40:32Z,CONTRIBUTOR
9579,MNIST Tutorial Appears to Not Toggle XLA Compilation,,"I have been using the JIT compilation/XLA tutorial (https://www.tensorflow.org/performance/xla/jit#step_3_run_with_xla), and it seems that whether or not XLA compilation happens doesn't depend on the statement on line 63 in mnist_softmax_xla.py. The comment above it says that line will turn on XLA JIT compilation. When I run with the two options explained on the page (--xla='' for compiling without XLA, and TF_XLA_FLAGS=--xla_generate_hlo_graph=.* for compiling with XLA), the second executes line 63 and the first does not. But, both seem to compute in exactly the same way, going through compiler/xla/service. The output for both runs is:
```
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
2017-05-01 12:50:25.203870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-01 12:50:25.203904: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-01 12:50:25.232661: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-05-01 12:50:25.232702: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices
2017-05-01 12:50:25.233155: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
2017-05-01 12:50:25.233165: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
2017-05-01 12:50:25.233894: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-05-01 12:50:25.233903: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices
2017-05-01 12:50:25.234360: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Xpu. Devices:
2017-05-01 12:50:25.234369: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
2017-05-01 12:50:25.234372: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (1): <undefined>, <undefined>
2017-05-01 12:50:25.234376: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (2): <undefined>, <undefined>
2017-05-01 12:50:25.234379: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (3): <undefined>, <undefined>
2017-05-01 12:50:25.234382: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (4): <undefined>, <undefined>
2017-05-01 12:50:25.234385: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (5): <undefined>, <undefined>
2017-05-01 12:50:25.234389: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (6): <undefined>, <undefined>
2017-05-01 12:50:25.234392: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (7): <undefined>, <undefined>
0.9206
```",1,,10,2017-05-01T20:04:20Z,NONE
9576,"dilated convolution in 3D, error:  No algorithm without scratch worked",,"I'm using tf.nn.convolution to implement the dilated convolution in 3D. I got ""No algorithm without scratch worked"" error during training. Here is the related code

To define the model,
```
def inference(self, images, is_training, keep_prob):
        """""" Forward inference
        Return:

        """"""
        c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))
        score = self._conv(c1, scope = 'score', filters = 2,  filter_size = (1,1,1) )

        pred = tf.nn.softmax(score)

        # pdb.set_trace()
        return score, pred

    def _conv(self, in_tensor, filters, scope, filter_size = None):
        """""" """"""

        if self._wd is None:
            myreg = None
        else:
            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))

        if filter_size is None:
            filter_size = self._filter_size

        with tf.variable_scope(scope):
            return tf.layers.conv3d(
                in_tensor, filters = filters,
                kernel_size = filter_size, padding = 'valid',
                activation = None,
                kernel_initializer  = tf.truncated_normal_initializer(stddev = self._stddev),
                kernel_regularizer =myreg,
                name = 'conv')        

    def _dilation_conv(self, in_tensor, n_filters, scope, dilation_rate, filter_size = None):
        """""" dilated convolution filter with batch norm. """"""
        
        if self._wd is None:
            myreg = None
        else:
            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))

        if filter_size is None:
            filter_size = self._filter_size

        batch_size, H, W, D, in_channel = in_tensor.get_shape().as_list()            

        with tf.variable_scope(scope):
            kernel = tf.get_variable('weights', shape = self._filter_size + (in_channel, n_filters),
                                     dtype = tf.float32,
                                     initializer = tf.truncated_normal_initializer(stddev=self._stddev))
            output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')

            # Somehow set training = True even for testing phase works
            # better.
            if self._bn:
                output = tf.layers.batch_normalization(
                    output, training = True, name = 'bn')

            return tf.nn.relu(output, 'relu')
            
    def get_loss(self, labels, scores, beta = 0.9999):
        """"""
        return total loss of the model, including data loss and
        regularization loss.
    
        It looks that softmax_cross_entropy_with_logits does not need the
        input logits 2 dimension. As long as the last dimension is for
        classes, it should work. So, we do not need reshape the input tensor. 

        TF has a weighted_cross_entropy_with_logits, but this function is
        for multi-class problem, i.e. a picture may have both a dog and a
        truck.
        """"""

        class_weight = tf.constant([beta, 1.0 - beta])
        # TF suppot numpy's broadcasting. score array has dim BXY2,
        # weights array has dim (2), which is broadcast to BXY2.
        weighted_logits = tf.multiply(scores, class_weight)

        # both logits and labels are BXY2 dimension. 
        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = weighted_logits, labels = labels)
        # fromm dim BXY to dim 0 (scalar)
        cross_entropy_mean = tf.reduce_mean(cross_entropy, name = 'cross_entropy')

        reg_loss_list = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
        if reg_loss_list:
            return cross_entropy_mean + tf.add_n(reg_loss_list)
        else:
            return cross_entropy_mean
```
And to train the model, I used tf.train.AdamOptimizer. I didn't paste the training related code, since I don't think they are relevant, but I can add them later if that helps. 

Here is the error logs I saw: 
``` 
In [40]: train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')
2017-05-01 15:08:10.813716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:85:00.0)
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1038     try:
-> 1039       return fn(*args)
   1040     except errors.OpError as e:

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1020                                  feed_dict, fetch_list, target_list,
-> 1021                                  status, run_metadata)
   1022 

/usr/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()
    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 466           pywrap_tensorflow.TF_GetCode(status))
    467   finally:

NotFoundError: No algorithm without scratch worked!
	 [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]
	 [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_89_Adam/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
<ipython-input-40-c48a6e49a4b4> in <module>()
----> 1 train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')

/home/weiliu/projects/seismic/code/weiliu/train.py in train(train_dataset, test_dataset, model, init_lr, summary_dir, in_ckpt, out_ckpt)
    141                          keep_prob_pl: 0.5}
    142 
--> 143             _, loss_value = sess.run([optimizer, loss], feed_dict = feed_dict)
    144 
    145             global_step_val = tf.train.global_step(sess, global_step)

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    776     try:
    777       result = self._run(None, fetches, feed_dict, options_ptr,
--> 778                          run_metadata_ptr)
    779       if run_metadata:
    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    980     if final_fetches or final_targets:
    981       results = self._do_run(handle, final_targets, final_fetches,
--> 982                              feed_dict_string, options, run_metadata)
    983     else:
    984       results = []

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1030     if handle is None:
   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1032                            target_list, options, run_metadata)
   1033     else:
   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1050         except KeyError:
   1051           pass
-> 1052       raise type(e)(node_def, op, message)
   1053 
   1054   def _extend_graph(self):

NotFoundError: No algorithm without scratch worked!
	 [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]
	 [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_89_Adam/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2', defined at:
  File ""/usr/local/bin/ipython"", line 11, in <module>
    sys.exit(start_ipython())
  File ""/usr/local/lib/python3.4/dist-packages/IPython/__init__.py"", line 119, in start_ipython
    return launch_new_instance(argv=argv, **kwargs)
  File ""/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/local/lib/python3.4/dist-packages/IPython/terminal/ipapp.py"", line 348, in start
    self.shell.mainloop()
  File ""/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py"", line 440, in mainloop
    self.interact()
  File ""/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py"", line 431, in interact
    self.run_cell(code, store_history=True)
  File ""/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-40-c48a6e49a4b4>"", line 1, in <module>
    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')
  File ""/home/weiliu/projects/seismic/code/weiliu/train.py"", line 116, in train
    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step = global_step)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py"", line 315, in minimize
    grad_loss=grad_loss)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py"", line 386, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py"", line 368, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py"", line 77, in _Conv3DGrad
    padding=op.get_attr(""padding"")),
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 663, in conv3d_backprop_input_v2
    padding=padding, name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

...which was originally created as op 'c1/dilation_conv', defined at:
  File ""/usr/local/bin/ipython"", line 11, in <module>
    sys.exit(start_ipython())
[elided 8 identical lines from previous traceback]
  File ""<ipython-input-40-c48a6e49a4b4>"", line 1, in <module>
    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')
  File ""/home/weiliu/projects/seismic/code/weiliu/train.py"", line 67, in train
    images_placeholder, is_training = istraining_pl, keep_prob = keep_prob_pl )
  File ""/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py"", line 71, in inference
    c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))
  File ""/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py"", line 116, in _dilation_conv
    output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 661, in convolution
    op=op)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 331, in with_space_to_batch
    return op(input, num_spatial_dims, padding)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 653, in op
    name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 140, in _non_atrous_convolution
    name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 529, in conv3d
    strides=strides, padding=padding, name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)

NotFoundError (see above for traceback): No algorithm without scratch worked!
	 [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]
	 [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_89_Adam/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

```
I also check the `atrous_convolution_test.py` and it seems I used it right. 

I'm on Ubuntu 14.04 64 bit, tensorflow version 1.1.0-rc2. 

If anyone can point me direction how to debug, that would be great. ",1,,7,2017-05-01T19:17:10Z,NONE
9571,model_dir deletion while running python script,"stat:contributions welcome,type:feature","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10
- **TensorFlow installed from (source or binary)**:  binary, installed via pip
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:na
- **CUDA/cuDNN version**: na
- **GPU model and memory**: na
- **Exact command to reproduce**:?

### Describe the problem
Feature request: As part of an hyperparameter optimization routine, I use tensorflow's high level api tf.contrib.learn.DNNRegressor() (should apply to the others as well). The problem is that it creates for each instance an own new model_dir, which I can't delete during running the python script (even after the model instance is overwritten and no longer in RAM). It is a problem because it consumes rather fast large amounts of disk storage. As far as I can see there is no way to delete the temp dir while running the program, only once it terminates the dir is released and removable. 

### Source code / logs
here is a pseudo code example:
https://stackoverflow.com/questions/43639516/model-dir-deletion-in-tensorflow",0,,3,2017-05-01T14:30:39Z,NONE
9550,ctc_greedy_decoder inconsistent with ctc_beam_search_decoder,,"The following extract from the the `ctc_beam_search_decoder` documentation seems to be misleading:
""The `ctc_greedy_decoder` is a special case of the `ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but that decoder is faster for this special case).""

Instead, the following results can be observed: 

| Decoding ""AA<ctc_blank>AA"" using | `merge_repeated=True` | `merge_repeated=False` |
| --- | --- | --- |
| `tf.nn.ctc_beam_search_decoder(top_paths=1, beam_width=1)` | ""A""   | ""AA"" |
| `tf.nn.ctc_greedy_decoder()` | ""AA"" | ""AAAA"" |

To reproduce:

```python
import numpy as np
import tensorflow as tf
from unittest import TestCase


class CtcDecodersTest(TestCase):
    def test(self):
        def decode_greedily(beam_search: bool, merge_repeated: bool):
            aa_ctc_blank_aa_logits = tf.constant(np.array([[[1.0, 0.0]], [[1.0, 0.0]], [[0.0, 1.0]],
                                                    [[1.0, 0.0]], [[1.0, 0.0]]], dtype=np.float32))
            sequence_length = tf.constant(np.array([5], dtype=np.int32))

            (decoded_list,), log_probabilities = \
                tf.nn.ctc_beam_search_decoder(inputs=aa_ctc_blank_aa_logits,
                                              sequence_length=sequence_length,
                                              merge_repeated=merge_repeated,
                                              beam_width=1) \
                    if beam_search else \
                    tf.nn.ctc_greedy_decoder(inputs=aa_ctc_blank_aa_logits,
                                             sequence_length=sequence_length,
                                             merge_repeated=merge_repeated)

            return list(tf.Session().run(tf.sparse_tensor_to_dense(decoded_list)[0]))

        self.assertEqual([0], decode_greedily(beam_search=True, merge_repeated=True))
        self.assertEqual([0, 0], decode_greedily(beam_search=True, merge_repeated=False))
        self.assertEqual([0, 0], decode_greedily(beam_search=False, merge_repeated=True))
        self.assertEqual([0, 0, 0, 0], decode_greedily(beam_search=False, merge_repeated=False))
```

This is confusing and probably not intended.

How to solve this:

- Adapt the documentation or
- Adapt the `ctc_beam_search_decoder` implementation to that of `ctc_greedy_decoder` or vice versa. Both directions would cover my use case (""AA""), this decision would depend on which of the other behaviors (""A"" or ""AAAA"") is needed and which of them could be dropped.

### System information
OSX 12.4, TensorFlow 1.1.0 CPU from binary",1,,11,2017-04-30T10:22:38Z,NONE
9545,Duplicate variable shown in Tensorboard expected?,"comp:tensorboard,stat:awaiting tensorflower,type:bug/performance","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS Sierra 12.12.4
- **TensorFlow installed from (source or binary)**:
pip
- **TensorFlow version (use command below)**:
1.1.0 (CPU)
### Describe the problem
I am trying to implement E2C (available from https://arxiv.org/pdf/1506.07365.pdf). Basically it is a neural network that is used for learning a transition model using neural networks. In the training set I have data of the form (X_t, X_t+1) where both X_t and X_t+1 needs to be transformed by an encoding network (e.g. a variational autoencoder). I use the following snippet for creating the encoding network (adapted from https://github.com/ericjang/e2c):

```python
    def encode(self, x, share=None):
        fc = tf.contrib.layers.fully_connected
        with tf.variable_scope('Encoder', reuse=share):
            l1 = fc(x, 400, weights_initializer=tf.orthogonal_initializer(),
                    activation_fn=tf.nn.relu)
            l2 = fc(l1, 100, weights_initializer=tf.orthogonal_initializer(),
                    activation_fn=tf.nn.relu)
            return l2

    def decode(self, z, share=None):
        fc = tf.contrib.layers.fully_connected
        with tf.variable_scope(""Decoder"", reuse=share):
            l1 = fc(z, 100, weights_initializer=tf.orthogonal_initializer(1.1),
                    activation_fn=tf.nn.relu)
            l2 = fc(l1, 400, weights_initializer=tf.orthogonal_initializer(1.1),
                    activation_fn=tf.nn.relu)

            return fc(l2, self.x_dim,
                      weights_initializer=tf.orthogonal_initializer(1.1),
                      activation_fn=tf.nn.sigmoid)
```
Then I would use something like

```python
h_enc_t = encoder(X_t)
h_enc_t_next = encoder(X_{t+1}, share=True)
```
to create the encoded output for the model.

The problem is that when visualizing this on Tensorboard, while it is sharing the variables by setting `share=True` for the variable scope, on the graph visulisation you will have `Encoder` and `Encoder_1` instead of just a `Decoder` scope. Of course they took different input since we need to transform X_t and X_t+1, but shouldn't the network be wrapped in the same scope since underneath we are reusing the same weights? I wonder if it is a feature to have `Encoder_1` and `Encoder` separately or it is a limitation of the variable scoping. The problem is illustrated in the screenshot below, you will see duplicates for 'Encoder' 'SampleQPhi"" etc:

![graph-run](https://cloud.githubusercontent.com/assets/6040760/25559064/98fecc5a-2d2b-11e7-8669-00b1227abf17.png)

However, I would expect something like this (as appeared in the paper) to be a more reasonable visualization (h_enc) with input x_t and x_t+1 are the same network:

<img width=""546"" alt=""screenshot 2017-04-30 15 51 01"" src=""https://cloud.githubusercontent.com/assets/6040760/25565322/fc04ab8a-2dbc-11e7-9876-5e823a3bf47b.png"">


Many thanks in advance!",0,,11,2017-04-29T21:43:08Z,NONE
9527,tf.while_loop much slower than static graph?,"stat:awaiting response,type:bug/performance","I'm running on TF 1.1, and I've used `tf.while_loop` + `TensorArray` to implement dynamic unrolling of a type of recurrence that I previously unrolled statically through python code. The difference in speed is very dramatic, with forward inference being about 200x slower when dynamically unrolled, and backprop about 2x slower. Is this expected? Are there any tricks for optimization that I'm missing? This is on CPU. Performance gap on GPU is even larger.",0,,21,2017-04-29T00:28:11Z,NONE
9525,Statically-linked libraries in TF binary can cause symbol collisions,"stat:awaiting tensorflower,type:bug/performance","TensorFlow currently statically links all dependencies. This sometimes causes hard-to-diagnose crashes (e.g. segfaults) when another version of a dependency is loaded into the process. This can even happen within TensorFlow if separate TensorFlow .so's are loaded into the same Python process.

Possible solutions would be to reduce the visibility of these symbols, dynamically link common libraries, or run TF in a separate process.

Known problematic libraries:
* protobuf (#8403, #8394)
* OpenCL, OpenCV (#7378)

Other related issues:
* #7480",1,,20,2017-04-28T22:55:08Z,MEMBER
9518,GPU version of self_adjoint_eig,type:feature,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux RBSylaptop 4.9.0-1-amd64 #1 SMP Debian 4.9.6-3 (2017-01-28) x86_64 GNU/Linux

- **TensorFlow installed from (source or binary)**:
$ pip3 install tensorflow-gpu
- **TensorFlow version (use command below)**:
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
- **GPU model and memory**:
Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.645
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.31GiB

### Describe the problem
It looks like there is no eigen vector kernel that would run on GPU. Even the CPU version seems to be serial as it uses only one core for a single matrix.

### Source code / logs
This code just create a random 10*10 matrix and try to compute its eigen values and vectors on the GPU.

    mat = np.random.random((10, 10))
    sess = tf.Session()
    with tf.device('/gpu:0'):
        eigen = tf.self_adjoint_eig(mat)
    sess.run(eigen)

Which fails with the error:

    InvalidArgumentError (see above for traceback): Cannot assign a device to node 'SelfAdjointEigV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
         [[Node: SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_DOUBLE, compute_v=true, _device=""/device:GPU:0""](SelfAdjointEigV2/input)]]


And for a large enough matrix, it can be seen that the CPU kernel only uses one core.",0,,10,2017-04-28T18:51:23Z,NONE
9509,Tensorflow with XLA hangs with both GPU and CPU at ~0% usage when training.,,"I am using the newest tensorflow which I built from source as of yesterday in an attempt to fix this issue.  Originally I had a source build of tensorflow 1.1.0.  I am running Ubuntu 16.04 with CUDA 8 and CUDNN 5.  My GPU is a GTX 1080.

The problem I am having is when I try to train my character based translator model using the XLA compiler.  The code makes it all the way through the initialize variables, etc up to the first run command which contains my train step and then just freezes.  Both my GPU and CPU are idle.  I attached gdb to my process and it seems to be stuck waiting for some sort of notification.  My model builds and runs fine if I am running it without training in predict mode but still with XLA.  It also runs fine if I train it without XLA.  Just the combo of XLA and training is the issue.

I attached to this my code plus some sample training data.  This problem should be reproducible by running the train.py.

[CharacterTranslator.zip](https://github.com/tensorflow/tensorflow/files/963946/CharacterTranslator.zip)",1,,5,2017-04-28T09:26:05Z,NONE
9506,No supported kernel for GPU devices is available for assigning a variable of int32 type,,"**tensorflow version**  v1.1.0-rc0-61-g1ec6ed5
**code to reproduce**
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import tensorflow as tf
print(tf.GIT_VERSION, tf.VERSION)

for device in ['cpu', 'gpu']:
    print(device)
    with tf.device('/{}:0'.format(device)):
        var = tf.get_variable('var{}'.format(device), shape=[1], dtype='int32')
        vari = tf.assign(var, [23])

    sess = tf.Session()
    sess.run(vari)
```
**error**
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'vargpu': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
```

This should be caused by [TF_CALL_GPU_NUMBER_TYPES](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/register_types.h#L171) only iterating over float types, and it is used to [generate the assign kernels](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dense_update_ops.cc#L174). However [TF_CALL_NUMBER_TYPES](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/register_types.h#L154) iterates over all types including integers. Is this asymmetry a deliberate design choice?",0,,12,2017-04-28T05:22:02Z,NONE
9503,Ops for Reading from Cloud Spanner,"stat:contributions welcome,type:feature","Is there any plan to make F1 public (be it a service in Google Cloud or just open source) and make it possible to store TensorFlow tensors in F1? I ask because as far as I can tell (might be wrong), there isn't a ""native"" database for TensorFlow (meaning a C++ reader with direct connection to the DB), and F1 supports Protobuf columns which would seem like a natural fit for Tensorflow data.

From [here](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41344.pdf)
> The F1 data model is very similar to the Spanner data
> model. In fact, Spanner’s original data model was more like
> Bigtable, but Spanner later adopted F1’s data model. At
> the logical level, F1 has a relational schema similar to that
> of a traditional RDBMS, with some extensions including
> explicit table hierarchy and columns with Protocol Buffer
> data types.
",0,,6,2017-04-27T22:16:06Z,NONE
9487,"terminate called after throwing an instance of 'std::bad_alloc', not out of memory","stat:awaiting response,type:bug/performance","Hi, I'm using Keras with tensorflow back-end to train a LSTM network, I was doing a grid search over the learning_rate and dropout factor with the fixed batch size of 64, It ran perfectly but in the middle of it was interrupted by signal 6: SIGABRT with the following error: 

    terminate called after throwing an instance of 'std::bad_alloc'  what():  std::bad_alloc

It should not be a memory allocation problem because it was running earlier for batch size of 64 which is not too much in my case

you can find my system information(tf_env.txt) from the following link:  
https://www.dropbox.com/s/wcv8y88fh659zck/tf_env.txt?dl=0




",0,,12,2017-04-27T14:27:05Z,NONE
9485,BernoulliWithSigmoidProbs is obsolete,type:feature,"I think `tf.contrib.distributions.BernoulliWithSigmoidProbs` can be removed, because `Bernoulli` itself has a `logits` parameter that does the exact same thing, afaik. If you agree, I can make a pull-request if necessary.",1,,5,2017-04-27T12:11:36Z,CONTRIBUTOR
9484,"ImportError (in import tensorflw-gpu as tf) : Tensorflow windows10, CUDA8.0/cuDNN5.1 and python 3.5.2","stat:community support,type:build/install","Hi, i am facing an issue if importError on a setup !
1. Windows10, Microsoft visual studio (2017)
2. CUDA 8.0/cuDNN5.1
3. Python 3.5.2
4. PATH for CUDA, cuDNN5.1 Libraries/bin/include set properly !!
5. Setup is created with Docker & tensorflow-gpu environment

While i am trying to verify my installation with ""import tensorflow-gpu as tf"", encountering with  ImportError: python library specific errors. pl do suggest some remedies !!

Here is complete log of error:  
$ python
Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow-gpu as tf
  File ""<stdin>"", line 1
    import tensorflow-gpu as tf
                     ^
SyntaxError: invalid syntax
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",0,,26,2017-04-27T11:04:11Z,NONE
9471,Time cost for each training step increases with the training procedure,type:build/install,"When I try to run a SRGAN network by 32 images with 96 * 96 size, each training step the time cost increases. At the beginning, each step cost 35 seconds, but when 160 steps later, the time cost increases to more than 200 seconds. By checking the time log, I can see it do increase with the training step. If I save the model and restart training process, the time cost reduces to about 35 seconds and start increasing again.",1,,22,2017-04-27T03:37:24Z,NONE
9434,Using replace to evaluate multiple gradients during training in Keras,"stat:contributions welcome,type:bug/performance","I am a researcher in optimization and I am interested in testing algorithms for training DNNs using keras, and am now using tensorflow backend.

In practice, I would like to do something a bit different from the other optimizers, I would like to compute the gradient at a slightly different value of the tensor of parameters than the current one, and the update I will make to the parameters will depend on both the current gradient and this other gradient.  

In practice this has proven more difficult than anticipated.
See https://github.com/fchollet/keras/issues/6175
it was suggested I come to here for further suggestions.

My code is a standard keras python code, the body does

model = Sequential()
model.add(Dense(512, input_shape=(784,)))
...
model.compile(loss='categorical_crossentropy',
              optimizer = myopt,
              metrics=['accuracy'])
history = model.fit(X_train, Y_train,
                    batch_size=batch_size, nb_epoch=nb_epoch, 
                    verbose=1, validation_data=(X_test, Y_test))


In the get_updates call function of my custom optimizer, it begins as usual

    def get_updates(self, params, constraints, loss):
        grads = self.get_gradients(loss, params)

Now, I want to now get the gradients at a different value of grads. First I tried just defining another tensor of the same structure but different values and take the get_gradients, but of course the loss is a graph depending on params already. Then I tried changing params itself (then copying the old values of the tensor to another one, to replace params after the evaluation) but apparently as the forward pass was not made this was ineffective. As per the advice in the above github conversation in keras, I tried,

        tempparams = [a+1. for a in params]
        replace = {p:npm for p, npm in zip(params, tempparams)}
        gradsn = [tf.contrib.graph_editor.graph_replace(g.op, replace) for g in grads]


but this is still not OK, as I get the error

TypeError: Expected a type in (<class 'tensorflow.python.framework.ops.Operation'>), got: <class 'tensorflow.python.ops.variables.Variable'


Thank you



",0,,7,2017-04-25T10:53:13Z,NONE
9420,[Java] Distributed mode support,"languages,stat:contributions welcome,type:feature","### Describe the problem

Is there any plan to add distributed mode to the Java API? I checked the code and it seems to be doable (unless I missed something) so I was wondering if anyone is already working on it? I went through the issue tracker and PRs but couldn't find anything related.",0,,6,2017-04-24T17:38:27Z,CONTRIBUTOR
9368,PreventGradients in SoftmaxCrossEntropyWithLogit ops,"stat:contributions welcome,type:feature","SparseSoftmaxCrossEntropyWithLogits cannot take second order gradients (It's not a beautiful hack, and I am not sure how much computational speed up it will bring). 
Adding PreventGradient node in the gradient graph seems to contaminate the computation graph structure, e.g. I am doing custom forward-mode automatic differentiation.
Reference: https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/python/ops/nn_grad.py#L334",0,,4,2017-04-21T15:34:28Z,NONE
9319,[feature] Mobile Integration with NNPACK,"stat:awaiting tensorflower,type:feature","Caffe2 use can use [NNPACK](https://github.com/Maratyszcza/NNPACK) for [which it says](http://caffe2.ai/docs/mobile-integration.html#null__performance-considerations):
>NNPACK, which specifically optimizes convolutions on ARM

>Currently Caffe2 is optimized for ARM CPUs with NEON (basically any ARM CPU since 2012). Perhaps surprisingly, ARM CPUs outperform the on-board GPUs (our NNPACK ARM CPU implementation outperforms Apple’s MPSCNNConvolution for all devices except the iPhone 7). 

>For a convolutional implementation, it is recommended to use NNPACK since that’s substantially faster (~2x-3x) than the standard im2col/sgemm implementation used in most frameworks. 

The readme for NNPACK lists Tensorflow as a framework that could potentially use it, though [that has not yet happened](https://github.com/Maratyszcza/NNPACK/issues/1).

I believe that TF also avoids using the im2col/sgemm approach on mobile and instead uses the Eigen TensorConvolution. It would be good to benchmark these two options against each other and see if TF performance can be improved by using the `NNPACK` conv instead of the eigen conv. There is an open ticket to do this benchmarking: https://github.com/Maratyszcza/NNPACK/issues/30.

As a feature I suggest offering an `NNPACK` backed kernel to allow comparing vs Eigen.",0,,7,2017-04-20T00:09:19Z,CONTRIBUTOR
9301,Quantized graph fails to work on NVIDIA Jetson TX1 architecture although it worked on a normal PC?,"stat:community support,type:build/install","### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
No
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:
Ubuntu 16.04 LTS on NVIDIA Jetson TX1 (Linux for Tegra 24.1)
- *TensorFlow installed from (source or binary)?*:
Compiled from source and installed via this wheel available here: https://github.com/rwightman/tensorflow/releases/tag/v1.0.0-alpha-tegra-ugly_hack
- *TensorFlow version* (use command below):
1.0 Alpha
- *CUDA/cuDNN version*:
8.0/5.1
- *GPU Model and Memory*:
Tegra X1, 4GB

### Describe the problem clearly
When I ran a quantized graph on my laptop, it works quite as expected (just slightly lower accuracy compared to the frozen graph, while much lower size). However, when I transferred the exact same quantized graph to run on an Jetson TX1, the file gives me a highly inaccurate class prediction, at a 100% probability for the random class. On the other hand, when I tried to perform inference from the frozen graph (from which the quantized graph was derived) on both my laptop and the Jetson TX1, I got the exact same answers as expected.

So I suspected it could have been an issue of data transfer causing the file to be slightly corrupted. I checked the files byte by byte at all points of transfer (from my laptop to memory stick, then memory stick to the Jetson), but I found the files are exactly the same. This is the command I used to check: `cmp $old_file $new_file || echo ""different files""`.

Thus, I am suspecting it could be an issue of how tensorflow performs on the Jetson TX1 ARM architecture (aarch64). Is there anyway to verify this, and if it is indeed a performance issue on an ARM architecture, is there a way to resolve this?

Thank you for your help.
",0,,19,2017-04-19T05:00:25Z,CONTRIBUTOR
9292,xorshift128+ version of (stateless) random ops,"stat:contributions welcome,type:feature","Currently, TensorFlow's random numbers use the Philox counter mode generator, which is extremely easy to parallelize on both CPU and GPU.  This applies to both the normal stateful ops and the new [`tf.contrib.stateless`](https://github.com/tensorflow/tensorflow/commit/cc45456e4ad0eff16127d1727d0cf48afb71ca0e) versions with custom seeding.

xorshift128+ is a simpler generator that could conceivably speed up random number generation.  Unfortunately, it is not a counter mode generator, and is thus difficult to parallelize or use safely in a random access setting.

Until now!  Commit https://github.com/girving/tensorflow/commit/60abb26f528f53e7692edb3e89489a69b59ae83e on branch https://github.com/girving/tensorflow/tree/xorshift implements random access into the xorshift128+ generator in a reasonably efficient manner, using some finite field machinery.  Specifically, jumps in xorshift128+ are represented as elements of the finite field GF(2^128), composed to produce other jumps, then mapped through linear maps to produce xorshift128+ values.

However, the code is a proof of concept.  A decent amount of further work would have to be done to get committed to TensorFlow.  In particular, the parallelism code on both CPU and GPU would have to be written, by computing one jump per thread of execution (many jumps can be computed more cheaply vs. one at a time).  The current code is also nonportable: it assumes special  instructions for carryless multiplication of polynomials over GF(2).  These instructions are available on recent Intel and AMD CPUs, but a slow path would need to be written to handle everything else.

Also, whether the result would actually be faster is an open question.

I don't have time to do the remaining work, so I am leaving this here as a project in case someone wants to take it on with my help.",0,,0,2017-04-18T18:25:35Z,CONTRIBUTOR
9284,Broadcasting support in `tf.where`,"stat:community support,type:feature","`tf.where` does not support broadcasting like its numpy equivalent at the moment. How easy would it be to add broadcasting? 

Here are some examples.

```python
condition = np.random.normal(0, 1, (3, 5, 1, 1)) < 0
x = np.zeros((7, 11))
y = np.ones((7, 11))

np.where(condition, x, y).shape  # (3, 5, 7, 11)
tf.where(condition, x, y)

>>> InvalidArgumentError: Shapes must be equal rank, but are 2 and 4 for 'Select_2' 
>>> (op: 'Select')  with input shapes: [3,5,1,1], [7,11], [7,11].
```

```python
condition = np.random.normal(0, 1, (3, 5, 1, 1)) < 0
x = np.zeros((1, 1, 7, 11))
y = np.ones((1, 1, 7, 11))

np.where(condition, x, y).shape  # (3, 5, 7, 11)
tf.where(condition, x, y)

>>> InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 1 and 3 
>>> for 'Select_3' (op: 'Select') with input shapes: [3,5,1,1], [1,1,7,11], [1,1,7,11].
```
",0,,11,2017-04-18T10:39:25Z,CONTRIBUTOR
9258,Create support for a score threshold in NonMaxSuppression to skip over boxes with low score,"stat:contributions welcome,type:feature",Right now tensorflow::ops::NonMaxSuppression only prunes away boxes that have a high IOU overlap with previously selected boxes. It would be nice to also support a threshold on score so that the algorithm can skip over boxes that have a score below that threshold. We strongly believe this feature will speed up nms. Is there a plan to add this score threshold as a parameter?,0,,2,2017-04-17T05:37:41Z,NONE
9234,Segfaults/NaN's in SVD,type:bug/performance,"I'm getting failures trying to run SVD on a particular matrix. The result is either all NaN's for u matrix, or it's segfaults like below.

To reproduce, run this script in Python3: [https://github.com/yaroslavvb/stuff/blob/master/svd_test.py](https://github.com/yaroslavvb/stuff/blob/master/svd_test.py)

I can't see anything special about this matrix beside the fact that it's badly conditioned. IE, I can perform SVD on this matrix in Mathematica [fine](https://www.wolframcloud.com/objects/f16d71a7-cc47-4a3d-b686-da440670eed3)
 @rmlarsen 

```
 #0  0x00007fffe320e121 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::perturbCol0(Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<long, 1, -1, 1, 1, -1>, 0, Eigen::InnerStride<1> > const&, Eigen::Matrix<float, -1, 1, 0, -1, 1> const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #1  0x00007fffe320fa81 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::computeSVDofM(long, long, Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Matrix<float, -1, 1, 0, -1, 1>&, Eigen::Matrix<float, -1, -1, 0, -1, -1>&) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #2  0x00007fffe321e21c in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::divide(long, long, long, long, long) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #3  0x00007fffe321dbb8 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::divide(long, long, long, long, long) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #4  0x00007fffe32220bd in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::compute(Eigen::Matrix<float, -1, -1, 1, -1, -1> const&, unsigned int) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #5  0x00007fffe32227a1 in tensorflow::SvdOp<float>::ComputeMatrix(tensorflow::OpKernelContext*, tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<float, -1, -1, 1, -1, -1> const, 0, Eigen::Stride<0, 0> >, 4> const&, tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<float, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>*) ()                                                                 from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so                                       #6  0x00007fffe3228c75 in tensorflow::LinearAlgebraOp<float>::ComputeTensorSlice(tensorflow::OpKernelContext*, long long, tensorflow::gtl::InlinedVector<tensorflow::Tensor const*, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorShape, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::Tensor*, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorShape, 4> const&) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so



```",1,,14,2017-04-15T07:27:46Z,CONTRIBUTOR
9210,Feature: Sparse matrix multiplications for Tensors with rank > 2,"stat:contributions welcome,type:feature","## System Information:
Windows 10, x64, Tensorflow 1.1.0.rc1

## Description:
The 3-D sparse tensor (placeholder) multiply with 3-D dense tensor has bug, the operation will failed.

```python
x = tf.sparse_placeholder(tf.float32, shape=[None, 2, 2])
y = tf.constant(np.ones([3, 2, 1]), dtype=tf.float32)
z = tf.matmul(x, y, a_is_sparse=True)

indices = [[1, 1, 1], [2, 0, 0], [3, 0, 1]]
values = [1.0, 2.0, 3.0]
dense_shape = [3, 2, 2]
x_val = tf.SparseTensorValue(indices, values, dense_shape)

with tf.Session() as sess:
  res = sess.run(z, feed_dict={x: x_val})
  print(res)
```
expected result(3x2x1):
```
[[[ 0.][ 1.]]
 [[ 1.][ 0.]]
 [[ 1.][ 0.]]]
```
but output some errors actually :

```python
Traceback (most recent call last):
  File ""D:/Learning/master_project/clinicalText/SourceCode/Python/DNN_CWS/seg_dnn.py"", line 369, in <module>
    cws = SegDNN(constant.VOCAB_SIZE, embed_size, constant.DNN_SKIP_WINDOW)
  File ""D:/Learning/master_project/clinicalText/SourceCode/Python/DNN_CWS/seg_dnn.py"", line 76, in __init__
    self.loss = tf.reduce_sum(tf.matmul(self.slim_map_matrix,tf.expand_dims(tf.transpose(self.word_score),2),a_is_sparse=True))
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1755, in matmul
    a = ops.convert_to_tensor(a, name=""a"")
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\ops.py"", line 639, in convert_to_tensor
    as_ref=False)
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\ops.py"", line 704, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 113, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 444, in make_tensor_proto
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 444, in <listcomp>
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\util\compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000195FA86B1D0>

```

change the `z` to 
```python
z = tf.sparse_tensor_dense_matmul(x,y)
```
also failed because the shape of sparse must 2-D,but `x`and`b`has 3-D",0,,3,2017-04-14T05:08:38Z,NONE
9202,Add support for matrix square root,"stat:contributions welcome,type:feature","Please consider adding a [matrix square root](https://en.wikipedia.org/wiki/Square_root_of_a_matrix) operation, with gradients.
It will make it possible to implement [stable whitening](https://arxiv.org/abs/1512.00809), which could be broadly useful, in addition to being useful for my particular problem :)
Note, Cholesky whitening is currently supported in TensorFlow, but I'm not aware of any guarantees it provides regarding the correspondences between whitened and non-whitened data.

It appears Eigen [already has a matrix square root function](https://eigen.tuxfamily.org/dox/unsupported/group__MatrixFunctions__Module.html#matrixbase_sqrt), so this might not be too hard to implement.",0,,12,2017-04-13T22:17:05Z,NONE
9201,Tensorflow Still Trying to use CUDA even when Session Created with device_count={'GPU': 0},"stat:contributions welcome,type:feature","### System Information
Using the `tensorflow/tensorflow:1.0.1-devel-gpu` Docker image.
`('v1.0.0-65-g4763edf-dirty', '1.0.1')`
Host: `Driver Version: 367.57`, `3.13.0-57-generic`

### Issue
If I `Set compute mode to EXCLUSIVE_PROCESS` on the Nvidia device (`sudo nvidia-smi -c 1`), then even though I tell the `Session` not to use GPUs (`config=tf.ConfigProto(device_count={'GPU': 0})`), Tensorflow attempts to use the GPU resulting in an inability to create session:
```
InternalErrorTraceback (most recent call last)
<ipython-input-1-cabf26c1451a> in <module>()
      1 import tensorflow as tf
      2 from tensorflow.python.framework import ops
----> 3 with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:
      4     pass

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)
   1174 
   1175     """"""
-> 1176     super(Session, self).__init__(target, graph, config=config)
   1177     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.
   1178     self._default_graph_context_manager = None

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)
    550     try:
    551       with errors.raise_exception_on_not_ok_status() as status:
--> 552         self._session = tf_session.TF_NewDeprecatedSession(opts, status)
    553     finally:
    554       tf_session.TF_DeleteSessionOptions(opts)

/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)
     22         if type is None:
     23             try:
---> 24                 self.gen.next()
     25             except StopIteration:
     26                 return

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc in raise_exception_on_not_ok_status()
    464           None, None,
    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 466           pywrap_tensorflow.TF_GetCode(status))
    467   finally:
    468     pywrap_tensorflow.TF_DeleteStatus(status)

InternalError: Failed to create session.
```
This can be demonstrated by running:
```
import tensorflow as tf
from tensorflow.python.framework import ops
with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:
    pass
```
when another process is using CUDA and the exclusive process mode is set.

If exclusive process mode is _not_ set, then the session is created but using `nvidia-smi`, I see that the process is using GPU ram (and CUDA):
```
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      2237    C   /usr/bin/python                                 61MiB |
```

The issue seems limited to TF trying to lock the CUDA device (an allocate ~61MB memory). Subsequent computations do happen correctly on the CPU.",0,,9,2017-04-13T21:04:36Z,CONTRIBUTOR
9180,Make `py_func` accept `SparseTensor`,"stat:contributions welcome,type:feature","### Describe the problem clearly
According to the [doc](https://www.tensorflow.org/api_docs/python/tf/py_func), `py_func` accepts `inp` as a list of tensors (or convertible to tensor). However `SparseTensor` is not one of them. Could we support `SparseTensor` as well? Semantically there is no reason to treat `SparseTensor` differently.

### Source Code / Logs
```
my_sparse_tensor = tf.SparseTensor(...)
tf.py_func(my_py_func, [my_sparse_tensor, ...], [tf.float32])
```
What I got:

`TypeError: Tensors in list passed to 'input' of 'PyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, ...] that are invalid`.
",0,,7,2017-04-13T07:54:14Z,NONE
9171,tf.set_random_seed does not reset random op state,,"TF Version: 1.1.0rc1 (installed from nightly: `Apr 10, 2017 1:03 AM`)
(run on CPU, Python 2)

```
import tensorflow as tf
import numpy as np

sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())

tf.set_random_seed(1)
a = tf.truncated_normal_initializer(seed=None)([1])
print(a.eval())

tf.set_random_seed(1)
b = tf.truncated_normal_initializer(seed=None)([1])
print(b.eval())
```

Output:
```
[ 1.05293429]
[-0.4487586]
```

Expected:
The same value, since...
> If the graph-level seed is set, but the operation seed is not: The system deterministically picks an operation seed in conjunction with the graph-level seed so that it gets a unique random sequence.

The values are identical in repeated runs of the whole script, but not after resetting the graph-level seed (as in the example above).

(possibly related to https://github.com/tensorflow/tensorflow/issues/9003)",1,,21,2017-04-12T17:10:14Z,CONTRIBUTOR
9150,C API Tensors,"stat:contributions welcome,type:feature","I am currently using the C API and building a Scala API on top of it. It seems that what is done in the Python API and the Java API is that the tensors fed into sessions are being copied to buffers internal to the native library. I am also currently doing that in the Scala library but I was wondering if we can do the following:

Let's assume we can share a pointer to the underlying data structure between C and Scala (through a Java NIO DirectMemoryBuffer for example). Then, is there any functionality to obtain a tensor ""view"" that is a slice of that tensor, directly using that buffer? I imagine that since the TF op kernels are implemented in C++, it should be possible to use the StridedSlice op directly on a tensor data structure (without needing to use a session). The same idea can be extended to other ops. So, first of all, is that true?

Secondly, if it is, where is that functionality available in the C API (or exposed elsewhere) so that I can use it from within my Scala library? I currently do the indexing on the byte buffer myself, but that can be painful for arbitrary slices.

One main issue with sharing a pointer is how to deal with the Java garbage collector. I haven't figured that out yet, but even if I can't do that, the above comment still applies. How can I use op kernels directly in order to manipulate tensors outside of the symbolic graph? That is useful for languages other than Python, where a library as powerful as numpy is not available.

Thank you!",0,,60,2017-04-11T23:49:14Z,CONTRIBUTOR
9149,Optimization flags are erroneously ignored in compilation of Tensorflow 1.1.0-rc1,"stat:contributions welcome,type:build/install","I am getting a large number of optimization flag related warnings in compilation of Tensorflow 1.1.0-rc1 from source

```
/usr/include/features.h:330:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]
 #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)
    ^
```
System Information:  
OS:CentOS 7
GCC: gcc 4.8.5
Python: python3.5
Tensorflow version:  TensorFlow 1.1.0-rc1
Bazel:  version 0.4.5
CUDA: CUDA 8.0 with GTX 1080 GPU

in the prompt of ./configure:

```
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3.5
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] Y
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
```
explicitly typing `-march=native -O2` or `-O2` in the line `Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: `""doesn't help. 

to compile I used:

`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`

I tried as early as tensorflow version 1.0.0 and I always get the ""`warning _FORTIFY_SOURCE requires compiling with optimization (-O)`"". Tensorflow version 0.12.1 doesn't seem to have this problem for me. 

Related issue:
#2153 
",0,,17,2017-04-11T23:42:59Z,NONE
9142,Make bounding box operators consistent,"stat:contributions welcome,type:bug/performance","Right now, the bounding box operators (tf.image.draw_bounding_boxes, tf.image.non_max_suppression and tf.image.sample_distorted_bounding_box) expect bounding boxes in the form of [ymin, xmin, ymax, xmax], with the origin (0,0) being the lower left corner of the image. But images themselves are tensors, and the pixel with index [0,0] in the tensor is in the top left, so bounding box coordinates are the opposite in the y direction to tensor indices.

Additionally, the operations tf.image.pad_to_bounding_box and tf.image.crop_to_bounding_box take coordinates in the form of [ymin, xmin, height, width], with the origin being the top-left corner, so the coordinates are inconsistent even within the image ops themselves (plus the parametrization of the bounding boxes is different, too).

And the tf.image.crop_and_resize op doesn't specify what origin it uses (though I think it's bottom left too)

I feel like this sort of inconsistency is unnecessarily confusing and a high risk for introducing errors.

It's especially bad since, if you supply bounding boxes the wrong way around to draw_bounding_boxes, it'll still draw them correctly (

All bounding box operators should use the same coordinate system and preferably the same parametrization, and preferably the coordinates should be consistent with image tensor indexing.",0,,5,2017-04-11T19:21:40Z,NONE
9125,KeyError in tf.contrib.graph_editor.graph_replace,"stat:contributions welcome,type:bug/performance","When applying `graph_replace` to graphs containing ops with the `_original_op` attribute, it can fail with a `KeyError`. The error occurs in `Transformer._copy_ops` when trying to copy an op whose `_original_op` has not yet been copied. The ordering of ops that are copied is not deterministic so this error pops up somewhat randomly.

The `_original_op` attributes appear to be created by `tf.gradients` to point back to the op from the forward pass.

Example code snippet (note: you may need to run this multiple times to get a failure):
```python
import tensorflow as tf
graph_replace = tf.contrib.graph_editor.graph_replace
w = tf.Variable(0.0, name=""w"")
y = tf.multiply(tf.multiply(w, w, name=""mul1""), w, name=""mul2"")
g = tf.gradients(y, w)[0]
g_new = graph_replace(g, {w.value(): g})
```

Error:
```
/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/graph_editor/transform.py in transform_op_if_inside_handler(info, op, keep_if_possible)
    122   """"""
    123   if op in info.sgv.ops:
--> 124     return info.transformed_ops[op]
    125   else:
    126     if keep_if_possible and info.graph is info.graph_:

KeyError: <tf.Operation 'mul1' type=Mul>
```

I see three possible fixes:
1. Remove `_original_op` attributes in the copied graph (I don't see anywhere in the TF codebase where it is used)
2. Move the creation of the `_original_op` attribute from the `copy_op_handler` function to the end of `Transformer._copy_ops` after all ops have been copied.
3. Topologically sort the ops being copied so that ops that are `_original_op` attributes are created before their children.

My [implementation](https://github.com/poolio/tensorflow/pull/1/files) of option 2 seems to fix this problem, but I might be missing something about the usage of `_original_op`.",0,,7,2017-04-11T07:12:56Z,NONE
9099,Nearest neighbor interpolation method for tf.image.crop_and_resize ?,"stat:contributions welcome,type:feature","At the moment, only bilinear interpolation is supported by crop_and_resize. 
However, when working with little images (and with labeled images), it sometimes makes more sense to use a nearest neighbor interpolation.
Any plans of adding a nearest neighbor interpolation for the method in the near future ? 
",0,,5,2017-04-10T08:45:57Z,NONE
9080,Support for nvidia-cuda-mps-server ,"stat:contributions welcome,type:feature","I'm experimenting with multiple Tensorflow GPU processes and the NVIDIA Multi-Process Server. 
https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf

I have the following MNIST example as a benchmark (neural.py)

```
import tensorflow as tf
import os

from tensorflow.examples.tutorials.mnist import input_data
data = input_data.read_data_sets('MNIST_data_%d' % os.getpid(), one_hot=True)

# construction phase
x = tf.placeholder(tf.float32, shape=[None, 784])
y = tf.placeholder(tf.float32, shape=[None, 10])

with tf.name_scope('fc_1'):
  W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))
  b1 = tf.Variable(tf.truncated_normal([200], stddev=0.1))
  h = tf.sigmoid(tf.matmul(x, W1) + b1)

with tf.name_scope('fc_2'):
  W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))
  b2 = tf.Variable(tf.truncated_normal([10], stddev=0.1))
  y_predict = tf.nn.softmax(tf.matmul(h, W2) + b2)

with tf.name_scope('eval'):
  with tf.name_scope('loss'):
    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_predict), reduction_indices=[1]))

learning_rate = 0.5

backprop = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)

correct = tf.equal(tf.argmax(y, 1), tf.argmax(y_predict, 1))
accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))

#execution

sess = tf.Session()

sess.run(tf.initialize_all_variables())

train_steps = 2000
batch_size = 50

for i in range(train_steps):
  batch_x, batch_y = data.train.next_batch(batch_size)
  sess.run(backprop, feed_dict={x: batch_x, y: batch_y})

print(sess.run(accuracy, feed_dict={x: data.test.images, y: data.test.labels}))
```

And I'm running two processes like this:
`$ time python neural.py &
     time python neural.py
`

Without `nvidia-cuda-mps-control` running as a daemon, this is the output:
```
0.9483
0.947

real    0m15.602s
user    0m6.172s
sys     0m5.092s

real    0m15.861s
user    0m6.288s
sys     0m1.964s
```

With `nvidia-cuda-mps-control` running as a daemon, I'm getting an internal error:

```
F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)
F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)
-bash: line 76: 47018 Aborted                 (core dumped) python neural.py
```

I can verify from the nvidia-mps logs in /var/log/nvidia-mps that the tensorflow Cuda context successfully started an nvidia-cuda-mps-server and connected to it.

**/var/log/nvidia-mps/control.log**
> [2017-04-09 10:05:09.539 Control 46322] Start
> [2017-04-09 10:05:21.023 Control 46322] Accepting connection...
> [2017-04-09 10:05:21.024 Control 46322] NEW CLIENT 46325 from user 1000: Server is not ready, push client to pending list
> [2017-04-09 10:05:21.024 Control 46322] Starting new server 46348 for user 1000

The MPS server should be compatible with the Cuda API which Tensorflow uses, so I'm uncertain about why I'm getting this error.

**Tensorflow version: 1.01**
**Ubuntu 16.04**
**Cuda 8.0, CuDNN**

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 8915:00:00.0     Off |                  Off |
| N/A   51C    P8    28W / 149W |     82MiB / 12205MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```",0,,14,2017-04-09T10:32:48Z,CONTRIBUTOR
9049,Android example using CMake on Windows not working,type:build/install,"I installed CPU-only Tensorflow version 1.0 on Windows using the pip installer. I am trying to get the Android example to run using CMake as explained in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android/cmake. I cloned the newest version of the tensorflow repository and created a new Android studio project and followed the instructions from the webpage above by modifying the gradle files.  I already found out that it should be 
`debugCompile project(path: ':TensorFlow-Android-Inference', configuration: 'debug')
releaseCompile project(path: ':TensorFlow-Android-Inference', configuration: 'release')`
instead of 
`debugCompile project(path: ':tensorflow_inference', configuration: 'debug')
releaseCompile project(path: ':tensorflow_inference', configuration: 'release')`
Now, however, I get a build error stating ""Error:Project :app declares a dependency from configuration 'releaseCompile' to configuration 'release' which is not declared in the descriptor for project :TensorFlow-Android-Inference.""
Has anyone tried this or could anyone point me to a proper explanation of how to use cMake to build the project. 
Any help would be very much appreciated. Thanks. 
",1,,8,2017-04-07T17:08:55Z,NONE
9001,Feature Request : Stochastic Depth,"stat:contributions welcome,type:feature","Stochastic Depth (aka layer dropout) has been shown to speed up and improve training in ResNets, as well as overall accuracy on testing sets. Essentially, every training step a random subset of residual layers are entirely removed from the network, and training proceeds on the remaining layers. Direct connections are made between the missing layers.  

It is described in this paper: https://arxiv.org/pdf/1603.09382.pdf. (Deep Networks with Stochastic Depth by Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Q. Weinberger)

I can't think of a way to implement this with the python API without reconstructing the model every training iteration, and I'm not familiar the with the C++ API / Cudnn to try to write the op myself.

Of course I'm willing to try any python-only suggestions.

Thanks in advance,

Alex ",0,,11,2017-04-05T22:39:40Z,NONE
8926,Image Distortions should be able to be applied to batches. [Feature Request?],"stat:contributions welcome,type:feature","The tf.image distortion functions only accept a single image as an input whereas it would be much more useful to be able to place the distortion within your graph flow so any batches of images that pass through it get distorted too. I believe a current solution is as suggeested by @mrry [here on Stack Overflow](http://stackoverflow.com/questions/38920240/tensorflow-image-operations-for-batches) however it feels like, much like the other ops for images work, being able to take batches would be much more useful.

Is the solution proposed by @mrry the accepted method or should the distortion functions be taking batches?",0,,25,2017-04-03T14:50:47Z,CONTRIBUTOR
8911,Feature Request : PathNorm and PathSGD,"stat:community support,type:feature","PathSGD was introduced in [this](https://arxiv.org/abs/1506.02617) paper. Is there existing support for this? If not, this is a feature request for:
- PathNorm computation (Equation 5 in the paper)
- PathSGD using the PathNorm

For the first part, the interface can be to provide a function `path_norm(a, b, p=2)` where `a` and `b` are tensors, `p` is a scalar. The function returns the p-PathNorm for the ""path"" between the tensors `a` and `b` (assuming that `b` depends on `a` and some weights. If not, there can be an exception or simply return `0`).",0,,33,2017-04-02T22:02:54Z,NONE
8884,8-bit quantized atrous conv2d op not supported,"stat:contributions welcome,type:feature","It looks like that 8-bit quantized atrous conv2d op is not supported. As per the latest API,  there are only 4 quantized ops supported namely quantized_conv2d, quantized_relu_x, quantized_max_pool and quantized_avg_pool.  Any target date by which 8-bit atrous conv2d op will be available?


",0,,1,2017-03-31T22:37:22Z,NONE
8873,Arbitrary dimension support for tf.tile and binary operators,"stat:contributions welcome,type:feature","`tf.transpose` uses template specialization for dimensions <= 5, then falls back to a slightly slower generic implementation which works for any dimension:

https://github.com/tensorflow/tensorflow/blob/504b91de8fa9a9cc4a4e17e59ed753ab677a1410/tensorflow/core/kernels/transpose_functor_cpu.cc#L23

It would be nice to use the same mechanism for `tf.tile` and the various binary operators.",0,,8,2017-03-31T16:34:22Z,CONTRIBUTOR
8841,Gradient of reduce_prod not available on GPU,"stat:contributions welcome,type:feature","The following example fails to colocate the values:
```python
with tf.device('/gpu:2'):
    x = tf.placeholder(tf.float32, shape=[None, 100])
    weight_dense_1 = tf.Variable(tf.zeros([100, 10]))
    dense_1_out = tf.matmul(x, weight_dense_1)
    y = tf.reduce_prod(tf.cast(tf.shape(dense_1_out), tf.float32))
    grad = tf.gradients(y, [weight_dense_1], colocate_gradients_with_ops=True)
```
A bunch of warnings like this is displayed:
```
WARNING:tensorflow:Tried to colocate gradients_1/Prod_1_grad/Rank with an op Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:2. Ignoring colocation property.
```
The symptom is similar to #3397. Using CPU or specifying all input dimensions solves the problem. But the cause seems different.

Gradient of `Prod` operation is defined in [python/ops/math_grad.py](https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/python/ops/math_grad.py#L102-L143). There, the operation is forced to run on CPU (see 182fef1b55640906637e4bf0d205e508c24549e7), mentioning the `listdiff()` operation is CPU-only.
I tried remove the forcing line and run this. It yields a kind explanation:
```
InvalidArgumentError: Cannot assign a device to node 'gradients/Prod_grad/range_1': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices: 
InvertPermutation: GPU CPU 
Transpose: GPU CPU 
ConcatV2: GPU CPU 
Pack: GPU CPU 
Cumprod: GPU CPU 
ListDiff: CPU 
Shape: GPU CPU 
    ...(many GPU CPU ops)
Reshape: GPU CPU 
Gather: CPU 
```

Two operations used here, namely [Gather](https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/core/kernels/gather_op.cc) and [ListDiff](https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/core/kernels/listdiff_op.cc), are defined on CPU-only. As some of the operations needed in calculating the gradient are CPU-only, by the colocation rule, they get grouped into CPU-only.

This also occurs when using `moments()` or [`sufficient_statistics()`](https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/python/ops/nn_impl.py#L495-L541) (the former calls the latter). There, when some of the axes of the tensor are unknown (like batch size), the total number of values (which is needed for the mean and variance) is calculated by `reduce_prod()` on `shape()`.
When the value of mean or variance is differentiated in some way (which is the case in batch normalization), a colocation between tensors named like `gradients/moments/sufficient_statistics/count_grad/Rank` and `moments/sufficient_statistics/count` fails.

Though `listdiff()` is renamed later on Python interface to `setdiff1d()`, it's still named `ListDiff` internally.
`gather()` operation is defined on GPU too, but only on float types.

It seems there hasn't been any issue on this. Would it mean that `Prod()` op is not differentiated in most of the cases?
How this can be solved? I'm not sure if the `setdiff1d()` operation is needed.
For me, this occured when using `moments()`, where the reciprocal of number of values is multiplicated to the sum of values. I think this is unnecessary, as it can be done with `reduce_mean()`. Is it right?

### Environment info
Operating System: **Ubuntu 16.04**.
Installed version of CUDA and cuDNN: **CUDA 8.0.61** / **cuDNN 5.1.10**.
pip3-installed `tensorflow-gpu==1.0.1`; all links here pointed to `r1.0`, but the problematic parts are the same as `master`.
`python -c ""import tensorflow; print(tensorflow.__version__)""` yields: `1.0.1`.",0,,1,2017-03-30T15:06:38Z,CONTRIBUTOR
8820,Feature Request: Accelerate TensorFlow core on FPGA - How?,stat:contributions welcome,"Consider the two following hardware scenarios:
1) Linux running on x86 w/ FPGA fabric connected via PCIe
2) Linux running on Arm A53 with AXI i/f to FPGA fabric (Think Xilinx Zynq)

How could the tensorflow core be accelerated for these scenarios? 
FPGA vendors do offer OpenCL binaries for running OpenCL APIs to parallelize computations.

Forgive me, I am a bit ignorant, still learning in this area, but I am intrigued by the future possibility of this, and would love to help in anyway I can.",0,,11,2017-03-29T22:49:54Z,NONE
8804,why use unknown batch_size in BasicDecoder class?,type:bug/performance,"I found that in the source code:[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py](basic_decoder.py)
```python
  @property
  def batch_size(self):
    return self._helper.batch_size

  def _rnn_output_size(self):
    size = self._cell.output_size
    if self._output_layer is None:
      return size
    else:
      # To use layer's compute_output_shape, we need to convert the
      # RNNCell's output_size entries into shapes with an unknown
      # batch size.  We then pass this through the layer's
      # compute_output_shape and read off all but the first (batch)
      # dimensions to get the output size of the rnn with the layer
      # applied to the top.
      output_shape_with_unknown_batch = nest.map_structure(
          lambda s: tensor_shape.TensorShape([None]).concatenate(s),
          size)
      layer_output_shape = self._output_layer._compute_output_shape(  # pylint: disable=protected-access
          output_shape_with_unknown_batch)
return nest.map_structure(lambda s: s[1:], layer_output_shape)
```

As above, since we can get the batch size by calling self._helper.batch_size, why it is set to be None in
`lambda s: tensor_shape.TensorShape([None]).concatenate(s)`?  Why the batch size is still unknown? Couldn't we set to be `lambda s: tensor_shape.TensorShape([self._helper.batch_size]).concatenate(s)`?",1,,12,2017-03-29T14:23:56Z,NONE
8773,Can I use tensorflow on Windows10 with c++ and gpu support,,"I wish to use tensorflow on windows10 with c++ and gpu support. Is there any pre build SDK for windows? Or I need to compile from sources?

when I tried to compile on windows with cmake and MSVC, smaple trainer cannot build correctly because of some header files missing, such as ""graph.pb.h"". Is there any solutions?

ENV:
windows10 vs2015 cmake3.6.2",1,,8,2017-03-28T10:37:49Z,NONE
8770,tf.contrib.seq2seq.sequence_loss with tf.nn.sampled_softmax_loss,"stat:contributions welcome,type:support","There maybe an incompatible matmul when use `tf.contrib.seq2seq.sequence_loss` together with `tf.nn.sampled_softmax_loss`. `sampled_softmax_loss` need a rank 2 tensor as its label, however in `sequence_loss`, the label has been reshape to [-1], which will raise an error:
ValueError: Shape must be rank 2 but is rank 1 for 'sequence_loss/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [50], [?,20].

```
    batch_size = 5
    max_step = 10
    dim = 20
    vocab_size = 100

    logits = tf.constant(np.random.randn(batch_size, max_step, dim),
                         tf.float32)
    targets = tf.constant(np.random.randint(vocab_size, size=(batch_size, max_step)),
                         tf.int32)
    target_weights = tf.constant(np.ones((batch_size, max_step)), tf.float32)
    proj_w = tf.constant(np.random.randn(vocab_size, dim), tf.float32)
    proj_b = tf.constant(np.zeros(vocab_size), tf.float32)

    def _sampled_loss(labels, logits):
        labels = tf.cast(labels, tf.int64)
        logits = tf.cast(logits, tf.float32)
        return tf.cast(
                        tf.nn.sampled_softmax_loss(
                            proj_w,
                            proj_b,
                            labels,
                            logits,
                            num_sampled=20,
                            num_classes=vocab_size),
                        tf.float32)

    softmax_loss_f = _sampled_loss

    loss = tf.contrib.seq2seq.sequence_loss(
                    logits,
                    targets,
                    target_weights,
                    softmax_loss_function=softmax_loss_f)

    sess = tf.Session()
    print sess.run(loss)
```
This error can be fixed if the I change line 81 in contrib/seq2seq/python/ops/loss.py:
`crossent = softmax_loss_function(labels=array_ops.reshape(targets, [-1, 1]), logits=logits_flat)`

tensorflow version: 1.01",0,,2,2017-03-28T04:24:41Z,NONE
8745,TFRecordWriter doesn't throw an error when disk partition gets out of space,"stat:awaiting tensorflower,type:bug/performance,type:support","## Problem
When tensorflow.python_io.TFRecordWriter(path) is initialized with a path leading to a device out of free storage space, one can still write() and close() it without receiving an error or exception. The resulting file is empty (0B).

## Environment info
TF v.1.0.1 installed from pip3 (package tensorflow-gpu) with Python 3.4.2 on a Linux server.

## Minimal example
    writer = tf.python_io.TFRecordWriter(output_file)
    for i in files_in_shard:
      # ....
      # [prepare record]
      writer.write(example.SerializeToString())
    writer.close()
Working example e.g. https://github.com/tensorflow/models/blob/master/inception/inception/data/build_image_data.py",0,,5,2017-03-27T07:50:04Z,NONE
8744,DC-ASGD(Delay Compensated Asynchronous Stochastic Gradient Descent)?,"stat:contributions welcome,type:feature","DC-ASGD is Microsoft's very useful algorithm for distributed asynchronous training. Compared with the ordinary ASGD algorithm, DC-ASGD has no significant loss in speed, but can get almost the same effect as Sequential SGD. As far as I know, other mainstream deep learning open source tools have implemented this algorithm, such as: CNTK, Mxnet, Paddle and so on. But in Tensorflow I have not found similar modules.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
[https://github.com/Microsoft/CNTK/issues/1295](https://github.com/Microsoft/CNTK/issues/1295)
[https://github.com/PaddlePaddle/Paddle/issues/185](https://github.com/PaddlePaddle/Paddle/issues/185)
[https://github.com/dmlc/mxnet/pull/3614](https://github.com/dmlc/mxnet/pull/3614)

### What other attempted solutions have you tried?
I tried to implement this algorithm in Tensorflow by myself.  I do not have enough ability to do this now.

### The link address of the paper
[Asynchronous Stochastic Gradient Descent with Delay Compensation for Distributed Deep Learning](https://arxiv.org/abs/1609.08326)",0,,7,2017-03-27T07:41:09Z,NONE
8665,freeze_graph not initializing tables,type:bug/performance,"I am not sure if this is an actual bug or if its expected but undocumented behavior.

I have a model that uses multiple lookup tables created via string_to_index. I freeze the model like so:
`bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/tmp/tf/graph.pbtxt 
--input_checkpoint=/tmp/tf/model.ckpt-0 --output_graph=/tmp/ticker_classifier.pb 
--output_node_names=sigmoid --initializer_nodes=init_all_tables`

However when the model is reloaded and I attempt to run it I get an error ""Table not initialized."" I get exactly the same resulting file whether I specify initializer_nodes or not. The behavior I was expecting was for the model to contain the lookup tables in a ready to use state for inference but I don't know if that is an unreasonable expectation.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I have not seen any issues related to this. I previously posted about this here http://stackoverflow.com/questions/42916383/how-to-properly-freeze-a-tensorflow-graph-containing-a-lookuptable

### Environment info
Operating System: MacOS and Linux (CentOS 7)

Installed version of CUDA and cuDNN: None

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) 07bb8ea2379bd459832b23951fb20ec47f3fdbd4
2. Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I have been unable to make a small example but I can spend more time on it if needed.

### What other attempted solutions have you tried?

The workaround is to add init_all_tables to the output_nodes and then run init_all_tables before feeding the session examples for inference. This does have the side effect of needing to distribute the source files for the tables to the same path on all nodes that was originally used for training.
",1,,20,2017-03-23T17:01:13Z,NONE
8661,graph_editor.graph_replace produces WARNING,"stat:contributions welcome,type:bug/performance","Since version 1.0.0 the method `tensorflow.contrib.graph_editor.graph_replace` raises the following warning:

WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.

 

### Minimal reproducible example 
```python 
import tensorflow as tf
import tensorflow.contrib.graph_editor as ge
a = tf.constant(1)
b = tf.constant(2)
c = tf.constant(3)
d = a +  b
e = ge.graph_replace([d], {a: c})
```

### Output log
INFO:tensorflow:Copying op: add
WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
INFO:tensorflow:Finalizing op: add

",0,,2,2017-03-23T14:13:21Z,NONE
8660,Error when creating a summary inside a tf.while_loop in a multi-GPU setup (like CIFAR-10),type:support,"Why diagnosing a problem with batch normalized RNNs, I tried to add a summary of the population statistics in my batch normalized cell, but then when I try to run the merged summaries I get the following error:

tensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'Merge/MergeSummary' has inputs from different frames. The input 'tower_2/rnn/while/multi_rnn_cell/cell_4/gru_cell/gates/r/rnn/multi_rnn_cell/cell_4/gru_cell/gates/r/pop_var_0' is in frame 'tower_2/rnn/while/tower_2/rnn/while/'. The input 'tower_3/rnn/while/multi_rnn_cell/cell_4/gru_cell/gates/r/rnn/multi_rnn_cell/cell_4/gru_cell/gates/r/pop_var_0' is in frame 'tower_3/rnn/while/tower_3/rnn/while/'.

This is on TensorFlow 1.0. I'll try to get a reduced testcase.",0,,14,2017-03-23T13:49:01Z,NONE
8658,Saving best models instead of most recent models with tf.train.Saver.,"stat:contributions welcome,type:feature","Most of the time I want to save the best models instead of the most recent models. Doing so using tf.train.Saver requires to choose when to save a model and to delete the worst model (which might not be the oldest) ""manually"".

A method to save the N best models (according to some user defined value) would be nice.",0,,12,2017-03-23T13:31:53Z,NONE
8652,AttributeError: 'NoneType' object has no attribute 'TF_NewStatus,,"In the latest sources the issue: https://github.com/tensorflow/tensorflow/issues/3388 is fixed in the thensorflow/python/client/session.py, But I now receive the following error instead:
```
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7fb2e08cee48>>
Traceback (most recent call last):
  File ""$HOME/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 595, in __del__
AttributeError: 'NoneType' object has no attribute 'TF_NewStatus'

```
I compiled the model manually using the latest version sources and using Bazel 0.4.5. The same seems to be true as with the issue 3388: The error is not always popping up and the run seems to have ended normally. However, now and then to above error message is displayed. ",1,,18,2017-03-23T08:39:57Z,NONE
8584,TF for Xeon Phi,stat:contributions welcome,"Hi,

Does tensorflow support xeon phi? 

Thanks !
Afshin",0,,17,2017-03-21T14:00:15Z,NONE
8564,`tf.test.compute_gradient` gives error when computation involves TensorArrays,type:bug/performance,"### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

``` python
a = tf.TensorArray(tf.float32, size=1)
x = tf.ones(5)
a = a.write(0, x)
y = a.stack()

grads = tf.gradients(y, x)

with tf.Session() as sess:
    print(""y"")
    print(sess.run(y))

    print(""grad"")
    print(sess.run(grads))

    # gives error:
    tf.test.compute_gradient(x, (5,), y, (5,))
```

The gradient calculation (`sess.run(grads)`) works fine, it is just something to do with how the gradients are being calculated within `tf.test.compute_gradients`.  Here is the stack trace:
```
File ""...\tensorflow\python\ops\gradient_checker.py"", line 312, in compute_gradient
    dx, dy = _compute_dx_and_dy(x, y, y_shape)
  File ""...\tensorflow\python\ops\gradient_checker.py"", line 193, in _compute_dx_and_dy
    grads = gradients.gradients(y, x, dy)
  File ""...\tensorflow\python\ops\gradients_impl.py"", line 560, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""...\tensorflow\python\ops\gradients_impl.py"", line 368, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""...\tensorflow\python\ops\gradients_impl.py"", line 560, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""...\tensorflow\python\ops\tensor_array_grad.py"", line 158, in _TensorArrayGatherGrad
    grad_source = _GetGradSource(grad)
  File ""...\tensorflow\python\ops\tensor_array_grad.py"", line 74, in _GetGradSource
    "", got: %s"" % op_or_tensor.name)
ValueError: Expected op/tensor name to start with gradients (excluding scope), got: Identity:0
```",1,,11,2017-03-20T20:53:44Z,CONTRIBUTOR
8550,"Android ""TF Stylize"" demo crash with ""input_max_range must be larger than input_min_range""",,"I have compiled and installed the demo app according to the instruction in the [README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md).  The ""TF Detect"" and ""TF Classify"" apps are working as expected.  However, starting the ""TF Stylize"" app, it always crashes in about 3 seconds.  The prebuilt apk crashes in the same way.  Here is the android logcat recorded:

> $ adb -s b80360c7 logcat  | grep Tensor
I/TensorFlowInferenceInterface( 6801): Checking to see if TensorFlow native methods are already loaded
I/TensorFlowInferenceInterface( 6801): TensorFlow native methods not found, attempting to load via tensorflow_inference
I/TensorFlowInferenceInterface( 6801): Successfully loaded TensorFlow native methods (RunStats error may be ignored)
I/TensorFlowInferenceInterface( 6801): Model load took 540ms, TensorFlow version: 1.0.1
I/TensorFlowInferenceInterface( 6801): Successfully loaded model from 'file:///android_asset/stylize_quantized.pb'
E/TensorFlowInferenceInterface( 6801): Failed to run TensorFlow inference with inputs:[input, style_num], outputs:[transformer/expand/conv3/conv/Sigmoid]
E/TensorFlowInferenceInterface( 6801): Inference exception: java.lang.IllegalArgumentException: input_max_range must be larger than input_min_range.
E/TensorFlowInferenceInterface( 6801):   [[Node: transformer/contract/conv1/Relu_eightbit_quantize_transformer/contract/conv1/InstanceNorm/batchnorm/add_1 = QuantizeV2[T=DT_QUINT8, mode=""MIN_FIRST"", _device=""/job:localhost/replica:0/task:0/cpu:0""](transformer/contract/conv1/InstanceNorm/batchnorm/add_1, transformer/contract/conv1/Relu_eightbit_min_transformer/contract/conv1/InstanceNorm/batchnorm/add_1, transformer/contract/conv1/Relu_eightbit_max_transformer/contract/conv1/InstanceNorm/batchnorm/add_1)]]
E/AndroidRuntime( 6801):        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.getTensor(TensorFlowInferenceInterface.java:486)
E/AndroidRuntime( 6801):        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeIntoFloatBuffer(TensorFlowInferenceInterface.java:332)
E/AndroidRuntime( 6801):        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.readNodeFloat(TensorFlowInferenceInterface.java:287)

As can be inferred from the logcat, the problem happens in `tensorflow/core/kernels/quantize_op.cc` line 71.  The app is using a quantized model.  I found that `input_min_range` is set to be `inf`, and `input_max_range` is `-inf`, which is obviously wrong.

What should be done to fix it?

The crash appears on Samsung Galaxy S4, but does not appears on emulator with Intel CPU.

[Edit]
With more experiment I found that sometimes the apps works without crashing, about 1 out of 10 trials.",1,,35,2017-03-20T08:29:22Z,NONE
8535,Feature request: add support for float16/float64 to tf.contrib.layers.batch_norm(),"stat:contributions welcome,type:feature","NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

`tf.contrib.layers.batch_norm` does not support `float16` due to defaulting to `dtype=tf.float32` for `get_variable()`.

https://github.com/tensorflow/tensorflow/blob/067cba5e4b873829f6cdfa61256079d2cfc45d02/tensorflow/python/layers/normalization.py#L141

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

- Ubuntu 16.04 Docker container
- Ubuntu 16.10 Docker host
- Dockerfile base `nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04`
- CUDA 8.0.61
- CUDNN 5.1.10
- NVidia driver version 378.13

```sh
$ uname -a
Linux 97fca57d7bb6 4.8.0-41-generic #44-Ubuntu SMP Fri Mar 3 15:27:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root    556000 Jan 26 23:48 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root        19 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
-rw-r--r-- 1 root root    415432 Jan 26 23:48 /usr/local/cuda/lib64/libcudart.so.8.0.61
-rw-r--r-- 1 root root    775162 Jan 26 23:48 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 jake users       13 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 jake users       18 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10
-rwxr-xr-x 1 jake users 84163560 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn.so.5.1.10
-rw-r--r-- 1 jake users 70364814 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn_static.a

$ conda -V
conda 4.3.14
```

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

```sh
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
1.0.1
```

Conda `environment.yml`:

```yaml
name: root

channels:
- defaults
- conda-forge
- menpo

dependencies:
- ipyparallel==5.2.0
- opencv3=3.1.0
- pip:
  - keras==1.2.2
  - pydicom==0.9.9
  - tensorflow-gpu==1.0.1
  - tflearn==0.3
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```py
import tensorflow as tf
from tensorflow.contrib.layers import batch_norm
# from normalization import batch_norm
with tf.Session() as sess, tf.device('/cpu'):
  inputs = tf.convert_to_tensor([1., 2.], dtype=tf.float16)
  norm = batch_norm(inputs)
  sess.run(tf.global_variables_initializer())
  sess.run(norm)
```

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-10-f094f32eca33> in <module>()
      1 a = tf.convert_to_tensor([1., 2.], dtype=tf.float16)
----> 2 tf.contrib.layers.batch_norm(a).eval()

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    175       current_args = current_scope[key_func].copy()
    176       current_args.update(kwargs)
--> 177     return func(*args, **current_args)
    178   _add_op(func)
    179   setattr(func_with_args, '_key_op', _key_op(func))

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)
    516           _scope=sc,
    517           _reuse=reuse)
--> 518       outputs = layer.apply(inputs, training=is_training)
    519 
    520       # Add variables to collections.

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)
    301       Output tensor(s).
    302     """"""
--> 303     return self.__call__(inputs, **kwargs)
    304 
    305 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)
    271             self.build(input_shapes)
    272           self._built = True
--> 273         outputs = self.call(inputs, **kwargs)
    274 
    275         # Apply activity regularization.

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)
    191       if not self.updates:
    192         mean_update = moving_averages.assign_moving_average(
--> 193             self.moving_mean, mean, self.momentum, zero_debias=False)
    194         variance_update = moving_averages.assign_moving_average(
    195             self.moving_variance, variance, self.momentum, zero_debias=False)

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)
     70         update_delta = _zero_debias(variable, value, decay)
     71       else:
---> 72         update_delta = (variable - value) * decay
     73       return state_ops.assign_sub(variable, update_delta, name=scope)
     74 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)
    675     def _run_op(a, *args):
    676       # pylint: disable=protected-access
--> 677       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)
    678     # Propagate __doc__ to wrapper
    679     try:

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
    791     with ops.name_scope(None, op_name, [x, y]) as name:
    792       if not isinstance(y, sparse_tensor.SparseTensor):
--> 793         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
    794       return func(x, y, name=name)
    795 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)
    635       name=name,
    636       preferred_dtype=preferred_dtype,
--> 637       as_ref=False)
    638 
    639 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)
    700 
    701         if ret is None:
--> 702           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    703 
    704         if ret is NotImplemented:

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)
    573     raise ValueError(
    574         ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r""
--> 575         % (dtype.name, t.dtype.name, str(t)))
    576   return t
    577 

ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(""BatchNorm_2/Reshape_1:0"", shape=(2,), dtype=float16)'
```

### What other attempted solutions have you tried?

Use a modified `tensorflow/python/layers/normalization.py` which passes `dtype=inputs.dtype.base_dtype`.
",0,,14,2017-03-19T15:56:59Z,NONE
8517,"CUDA_ERROR_DEINITIALIZED running CIFAR10_multi_gpu on CUDA8.0 with cuDNN v5, built from pip",type:support,"## Environment info

### Hardware Platform: 
Google Cloud Compute Engine
4 vCPUs, 15 GB memory
4 * NVIDIA Tesla K80

### Software Platform: 
Operating System: Ubuntu 16.04
cuDNN v5
CUDA toolkit 8.0
CUDA Compute Capability 3.7

### Tensor-flow:
Installed from pip 
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl
(Installing from source also doesn't work)
## Steps to reproduce

python3 cifar10_multi_gpu_train.py --num_gpus=4

Error occurs after training.

## What have you tried?

1. restart machine and rerun several times;
2. --num_gpus=2 --> Segmentation fault
3. Reinstall Tensor-flow from source

## Logs or other output that would be helpful
Log file is attached.
[Terminal Saved Output.txt](https://github.com/tensorflow/tensorflow/files/852192/Terminal.Saved.Output.txt)
",1,,12,2017-03-18T05:36:03Z,NONE
8467,Better control of logging verbosity,"stat:contributions welcome,type:feature","I'm creating a simple LSTM in Keras, and during training I get these warnings:

![screenshot from 2017-03-16 13-25-23](https://cloud.githubusercontent.com/assets/23310996/23995972/170f3a10-0a4c-11e7-92f6-f7ee865e65e6.png)

I know I can set the `TF_CPP_MIN_LOG_LEVEL` according to this question: http://stackoverflow.com/questions/35869137/avoid-tensorflow-print-on-standard-error

or use the `tf.logging.set_verbosity(verbosity)` to control this, but for my example I would like to 

1. Hide the warnings that Tensorflow wasn't compiled to use ... instructions.
2. Show the logging of device when starting a new session, that is very useful to confirm that the GPU support is working.
3. Hide the Pool allocator warnings since they clutter the console output from Keras during training.

I haven't found a way to do this, perhaps it could be added as a feature?





",0,,3,2017-03-16T12:37:02Z,NONE
8465,non_max_suppression should support batches,"stat:contributions welcome,type:feature","

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Might be related/nice to do when overworking non_max_suppression for #7511

Related SO: http://stackoverflow.com/questions/39456554/tensorflow-tensor-with-inconsistent-dimension-size


### Description

Most image ops work on batches of images, so it'd make sense if tf.image.non_max_suppression worked on batches of bounding-boxes , returning batches of selected indices.

Although I'm not completely sure how it'd work with the variable result lengths that are likely to happen in this case, perhaps masking or padding them? There's already the max_output_size parameter.

And I'm not entirely sure how well it'd work with gather (gather_nd?), since if it doesn't work well with those, this change wouldn't be as useful
",0,,1,2017-03-16T11:33:05Z,NONE
8451,XLA segfaults with large graphs,stat:contributions welcome,"TensorFlow allows graphs to be larger than 2GB, however those graphs can't be serialized.

I suspect this is the cause of segfaults we've been seeing because of following line in dump_graph.cc

`65    TF_CHECK_OK(WriteTextProto(Env::Default(), path, graph_def));
`

It would be useful to provide an informative error message because troubleshooting this requires looking at core file:

```
ulimit -Sc unlimited
gdb python
core core
bt
```

Here's the backtrace

```
#0  0x00007fc6dcdae428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54
#1  0x00007fc6dcdb002a in __GI_abort () at abort.c:89
#2  0x00007fc6c04b8417 in tensorflow::internal::LogMessageFatal::~LogMessageFatal() () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007fc6bd05cb1e in tensorflow::dump_graph::DumpGraphDefToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::GraphDef const&) ()
   from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#4  0x00007fc6bd05ce88 in tensorflow::dump_graph::DumpGraphToFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Graph const&, tensorflow::FunctionLibraryDefinition const*) () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#5  0x00007fc6bcffd6c2 in tensorflow::EncapsulateSubgraphsPass::Run(tensorflow::GraphOptimizationPassOptions const&) ()
   from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#6  0x00007fc6bec68e00 in tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&) ()
   from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#7  0x00007fc6bec768a3 in tensorflow::SimpleGraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&, std::unique_ptr<tensorflow::SimpleClientGraph, std::default_delete<tensorflow::SimpleClientGraph> >*) () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#8  0x00007fc6be43d293 in tensorflow::DirectSession::CreateGraphs(tensorflow::BuildGraphOptions const&, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> > > > >*, std::unique_ptr<tensorflow::FunctionLibraryDefinition, std::default_delete<tensorflow::FunctionLibraryDefinition> >*, tensorflow::DirectSession::RunStateArgs*) () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#9  0x00007fc6be43f4cf in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, tensorflow::gtl::ArraySlice<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, tensorflow::gtl::ArraySlice<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) ()
   from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#10 0x00007fc6be44085e in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#11 0x00007fc6bcfd4641 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Tensor**, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Buffer*, TF_Status*) [clone .constprop.498] ()
   from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#12 0x00007fc6bcfd4e58 in TF_Run () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#13 0x00007fc6bcf0b15d in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#14 0x00007fc6bcf0b2a3 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#15 0x00007fc6bceed225 in _wrap_TF_Run () from /my_code/tensorflow_ops/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#16 0x00007fc6ddd335e9 in PyCFunction_Call (func=0x7fc6c5120828, args=0x7fc68c1765f8, kwds=<optimized out>) at Objects/methodobject.c:109
#17 0x00007fc6dddbabd5 in call_function (oparg=<optimized out>, pp_stack=0x7ffc0d0dfa78) at Python/ceval.c:4705
#18 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3236
#19 0x00007fc6dddbbb49 in _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=6, kws=0x0, kwcount=0, defs=0x0, defcount=0, 
    kwdefs=0x0, closure=0x7fc6d70ac780, name=0x0, qualname=0x0) at Python/ceval.c:4018
#20 0x00007fc6dddbbcd8 in PyEval_EvalCodeEx (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=<optimized out>, kws=<optimized out>, kwcount=0, defs=0x0, 
    defcount=0, kwdefs=0x0, closure=0x7fc6d70ac780) at Python/ceval.c:4039
#21 0x00007fc6ddd11542 in function_call (func=0x7fc68feb3268, arg=0x7fc68c3903a8, kw=0x0) at Objects/funcobject.c:627
#22 0x00007fc6ddcde236 in PyObject_Call (func=0x7fc68feb3268, arg=<optimized out>, kw=<optimized out>) at Objects/abstract.c:2165
#23 0x00007fc6dddb8234 in ext_do_call (nk=-1942420568, na=0, flags=<optimized out>, pp_stack=0x7ffc0d0dfdc8, func=0x7fc68feb3268) at Python/ceval.c:5034
#24 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3275
#25 0x00007fc6dddbbb49 in _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=8, kws=0x7fd5098, kwcount=0, defs=0x0, defcount=0, 
    kwdefs=0x0, closure=0x0, name=0x7fc6d74eafb0, qualname=0x7fc6d74f07c8) at Python/ceval.c:4018
#26 0x00007fc6dddbadf5 in fast_function (nk=<optimized out>, na=8, n=<optimized out>, pp_stack=0x7ffc0d0dffe8, func=0x7fc6d74add90) at Python/ceval.c:4813
#27 call_function (oparg=<optimized out>, pp_stack=0x7ffc0d0dffe8) at Python/ceval.c:4730
#28 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3236
#29 0x00007fc6dddbbb49 in _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=7, kws=0x7fd7640, kwcount=0, defs=0x0, defcount=0, 
    kwdefs=0x0, closure=0x0, name=0x7fc6d74f13e8, qualname=0x7fc6d74f0738) at Python/ceval.c:4018
#30 0x00007fc6dddbadf5 in fast_function (nk=<optimized out>, na=7, n=<optimized out>, pp_stack=0x7ffc0d0e0208, func=0x7fc6d74add08) at Python/ceval.c:4813
#31 call_function (oparg=<optimized out>, pp_stack=0x7ffc0d0e0208) at Python/ceval.c:4730
#32 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3236
#33 0x00007fc6dddbb166 in fast_function (nk=<optimized out>, na=6, n=<optimized out>, pp_stack=0x7ffc0d0e0388, func=0x7fc6d74adc80) at Python/ceval.c:4803
#34 call_function (oparg=<optimized out>, pp_stack=0x7ffc0d0e0388) at Python/ceval.c:4730
#35 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3236
#36 0x00007fc6dddbbb49 in _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=3, kws=0x40e5488, kwcount=0, defs=0x7fc6d74a7060, 
    defcount=3, kwdefs=0x0, closure=0x0, name=0x7fc6dc762458, qualname=0x7fc6d74ead30) at Python/ceval.c:4018
#37 0x00007fc6dddbadf5 in fast_function (nk=<optimized out>, na=3, n=<optimized out>, pp_stack=0x7ffc0d0e05a8, func=0x7fc6d74adae8) at Python/ceval.c:4813
#38 call_function (oparg=<optimized out>, pp_stack=0x7ffc0d0e05a8) at Python/ceval.c:4730
#39 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3236
#40 0x00007fc6dddbbb49 in _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=4, kws=0x41f8440, kwcount=0, defs=0x7fc6d7761df0, 
    defcount=1, kwdefs=0x0, closure=0x0, name=0x7fc6d77a1ee0, qualname=0x7fc6d77a1ee0) at Python/ceval.c:4018
#41 0x00007fc6dddbadf5 in fast_function (nk=<optimized out>, na=4, n=<optimized out>, pp_stack=0x7ffc0d0e07c8, func=0x7fc6d76ecd90) at Python/ceval.c:4813
#42 call_function (oparg=<optimized out>, pp_stack=0x7ffc0d0e07c8) at Python/ceval.c:4730
#43 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3236
#44 0x00007fc6dddbbb49 in _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=1, kws=0x1c06428, kwcount=0, defs=0x7fc6d76f1320, 
    defcount=2, kwdefs=0x0, closure=0x0, name=0x7fc6dc762458, qualname=0x7fc6d772a170) at Python/ceval.c:4018
#45 0x00007fc6dddbadf5 in fast_function (nk=<optimized out>, na=1, n=<optimized out>, pp_stack=0x7ffc0d0e09e8, func=0x7fc6d76e7730) at Python/ceval.c:4813
#46 call_function (oparg=<optimized out>, pp_stack=0x7ffc0d0e09e8) at Python/ceval.c:4730
#47 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3236
```",0,,6,2017-03-15T23:35:16Z,CONTRIBUTOR
8431,dilated convoluton uses a lot of memory,type:feature,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

* https://github.com/tensorflow/tensorflow/issues/5083 

### Environment info
Operating System: `Linux hpclogin2 2.6.32-642.15.1.el6.x86_64 #1 SMP Thu Feb 23 11:19:57 CST 2017 x86_64 x86_64 x86_64 GNU/Linux`

Installed version of CUDA and cuDNN: 8.0 and 5.1
<details>
<summary>(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):</summary>
```
lrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so -> libcublas.so.8.0
lrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0 -> libcublas.so.8.0.27
-rwxr-xr-x 1 sebo root  38838688 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas.so.8.0.27
-rw-r--r-- 1 sebo root  49345532 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_device.a
-rw-r--r-- 1 sebo root  45050574 Sep  1  2016 /appl/cuda/8.0/lib64/libcublas_static.a
-rw-r--r-- 1 sebo root    560184 Sep  1  2016 /appl/cuda/8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 sebo root    394472 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 sebo root    737516 Sep  1  2016 /appl/cuda/8.0/lib64/libcudart_static.a
lrwxrwxrwx 1 sebo root        15 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so -> libcufft.so.8.0
lrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0 -> libcufft.so.8.0.27
-rwxr-xr-x 1 sebo root 146745600 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft.so.8.0.27
-rw-r--r-- 1 sebo root 129655446 Sep  1  2016 /appl/cuda/8.0/lib64/libcufft_static.a
lrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so -> libcufftw.so.8.0
lrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0 -> libcufftw.so.8.0.27
-rwxr-xr-x 1 sebo root    456424 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw.so.8.0.27
-rw-r--r-- 1 sebo root     42134 Sep  1  2016 /appl/cuda/8.0/lib64/libcufftw_static.a
lrwxrwxrwx 1 sebo root        17 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so -> libcuinj64.so.8.0
lrwxrwxrwx 1 sebo root        20 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0 -> libcuinj64.so.8.0.27
-rwxr-xr-x 1 sebo root   6459464 Sep  1  2016 /appl/cuda/8.0/lib64/libcuinj64.so.8.0.27
-rw-r--r-- 1 sebo root   1649302 Sep  1  2016 /appl/cuda/8.0/lib64/libculibos.a
lrwxrwxrwx 1 sebo root        16 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so -> libcurand.so.8.0
lrwxrwxrwx 1 sebo root        19 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0 -> libcurand.so.8.0.27
-rwxr-xr-x 1 sebo root  59057024 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand.so.8.0.27
-rw-r--r-- 1 sebo root  59273876 Sep  1  2016 /appl/cuda/8.0/lib64/libcurand_static.a
lrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so -> libcusolver.so.8.0
lrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0 -> libcusolver.so.8.0.27
-rwxr-xr-x 1 sebo root  52380368 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver.so.8.0.27
-rw-r--r-- 1 sebo root  22313722 Sep  1  2016 /appl/cuda/8.0/lib64/libcusolver_static.a
lrwxrwxrwx 1 sebo root        18 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so -> libcusparse.so.8.0
lrwxrwxrwx 1 sebo root        21 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0 -> libcusparse.so.8.0.27
-rwxr-xr-x 1 sebo root  42976296 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse.so.8.0.27
-rw-r--r-- 1 sebo root  51604078 Sep  1  2016 /appl/cuda/8.0/lib64/libcusparse_static.a
```
</details>
<br>


If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`): 168d188168b30b204099f21e456151752d7fb718
2. The output of `bazel version`: `0.4.3`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```py
import numpy as np
import sugartensor as stf
import tensorflow as tf


def get_variable(name, in_dim, out_dim, size=None):
    if size is None:
        size = 1
        shape = (in_dim, out_dim)
    else:
        shape = (size, in_dim, out_dim)

    w = tf.get_variable(name, shape, dtype=tf.float32,
                        initializer=tf.random_uniform_initializer(
                            minval=-np.sqrt(1 / (in_dim * size)),
                            maxval=np.sqrt(1 / (in_dim * size))
                        ))
    return w

# build forward pass
embedding = get_variable('embed', 128, 892)
embedding_inv = get_variable('embed-inv', 892, 128)

data = tf.placeholder(name='x', shape=(160, 200), dtype=tf.int32)
output = tf.nn.embedding_lookup(embedding, data)

for i in range(60):
    Wi = get_variable(f'W{i}', 892, 892, 5)
    output = tf.nn.convolution(input=output, filter=Wi,
                               padding='SAME', dilation_rate=[16],
                               name='aconv1d')
    output = tf.nn.relu(output)

logits = tf.reshape(tf.matmul(tf.reshape(output, [-1, 892]), embedding_inv),
                    [160, 200, 128])

# optimize for the idendity function
loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(
    labels=data, logits=logits
))

# create update ops
optimizer = tf.train.AdamOptimizer()
grad_and_vars = optimizer.compute_gradients(loss, tf.trainable_variables())
update_ops = optimizer.apply_gradients(grad_and_vars)

config = tf.ConfigProto(allow_soft_placement=True)
with tf.Session(config=config) as sess:
    sess.run(tf.global_variables_initializer())

    for i in range(1000):
        loss_result = sess.run([loss, update_ops], feed_dict={
            data: np.random.randint(0, 128, size=(160, 200))
        })[0]
        print(f'iteration {i} complete: {loss_result}')
```

This example is perhaps too theoretical to be discussed from a practical application perspective. The actual application is the [ByteNet](https://arxiv.org/abs/1610.10099) model, the implementation is very similar to https://github.com/buriburisuri/ByteNet. The ByteNet model stacks multiple one-dimensional-dilated-convolutions (30), because each of them uses `space_to_batch` they use a lot of memory.


### What other attempted solutions have you tried?

I've implemented one-dimensional-masked-dilated-convolutions using `tf.scan`, this uses much less memory but is also slower.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

* The error log from the actual application: https://gist.github.com/AndreasMadsen/91e49e13f0085ececbef0f80c830c5af (note that this happens after 21334 iterations/14 hours, so there may also be a garbage collection issue)
* The error log from the simplified example: https://gist.github.com/AndreasMadsen/94f5100aff697cdf5ff6c26f90a6dad7",1,,13,2017-03-15T12:12:04Z,CONTRIBUTOR
8416,CPU resources of Tensorflow's docker containers could not be controlled by --cup-shares  ,type:bug/performance,"### Environment info
OS:Ubuntu14.04LTS
GPU:Nvidia Pascal TITUN X
CUDA8.0
cuDNN CUDA8.0 V5.1
Docker Verison:17.03.0-ce
Nvidia docker : 1.0.1
CPU Intel Core i7 6900K , Hyper-THreading off , Turbo boost off


####Docker file
I installed Tensorflow by Dockerfile as below;

================================
 FROM nvidia/cuda:8.0-cudnn5-devel

ENV http_proxy http://mycompany.proxy:8080
ENV https_proxy http://mycompany.proxyp:8080


RUN     apt-get update  &&  apt-get install -y \
        python-dev \
        python-pip \
        nano \
        git 
    
RUN    rm -rf /var/lib/apt/lists/* /var/cache/apt/archieves/* 

RUN    pip install --upgrade --user https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0-cp27-none-linux_x86_64.whl

WORKDIR /root/.local/lib/python2.7/site-packages/tensorflow

RUN git clone https://github.com/tensorflow/models.git

WORKDIR /root/.local/lib/python2.7/site-packages/tensorflow/models/tutorials/image/cifar10

####My Procedure[a]
(1) At first ,I build Dockerfile 
     $ nvidia-docker build -t cpu:tensorflow0.

     Tensorflow docker image was build with no-problem and no-erros.

(2)Next  I run two docker container and log in two container via Bash
  $ nvidia-docker run --cpuset-cpus=0-5 --cpu-shares=2048 -it cpu:tensorflow0
  $nvidia-docker run --cpuset-cpus=0-5 --cpu-shares=1024 -it cpu:tensorflow0

    I used all CPU cores(6 cores).

(3) I did ""python cifar10_train.py"" on two containers ,and check cpu-resources by docker stats.
     By the way, tow python examples""cifar10_train.py"" were same code.  
     CPU Resource of one container was  339.86%
     CPU Resources of another on another container was 230.19% 
   
      CPU Resouce Rate 339.86 : 230.19 was not different from --cpu-shares Rate 2048:1024 

  ####My Procedure[b]
To make sure, I did same procedure by using CPU 5cores.   

(1)Next  I run two docker container and log in two container via Bash
  $ nvidia-docker run --cpuset-cpus=0-4 --cpu-shares=2048 -it cpu:tensorflow0
  $nvidia-docker run --cpuset-cpus=0-4 --cpu-shares=1024 -it cpu:tensorflow0

    I used only 5 CPU cores. because --cpuset-cpus=0-4

(2) I did ""python cifar10_train.py"" on two containers ,and check cpu-resources by docker stats.
     By the way, tow python examples""cifar10_train.py"" were same code.  
     CPU Resource of one container was  278.13%
     CPU Resources of another on another container was 195.80% 
   
      CPU Resources Rate 278.13 :195.80 was not different from --cpu-shares Rate 2048:1024 

 ####My Procedure[c]
 I did same process by Chainer Containers :Chainer Version 1.21.0

 (1)6cores :Two Chainer containers ,--cpusets-cpu=0-5,--cpu-shares=2048 and --cpu-shares=1024

     CPU resources   394.23 : 195.41 nealy 2:1 , It is as same as 2048:1024

(2) 5cores :Two Chainer containers ,--cpusets-cpu=0-4,--cpu-shares=2048 and --cpu-shares=1024

     CPU resources   330 .82: 166.13 nealy 2:1 , It is as same as 2048:1024

 ####My additional Procedure[d]
I run 4 docker container at --cpu-shares setting at 2048,1024,1024 ,and 512.

*Tensoflow 4 Container CPU resources : 205.21 : 135.68 : 142.71 : 97.94
  They were not rates of --cpu-shares ; 2.09 : 1.39 : 1.46 : 1.0

*Chainer 4 Containers CPU resources : 267.44 : 133.93 :129.59 : 59.98
  They ware nearly equal rate of --cpu-shares ; 4.45 : 2.23 : 2.26 : 1.0   

####Result

Two Chainer's docker containers operated according with the setting of --cpu-shares.
But  Two Tensorflow's docker containers did not operate according with the setting of --cpu-shares.

 ####My Question
Do you know the reason why two Tensorflow's containers did not operate according with the setting of --cpu-shares?



",1,,5,2017-03-15T01:59:13Z,NONE
8350,Not able to run tensorflow with OpenBLAS support,stat:community support,"Hi,

Im trying to use OpenBLAS for gemm operations instead of EIGEN with tensorflow.
I have followed the steps given in 
http://eigen.tuxfamily.org/dox-devel/TopicUsingBlasLapack.html

and compiled the tensoflow android demo application with -DEIGEN_USE_BLAS support and have linked the libopenblas.a to EIGEN by placing the OpenBLAS headers and static library in eigen_archive along with BUILD file.
****The BUILD File of OpenBLAS is as follows**:**

licenses([""notice""])

 cc_library(
      name = ""openblas"",
      hdrs = glob([""include/*.h""]),
      srcs = [""lib/libopenblas.a""],
      visibility = [""//visibility:public""],
  )

The BUILD file of EIGEN has been appended to include and link the openblas library as follows:
 cc_library(
     name = ""eigen"",
     hdrs = EIGEN_MPL2_HEADER_FILES,
     defines = [
         # This define (mostly) guarantees we don't link any problematic
         # code. We use it, but we do not rely on it, as evidenced above.
         ""EIGEN_MPL2_ONLY"",
     ],
     includes = ["".""],
     copts = [""-IOpenBLAS/include""],
     deps = [""//OpenBLAS:openblas""],
     visibility = [""//visibility:public""],
 )

The build is given as follows:
bazel build --copt=-DEIGEN_USE_BLAS --fat_apk_cpu=arm64-v8a //tensorflow/examples/android:tensorflow_demo --verbose_failures

The Build is completed successfully and im able to run the apks installed on the target. But the print statements which i have put in OpenBLAS and Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h using android logging LOGI or LOGD doesnt get displayed in logcat of the device.

The Build fails if i dont link the openblas library in EIGEN BUILD file and use  -DEIGEN_USE_BLAS, which shows that libopenblas is getting linked to EIGEN.

Can you please suggest what is the problem in the above procedure ?
How can we validate OpenBLAS is actually getting used?",0,,2,2017-03-13T12:05:28Z,NONE
8348,Taking gradients after using SparseTensor in while_loop leads to TypeError,"stat:contributions welcome,type:bug/performance","### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Found various issues on SparseTensors, but nothing about while loops and gradients.


### Environment info
Operating System:
Ubuntu 14.04

Installed version of CUDA and cuDNN: 
None

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 
0.12.1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

This code leads to the error (when trying to compute the gradients) `TypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fb966845f98>`
```
import tensorflow as tf


def body(A, b, x, i):
    i += 1
    b = b + tf.sparse_tensor_dense_matmul(A, x)
    return A, b, x, i


def cond(A, b, x, i):
    return i < 5


sess = tf.InteractiveSession()
indices = [[0, 0], [1, 1]]
values = [1., 1.]
A = tf.SparseTensor(indices, values, (100, 100))
x = tf.ones((100, 1))
b = tf.zeros_like(x)
[_, b, _, _] = tf.while_loop(cond, body, [A, b, x, tf.constant(0)])
grad = tf.gradients(b, x)
print(sess.run([grad]))
sess.close()
```

### What other attempted solutions have you tried?

If `A` is removed as a loop variable everything works as expected:

```
import tensorflow as tf


def body(b, x, i):
    i += 1
    b = b + tf.sparse_tensor_dense_matmul(A, x)
    return b, x, i


def cond(b, x, i):
    return i < 5


sess = tf.InteractiveSession()
indices = [[0, 0], [1, 1]]
values = [1., 1.]
A = tf.SparseTensor(indices, values, (100, 100))
x = tf.ones((100, 1))
b = tf.zeros_like(x)
[b, _, _] = tf.while_loop(cond, body, [b, x, tf.constant(0)])
grad = tf.gradients(b, x)
print(sess.run([grad]))
sess.close()
```


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

```
Traceback (most recent call last):
  File ""sparse_tensor_gradient_error.py"", line 21, in <module>
    grad = tf.gradients(b, x)
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py"", line 427, in gradients
    _SetGrad(grads, y, loop_state.ZerosLikeForExit(y))
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1165, in ZerosLikeForExit
    result = array_ops.zeros_like(val, optimize=False)
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1471, in zeros_like
    tensor = ops.convert_to_tensor(tensor, name=""tensor"")
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 441, in make_tensor_proto
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 441, in <listcomp>
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fb966845f98>
```
",0,,1,2017-03-13T10:17:28Z,NONE
8328,"orthogonal_initializer() on GPU, horrible error message","stat:awaiting tensorflower,type:feature","Works fine on CPU.

**Error message is horrible**, without any hints towards `orthogonal_initializer`, or line it is used on, or GPU, or essence of the problem.

Problems like this (not the first one for me) can only be handled as theory-by-theory manual search by user.

Isolated example:

```python
import tensorflow as tf
import numpy as np

def strange_assign():
	config = tf.ConfigProto()
	config.allow_soft_placement = True
	sess = tf.InteractiveSession(config=config)
	with tf.device(""gpu:0""):
		g1 = tf.get_variable(""g1"", [2,2], tf.float32, tf.constant_initializer(1.0))
		g2 = tf.get_variable(""g2"", [2,2], tf.float32, tf.zeros_initializer())
		g3 = tf.get_variable(""g3"", [2,2], tf.float32, tf.ones_initializer())
		g4 = tf.get_variable(""g4"", [2,2], tf.float32, tf.orthogonal_initializer(1.0))
		g5 = tf.get_variable(""g5"", [2,2], tf.float32, tf.random_normal_initializer())
		g6 = tf.get_variable(""g6"", [2,2], tf.float32, tf.random_uniform_initializer())

	tf.global_variables_initializer().run()
	for test in [g1,g2,g3,g4,g5,g6]:
		t = sess.run(test)
		print(""ASSIGN TEST"", test.name)
		ph = tf.placeholder(tf.float32, t.shape)
		try:
			sess.run( [tf.assign(test, ph)] , feed_dict = { ph: t })
			print(""OK"")
		except:
			print(""FAIL"")

strange_assign()
```

Output:

```
ASSIGN TEST g1:0
OK
ASSIGN TEST g2:0
OK
ASSIGN TEST g3:0
OK
ASSIGN TEST g4:0
E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Invalid argument: AttrValue must not have reference type value of float_ref
	 for attr 'tensor_type'
	; NodeDef: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: AttrValue must not have reference type value of float_ref
	 for attr 'tensor_type'
	; NodeDef: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
	 [[Node: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25)]]
FAIL
ASSIGN TEST g5:0
OK
ASSIGN TEST g6:0
OK
```


Error message:

```
E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Invalid argument: AttrValue must not have reference type value of float_ref
	 for attr 'tensor_type'
	; NodeDef: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: AttrValue must not have reference type value of float_ref
	 for attr 'tensor_type'
	; NodeDef: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
	 [[Node: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25)]]
Traceback (most recent call last):
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1022, in _do_call
    return fn(*args)
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1004, in _run_fn
    status, run_metadata)
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: AttrValue must not have reference type value of float_ref
	 for attr 'tensor_type'
	; NodeDef: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
	 [[Node: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""wtf.py"", line 29, in <module>
    strange_assign()
  File ""wtf.py"", line 23, in strange_assign
    sess.run( [tf.assign(test, ph)] , feed_dict = { ph: t })
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File "".linuxbrew/Cellar/python3/3.5.2_3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: AttrValue must not have reference type value of float_ref
	 for attr 'tensor_type'
	; NodeDef: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
	 [[Node: g1/_23 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_3_g1"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/gpu:0""](^_recv_Placeholder_3_0/_25)]]
```

Versions:

1.0.1

/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44

/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5

",0,,5,2017-03-12T16:35:19Z,NONE
8271,ImportError: No module named 'tensorflow.contrib.ffmpeg.ops',,"### Environment info
Operating System: Windows 10

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 5.1

If installed from binary pip package, provide:

1. A link to the pip package you installed: `tensorflow_gpu-1.0.1-cp35-cp35m-win_amd64.whl`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 1.0.1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

`python -c ""from tensorflow.contrib import ffmpeg""`

Output:

`Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\Guillaume COTER\Anaconda3\lib\site-packages\tensorflow\contrib\ffmpeg\__init__.py"", line 26, in <module>
    from tensorflow.contrib.ffmpeg.ffmpeg_ops import decode_audio
  File ""C:\Users\Guillaume COTER\Anaconda3\lib\site-packages\tensorflow\contrib\ffmpeg\ffmpeg_ops.py"", line 23, in <module>
    from tensorflow.contrib.ffmpeg.ops import gen_decode_audio_op_py
ImportError: No module named 'tensorflow.contrib.ffmpeg.ops'`",1,,8,2017-03-10T10:31:36Z,NONE
8264,Auto-Configuration Error: Cannot find cudnn.h at /usr/lib/x86_64-linux-gnu/include/cudnn.h,type:build/install,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
#4397, but it's for 16.04

### Environment info
Operating System: Ubuntu 14.04
Installed version of CUDA and cuDNN: 8.0, 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
ls -l /path/to/cuda/lib/libcud*
-rw-r--r-- 1 root 543K Jan 26 15:48 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root   16 Jan 26 15:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root   19 Jan 26 15:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
-rw-r--r-- 1 root 406K Jan 26 15:48 /usr/local/cuda/lib64/libcudart.so.8.0.61
-rw-r--r-- 1 root 757K Jan 26 15:48 /usr/local/cuda/lib64/libcudart_static.a
```
```
ll /usr/lib/x86_64-linux-gnu/libcudnn*                                                                                                                                                                
lrwxrwxrwx 1 root  29 Mar  1 11:58 /usr/lib/x86_64-linux-gnu/libcudnn.so -> /etc/alternatives/libcudnn_so
lrwxrwxrwx 1 root  18 Nov  6 23:19 /usr/lib/x86_64-linux-gnu/libcudnn.so.5 -> libcudnn.so.5.1.10
-rw-r--r-- 1 root 81M Nov  6 23:19 /usr/lib/x86_64-linux-gnu/libcudnn.so.5.1.10
lrwxrwxrwx 1 root  32 Mar  1 11:58 /usr/lib/x86_64-linux-gnu/libcudnn_static.a -> /etc/alternatives/libcudnn_stlib
-rw-r--r-- 1 root 68M Nov  6 23:19 /usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a
```

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`): e895d5ca395c2362df4f5c8f08b68501b41f8a98
2. The output of `bazel version`: 
```
INFO: Reading 'startup' options from /root/.bazelrc: --batch
Build label: 0.4.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 7 18:47:11 2016 (1481136431)
Build timestamp: 1481136431
Build timestamp as int: 1481136431
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I ran
```
./configure
```
It failed with
```
INFO: Reading 'startup' options from /root/.bazelrc: --batch
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
INFO: Reading 'startup' options from /root/.bazelrc: --batch
ERROR: package contains errors: tensorflow/compiler/tests.
ERROR: error loading package 'tensorflow/compiler/tests': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
        File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 816
                _create_cuda_repository(repository_ctx)
        File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 729, in _create_cuda_repository
                _get_cuda_config(repository_ctx)
        File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 585, in _get_cuda_config
                _cudnn_version(repository_ctx, cudnn_install_base..., ...)
        File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 296, in _cudnn_version
                _find_cuda_define(repository_ctx, cudnn_install_base..., ...)
        File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 271, in _find_cuda_define
                auto_configure_fail(""Cannot find cudnn.h at %s"" % st...))
        File ""/tensorflow/third_party/gpus/cuda_configure.bzl"", line 93, in auto_configure_fail
                fail(""
%sAuto-Configuration Error:%s ...))

Auto-Configuration Error: Cannot find cudnn.h at /usr/lib/x86_64-linux-gnu/include/cudnn.h
```

I noticed the cudnn.h is in /usr/include/cudnn.h somehow, while its libs are in /usr/lib/x86_64-linux-gnu/.

I read cuda_configure.bzl, but didn't find an easy way to let it find both cudnn headers and libs.
",1,,20,2017-03-10T05:47:45Z,NONE
8256,Variable for Go?,"stat:contributions welcome,type:feature","Is Variable being worked on in the Go bindings?
",0,,5,2017-03-10T01:28:22Z,NONE
8246,TensorFlow equivalent to numpy.repeat,"stat:contributions welcome,type:feature","This is a popular question on StackOverflow:
http://stackoverflow.com/questions/35361467/tensorflow-numpy-repeat-alternative

But note that the answer so far only works for some use cases (the one presented in the question).

The best I could come up with for a general solution uses `tf.while_loop`, which is pretty verbose (and maybe slower than necessary). I'll add a link to the implementation I wrote for `tf.contrib.training.resample_at_rate` after the next internal/github sync.",0,,10,2017-03-09T18:09:38Z,MEMBER
8227,[feature] Smarter Handling of Image Data Format,"stat:contributions welcome,type:feature","Right now the responsibility of choosing image data format (i.e. the representation of batches of image) is that of the data scientist (ie model writer). I suggest there should a solution in TF to move this to the optimizer (XLA perhaps?) or worst cast Op writer.

For some background:

Currently Tensorflow supports `NCHW` and `NHWC` (though other formats like [CHWN](https://github.com/soumith/convnet-benchmarks/issues/66#issuecomment-155944875) might be possible down the road). Many of the Ops support both formats. That being said, the docs say:
>The best practice is to build models that work with both NCHW and NHWC as it is common to train using NCHW on GPU, and then do inference with NHWC on CPU.

This requires the user to have to do some ""wrangling"" (e.g. loading the checkpoint of weights and re-buidling graph in Python) to map from one image format to another. Further this must be done with some knowledge of the platform on which the graph will be executed (ie which ops are defined, and if both, which is faster)?

Right now model builder must [build the model to take in channel order and pass that around](https://github.com/tensorflow/tensorflow/issues/8137). Ideally the model could be written once with enough meta information attached to the graph to allow optimizers after the fact (ie at inference time on other platforms) to choose the best representation. Further even at training time, it would be great if the data scientist didn't need to be concerned with image data format (ie dimension ordering) and could use abstractions for accessing results that took care of data access.

I don't have a clear proposal of how to clean this up, but this seems like a potential pain point, or a the very least results in people leaving performance on the table both when training and at inference. 

**TL; DR** Many data scientists just want to write CNNs without thinking about tensor layouts.",0,,6,2017-03-09T02:19:59Z,CONTRIBUTOR
8225,[feature] Define Op Polymorphic on Fully Defined vs not Fully Defined Shape,"stat:contributions welcome,type:feature","Repost from [SO](http://stackoverflow.com/questions/42655141/tensorflow-define-op-polymorphic-on-fully-defined-vs-not-fully-defined-shape/42683994#42683994):

When defining an Op in Tensorflow, make it possible to provide two Kernels for the op that are polymorphic on whether the shape for the inputs are fully defined.

For example, you can then optimize when shape is fully known / defined by constructing certain structures once at Kernel construction.

/CC @mrry ",0,,0,2017-03-09T01:50:50Z,CONTRIBUTOR
8224,Feature request: numeric type promotion,,"TensorFlow does some numeric type promotion.
It should do more of it.

Examples:
```
# this works, 2 is int32, gets promoted to float32
tf.pow(2.,2)

# this fails, apply_op promotion logic is not smart enough
tf.pow(2,2.)

# this fails, [2,] is converted to int32 but needs to be int64
tf.sparse_placeholder(tf.float32, [2,])

# this works, numpy arrays are int64 by default
tf.sparse_placeholder(tf.float32, np.array([2,]))
```

This came up in:
https://github.com/tensorflow/tensorflow/issues/7483
https://github.com/tensorflow/tensorflow/issues/7220
https://github.com/tensorflow/tensorflow/issues/7170

cc @josh11b who wrote type promotion logic in OpDefLibrary.apply_op
cc @suharshs who changed the default to treat Python integer as int32",0,,7,2017-03-09T01:42:22Z,CONTRIBUTOR
8211,[feature] Support Building for iOS Using Bazel,type:build/install,"Would be great to be able to build for ios using Bazel rather than make. This would allow more rapid development of ops that can only run on iOS (eg: [Metal Performance Shaders](https://github.com/tensorflow/tensorflow/issues/7958)).

Carry over from: https://github.com/tensorflow/tensorflow/issues/5360#issuecomment-283557890

It looks like there might be some progress here: https://github.com/tensorflow/tensorflow/commit/78c9dec5a62e74389608c709027fb8eabdf2bef0  ?
/CC @petewarden @aselle",1,,5,2017-03-08T19:36:51Z,CONTRIBUTOR
8208,Feature Request: armv7k support for WatchOS,type:feature,"There is no build target for the armv7k architecture in the compile_ios_tensorflow.sh makefile. This means that tensorflow currently does not work on the Apple Watch. Having support for one of the most popular wearables would be a big boon to what developers could do with machine learning.

I asked a question about this a month ago on Stack Overflow but only got crickets, so I'm asking here as a feature request.

Related Stack Overflow question:
https://stackoverflow.com/questions/41990420/tensorflow-on-watchos",1,,19,2017-03-08T18:47:59Z,NONE
8137,Support consistent data_format between tf.layers and everything else,"stat:contributions welcome,type:feature","The functions in `tf.layers` take a `data_format` parameter. However, this parameter has different semantics from the identically named `data_format` parameter everywhere else in TensorFlow. It's expected to be `channels_first` or `channels_last`, versus `NHWC`, `NCHW`, or `NDHWC` everywhere else. As such, it's inconvenient from a DX perspective to intersperse `tf.layers` code with other TensorFlow code, as it requires passing different values for the identically-named `data_format` parameter.

Ideally, the functions in `tf.layers` should support the more explicit `data_format` strings. While `channels_first` and `channels_last` are easier to understand, they're less explicit, as there do exist cases outside of TensorFlow where the tensor layout is CHWN, given which `channels_first` meaning `NCHW` is not optimally clear.

On the same note, it's a bit inconvenient that `tf.layers.batch_normalization` takes `axis` instead of `data_format`; while this is more correct, it makes it annoying to switch back and forth, especially that the fused batch norm implementation only supports NHWC and NCHW anyway, rather than batch norm on an arbitrary axis.",0,,6,2017-03-06T19:06:22Z,CONTRIBUTOR
8112,tf_upgrade doesn't update RNN cells,,"Migration script `tf_upgrade.py` does not update RNN cell locations from `tf.nn.rnn_cell` to `tf.contrib.rnn` leading to error: `AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'rnn_cell'`

Upgrading
```python
import tensorflow as tf

rnn = tf.nn.rnn_cell.GRUCell(128)
tf.initialize_all_variables()  # Checking if tf_upgrade works at all
```
becomes
```python
import tensorflow as tf

rnn = tf.nn.rnn_cell.GRUCell(128)
tf.global_variables_initializer()  # Checking if tf_upgrade works at all
```
when it should be
```python
import tensorflow as tf

rnn = tf.contrib.rnn.GRUCell(128)
tf.global_variables_initializer()  # Checking if tf_upgrade works at all
```",1,,3,2017-03-06T05:21:31Z,NONE
8109,libxsmm build errors with Python 3,,"It seems like some dependencies are not Python 3 compatible.

Building with `--define tensorflow_xsmm=1 --define tensorflow_xsmm_backward=1` gives following 

cc @benoitsteiner 

```
ERROR: /local_home/yaroslav/bazel/external/libxsmm_archive/BUILD.bazel:112:1: Co
uldn't build file python3/external/libxsmm_archive/scripts/libxsmm_utilities.py:
 Converting to Python 3: external/libxsmm_archive/scripts/libxsmm_utilities.py f
ailed: 2to3 failed: error executing command bazel-out/host/bin/external/bazel_tools/tools/python/2to3 --no-diffs --nobackups --write --output-dir bazel-out/host
/genfiles/python3/external/libxsmm_archive/scripts --write-unchanged-files ... (
remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitSta
tusException: Process exited with status 1.                                     ERROR: /local_home/yaroslav/bazel/external/libxsmm_archive/BUILD.bazel:130:1: Co
uldn't build file python3/external/libxsmm_archive/scripts/libxsmm_dispatch.py:
Converting to Python 3: external/libxsmm_archive/scripts/libxsmm_dispatch.py fai
led: 2to3 failed: error executing command bazel-out/host/bin/external/bazel_tools/tools/python/2to3 --no-diffs --nobackups --write --output-dir bazel-out/host/g
enfiles/python3/external/libxsmm_archive/scripts --write-unchanged-files ... (re
maining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatu
sException: Process exited with status 1.                                       ERROR: /local_home/yaroslav/bazel/external/libxsmm_archive/BUILD.bazel:112:1: Co
uldn't build file python3/external/libxsmm_archive/scripts/libxsmm_specialized.p
y: Converting to Python 3: external/libxsmm_archive/scripts/libxsmm_specialized.
py failed: 2to3 failed: error executing command bazel-out/host/bin/external/bazel_tools/tools/python/2to3 --no-diffs --nobackups --write --output-dir bazel-out/
host/genfiles/python3/external/libxsmm_archive/scripts --write-unchanged-files .
.. (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExi
tStatusException: Process exited with status 1.                                 ERROR: /local_home/yaroslav/bazel/external/libxsmm_archive/BUILD.bazel:124:1: Co
uldn't build file python3/external/libxsmm_archive/scripts/libxsmm_config.py: Co
nverting to Python 3: external/libxsmm_archive/scripts/libxsmm_config.py failed:
 2to3 failed: error executing command bazel-out/host/bin/external/bazel_tools/tools/python/2to3 --no-diffs --nobackups --write --output-dir bazel-out/host/genfi
les/python3/external/libxsmm_archive/scripts --write-unchanged-files ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
ERROR: /local_home/yaroslav/bazel/external/libxsmm_archive/BUILD.bazel:118:1: Couldn't build file python3/external/libxsmm_archive/scripts/libxsmm_interface.py:
 Converting to Python 3: external/libxsmm_archive/scripts/libxsmm_interface.py f
ailed: 2to3 failed: error executing command bazel-out/host/bin/external/bazel_to
ols/tools/python/2to3 --no-diffs --nobackups --write --output-dir bazel-out/host/genfiles/python3/external/libxsmm_archive/scripts --write-unchanged-files ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitSta
tusException: Process exited with status 1.
```",2,,6,2017-03-06T02:42:30Z,CONTRIBUTOR
8100,XLA Design :: Incorporate Polyhedral Compilation (through LLVM Polly).,"stat:contributions welcome,type:feature","Polyhedral Compilation is a method of modeling iterations of loop nests into points on a multidimensional space (Determined by the loop nest depth). A detailed description can be found on the website as given [here](http://polyhedral.info/).

Is it possible to pass the deeply nested kernels (for-loops) modeled in TensorFlow via XLA-JIT (or independently) through [Polly](http://polly.llvm.org/) that will extract dependence information and perform scheduling using Polyhedral compilation? Tensorflow Ops can be reproduced and modeled to basic math operators and can be applied to points on the Integer Polyhedra. 

This can lead to significant speedup in program execution. However, since Polyhedral compilation can be expensive, it can lead to increase in compile time. (Trade-off in compile time)

I am a student working on Polyhedral Compilation and would love to contribute to this if it spans out!",0,,29,2017-03-05T10:43:50Z,NONE
8025,quantize_graph round and quantize modes are broken,type:bug/performance,"Looking at code in master. /CC @petewarden 

A `KeyError` is always produced.

[Consider the `round` mode](already_visited):
```python
    if self.mode == ""round"":
      self.already_visited = {}
      for output_node in output_nodes:
        self.round_nodes_recursively(output_node)
```
which [will fails for all calls](https://github.com/tensorflow/tensorflow/blob/fa4ba830f437fdb9dc1085b4d68a3bab41a16e20/tensorflow/tools/quantization/quantize_graph.py#L402-L404):
```
  def round_nodes_recursively(self, current_node):
    """"""The entry point for simple rounding quantization.""""""
    if self.already_visited[current_node.name]:
```
with a key error since the `already_visited` dict will be empty. ",1,,5,2017-03-02T19:35:20Z,CONTRIBUTOR
8011,TypeError: Fetch argument None has invalid type <class 'NoneType'>,type:bug/performance,"Feature request for a better error description OR for better summary handling:

The following code works fine if some summaries where defined before:
```
ops=[] 
ops += [tf.summary.merge_all()]
session.run(ops)
```
However if there were no summaries we get:
TypeError: Fetch argument None has invalid type <class 'NoneType'>

Which is really saying:  ""One of the session.run ops where empty, which is forbidden.""
Alternatively let merge_all return a NoOp if there are no summaries.",1,,7,2017-03-02T13:59:38Z,NONE
7970,SyncReplicasOptimizer race condition strange behavior?,"stat:awaiting tensorflower,type:bug/performance","It seems there is a strange race condition in SyncReplicasOptimizer leading to strange behaviour. I include below an example code to reproduce what seems to be a bug (hopefully in my code) as well as the commands to reproduce it (pretty much the same code as in mnist_replica.py).


I am trying to implement  synchronized SGD using SyncReplicasOptimizer, I also used the queue trick to make the parameter server stop gracefully when all workers are done. I have 4 workers and 1 parameter server. Worker 0 is the chief worker.

Please bear with me for the long explanation of the different issues (they depend on the order in which processes are launched)

**** First kind of issue ****

launch the processes in this order 
    
    python test.py --job_name ps
    python test.py --job_name worker --taks_index 0
    python test.py --job_name worker --taks_index 1
    python test.py --job_name worker --taks_index 2
    python test.py --job_name worker --taks_index 3

The last worker throws the following error :

    I tensorflow/core/distributed_runtime/master_session.cc:909] DeregisterGraph error: Unavailable: {""created"":""@1488366991.043859719"",""description"":""OS Error"",""errno"":104,""file"":""external/grpc/src/core/lib/iomgr/tcp_posix.c"",""file_line"":229,""grpc_status"":14,""os_error"":""Connection reset by peer"",""syscall"":""recvmsg""}

and quits, and it happens also that it hangs (not realising that the variable epoch is greater than 4, triggering the break from the training loop, and the enqueue operation to let the ps stop gracefully).

It also happen that all is fine, and the execution terminates without any errors.


**** Second kind of issue ****

launch the processes in this order 
    
    python test.py --job_name ps
    python test.py --job_name worker --taks_index 3
    python test.py --job_name worker --taks_index 2
    python test.py --job_name worker --taks_index 1
    python test.py --job_name worker --taks_index 0


The chief here being launched at last.

Strangely, the chief completes the loop and quits ( I thought with SyncReplicasOptimizer it had to wait for the other workers to complete each step).

As for the other workers, I had all sort of results when doing the same experiment many times 

1) Some workers simply hang and do not execute a single step in the `while true` training loop

2) Some execute some steps, then simply hang, apparently they lose contact with the chief, and do not realise that the variable `epoch` is greater than 4, triggering the `break from the training loop.

Thank you for help with this issue.

Below is the code of test.py

    import os
    import shutil
    import tempfile
    import numpy as np
    import pandas as pd
    import argparse
    
    from keras.models import Sequential
    from keras.layers.core import Dense
    from keras.regularizers import l2
    import tensorflow as tf
    import keras
    
    nb_samples = 50
    nb_features = 5
    X_train = np.random.randn(nb_samples * nb_features).reshape((nb_samples, nb_features))
    Y_train = np.random.randn(nb_samples).reshape((nb_samples, 1))
    
    def build_keras_model(input_dim):
      hidden_dim = 10
    
      model = Sequential()
      model.add(Dense(input_dim = input_dim,
                      output_dim=hidden_dim,
                      activation='tanh'
                      ))
    
      model.add(Dense(output_dim=1, activation='linear'))
    
      model.compile(loss='mse', optimizer='adam')
      
      return model
    
    
    
    
    ################################################
    # DISTRIBUTE
    ################################################
    
    parser = argparse.ArgumentParser(description='tensorflow')
    parser.add_argument('--job_name', dest='job_name')
    parser.add_argument('--task_index', dest='task_index', default=0)
    args = parser.parse_args()
    
    
    ps_hosts = ['localhost:2222']
    worker_hosts = ['localhost:2223', 'localhost:2224', 'localhost:2225', 'localhost:2226']
    job_name = args.job_name
    task_index = int(args.task_index)
    
    # Create a cluster from the parameter server and worker hosts.
    cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})
      
    server = tf.train.Server(cluster,
                             job_name=job_name,
                             task_index=task_index,
                             config=tf.ConfigProto(log_device_placement=True,
                                                   inter_op_parallelism_threads=1,
                                                   intra_op_parallelism_threads=1))
    
    
    if job_name =='ps':
      with tf.device(""/job:ps/task:0""):
        queue = tf.FIFOQueue(len(worker_hosts), tf.int32, shared_name=""done_queue"")
      sess = tf.Session(server.target)
      # wait until all workers are done
      for i in range(len(worker_hosts)):
        sess.run(queue.dequeue())
    else:
      with tf.device(tf.train.replica_device_setter(
                                  worker_device=""/job:worker/task:%d"" % task_index,
                                  cluster=cluster)):
    
        keras.backend.set_learning_phase(1)
        keras.backend.manual_variable_initialization(True)
    
        model = build_keras_model(nb_features)
        preds = model.output
        targets = tf.placeholder(tf.float32, [None, 1])
        total_loss = tf.reduce_mean(
                            keras.objectives.mean_squared_error(targets, preds))
    
        global_step = tf.Variable(0, name=""global_step"", trainable=False)
        # For early stopping management
        epoch = tf.Variable(0, name=""epoch"", trainable=False)
        inc_epoch_op = tf.assign_add(epoch, 1)
    
        is_chief=(task_index == 0)
    
        opt = tf.train.AdamOptimizer()
        num_workers = len(worker_hosts)
        replicas_to_aggregate = num_workers
        opt = tf.train.SyncReplicasOptimizer(
                                             opt,
                                             replicas_to_aggregate=replicas_to_aggregate,
                                             total_num_replicas=num_workers,
                                             name=""sync_replicas"")
    
        train_op = opt.minimize(total_loss, global_step=global_step)
        local_init_op = opt.local_step_init_op
        if is_chief:
          local_init_op = opt.chief_init_op
        ready_for_local_init_op = opt.ready_for_local_init_op
    
        # Initial token and chief queue runners required by the sync_replicas mode
        chief_queue_runner = opt.get_chief_queue_runner()
        sync_init_op = opt.get_init_tokens_op()
    
        init_op = tf.global_variables_initializer()
        with tf.device(""/job:ps/task:0""):
          queue = tf.FIFOQueue(len(worker_hosts), tf.int32, shared_name=""done_queue"")
          enqueue_op = queue.enqueue(1)
     
        train_dir = tempfile.mkdtemp(prefix = 'worker_%d' % task_index)
        sv = tf.train.Supervisor(
                                 is_chief=is_chief,
                                 logdir=train_dir,
                                 init_op=init_op,
                                 local_init_op=local_init_op,
                                 ready_for_local_init_op=ready_for_local_init_op,
                                 recovery_wait_secs=1,
                                 global_step=global_step)
        
        print '######################################### ALL CREATED'
        sess = sv.prepare_or_wait_for_session(server.target)
        keras.backend.set_session(sess)
        print '#######  SESSION OK ********'
        if is_chief:
          sess.run(sync_init_op)
          sv.start_queue_runners(sess, [chief_queue_runner])
        local_step = 0
        while True:
          train_feed = {model.input: X_train, targets: Y_train}
    
          _, step = sess.run([train_op, global_step], feed_dict=train_feed)
          loss = sess.run(total_loss, feed_dict = train_feed)
          if is_chief:
            sess.run(inc_epoch_op)
          local_step += 1
          print '## epoch ', epoch.eval(sess)
          if epoch.eval(sess) > 4:
            print '######################  TRYING TO LEAVE'
            break
    
        shutil.rmtree(train_dir)
        print '######################  WHILE LOOP LEFT'
        sess.run(enqueue_op)
        print '## ENQUEUE OP DONE'
    
",0,,30,2017-03-01T11:30:04Z,NONE
7966,Compile TensorFlow 1.0 on Windows 10 for Python 3.6 (Anaconda) cause compile issues,"stat:community support,type:build/install","As per agreement in #6999 [specific comment](https://github.com/tensorflow/tensorflow/issues/6999#issuecomment-280749568), I'm creating a new issue for compilation errors for TF 1.0 under Windows for Python 3.6

**Pre-requisites:**
Windows 10 v.14986
Python 3.6 64 bit (Anaconda 4.3)
git version 2.11.0.windows.1
Visual Studio Build Tools (called ""Build Tools for Visual Studio 2017 RC"" in the [download](https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2017-rc) section)
cmake-3.8.0-rc1 and swigwin-3.0.12 (just downloaded latest version at that moment)
TensorFlow 1.0.0 from source (master branch from github)

**Reproduction**. I followed [instruction](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md) for CMake just running two commands - CMake first and MSBuild second.

To compile, I made two changes in sources. I found them based on compilation errors.
One was adding `#include <intrin.h>` to `tensorflow\core\platform\windows\cpu_info.h` inside of `#ifndef` block because of the following error:
> error C3861: '__cpuidex': identifier not found 

I found [commit](https://github.com/tensorflow/tensorflow/commit/a672cb166dae93ae955c1d38f3de8903dd242373) introduced usage of `__cpuidex` function. Based on [this](https://msdn.microsoft.com/en-us/library/hskdteyh.aspx) MSDN link, I discovered that Header file `<intrin.h>` has to be included.  That's why I put it inside `cpu_info.h` (not sure if it's exactly perfect place).

**Second issue** was commenting out procedures `_mm256_extract_epi32` and `_mm256_insert_epi32` in `tensorflow\core\platform\windows\intrinsics_port.h` due to error

> error C2169: '_mm256_extract_epi32': intrinsic function, cannot be defined 

The second issue with `_mm256_extract_epi32` may be connected with the same reason, I don't know. 
In the meantime, `platform/windows/intrinsics_port.h` [references](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/windows/intrinsics_port.h#L22) `immintrin.h`, but I don't see it's actually included anywhere. I assume it may correlate with `instrih.h` inclusion (based on [this](https://msdn.microsoft.com/en-us/library/26td21ds.aspx) link). Meanwhile, `_mm256_extract_epi32 `can be found in `avxintrin.h` which may be is included by `immintrin.h`.

> // the following avx intrinsics are not defined on windows
> // in immintrin.h so we define them here.

After fixing those two issues, that, I was able to successfully run
> MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj

Which gave me `tensorflow-1.0.0-cp36-cp36m-win_amd64.whl`, that I successfully installed into Python using `pip`. It seems to be working - I was able to run couple of jupyter notebooks, including udacity assignments.

BTW, compilation took about 2-3 hours on my week laptop (i5-4200U).",0,,9,2017-03-01T09:20:16Z,CONTRIBUTOR
7958,Support MPSCNN (MetalPerformanceShaders) on iOS,"stat:contributions welcome,type:feature","Related to: https://github.com/tensorflow/tensorflow/issues/3001

Take advantage of the [MPSCNN (Metal Performance Shaders) framework from Apple](https://developer.apple.com/reference/metalperformanceshaders).

See [blog post](http://machinethink.net/blog/apple-deep-learning-bnns-versus-metal-cnn/) for a comparison of BNSS to MPSCNN (and [associated code](https://github.com/hollance/BNNS-vs-MPSCNN)).

**TL; DR** BNNS is faster for smaller networks but slower for bigger networks.

Related: https://github.com/tensorflow/tensorflow/issues/4846",0,,29,2017-03-01T03:42:08Z,CONTRIBUTOR
7956,Method log_prob_with_logits() for Dirichlet,,"It would be useful to have a log_prob_with_logits() method for the Dirichlet distribution.

The reason being is that it is often useful to model the discrete posterior distribution in log space, which doesn't let all probabilities to go exactly to zero. Then the Dirichlet prior can be applied to the data in log space. Note, that if the posterior is converted to the normalised distribution, then some of the discrete probabilities may actually go to zero due to the rounding errors. Then the Dirichlet prior cannot be applied to this distribution because it doesn't allow zero probabilities.

The log_prob_with_logits() calculation would be very simple to implement. The log(x_i) would need to be replaced with just x_i, and an additional term with LogSumExp(x) added.

This would actually enable the possibility to use the Dirichlet prior on the discrete viariables in log space (can also be part of a neural network).",1,,25,2017-03-01T01:22:41Z,NONE
7938,Add Python Graph Transform examples,"stat:contributions welcome,type:docs","The docs for the [Graph Transform Tool](https://github.com/tensorflow/tensorflow/blob/d699a66e940b26e991b29b27f4e3ad2e8e3282d2/tensorflow/tools/graph_transforms/README.md#writing-your-own-transforms) talk about writing your own transforms but way to do so is in C++. It would be cool if there was an example of / c++ hook writing transforms in Python as well. For example, here is one Python transform (by @mrry): http://stackoverflow.com/a/40852855/2638485 (https://github.com/tensorflow/tensorflow/issues/5918).",0,,7,2017-02-28T03:35:41Z,CONTRIBUTOR
7876,Import meta graph followed by save overwrites the previous checkpoints,type:bug/performance,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): using CPU version of tensorflow 1.0.0

If installed from binary pip package, provide:

1. A link to the pip package you installed: pip install tensorflow
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 1.0.0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```python
import tensorflow as tf

graph = tf.Graph()
with graph.as_default():
    initializer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5, seed=42, dtype=tf.float32)
    var1 = tf.get_variable('var1', shape=(1,), dtype=tf.float32, initializer=initializer)
    saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=20)
    init_op = tf.global_variables_initializer()
    graph.finalize()

with tf.Session(graph=graph) as sess:
    sess.run(init_op)
    saver.save(sess, 'sample_graph', global_step=0)

graph = tf.Graph()
with tf.Session(graph=graph) as sess:
    saver = tf.train.import_meta_graph('sample_graph-0.meta')
    saver.restore(sess, './sample_graph-0')
    saver.save(sess, 'sample_graph', global_step=1)
    print(saver.last_checkpoints) # lists only ['sample_graph-1'] does not preserve the previous checkpoint sample_graph-0
```
Essentially I am checkpointing a graph and then importing it. On trying to save the next checkpoint, the saver overwrites the previous checkpoint in the checkpoint file (the actual meta, index and data files are not overwritten) and only the last saved checkpoint is present in the `checkpoint` file. Is this the intended behavior? Is there any way to preserve the checkpoints across multiple saves of the graph.

### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
",1,,4,2017-02-25T07:37:53Z,NONE
7868,Hyper-parameter search in TensorFlow,"stat:contributions welcome,type:feature","Hi all,

Thanks for the great work on TensorFlow.

Is anybody aware of any available TF feature for automatic hyper-parameter search? E.g., using Grid Search, or Random Search or Bayesian Optimization?

Thanks!
Hamid",1,,16,2017-02-24T23:37:50Z,NONE
7848,[Feature Request] Predict posterior probability of data per each component in GMM ,stat:contributions welcome,"It would be very helpful  if  method is provided to predict posterior probability of data per each component in GMM.

A stackoverflow [question ](http://stackoverflow.com/questions/42357268/looking-for-a-method-to-replace-sklearn-mixture-gaussianmixture-predict-probax) has already been raised by longwoo.

",0,,9,2017-02-24T13:27:26Z,NONE
7822,Returning argmax with tf.nn.pool,"stat:contributions welcome,type:feature","Feature request for returning argmax for N-D pooling with `tf.nn.pool`, as in `tf.nn.max_pool_with_argmax`.",0,,2,2017-02-23T18:09:38Z,NONE
7808,TensorFlow builds LLVM even if ./configured without XLA,type:build/install,"At HEAD (4ac9c09d5ca57a03b8daa5fb9e295947b1619854), if I configure TensorFlow without XLA support and run

    blaze build //tensorflow/...

it still builds both XLA and LLVM (or at least parts, since I haven't waited for it to finish).  Needless to say, it also downloads LLVM, which ideally would not be necessary without XLA support.

Is it possible to skip building a compiler if I don't want XLA?",1,,11,2017-02-23T05:08:15Z,CONTRIBUTOR
7712,Feature request: add parametric ELU (PELU) activation function,"stat:contributions welcome,type:feature","# Proposal
The exponential linear unit (ELU) is already in TensorFlow as `tf.nn.elu` which is great. The new parametric version (called PELU) shows very promising experimental results so I wonder if it could be added in to TensorFlow too in order to encourage more widespread experimentation with it by the deep learning community. One problem with it though is that it's stateful (e.g. `tf.Variable`), meaning it's not clear to me where in TensorFlow it fits in.

# Implementation
Here's an implementation of the PELU that I've been using lately (I'm assuming batch_size is the first dimension in `x`):
```python
def pelu(x):
  """"""Parametric Exponential Linear Unit (https://arxiv.org/abs/1605.09332v1).""""""
  with tf.variable_scope(x.op.name + '_activation', initializer=tf.constant_initializer(1.0)):
    shape = x.get_shape().as_list()[1:]
    alpha = tf.get_variable('alpha', shape)
    beta = tf.get_variable('beta', shape)
    positive = tf.nn.relu(x) * alpha / (beta + 1e-9)
    negative = alpha * (tf.exp((-tf.nn.relu(-x)) / (beta + 1e-9)) - 1)
    return negative + positive
```

# Reference
https://arxiv.org/abs/1605.09332v1",0,,9,2017-02-20T22:05:41Z,CONTRIBUTOR
7702,"dynamic_rnn_decoder returns shape [?, batch_size, cell.output_size]",stat:contributions welcome,"According to [the docs](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder),  the dynamic_rnn_decoder returns a tuple contaning `outputs`, which is a Tensor of shape `[max_time, batch_size, cell.output_size]`(provided `time_major==True`).

In my case, however, the first dimension of that Tensor is returned as underspecified (Dimension `?`), and in fact depending on the provided batch when running the RNN. 

If this is the intended behaviour, it should probably be highlighted in the documentation that `max_time` is variable.

Reproduce with:

```import tensorflow as tf
import numpy as np

# toy data, timesteps between 1 and 10
timesteps = np.random.randint(1, 11, [10])
X=np.random.randint(0, 20, [10,10,1])

batch_size = 2
max_ts = 10
inputs = tf.placeholder(tf.float32, 
                        (max_ts, batch_size, 1), name=""X_in"")

cell_fw = tf.contrib.rnn.LSTMCell(50)
cell_bw = tf.contrib.rnn.LSTMCell(50)
cell_dec = tf.contrib.rnn.LSTMCell(50)

seq_lens = tf.placeholder(tf.int32, batch_size, name=""seq_lens"")

enc_outputs, states = tf.nn.bidirectional_dynamic_rnn(
    cell_fw, cell_bw, inputs, time_major=True, sequence_length=seq_lens, dtype=tf.float32)

decoder_inp = tf.concat(enc_outputs, axis=2) 

attention_states = tf.zeros([batch_size, 1, cell_dec.output_size],
                                    name=""attention_states"")

att_keys, att_vals, att_score_fn, att_construct_fn = \
            tf.contrib.seq2seq.prepare_attention(attention_states,
                                                 attention_option=""luong"",
                                                 num_units=50)

dynamic_fn_train = tf.contrib.seq2seq.attention_decoder_fn_train(
            states[0], att_keys, att_vals, att_score_fn, att_construct_fn)

outputs, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(
            cell_dec, dynamic_fn_train, decoder_inp, time_major=True,
            sequence_length=seq_lens)

with tf.Session() as sess:
    feed_dict = {inputs: X[:,:2,:], seq_lens: ts[:2]}
    sess.run(tf.global_variables_initializer())
    out = sess.run(outputs, feed_dict=feed_dict)
    print(out.shape[0])
```

The very last print statement will show that the first output dimension is not max_ts, but the max timestep of the batch (<= 10)",1,,7,2017-02-20T15:12:53Z,NONE
7700,Can't enforce shape invariants with TensorArrays in while_loop,type:docs,"I can't enforce shape invariants in a while_loop if one of the inputs is a TensorArray. Here's a minimal example: 
```
import tensorflow as tf

def body(i,ta):
    ta = ta.write(i,1.0)
    return (i+1,ta)

arr_size = 10
ta = tf.TensorArray(tf.float32, size=arr_size)

i = tf.constant(0,tf.int32)
input = (i,ta)
cond = lambda i,_ : i < arr_size
output = tf.while_loop(cond, body,input,shape_invariants=(i.get_shape(),tf.TensorShape(arr_size)))

#works fine without shape_invariants:
#output = tf.while_loop(cond, body,input)

mat = output[1].stack()
sess = tf.InteractiveSession()
print(mat.eval())
```

The code above works fine if the while_loop is not fed shape_invariants. Using shape_invariants though, I get the following error: 
```
ValueError: The shape invariant specified for TensorArray:1 is not compatible with the initial shape of the loop variable. It enters the loop with shape <unknown>, but the specified shape invariant is (10,).
```

Am I doing something wrong or is this a bug?

Thanks! ",1,,8,2017-02-20T15:03:51Z,NONE
7669,"The tutorial ""Logging and Monitoring Basics with tf.contrib.learn"" has error.",type:bug/performance,"When I used the code snippet in the section ""Customizing the Evaluation Metrics with MetricSpec"" of the tutorial [Logging and Monitoring Basics with tf.contrib.learn](https://www.tensorflow.org/get_started/monitors). the code snippet is 

```python
validation_metrics = {
    ""accuracy"":
        tf.contrib.learn.metric_spec.MetricSpec(
            metric_fn=tf.contrib.metrics.streaming_accuracy,
            prediction_key=tf.contrib.learn.prediction_key.PredictionKey.
            CLASSES),
    ""precision"":
        tf.contrib.learn.metric_spec.MetricSpec(
            metric_fn=tf.contrib.metrics.streaming_precision,
            prediction_key=tf.contrib.learn.prediction_key.PredictionKey.
            CLASSES),
    ""recall"":
        tf.contrib.learn.metric_spec.MetricSpec(
            metric_fn=tf.contrib.metrics.streaming_recall,
            prediction_key=tf.contrib.learn.prediction_key.PredictionKey.
            CLASSES)
}
```

My tensorflow version is r1.0 . When I run my program, it print the following error:

```shell
$ python iris.py 
Traceback (most recent call last):
  File ""iris.py"", line 72, in <module>
    tf.app.run()
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""iris.py"", line 24, in main
    ""accuracy"": tf.contrib.learn.metric_spec.MetricSpec(
AttributeError: 'module' object has no attribute 'metric_spec'
```

I found that the class `tf.contrib.learn.metric_spec.MetricSpec` has been renamed to [`tf.contrib.learn.MetricSpec`](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/MetricSpec). 

The class `tf.contrib.learn.prediction_key.PredictionKey` also has been renamed to [`tf.contrib.learn.PredictionKey`](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/PredictionKey).",1,,25,2017-02-19T15:52:17Z,NONE
7662,Add a dynamic_partial_sum operator to tensorflow?,"stat:contributions welcome,type:feature","Hi,

In my application I need to do operations that dynamically sum some rows of a matrix to get a new matrix.  There will be an input tensor named ""index"" that guides which part of the tensor to be summed. 

An example is, if the input matrix is
```python
[ [   1,   1,   1],
  [  10,  10,  10],
  [ 100, 100, 100] ]
```
And the index is
```python
[ [ 0, 2 ],
  [ 2, 3 ]]
```
which simply says the output tensor will have two rows (because the ""index"" have two rows), the first row is the sum of rows with row number i that satisfies `0 <= i < 2` in the input, and the second row is the sum of rows with row number 2. So the result should be
```python
[ [  11,  11,  11],
  [ 100, 100, 100] ]
```

I don't find any existing operation that does this job, so I implement it (support only 2d matrix and GPU) by myself.  Since I already have an implementation, I'm not requesting a new feature here. But I do want to know that if the tensorflow team is interested in adding this operation as part of tensorflow. If the answer is yes, I will add CPU support (maybe also xla? I have no idea on how to add xla support yet), and then create a pull request for that.",0,,8,2017-02-19T07:30:10Z,CONTRIBUTOR
7634,Setting import_scope on import_meta_graph causes error for attached metagraph file,"stat:awaiting tensorflower,type:bug/performance","Using the attached meta file:
```
model_fn = './my-model.meta'

graph = tf.Graph()
sess = tf.InteractiveSession(graph=graph)

t_input = tf.placeholder(np.float32, name='images') # define the input tensor
t_preprocessed = tf.expand_dims(t_input, 0)

new_saver = tf.train.import_meta_graph(model_fn, input_map={'images': t_input}, import_scope='import')
new_saver.restore(sess, './')
```
results in:
```
KeyError: ""The name 'gradients/discriminator/minibatch/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter:0' refers to a Tensor which does not exist. The operation, 'gradients/discriminator/minibatch/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter', does not exist in the graph.""
```
I'm trying to remap the input so I can do image space optimization with a library that assumes the network input is (width, height, channels). Loading doesn't error if I load without the input_map and import_scope keyword arguments; however, this causes problems for the library I'm interacting with. Setting import_scope alone does cause an error.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Asked on Stack Overflow in case this isn't a bug: http://bit.ly/2lW7lRA

### Environment info
Operating System:

Mac

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
1.0.0

[my-model.meta.zip](https://github.com/tensorflow/tensorflow/files/784246/my-model.meta.zip)
",0,,4,2017-02-17T20:48:04Z,NONE
7632,max_pool3d does not support float16(half),"stat:contributions welcome,type:feature","I'm using version 0.12.1 on Ubuntu 14.04 LTS 64 bit. Here is the minimal example I run to find the error:

```
    with tf.Graph().as_default():
        a = tf.constant(1, shape = [1, 4, 4, 4, 1], dtype = tf.float16)
        b = tf.nn.max_pool3d(a, ksize = [1, 2, 2, 2, 1], strides = [1, 2, 2, 2, 1], padding = 'SAME')

        with tf.Session() as sess:
            print(sess.run([a, b]))
```

The I got error:

```
...
InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'MaxPool3D' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='CPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_FLOAT]
```

If I use ```dtype = tf.float32```, there is no error. ```max_pool3d``` python docstring says it supports half precision, but why ```dtype = tf.float16``` does not work?


",0,,10,2017-02-17T20:02:44Z,NONE
7610,3D convolutions unnaturally slow on CPU,type:bug/performance,"3D convolutions on CPU seem unnaturally slow. 
I can't use GPU due to memory limit, so I'm looking at CPU execution. 

2D convolutions in TensorFlow seem to be well-optimized, all CPU cores are used, performance is just few times below GPU.

With 3D convolutions - the difference is orders of magnitude. 

Also, I've compared with Theano. Theano 3D convolutions run on single core but still are 10 times faster.

Strangely, TF uses all cores on CPU with 3Dconv,  so there must be some bug or extreme inefficiency in implementation.

With the same small test model (just couple of 3d conv layers) I get 1 second epoch time on GPU (both TF and Theano, theano just a bit faster), 5 seconds on CPU Theano single threaded, and 50 seconds with (seemingly) multi-threded TF

### Environment info
I've tried different TF versions from 0.12 to 1.00, installed from pip. Latest one from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.0-cp35-cp35m-linux_x86_64.whl

The OS is CentOS Linux release 7.2.1511 (Core) , kernel 3.10.0-327.18.2.el7.x86_64

I'm using Keras back-end, so I can't be 100% sure if the problem is not in the way Keras translates Convolution3D call into TF primitives, but it does not seem likely. 

cheers
Alex",1,,11,2017-02-17T06:05:16Z,NONE
7541,Fatal messages mixing C libtensorflow with python tensorflow,"stat:contributions welcome,type:feature","I'm trying to write mixed C tensorflow code with python tensorflow code by
embedding the CPython interpreter in my application.

I'm mainly doing this because defining the model is only really possible in
Python at the moment due to the lack of gradients (#6268), and I want to define
new models from the C side at speed without needing to invoke or
communicate to an external python process to get a new model.

To reproduce the problem is quite straightforward, simply `import tensorflow`
in python after the libtensorflow library has already been dynamically linked.
Here is a quick reproducer in pure python which will not run:

```python
import ctypes

tf_dll = ctypes.CDLL(""/usr/local/lib/libtensorflow.so"")

import tensorflow
```

libtensorflow can be obtained like so:

```
TF_TYPE=cpu # Set to gpu for GPU support
TF_OS=linux
curl -L \
  ""https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-${TF_TYPE}-${TF_OS}-x86_64-1.0.0.tar.gz"" |
sudo tar -C /usr/local -xz
```

Here are two fatal messages I have encountered (the first from the Python reproducer above, the second from a C program):

```
F tensorflow/stream_executor/cuda/cuda_platform.cc:180] Check failed: ::perftools::gputools::port::Status::OK() == (MultiPlatformManager::RegisterPlatform(std::move(platform))) (OK vs. Internal: platform is already registered with name: ""CUDA"")
```

```
F tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count
```

I assume the problem is that the `_pywrap_tensorflow.so` has tensorflow
statically linked into them, so they don't use libtensorflow. Then you have
two shared libraries conflicting with one another.

Is there a way to avoid this conflict?",0,,8,2017-02-15T21:49:22Z,NONE
7537,Feature request: get available GPU memory,"stat:contributions welcome,type:feature","Please add an API to get available memory from the GPU. 

When tf.Session() starts, it shows the free memory. 
![image](https://cloud.githubusercontent.com/assets/7299296/22991586/a298c2fa-f371-11e6-92a3-c514cb148bf3.png)
",0,,3,2017-02-15T19:27:36Z,NONE
7515,[feature requests] DecodeCSVOP to parse only the first len(record_defaults) columns of a csv,"stat:contributions welcome,type:feature","Suppose that my data.csv is :
_1,2,3_
_2,4,6_

and for some other purpose we add a new column to a new csv data2.csv
_1,2,3,comment_

the code below fails if the input is data2.csv:
`col1,col2,col3 = tf.decode_csv(line,record_defaults=[[1],[1],[1]]) `

Hope that tf.decode_csv() only decodes the first len(record_defaults) columns only, so that it works for both data1.csv as well as data2.csv.
What's more, we can add  ""a column index list parameter"" to indicate which columns to be decoded.
",0,,9,2017-02-15T03:40:31Z,NONE
7511,non_max_suppression is very slow and doesn't appear to have a cuda or multi-threaded implementation,"stat:contributions welcome,type:feature","
It appears that tf.image.non_max_suppression currently takes about 200ms for about 8000 boxes, runs on a single CPU thread and doesn't have a GPU implementation.

### Environment info
Operating System:
Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
8.0, 5.1.5

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.0-rc1

",0,,6,2017-02-15T00:37:17Z,NONE
7508,import_graph_def's input_map doesn't remap control inputs,type:bug/performance,"If a graph `g` has a node `y` with a control input like `^x`, I would have thought that `tf.import_graph_def(g, input_map={""x"": z})` would result in a graph having a node `y` with a control input`^z`. 

Instead I get an error: `ValueError: Attempted to map inputs that were not found in graph_def: [x:0]`.  This is on master.

Complete example: 

```python
import tensorflow as tf
g1=tf.Graph()
with g1.as_default():
    x=tf.constant(0.0, name=""x"")
    with tf.control_dependencies([x]):
        y=tf.constant(1, name=""y"")
g2=tf.Graph()
with g2.as_default():
    z=tf.constant(1.0, name=""z"")
    tf.import_graph_def(g1.as_graph_def(), input_map={""x"": z})

```",1,,8,2017-02-14T20:39:01Z,CONTRIBUTOR
7480,preprocessor definition clash with glog,"stat:awaiting response,type:bug/performance","CHECK macros from `platform/logging.h` leak out into `core/public` headers which clash with users of glog.

One path is through `core/platform/allocator.h`:
```
In file included from external/org_tensorflow/tensorflow/core/platform/logging.h:25:0,
                 from external/org_tensorflow/tensorflow/core/framework/allocator.h:26,
                 from external/org_tensorflow/tensorflow/core/framework/tensor.h:21,
                 from external/org_tensorflow/tensorflow/core/public/session.h:23,
(snip)
external/org_tensorflow/tensorflow/core/platform/default/logging.h:224:0: note: this is the location of the previous definition
 #define CHECK_OP_LOG(name, op, val1, val2)                            \
 ^
```
This one is easy to fix by moving method implementation to allocator.cc.

Another is through `core/lib/core/status.h`.
```
In file included from external/org_tensorflow/tensorflow/core/platform/logging.h:25:0,
                 from external/org_tensorflow/tensorflow/core/lib/core/status.h:24,
                 from external/org_tensorflow/tensorflow/core/lib/core/errors.h:19,
                 from external/org_tensorflow/tensorflow/core/framework/tensor_shape.h:24,
                 from external/org_tensorflow/tensorflow/core/framework/tensor.h:24,
                 from external/org_tensorflow/tensorflow/core/public/session.h:23,
```

This one is more work to fix because `TF_CHECK_OK` is used all over the code, but it does not seem to be necessary for `core/public`.
",1,,10,2017-02-14T00:06:36Z,NONE
7467,Feature request: Add early stopping mechanism to slim.evaluation_loop,"stat:awaiting tensorflower,type:feature","Would it be possible to add early stopping mechanism to slim.evaluation_loop?

",1,,5,2017-02-13T14:21:46Z,NONE
7448,tf.summary.FileWriter crashes with AlreadyExistsError,"stat:community support,type:feature","We have a cluster with ~20 GPUs that we often use to train multiple networks in parallel, and we use `tf.summary.Filewriter` to keep track of the networks' progress. However, some jobs are crashing when they attempt to create their `FileWriter`s with the following stack trace:

```
[...]
  File ""/ubc/cs/research/tracking-raid/julm/eyescream/tensorflow/pose_estimation/linear_model.py"", line 141, in __init__
    self.train_writer = tf.summary.FileWriter( os.path.join(summaries_dir, 'train' ))
  File ""/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/summary/writer/writer.py"", line 308, in __init__
    event_writer = EventFileWriter(logdir, max_queue, flush_secs)
  File ""/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/summary/writer/event_file_writer.py"", line 69, in __init__
    gfile.MakeDirs(self._logdir)
  File ""/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 299, in recursive_create_dir
    pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)
  File ""/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.AlreadyExistsError: /global/scratch/julm/3d_experiments
```

I am writing the `Filewriter`s' progress under `/global/scratch/julm/3d_experiments/`, and creating multiple subdirectories depending on the hyperparameters that each network is using.

The error seems to suggest that the `FileWriter` is trying to create the directory `/global/scratch/julm/3d_experiments/` and crashing because the directory already exists. Moreover, only around 1 in 5 jobs crashes with this error.

Do you know if I could somehow ignore this error? I don't think the fact that the directory exists should trigger an error for the user.

Our cluster runs under OpenSUSE 42.2.",0,,5,2017-02-12T05:40:00Z,NONE
7422,Feature: Add reduce_average (weighted reduce_mean),type:feature,[Numpy has a function `average`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.average.html) which peforms a weighted mean. I suggest adding this function to tensorflow or adding an optional `weights` argument to `reduce_mean`.,1,,10,2017-02-10T19:06:16Z,CONTRIBUTOR
7404,No attribute 'outer_context' when calculating gradient from imported graph,type:docs,"It seems when you import a graph with a ""while"" loop, you can't calculate gradients as you could on the original graph. e.g.

```python
import tensorflow as tf
i=tf.constant(0, name=""input"")
out=tf.while_loop(lambda i: tf.less(i,5), lambda i: [tf.add(i,1)], [i], name=""output"")
graph_def = tf.get_default_graph().as_graph_def()

g = tf.Graph()
with g.as_default():
    tf.import_graph_def(graph_def)
s = tf.Session(graph=g)
i_imported = g.get_tensor_by_name(""import/input:0"")
out_imported = g.get_tensor_by_name(""import/output/Exit:0"")
tf.gradients(out_imported, i_imported)
```

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-12-e7e2b78684d3> in <module>()
----> 1 tf.gradients(out_imported, i_imported)

/Users/malmaud/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.pyc in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)
    439     pending_count, loop_state = _PendingCount(ops.get_default_graph(), to_ops,
    440                                               from_ops,
--> 441                                               colocate_gradients_with_ops)
    442 
    443     # Iterate over the collected ops.


/Users/malmaud/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.pyc in _PendingCount(graph, to_ops, from_ops, colocate_gradients_with_ops)
    184   # 'loop_state' is None if there are no while loops.
    185   loop_state = control_flow_ops.MaybeCreateControlFlowState(
--> 186       between_op_list, between_ops, colocate_gradients_with_ops)
    187 
    188   # Initialize pending count for between ops.

/Users/malmaud/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc in MaybeCreateControlFlowState(between_op_list, between_ops, colocate_gradients_with_ops)
   1293           loop_state.AddWhileContext(op, between_op_list, between_ops)
   1294       else:
-> 1295         loop_state.AddWhileContext(op, between_op_list, between_ops)
   1296   return loop_state
   1297 

/Users/malmaud/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc in AddWhileContext(self, op, between_op_list, between_ops)
   1102     if grad_state is None:
   1103       # This is a new while loop so create a grad state for it.
-> 1104       outer_forward_ctxt = forward_ctxt.outer_context
   1105       if outer_forward_ctxt:
   1106         outer_forward_ctxt = outer_forward_ctxt.GetWhileContext()

AttributeError: 'NoneType' object has no attribute 'outer_context'
```",1,,11,2017-02-10T03:14:10Z,CONTRIBUTOR
7397,`tf.dynamic_stitch` gradient is incorrect,"stat:contributions welcome,type:bug/performance","### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
``` python
import tensorflow as tf

x = tf.zeros((1, 3))
y = tf.dynamic_stitch([[0], [0]], [x, tf.ones((1, 3))])

with tf.Session() as sess:
    print(""y"")
    print(sess.run(y))

    analytic, numeric = tf.test.compute_gradient(x, (1, 3), y, (1, 3))
    print(""analytic"")
    print(analytic)
    print(""numeric"")
    print(numeric)
```

gives output
```
y
[[ 1.  1.  1.]]
analytic
[[ 1.  0.  0.]
 [ 0.  1.  0.]
 [ 0.  0.  1.]]
numeric
[[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]]
```

The numeric gradient correctly shows that `x` has no impact on `y` (since the value of `x` is completely overwritten by a constant in the `dynamic_stitch`).  The analytic gradient is incorrect; it seems like the gradient calculation in `dynamic_stitch` does not handle the case where there are duplicate indices being merged.
",0,,4,2017-02-09T19:09:54Z,CONTRIBUTOR
7394,Segfault when calling TF_OperationGetAttrTensor on malformed tensor,,"On 1.0.0-rc1 (and earlier versions), this segfaults:

```c
void dealloc(void* data, size_t len, void* arg) {
}

int main() {
  TF_Tensor* empty = TF_NewTensor(TF_FLOAT, NULL, 0, NULL, 0, dealloc, NULL);
  TF_Graph* graph = TF_NewGraph();
  TF_OperationDescription* desc = TF_NewOperation(graph, ""Const"", ""empty"");
  TF_Status* status = TF_NewStatus();
  TF_SetAttrTensor(desc, ""value"", empty, status);
  TF_SetAttrType(desc, ""dtype"", TF_FLOAT);
  TF_Operation* op = TF_FinishOperation(desc, status);
  TF_Tensor* value;
  TF_OperationGetAttrTensor(op, ""value"", &value, status); //Segfaults
  return 0;
}
```

Note that `TF_Message(status)` is `TF_OK` after the calls to `TF_SetAttrTensor` and `TF_FinishOperation`. ",1,,6,2017-02-09T18:04:40Z,CONTRIBUTOR
7378,Seg fault when using tf session with opencv 3,type:docs,"Hi, 

We noticed that when we try to use tensorflow with opencv 3, it consistently seg faults and crashes. The commands are:

```
import cv2
import numpy as np
import tensorflow as tf

with tf.Session() as sess:
    img = cv2.imread('messi5.jpg', 0)
    rows, cols = img.shape
    M = np.float32([[1, 0, 100], [0, 1, 50]])
    dst = cv2.warpAffine(img, M, (cols, rows))
    cv2.imshow('img', dst)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
```

Assuming you have a messi5.jpg in the folder (https://raw.githubusercontent.com/abidrahmank/OpenCV2-Python-Tutorials/master/data/messi5.jpg)

We see this issue when we use tensorflow 0.12 GPU enabled, opencv 3.2.0 and python 2.7.6, CUDA 8.0 and CuDNN 5.1.5 . We did not observe this issue with opencv version 2.4.13 or 2.4.9.

We will also filed a bug report on opencv (https://github.com/opencv/opencv/issues/8155)

",1,,12,2017-02-09T06:49:37Z,NONE
7312,incorrect usage of num_gpus & num_workers in mnist_replica.py,stat:contributions welcome,"[mnist_replica.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L126) has the following code. 
```
 if FLAGS.num_gpus < num_workers:
    raise ValueError(""number of gpus is less than number of workers"")
```
This will work fine in a single worker setup with one or more GPUs. However, it will throw error if the number of workers is greater than the number of GPUs available in each worker. For example, using 2 workers each with 1 GPU will trigger this error.

It looks like this if-block can be removed. If that is an acceptable change, I can send a PR for that.",0,,9,2017-02-07T02:49:12Z,CONTRIBUTOR
7278,Feature request: separable convolutions in 3D,"stat:contributions welcome,type:feature","I would like a `tf.nn.separable_conv3d` identical to `tf.nn.separable_conv2d` except with separability between dimentions [1,2,3] and 4, for use with 3D CNNs.

Rationale: separable convolutions perform very well in 2D (see: Xception architecture https://arxiv.org/abs/1610.02357 ).  In 3D, the number of parameters grows even faster for non-separable convolutions, so the reduction in parameters from using separable convolutions would be relatively even bigger.  This is one of the reasons 3D networks tend to have a simpler architecture than 2D.  

Necessity: There doesn't seem to be any way to implement this other than in the TF core. (Suggestions?)",0,,11,2017-02-06T02:28:53Z,NONE
7251,Native GPU version of `tf.dynamic_stitch`,"stat:contributions welcome,type:feature","### Environment info
Operating System: Windows 10

Installed version of CUDA and cuDNN: 8.0, 5105
tensorflow release 0.12.1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
``` python
import tensorflow as tf
from tensorflow.python.client.timeline import Timeline

with tf.device(""/gpu:0""):
    x = tf.ones(100)
    idxs = tf.range(100)

    for _ in range(10):
        y = tf.identity(x)
        x = tf.dynamic_stitch([idxs, idxs], [x, y])
        # x = tf.gather(y, idxs)

with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
    metadata = tf.RunMetadata()
    sess.run(x, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
             run_metadata=metadata)

timeline = Timeline(metadata.step_stats)
with open(""profile.json"", ""w"") as f:
    f.write(timeline.generate_chrome_trace_format())
```

The `log_device_placement` output shows that everything is assigned to the GPU, as expected.  However, inspecting the trace output shows that data is being copied on and off the GPU for each call to `dynamic_stitch`.  This is something specific to the `dynamic_stitch` implementation, because using `tf.gather` (a similar indexed read operation, and functionally equivalent in this case), doesn't show this behaviour.

Is this intended behaviour for `dynamic_stitch` (i.e., the copying to and from the GPU is necessary)?  Or is this a bug?  If it isn't a bug, is there some equivalent solution that doesn't require the data to be copied back and forth?",0,,16,2017-02-03T21:48:30Z,CONTRIBUTOR
7246,Pool Allocator Problem,stat:community support,"I was running LSTM having 2 layers and 64 nodes in each layer running in batch mode with small data size. I am unable to figure out the problem. I am getting warning like 

 tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1323 get requests, put_count=2336 evicted_count=1000 eviction_rate=0.428082 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 6326 get requests, put_count=5369 evicted_count=2000 eviction_rate=0.372509 and unsatisfied allocation rate=0.470123
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 193 to 212
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1415 get requests, put_count=2440 evicted_count=1000 eviction_rate=0.409836 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1590 get requests, put_count=3623 evicted_count=2000 eviction_rate=0.552029 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1137 get requests, put_count=2186 evicted_count=1000 eviction_rate=0.457457 and unsatisfied allocation rate=0

Because of which code runs very slow.

**Machine 1**
Configuration as follows:
Environment Information (we've tried several different permutations):
OS: CentOS 7.2
CUDA: 8.0.44 and 7.5.17
CUDNN: 5.1 and 5.0
Tensorflow: 0.11.0rc0, 0.11.0, 0.12.1, 1.0.0rc0
Nvidia drivers: 352.39, 367.48
GPU:Tesla k80
servers with 2 K80 cards each (2 GPUs per card, for a total of 4 GPUs per machine).

If I run the same code on different machine the code runs fine without any warning:
**Machine 2**
OS:Ubuntu 16.04.1 LTS
CUDA: 8.0
CUDNN: 5.0
Tensorflow:0.12.1
Nvidia drivers: 367.48
GPU:GeForce GTX TITAN.
",0,,4,2017-02-03T18:00:21Z,NONE
7162,"Can't quantize nodes of an RNN (""The node has inputs from different frames."")",,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I found a few similar, but not equivalent, problems with frozen/quantized graphs:

Cannot import graph_def for 8-bit Quantized cnn model #5470

tf.import_graph_def: graph_def is invalid at node #4044

Unable to import frozen graph with batchnorm #3628 

### Environment info
Operating System: Ubuntu 16.10

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root   558720 Sep 14 20:02 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Sep 14 20:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Sep 14 20:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 Sep 14 20:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Sep 14 20:02 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://pypi.python.org/pypi/tensorflow-gpu
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`:

```
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
0.12.1
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I reduced this to a simple RNN model available here on branch tf_issue_7162: https://github.com/reuben/tf-export-test/tree/tf_issue_7162

You don't have to train it again, the repository includes a checkpoint with trained weights. If you run the commands starting from the freeze_graph in the [README](https://github.com/reuben/tf-export-test/blob/master/README.md) there, you get this error when importing the quantized graph:

```
Traceback (most recent call last):
  File ""import.py"", line 14, in <module>
    imports = tf.import_graph_def(pb, name="""")
  File ""/home/reuben/.local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 339, in import_graph_def
    % (input_name,)))
ValueError: graph_def is invalid at node u'RNN/cond/Greater/y': More inputs specified ('RNN/cond/Switch:0') than the op expects..
```",1,,25,2017-01-31T13:42:51Z,NONE
7149,[Java][Feature] Generating operation methods used to build a graph,"stat:contributions welcome,type:feature","As suggested in https://www.tensorflow.org/versions/r0.11/how_tos/language_bindings, the list of operation methods for building a graph should be generated dynamically from the list exposed by the core, using preferably protobuf. 

Is anyone already working on that feature? If not, I'm tempted to try it. I was thinking of generating a builder hierarchy that allows to optionally set an argument after adding an operation. For example
```java
GraphBuider
    .matMul(a, b)
        .withTransposeB(true)
    .softmax(logits)
    ...
```
and the GraphBuilder classes would be generated at build time by Bazel and would make use of the already existing OperationBuilder. Since I'm new to Tensorflow, please tell me if that doesn't make any sense to you

Thanks

(p.s. as suggested by @drpngx, I've started this discussion as a seperate issue to avoid continuing the #5 saga)",0,,10,2017-01-30T18:24:34Z,CONTRIBUTOR
7133,Loading Files with New Tensorflow,,"Using newest version of Tensorflow on Linux.

Ok so I had a working Saver.restore going for literally months and everyone was fine:
saver = tf.train.Saver()
saver.restore(sess, ""deep_tweet_lstm_w-300000"")

deep_tweet_lstm_w-300000 was the name of the file with the data points.

Ever since updating my Tensorflow I get this error: 
NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for deep_tweet_lstm_w-300000

I honestly find this change infuriating, how in the world do I load this file with the new Tensorflow?  ",1,,18,2017-01-29T18:37:40Z,NONE
7129,Possible bug in ctc_beam_search_test.cc ?,,"Hello,

I've found something very confusing in the above file, I can't see how [line number 54](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_beam_search_test.cc#L54) can work correctly.

```
 to_state->labels.push_back(to_label);
```

From what I can make out each child beam entry has a new state associated with it, so the `to_state` being passed to the `ExpandState` method should only ever be called with a single label, representing the current class at that time.

I'm attempting to integrate a full n-gram language model into a beam scorer and this certainly seems to be the case. In order to build a string of all characters in the beam I must make a reference back to `from_state` in my `HistoryBeamState` and traverse back up the tree.

This is not the case in the unit test though, and in fact if I log some output there I can see the `to_state` being reused with different `to_label` values. Hence the test does pass.

Have I greatly misunderstood something here or is this not what the expected behaviour should be? I notice the test has a beam width less that the number of classes in the input tensor, which I guess is not so realistic? Perhaps I'm seeing an artifact of this?

Any feedback would be great, I think understanding is correct but can't make sense of this unit test.",1,,6,2017-01-29T00:05:21Z,NONE
7128,QR decomposition is slow,stat:contributions welcome,"We are doing a bunch of of QR decompositions in numpy. I did preliminary investigation of moving them to TF, but TF version is slow compared to numpy.

Below is a benchmark script that runs QR decomposition of 4096x4096 matrix. It took 7.3 seconds in TF and 1.93 in numpy MKL. Numpy MKL is the default numpy that comes when installing Anaconda.

version: HEAD from last week, built with `--config=cuda --config=opt`
cpu: 32 core Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz
https://github.com/yaroslavvb/stuff/blob/master/tiny_runs/qr_test.py

Note that `pip install --upgrade $TF_BINARY_URL` will overwrite MKL numpy with OpenBLAS numpy that is actually slower than TF version. The way to check is to look at `np.__config__.show()` and look for strings like `mkl_intel_lp64`. You can get MKL version back by uninstalling numpy and doing `conda install numpy`

@rmlarsen 
",1,,14,2017-01-28T19:20:15Z,CONTRIBUTOR
7116,Packet16q16i does not name a type,"stat:awaiting response,type:build/install","When I compile from source using the flag of AVX512 on Xeon Phi with gcc, I come across a problem as below:
ERROR: tensorflow/tensorflow/core/kernels/BUILD:895:1: C++ compilation of rule '//tensorflow/core/kernels:gather_functor' failed: gcc failed: error executing command /opt/rh/devtoolset-4/root/usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/opt/rh/devtoolset-4/root/usr/bin -B/usr/bin -Wunused-but-set-parameter ... (remaining 56 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:35:0,
                 from ./tensorflow/core/framework/numeric_types.h:25,
                 from ./tensorflow/core/framework/type_traits.h:22,
                 from ./tensorflow/core/kernels/gather_functor.h:22,
                 from tensorflow/core/kernels/gather_functor.cc:50:
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX512.h:84:11: error: 'Packet16q16i' does not name a type
   typedef Packet16q16i half;
           ^
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX512.h:135:11: error: 'Packet16q16i' does not name a type
   typedef Packet16q16i half;

Is it caused by some code missing? I add some code in the file PacketMathAVX512.h:
typedef struct Packet16q16i {
  __m512i val;
  operator __m512i() const { return val; }
  Packet16q16i();
  Packet16q16i(__m512i val) : val(val) {}
} Packet16q16i;

However, it is still failed with the following issue:

ERROR: tensorflow/tensorflow/core/kernels/BUILD:346:1: C++ compilation of rule '//tensorflow/core/kernels:split_lib' failed: gcc failed: error executing command 

external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GenericPacketMath.h:478:16: error: 'alignment' is not a member of 'Eigen::internal::unpacket_traits<Eigen::internal::Packet64q8u>'
   if(Alignment >= unpacket_traits<Packet>::alignment)
                ^
I am not sure if I did something wrong. Can someone help?

I use the command provided in [https://github.com/tensorflow/tensorflow/issues/4775](url)
bazel build --ignore_unsupported_sandboxing -c opt //tensorflow/tools/pip_package:build_pip_package  --copt ""-mavx512f"" --copt ""-mavx512cd"" --copt ""-mavx512er"" --copt ""-mavx512pf"" --copt ""-mavx2"" --copt ""-fopt-info-vec-all"" --copt ""-DEIGEN_ENABLE_AVX512"" --copt ""-DEIGEN_ENABLE_AVX2""  --verbose_failures   -j 64

The gcc version is 5.3.

BTW, I also tried to use Intel compiler to compile the code, but failed. I saw two issues are discussed, but it seems that there is no solution. ",1,,27,2017-01-27T21:15:26Z,NONE
7108,Tensorflow freezes on iOS during Session::Run,"stat:community support,type:bug/performance","Tensorflow hangs on iOS during Session::Run. I have a deep LSTM model that requires running session.run many times. The program occasionally hangs after running a few sessions without consuming any cpu. Tensorflow seems to get stuck at DirectSession::WaitForNotification.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

https://github.com/tensorflow/tensorflow/issues/2121
https://github.com/tensorflow/tensorflow/issues/2788

### Environment info
Operating System: iOS

git rev-parse HEAD:  e60e72435f0dfebe6424ab4c525523486006d47a

Build label: 0.2.3
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue May 17 14:22:21 2016 (1463494941)
Build timestamp: 1463494941
Build timestamp as int: 1463494941

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

    std::vector<tensorflow::Tensor> outputs;
    for (int t = 0; t < count; ++t) {        
        std::vector<std::pair<std::string, tensorflow::Tensor>> feed =....
        auto status = g_session->Run(feed, out_layer_names, {}, &outputs);
        if (!status.ok()) {
            LOG(ERROR) << status.ToString();
            return @""Internal Error!"";
        }
        ....
    }

### Logs or other output that would be helpful

This is a stack trace of all of the threads when the program freezes:

* thread #1: tid = 0x206350, 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8, queue = 'com.apple.main-thread', stop reason = signal SIGSTOP
    frame #0: 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #1: 0x000000018331c9c0 libsystem_pthread.dylib`_pthread_cond_wait + 640
    frame #2: 0x0000000182c453ec libc++.1.dylib`std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 56
    frame #3: 0x00000001000ef6fc App`tensorflow::DirectSession::WaitForNotification(tensorflow::Notification*, long long) + 176
    frame #4: 0x00000001000eb1cc App`tensorflow::DirectSession::WaitForNotification(tensorflow::DirectSession::RunState*, tensorflow::CancellationManager*, long long) + 48
    frame #5: 0x00000001000e91b8 App`tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<tensorflow::Tensor, std::__1::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) + 1868
  * frame #6: 0x00000001000e8a40 App`tensorflow::DirectSession::Run(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<tensorflow::Tensor, std::__1::allocator<tensorflow::Tensor> >*) + 112
    frame #7: 0x000000010052e01c App`tensorflow::internal::AppendProtoDebugString(tensorflow::strings::ProtoTextOutput*, tensorflow::Feature const&) + 6028
    frame #8: 0x000000010053c138 App`main + 24316
    frame #9: 0x0000000100535f00 App`tensorflow::internal::AppendProtoDebugString(tensorflow::strings::ProtoTextOutput*, tensorflow::Feature const&) + 38512
    frame #10: 0x0000000100535794 App`tensorflow::internal::AppendProtoDebugString(tensorflow::strings::ProtoTextOutput*, tensorflow::Feature const&) + 36612
    frame #11: 0x000000018a173d30 UIKit`-[UIApplication sendAction:to:from:forEvent:] + 96
    frame #12: 0x000000018a2e7880 UIKit`-[UIBarButtonItem(UIInternal) _sendAction:withEvent:] + 168
    frame #13: 0x000000018a173d30 UIKit`-[UIApplication sendAction:to:from:forEvent:] + 96
    frame #14: 0x000000018a173cb0 UIKit`-[UIControl sendAction:to:forEvent:] + 80
    frame #15: 0x000000018a15e128 UIKit`-[UIControl _sendActionsForEvents:withEvent:] + 452
    frame #16: 0x000000018a15e290 UIKit`-[UIControl _sendActionsForEvents:withEvent:] + 812
    frame #17: 0x000000018a17359c UIKit`-[UIControl touchesEnded:withEvent:] + 584
    frame #18: 0x000000018a1730c4 UIKit`-[UIWindow _sendTouchesForEvent:] + 2484
    frame #19: 0x000000018a16e328 UIKit`-[UIWindow sendEvent:] + 2988
    frame #20: 0x000000018a13eda0 UIKit`-[UIApplication sendEvent:] + 340
    frame #21: 0x000000018a92875c UIKit`__dispatchPreprocessedEventFromEventQueue + 2736
    frame #22: 0x000000018a922130 UIKit`__handleEventQueue + 784
    frame #23: 0x0000000184236b5c CoreFoundation`__CFRUNLOOP_IS_CALLING_OUT_TO_A_SOURCE0_PERFORM_FUNCTION__ + 24
    frame #24: 0x00000001842364a4 CoreFoundation`__CFRunLoopDoSources0 + 524
    frame #25: 0x00000001842340a4 CoreFoundation`__CFRunLoopRun + 804
    frame #26: 0x00000001841622b8 CoreFoundation`CFRunLoopRunSpecific + 444
    frame #27: 0x0000000185c16198 GraphicsServices`GSEventRunModal + 180
    frame #28: 0x000000018a1a97fc UIKit`-[UIApplication _run] + 684
    frame #29: 0x000000018a1a4534 UIKit`UIApplicationMain + 208
    frame #30: 0x00000001005362b4 App`main + 120
    frame #31: 0x00000001831455b8 libdyld.dylib`start + 4

  thread #4: tid = 0x206397, 0x000000018331ad88 libsystem_pthread.dylib`start_wqthread
    frame #0: 0x000000018331ad88 libsystem_pthread.dylib`start_wqthread

  thread #8: tid = 0x20639b, 0x0000000183239188 libsystem_kernel.dylib`mach_msg_trap + 8, name = 'com.apple.uikit.eventfetch-thread'
    frame #0: 0x0000000183239188 libsystem_kernel.dylib`mach_msg_trap + 8
    frame #1: 0x0000000183238ff8 libsystem_kernel.dylib`mach_msg + 72
    frame #2: 0x00000001842365d0 CoreFoundation`__CFRunLoopServiceMachPort + 192
    frame #3: 0x00000001842341ec CoreFoundation`__CFRunLoopRun + 1132
    frame #4: 0x00000001841622b8 CoreFoundation`CFRunLoopRunSpecific + 444
    frame #5: 0x0000000184c9f26c Foundation`-[NSRunLoop(NSRunLoop) runMode:beforeDate:] + 304
    frame #6: 0x0000000184cbfdd0 Foundation`-[NSRunLoop(NSRunLoop) runUntilDate:] + 96
    frame #7: 0x000000018ab1dc38 UIKit`-[UIEventFetcher threadMain] + 136
    frame #8: 0x0000000184d9ce68 Foundation`__NSThread__start__ + 1024
    frame #9: 0x000000018331d850 libsystem_pthread.dylib`_pthread_body + 240
    frame #10: 0x000000018331d760 libsystem_pthread.dylib`_pthread_start + 284
    frame #11: 0x000000018331ad94 libsystem_pthread.dylib`thread_start + 4

  thread #9: tid = 0x2063c0, 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #0: 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #1: 0x000000018331c9c0 libsystem_pthread.dylib`_pthread_cond_wait + 640
    frame #2: 0x0000000182c453ec libc++.1.dylib`std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 56
    frame #3: 0x000000010019535c App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 6296
    frame #4: 0x0000000100194e40 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 4988
    frame #5: 0x00000001001949dc App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3864
    frame #6: 0x00000001001946e4 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3104
    frame #7: 0x00000001001a5828 App`void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 100
    frame #8: 0x000000018331d850 libsystem_pthread.dylib`_pthread_body + 240
    frame #9: 0x000000018331d760 libsystem_pthread.dylib`_pthread_start + 284
    frame #10: 0x000000018331ad94 libsystem_pthread.dylib`thread_start + 4

  thread #10: tid = 0x2063c1, 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #0: 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #1: 0x000000018331c9c0 libsystem_pthread.dylib`_pthread_cond_wait + 640
    frame #2: 0x0000000182c453ec libc++.1.dylib`std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 56
    frame #3: 0x000000010019535c App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 6296
    frame #4: 0x0000000100194e40 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 4988
    frame #5: 0x00000001001949dc App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3864
    frame #6: 0x00000001001946e4 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3104
    frame #7: 0x00000001001a5828 App`void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 100
    frame #8: 0x000000018331d850 libsystem_pthread.dylib`_pthread_body + 240
    frame #9: 0x000000018331d760 libsystem_pthread.dylib`_pthread_start + 284
    frame #10: 0x000000018331ad94 libsystem_pthread.dylib`thread_start + 4

  thread #11: tid = 0x2063c2, 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #0: 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #1: 0x000000018331c9c0 libsystem_pthread.dylib`_pthread_cond_wait + 640
    frame #2: 0x0000000182c453ec libc++.1.dylib`std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 56
    frame #3: 0x000000010019535c App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 6296
    frame #4: 0x0000000100194e40 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 4988
    frame #5: 0x00000001001949dc App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3864
    frame #6: 0x00000001001946e4 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3104
    frame #7: 0x00000001001a5828 App`void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 100
    frame #8: 0x000000018331d850 libsystem_pthread.dylib`_pthread_body + 240
    frame #9: 0x000000018331d760 libsystem_pthread.dylib`_pthread_start + 284
    frame #10: 0x000000018331ad94 libsystem_pthread.dylib`thread_start + 4

  thread #12: tid = 0x2063c3, 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #0: 0x0000000183256e1c libsystem_kernel.dylib`__psynch_cvwait + 8
    frame #1: 0x000000018331c9c0 libsystem_pthread.dylib`_pthread_cond_wait + 640
    frame #2: 0x0000000182c453ec libc++.1.dylib`std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 56
    frame #3: 0x000000010019535c App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 6296
    frame #4: 0x0000000100194e40 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 4988
    frame #5: 0x00000001001949dc App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3864
    frame #6: 0x00000001001946e4 App`tensorflow::thread::ThreadPool::CurrentThreadId() const + 3104
    frame #7: 0x00000001001a5828 App`void* std::__1::__thread_proxy<std::__1::tuple<std::__1::function<void ()> > >(void*) + 100
    frame #8: 0x000000018331d850 libsystem_pthread.dylib`_pthread_body + 240
    frame #9: 0x000000018331d760 libsystem_pthread.dylib`_pthread_start + 284
    frame #10: 0x000000018331ad94 libsystem_pthread.dylib`thread_start + 4

",0,,23,2017-01-27T09:39:30Z,CONTRIBUTOR
7094,Feature request: Multi-label Binarizer (k-hot),"stat:contributions welcome,type:feature","Hi, I feel like an array op that converts between iterable of iterables and a multi-label format would be useful for preprocessing in multi-label tasks. Basically a tensorflow version of a sklearn [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) that can iterate through Tensors.
I would assume a `tf.one_hot()` modification can work.
Thanks.",0,,6,2017-01-26T15:51:35Z,CONTRIBUTOR
7091,Feature request: let tf.layers.batch_normalization normalize over multiple axes,"stat:contributions welcome,type:feature","When using `tf.nn.batch_normalization` and `tf.nn.moments` it's possible to choose which axes are aggregated and thus which dimensions are normalized. For `tf.contrib.layers.batch_norm` and `tf.contrib.layers.layer_norm` the assumption is that only one dimension is normalized. There are use cases where it would be nice to independently normalize across both width and filters (for example audio spectrograms, where ""width"" could be seen as the time axis). Could the layers API be changed to be as flexible as `tf.nn.batch_normalization`?",0,,11,2017-01-26T14:12:34Z,CONTRIBUTOR
7030,Feature Request: an op that returns bytes_in_use for its device,"stat:contributions welcome,type:bug/performance,type:feature","We are trying to optimize some models to fit into TitanX's 12GB of RAM, and it's hard because of lack of transparency in TF available memory.

What would help this situation is an op that returns amount of bytes on its device when executed. Something similar to what's done in [stack_ops](https://github.com/tensorflow/tensorflow/blob/64edd34ce69b4a8033af5d217cb8894105297d8a/tensorflow/core/kernels/stack_ops.cc#L222) for memory-aware heuristics

```
DeviceContext* device_ctxt = ctx->op_device_context();
auto device = static_cast<tensorflow::Device*>(ctx->device());
Allocator* allocator = device->GetAllocator(alloc_attrs);
AllocatorStats stats;
allocator->GetStats(&stats)
//  output stats.bytes_in_use

```

This op can be wedged between other ops using control dependencies and used for memory debugging. This is complementary to request in https://github.com/tensorflow/tensorflow/issues/6716 because it would account for memory from parallel run calls, variables, persistent tensors.

I can take this issue if this op fits into TF framework",0,,16,2017-01-24T01:25:10Z,CONTRIBUTOR
7004,Build with --define tensorflow_xsmm=1 fails on MacOS Sierra,stat:contributions welcome,"Building current master after the recent commits to enable libxsmm.

    bazel build --copt=-march=native -c opt --define tensorflow_xsmm=1 --verbose_failures //tensorflow/tools/pip_package:build_pip_package

The important error lines (I think) are:

> tensorflow/core/kernels/sparse_matmul_op.cc:1408:3: error: unknown type name 'cpu_set_t'
  cpu_set_t old_cpu_set;
  
> tensorflow/core/kernels/sparse_matmul_op.cc:1413:39: error: use of undeclared identifier 'cpu_set_t'
    ret = sched_getaffinity(0, sizeof(cpu_set_t), &old_cpu_set);

The full result of --verbose_failures is attached.
[tf_libxsmm_error.txt](https://github.com/tensorflow/tensorflow/files/721760/tf_libxsmm_error.txt)

Searching for 'cpu_set_t' on OSX turned up [this code example under heading 2.2](https://github.com/Cibiv/NextGenMap/issues/6) and claims that 'cpu_set_t' is not defined on OSX and Apple's own multithreading code needs to be substituted. So maybe the code using 'cpu_set_t' is not meant to be reached on Macs and the libxsmm code is not ready to be used on my machine.





",0,,4,2017-01-22T07:11:54Z,CONTRIBUTOR
6992,Feature request: LU Decomposition,"stat:awaiting tensorflower,type:feature","I suggest adding LU decomposition with partial pivoting to Tensorflow. The implementation must support rectangular matrices as well, and not only square matrices. Tensorflow already uses LU decomposition for solving linear systems of equations.

LU decomposition can be used as an efficient algorithm for finding the range of a matrix and its low rank approximation. The advantages over QR and SVD are that LU is more computationally efficient and is very suited for GPUs giving a significant speed boost to many computational tasks.

See the following papers:

1) Li, H., Linderman, G. C., Szlam, A., Stanton, K. P., Kluger, Y., & Tygert, M. (2017). Algorithm 971: An Implementation of a Randomized Algorithm for Principal Component Analysis. ACM Transactions on Mathematical Software (TOMS), 43(3), 28
2) Shabat, G., Shmueli, Y., Aizenbud, Y., & Averbuch, A. (2016). Randomized LU decomposition. Applied and Computational Harmonic Analysis.
3) Li, H., Kluger, Y., & Tygert, M. (2016). Randomized algorithms for distributed computation of principal component analysis and singular value decomposition. arXiv preprint arXiv:1612.08709.

",0,,7,2017-01-21T10:01:30Z,NONE
6955,Better way to transfer data from memory to tensor in C++ API,stat:contributions welcome,"This is more of a general feature request for a better way to load data into a tensor in the C++ API, but I'll take our specific case as a reference.

We currently train a model in Python, freeze it, and load it in a C++ production pipeline. This works fine, but it seems the only way of loading data into a tensor is by looping through every single element in the data and copying it to a tensor. In our case, we're dealing with a 1920x1080 ~30 fps video input signal (each frame coming as an OpenCV matrix) making it infeasible to do if we want to process a video within a reasonable amount of time.

It seems there is a way of creating a tensor from a pointer in the C API (see http://stackoverflow.com/questions/39379747/import-opencv-mat-into-c-tensorflow-without-copying), which we will test next, but it would be nice to also have this functionality in the C++ API.

For reference, it takes approximately 900 ms to copy from an 1920x1080x3 OpenCV matrix to a tensor while it takes 315 ms to do session.run (which I assume includes transferring between CPU and GPU memory). 

An issue related to this is that we will probably already have the data on the GPU from some earlier preprocessing, so we would also be very interested in not having to transfer between CPU and GPU unnecessarily.

So I guess it boils down to:

1. Are there any plans for making it easier to load data already in memory to a tensor?
2. How can we contribute?",0,,17,2017-01-19T10:46:37Z,CONTRIBUTOR
6925,support for depth pooling in maxpool3d?,stat:contributions welcome,"Is depth pooling in the works for MaxPool3D? Any pointers on how I should/could get this going myself? 
```
UnimplementedError (see above for traceback): Pooling is not yet supported on the depth dimension.
[[Node: max_pool_1 = MaxPool3D[T=DT_FLOAT, ksize=[1, 2, 2, 2, 64], padding=""VALID"", strides=[1,
 1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_1)]]
```
Here's an example of how I'm using it:
```Python
def maxpool3d(input_, kd, kh, kw, stride=1,scope=None):
    input_cdim = input_.get_shape().as_list()[-1]
    batch_size = input_.get_shape().as_list()[0]
    kernel = [batch_size, kd, kh, kw, input_cdim]
    return tf.nn.max_pool3d(input_, kernel,
        strides=[1,stride,stride,stride,1], padding=""VALID"", name=scope)
# ...
# Perform 2 3D convolutions without max pooling.
x = tf.nn.relu(conv3d(x, 4, 4, 4, 64, scope=""conv_1""))
x = tf.nn.relu(conv3d(x, 4, 4, 4, 64, scope=""conv_2""))

# Downsample with max pooling.
x = maxpool3d(x, 2, 2, 2, scope=""max_pool_1"")
```",0,,5,2017-01-18T10:19:29Z,NONE
6893,get_matching_files issue,"stat:contributions welcome,type:bug/performance,type:feature","In [saver.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py), if the argument of `get_matching_files` is a relative path with no ./ in the beginning, `get_matching_files` will return an empty list. e.g., `get_matching_files(""filename"")` returns `[]`, while `get_matching_files(""./filename"")` returns `['filename']`

Thus when using [freeze_graph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) with input checkpoint in the same directory, I found the issue below:

```
python freeze_graph.py \
--input_graph=input_graph.pb \
--input_checkpoint=input.ckpt \
--output_graph=output_graph.pb \
--output_node_names=Softmax

Input checkpoint 'input.ckpt' doesn't exist!
```

",0,,4,2017-01-17T05:33:55Z,CONTRIBUTOR
6847,Better documentation for tf.extract_image_patches,"stat:contributions welcome,type:docs","In this [issue](https://github.com/tensorflow/tensorflow/issues/6743#issuecomment-272525783) someone requested a reverse operation to `tf.extract_image_patches`. The comments suggest that there exists a [gradient operation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_grad.py#L575) for this purpose which was added with [this PR](https://github.com/tensorflow/tensorflow/pull/3672).

Unfortunately it is not obvious how to apply this gradient operation and there are no information on this in the [api docs](https://www.tensorflow.org/versions/master/api_docs/python/array_ops/slicing_and_joining#extract_image_patches) therefor I request to add an example to [tf.extract_image_patches](https://github.com/tensorflow/tensorflow/blob/a4c8df209d7413068f4ed3e71c43eb798fbd5580/tensorflow/g3doc/api_docs/python/functions_and_classes/shard4/tf.extract_image_patches.md) where one transforms an `image` tensor of shape `(image_height, image_width, channels)` to `(patch_num, patch_height, patch_width, channels)` and vice versa.

Thank you in advance!",0,,11,2017-01-14T08:29:25Z,NONE
6815,keep_dims vs keepdims,type:feature,"There are 15 results for [keepdims](https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=keepdims) and 77 results for [keep_dims](https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=keep_dims&type=Code) in TF codebase, any chance this can be made consistent in 1.0? Ideally TF would just match numpy API and use `keepdims` @martinwicke @karpathy

",1,,6,2017-01-12T20:30:55Z,CONTRIBUTOR
6774,`import_meta_graph` appends `_1` to node in GraphDef but doesn't add `_1` to Variable name in Collection,type:bug/performance,"In an example below, second `import_meta_graph` will create variable nodes `[a, a_1]`, but corresponding global variables collection has variables `[a, a]`. So now `report_uninitialized_variables` is empty, even though there's an uninitialized variable `a_1` in the graph. Example below crashes with `uninitialized` error.

```
import tensorflow as tf

tf.reset_default_graph()
sess = tf.Session()
tf.Variable(tf.ones(()), name='a')
sess.run(tf.global_variables_initializer())
saver = tf.train.Saver()
saver.save(sess, 'dummy')
        
tf.reset_default_graph()
sess = tf.Session()
saver = tf.train.import_meta_graph('dummy.meta')
saver = tf.train.import_meta_graph('dummy.meta')
saver.restore(sess, './dummy')
sess.run(tf.initialize_all_variables())
sess.run(tf.report_uninitialized_variables())  # => prints empty
sess.run(""a_1:0"")   # => crashes with a_1 not initialized
```",0,,8,2017-01-10T22:11:24Z,CONTRIBUTOR
6767,dynamic_rnn slower using master code then 0.12.1 release code,"stat:awaiting tensorflower,type:bug/performance","For master code, git rev-parse HEAD 
ec7929b878926c39255254e9aea992f0bc65aa68

same code running for 0.12.1
 batch_size:[256] batches/s:[4.76] insts/s:[1217.74] 
 batch_size:[256] batches/s:[5.39] insts/s:[1379.17] 
 batch_size:[256] batches/s:[5.11] insts/s:[1306.94] 
 batch_size:[256] batches/s:[5.05] insts/s:[1292.61] 

for master code:
batch_size:[256] batches/s:[4.18] insts/s:[1069.37] 
 batch_size:[256] batches/s:[4.77] insts/s:[1220.00] 
 batch_size:[256] batches/s:[4.81] insts/s:[1231.52] 
batch_size:[256] batches/s:[4.55] insts/s:[1164.99] 


",1,,11,2017-01-10T12:20:45Z,NONE
6733,Export meta graph option in image retraining,"stat:awaiting tensorflower,type:feature","I was trying to tensorflow serve my retrained graph ( *.pb file ) but if I understand correctly it doesn't contain meta graph in it, so wouldn't it be nice to have export meta graph options in retrain.py ?",0,,4,2017-01-09T06:13:53Z,NONE
6720,tf.image.resize_images() - weird padding behaviour? ,"stat:contributions welcome,type:bug/performance","The tf.image.resize_images() seems to use a strange padding option, which one is not clear to me at the moment. I tried to replicate the bilinear interpolation with various padding options in for example skimage, but cant replicate the behaviour.

It would be nice to be able to set the padding option used in tf.images.resize_images(), or document what is used at least.

Example code for comparing the results of  tf.images.resize_images() and skimage transform:
Looks like  tf.images.resize_images() does some weird unsymmetrical padding!?
Using tensorflow 0.12.1:
```
import tensorflow as tf
import tensorlayer as tl
import numpy as np
import skimage
from scipy.misc import imread, imresize, imsave

sess = tf.InteractiveSession()

#create simple test image
imsize = 3
xa, ya = np.ogrid[:imsize, :imsize]
img = np.repeat((xa + ya)[..., np.newaxis], 3, 2) / float(imsize + imsize)

x = tf.placeholder(tf.float32, [1, imsize, imsize, 3])
y = tf.image.resize_images(x,(imsize*3, imsize*3))

sess.run(tf.global_variables_initializer())

upsampled_tf_result = sess.run(y, feed_dict={x: [img]})
upsampled_skimage_result = skimage.transform.rescale(img,
                                     3,
                                     mode='symmetric',
                                     cval=0,
                                     order=1,
                                     preserve_range=False)

print(np.allclose(upsampled_tf_result, upsampled_skimage_result))

imsave('upsampled_tf_result.png', np.squeeze(upsampled_tf_result))
imsave('upsampled_skimage_result.png', upsampled_skimage_result)
```",0,,15,2017-01-08T02:00:42Z,NONE
6716,Feature request: easier access to tensor de-allocation information,type:feature,"TLDR; to debug TensorFlow out-of-memory situations one needs to see tensor de-allocation info.

You can see allocation stats in timeline, but without de-allocation info you can't calculate peak memory. Currently getting peak memory is possible by:

1. Hacking TensorFlow to print deallocation messages with timestamps as [here](https://github.com/yaroslavvb/tensorflow/commit/5d4cd97c0a73e91ee37c025cd7a62fb46aae76a0)

2. A bunch of regular expression to parse `__LOG_MEMORY__` messages as in [here](https://github.com/yaroslavvb/notebooks/blob/master/saving%20memory%20by%20using%20functions.ipynb)

Since this needs building your own version of tensorflow, this is not accessible to most people. Perhaps this can be remedied by adding deallocation events to session run timeline? @michaelisard 

Some recent places this issue came up:
http://stackoverflow.com/questions/41517145/outer-product-based-conv-filters-consume-disproportionately-high-memory
http://stackoverflow.com/questions/41496251/fitting-large-matrix-calculations-into-memory-when-using-tensorflow
http://stackoverflow.com/questions/41451273/tensorflow-specifying-storage-of-layer-activations
http://stackoverflow.com/questions/40190510/tensorflow-how-to-log-gpu-memory-vram-utilization/40197094#comment70145571_40197094
https://github.com/tensorflow/tensorflow/issues/6019#issuecomment-268037463",1,,20,2017-01-07T20:07:38Z,CONTRIBUTOR
6683,Tensorflow Model with CTC loss having save and restore problem,,"I am using tensorflow 0.12 without GPU support. I was testing it with various models. My template structure is
```
#Load some data from file
graph=tf.Graph()
with graph.as_default():
     #Build Network
     #saver=tf.train.Saver()
with tf.Session(graph=graph) as session:
     if(sys.argv[1]==""load""):
          saver.restore(session,""weight_last"")
     else:
           initop=tf.global_variables_initializer()
           session.run(initop)
    #Continue Training
```
Now, I am facing a strange issue. When I am creating a MLP or RNN with this structure with a categorical cross entropy loss model this saving and restoring is working perfectly, i.e. after restore the loss is showing exact value that was showed during last save. But unfortunately when the network is loaded with CTC loss then after restoring the model is starting almost a new training. I am not sure what is going wrong? Any help shall be highly appreciated.",1,,64,2017-01-06T07:19:15Z,NONE
6635,Incorrect gradient when using tf.dynamic_stitch and tf.gather?,type:bug/performance,"In Tensorflow 0.12, I find the discrepancy of gradients in two mathematically equivalent training procedures of LSTM, probably due to the use of tf.gather and tf.dynamic_stitch.  One is the normal procedure using the whole batch of training examples to unroll the LSTM in each step. The other first uses tf.gather to select ALL the examples of the whole batch in each step, then unroll the LSTM with those examples and finally use tf.dynamic_stitch to update the corresponding states and outputs.

These two procedures should be equivalent as they both essentially use the whole batch. However, the gradients of the same variables are significantly different.

The code is as follows (the core parts are essentially `# 1.` and  `# 2.`):

```python
batch_size = 2
num_timesteps = 10
vocab_size = 10
num_embedding_nodes = 32
hidden_size = 128
n_class = 2
learning_rate = 0.001
inputs = tf.placeholder(tf.int64, [batch_size, num_timesteps])
targets = tf.placeholder(tf.int64, [batch_size])
embedding = tf.get_variable(""embedding"", [vocab_size, num_embedding_nodes])
x = tf.nn.embedding_lookup(embedding, inputs)
w_predict = tf.get_variable(""w_predict"", [hidden_size, n_class])
b_predict = tf.get_variable(""b_predict"", [n_class])

with tf.variable_scope('lstm') as lstm_scope:
  cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=1.0, state_is_tuple=False)
  state = cell.zero_state(batch_size, dtype=tf.float32)
  state1 = cell.zero_state(batch_size, dtype=tf.float32)
  for t in range(num_timesteps):
    if t == 0:
      output, state = cell(x[:, t, :], state)
      lstm_scope.reuse_variables()
      output1, state1 = cell(x[:, t, :], state1)
    else:
      lstm_scope.reuse_variables()
      # 1. normal lstm 
      output, state = cell(x[:, t, :], state)
      # 2. lstm using tf.gather and tf.dynamic_stitch to select all samples from batch
      idx_select = tf.range(batch_size)
      tmp_output, tmp_state = cell(tf.gather(x[:, t, :], idx_select), tf.gather(state1, idx_select))
      output1 = tf.dynamic_stitch([tf.range(batch_size), idx_select], [output1, tmp_output])
      state1 = tf.dynamic_stitch([tf.range(batch_size), idx_select], [state1, tmp_state])
logits = tf.nn.xw_plus_b(output, w_predict, b_predict)
cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, targets, name=None)
logits1 = tf.nn.xw_plus_b(output1, w_predict, b_predict)
cross_entropy1 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits1, targets, name=None)
trainable = tf.trainable_variables()
grad = tf.gradients(cross_entropy, trainable)
grad1 = tf.gradients(cross_entropy1, trainable)

######## gradient log
cg = []
for g in grad:
  if g is not None:
    cg += [g]
cg1 = []
for g in grad1:
  if g is not None:
    cg1 += [g]

optimizer = tf.train.AdamOptimizer(learning_rate)
train_op = optimizer.apply_gradients(zip(grad, trainable))
init_op = tf.initialize_all_variables()


"""""" Training """"""
## arbitrary synthetic data
# we use two training examples, each with length 10
my_input = np.array([[3,4,6,8,3,5,8,9,2,4], [4,2,3,8,5,2,2,3,6,1]])
my_target = np.array([0,1])
sess = tf.Session()
sess.run(init_op)

epoch = 0
while epoch < 5:
  epoch += 1
  fetches = [train_op, cg, cg1]
  outputs = sess.run(fetches, feed_dict={inputs: my_input, targets: my_target})
  gradients = outputs[1] 
  gradients1 = outputs[2] 
  print 'epoch %d:' % epoch 
    for i, g in enumerate(gradients):
      if i > 0:
	print('norm of gradient of var %d: %f' % (i, LA.norm(gradients[i])))
	print('norm of gradient1 of var %d: %f' % (i, LA.norm(gradients1[i])))
```

The sample output is:
```
epoch 1:
norm of gradient of var 1: 0.644620
norm of gradient1 of var 1: 0.644620
norm of gradient of var 2: 0.393020
norm of gradient1 of var 2: 0.393020
norm of gradient of var 3: 0.838759
norm of gradient1 of var 3: 102.815338
norm of gradient of var 4: 0.435841
norm of gradient1 of var 4: 44.867126
epoch 2:
norm of gradient of var 1: 0.613848
norm of gradient1 of var 1: 0.611423
norm of gradient of var 2: 0.355387
norm of gradient1 of var 2: 0.351987
norm of gradient of var 3: 0.797761
norm of gradient1 of var 3: 96.391121
norm of gradient of var 4: 0.397020
norm of gradient1 of var 4: 39.937107
epoch 3:
norm of gradient of var 1: 0.603118
norm of gradient1 of var 1: 0.603118
norm of gradient of var 2: 0.318260
norm of gradient1 of var 2: 0.318260
norm of gradient of var 3: 0.773661
norm of gradient1 of var 3: 93.290131
norm of gradient of var 4: 0.366684
norm of gradient1 of var 4: 36.636879
epoch 4:
norm of gradient of var 1: 0.607643
norm of gradient1 of var 1: 0.607643
norm of gradient of var 2: 0.280101
norm of gradient1 of var 2: 0.280101
norm of gradient of var 3: 0.763007
norm of gradient1 of var 3: 92.295441
norm of gradient of var 4: 0.340769
norm of gradient1 of var 4: 33.630474
epoch 5:
norm of gradient of var 1: 0.622874
norm of gradient1 of var 1: 0.619443
norm of gradient of var 2: 0.239731
norm of gradient1 of var 2: 0.235509
norm of gradient of var 3: 0.757205
norm of gradient1 of var 3: 93.335388
norm of gradient of var 4: 0.312203
norm of gradient1 of var 4: 30.536301
```

We can see that the gradient and gradient1 of var3 have significantly different norms in every epoch, which should be the same. So is var4. Those two are the trainable variables of LSTM. In fact, if the sequence length is 50 instead of 10, the discrepancy is even much larger.

Could anybody tell me why it is the case?

### Environment info
Operating System: ubuntu 14.04
",1,,7,2017-01-04T13:11:04Z,NONE
6633,CudnnRnnSequenceTensorDescriptor should support different sequence lengths,type:feature,"According to the cuDNN docs, the functions `cudnnRNNForwardInference` / `cudnnRNNForwardTraining` get the argument `cudnnTensorDescriptor_t* xDesc`, where:

xDesc: Array of tensor descriptors. Each must have the same second dimension. The first dimension may decrease from element n to element n + 1 but may not increase.

The usage of `xDesc` is a bit non-straight-forward. I wrote about that in more detail [here](http://stackoverflow.com/questions/41461670/cudnnrnnforwardtraining-seqlength-xdesc-usage).
According to a [comment in the CNTK code](https://github.com/Microsoft/CNTK/blob/7c5fb2d7d806148b5cbd795407f7c7b6a1a64520/Source/Math/CuDnnRNN.cpp) about the dimensions of each `xDesc[t]`:

> these dimensions are what CUDNN expects: (the minibatch dimension, the data dimension, and the number 1 (because each descriptor describes one frame of data)

TensorFlow sets the same minibatch dimension for each `xDesc[t]` in `CudnnRnnSequenceTensorDescriptor`:

    int dims[] = {batch_size, data_size, 1};
    int strides[] = {dims[1] * dims[2], dims[2], 1};
    status = dynload::cudnnSetTensorNdDescriptor(
        parent, handle /*tensorDesc*/, data_type /*dataType*/,
        sizeof(dims) / sizeof(dims[0]) /*nbDims*/, dims /*dimA*/,
        strides /*strideA*/);
    CUDNN_RETURN_IF_FAIL(status, ""Failed to update tensor descriptor"");
    // Replicate handle across the number of steps.
    handles_.assign(seq_length, handle);

Also `createRnnSequenceTensorDescriptor` needs a new API to allow for that.

And I'm not sure if there are ways to prepare the input `x` for `cudnnRNNForwardTraining` so that it has all sequences contiguously behind each other, and the sequences are sorted by sequences length.
Similar as [`PackSequencesForCuDNN` in CNTK](https://github.com/Microsoft/CNTK/blob/4472649412929543d4dfe553f50be5d9b3102521/Source/ComputationNetworkLib/RNNNodes.cpp#L265).
",1,,16,2017-01-04T10:56:09Z,NONE
6624,Fail with error (rather than hanging) when init_op requires starting queues (ManagedSesssion etc),"stat:awaiting response,type:bug/performance","In 0.12 and in master

`MonitoredSession` wraps the original `SessionCreator` in a `_CoordinatedSessionCreator` in an attempt to ensure queue runners are started before the session is run, however the original session has to be created first (as it is an argument to start_queue_runner). In the case of `ChiefSessionCreator`, `ChiefSessionCreator.create_session` calls `ChiefSessionCreator._get_session_manager`
which instantiates a new `SessionManager` and returns it. Then `ChiefSessionCreator.create_session` calls `SessionManager.prepare_session` which calls `sess.run(init_op)`. Thus resulting in `sess.run(init_op)` being run before `start_queue_runner` is called. 

This makes it impossible to initialize variables from queues. Even if this is intended behavior, it causes the initialization of `MonitoredSession` to stall without any logging output, and not respond to SIGTERM.

It seems that `prepare_session` may need to be split into two calls for this use case. ",0,,16,2017-01-04T02:32:48Z,NONE
6596,[ Bug ] The 2nd Saver fails to recognize its Checkpoint State file.,"stat:awaiting response,type:bug/performance","**Operating System:** macOS Sierra

**Steps to Reproduce:**
1. In a session, create two Savers.
2. Let one of the Saver save the variables.
3. Let the other Saver save the variables in a different directory from the first Saver's destination directory.

**Result:**
An Info message is displayed indicating that a Checkpoint State file does not exist (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L738). And TensorFlow creates a new Checkpoint State file. This happens every time the 2nd Saver saves the variables.

**Expected Result:**
The 2nd Saver's Checkpoint State file should be recognized.

**Code to Reproduce:**
```
with tf.Session(graph=graph) as sess:
    ...
    saver_best = tf.train.Saver()
    saver_hourly = tf.train.Saver(max_to_keep=None)  
    ...
    for i in range(max_step):
        ...
        if last_hourly_save + datetime.timedelta(hours=1) < datetime.datetime.now():                     
            path_checkpoint_file = saver_hourly.save(sess, 'checkpoint_directory/hourly/model', global_step=i, latest_filename='hourly_checkpoint')
        ...
        if best:
            path_checkpoint_file = saver_best.save(sess, 'checkpoint_directory/best/model', global_step=i, latest_filename='best_checkpoint')
        ...
```",0,,4,2017-01-01T23:06:34Z,NONE
6518,tf.sequence_mask with int64 does not work,"stat:contributions welcome,type:feature","Given some tensor `x` with shape (batch,time) and `seq_lens` of shape (batch,) of dtype `int64`, I wanted to use this code:
```
    mask = tf.sequence_mask(seq_lens, maxlen=tf.shape(x)[1])
```

This fails with `TypeError: Input 'y' of 'Less' Op has type int64 that does not match type int32 of argument 'x'.` in `gen_math_ops._range(0, maxlen, 1) < expand_dims(lengths, 1)`.

If I add `seq_lens = tf.cast(seq_lens, ""int32"")` before, then it works.

Casting `tf.shape(x)[1]` to `int64` does not work (because of `gen_math_ops._range(0, maxlen, 1)` which treats `0` and `1` as `int32` and then raises `TypeError: Input 'limit' of 'Range' Op has type int64 that does not match type int32 of argument 'start'`).
",0,,7,2016-12-27T11:47:28Z,NONE
6504,Feature Request: Gradient for QR op,"stat:contributions welcome,type:feature","The QR op is currently implemented but has no gradient.  It would be very useful if the gradient were defined so that the op could be used in networks and cost functions.
",1,,10,2016-12-26T14:15:34Z,NONE
6456,tensorflow.python.framework.errors.InvalidArgumentError,stat:awaiting tensorflower,"I getting error when using  cifar10 model to train my tfrecord datasets  which are made with tf.python_io.TFRecordWriter().

on tensorflow0.8 ,it's running ok, but on tensorflow 0.10 and 0.11 ,there is the error : tensorflow.python.framework.errors.InvalidArgumentError

File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 133, in <module>
    tf.app.run()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 129, in main
    train()
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 99, in train
    _, loss_value = sess.run([train_op, loss])
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Received a label value of 246 which is outside the valid range of [0, 20).  Label values: 10 104 185 191 178 50 116 159 192 201 173 173 81 246 110 116 153 10 114 193 167 208 173 225 97 113 84 82 179 101 90 190 107 208 155 229 239 163 28 71 173 192 200 178 83 125 238 146 213 70 34 121 129 33 207 124 157 70 117 147 80 30 153 231 156 63 130 147 143 205 86 60 97 90 202 94 127 91 191 127 123 199 201 69 220 185 152 175 86 121 60 132 73 109 100 163 218 162 201 202 40 108 63 116 195 105 124 195 107 96 86 152 58 141 166 28 55 135 128 49 180 119 237 38 59 189 202 66
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]

Caused by op u'cross_entropy_per_example/cross_entropy_per_example', defined at:
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 133, in <module>
    tf.app.run()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 129, in main
    train()
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 72, in train
    loss = cifar10.loss(logits, labels)
  File ""/Users/yang/Documents/cifar10/cifar10.py"", line 286, in loss
    logits, labels, name='cross_entropy_per_example')
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 764, in sparse_softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1857, in _sparse_softmax_cross_entropy_with_logits
    features=features, labels=labels, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 748, in apply_op
    op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Received a label value of 246 which is outside the valid range of [0, 20).  Label values: 10 104 185 191 178 50 116 159 192 201 173 173 81 246 110 116 153 10 114 193 167 208 173 225 97 113 84 82 179 101 90 190 107 208 155 229 239 163 28 71 173 192 200 178 83 125 238 146 213 70 34 121 129 33 207 124 157 70 117 147 80 30 153 231 156 63 130 147 143 205 86 60 97 90 202 94 127 91 191 127 123 199 201 69 220 185 152 175 86 121 60 132 73 109 100 163 218 162 201 202 40 108 63 116 195 105 124 195 107 96 86 152 58 141 166 28 55 135 128 49 180 119 237 38 59 189 202 66
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]",0,,7,2016-12-22T09:42:15Z,NONE
6446,TF_CUDA_VERSION and TF_CUDNN_VERSION can be too specific,"stat:awaiting tensorflower,type:build/install","If you run `./configure` and provide your own `TF_CUDA_VERSION` and `TF_CUDNN_VERSION`, you will get an error message if your version is too specific.

For example, setting `TF_CUDA_VERSION=7.5.18` will result in an error when `nvcc` reports a version `7.5`. If you set `TF_CUDNN_VERSION=5.1.3`, you get an error because `cudnn.h` reports version `5`.

I think in previous versions of TensorFlow this didn't happen, and it's only a minor annoyance, but it would be nice to fix this.",1,,5,2016-12-21T23:38:10Z,CONTRIBUTOR
6431,Does TF support multicore processing on Android?,stat:awaiting tensorflower,"As we know, iPhone play better performance than other Android mobiles on single CPU, presenting Android takes more time to run an inference. But Android usually have four or more CPU cores and iPone have only two. So I want to speed up Android's inference by using multicore processing.

**What solutions have you tried?**
I add -fopenmp build options according to Eigen multi-threading docs, but it doesn't work, the speed is still the same. 
Could anyone point me in the right direction here?
Thanks!",1,,6,2016-12-21T04:19:55Z,NONE
6417,Saver can't handle filename only ,"stat:awaiting tensorflower,type:support","Hey everyone,

it seems to me like - at least on Windows - the `tf` saver can't save model files whose path consists only of the file's name with no parent path, relative nor absolute. The issue lies at or around [saver.py:1363](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L1363) where it tries to check whether the parent directory of the file is actually a directory. There is no parent directory given (i.e. an empty string) and as such `gFile.IsDirectory` can't check anything. It fails and raises a ValueError that the parent directory does not exist. 

Expected behavior _in my opinion_ would be that the current working directory is used as the parent path when using no path/just a filename (i.e. a relative path). 

## Some details about my system specs:

* Windows 10
* Python 3.5.2
* TF 0.12.0 (in a virtual environment; `pip install tensorflow --upgrade` just executed; issue persists)


So, I'm wondering whether this is an expected behavior and how to deal with it or if it is an actual bug that needs to be addressed.",0,,16,2016-12-20T10:13:40Z,NONE
6379,Inconsistency in parameter naming,"stat:contributions welcome,type:docs,type:feature","```
tf.nn.conv1d(value, filters, stride, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
tf.nn.conv3d(input, filter, strides, padding, name=None)
```

There's discrepancy between parameter naming between conv1d and 2,3d counterparts. Firstly value vs input, and then singular vs plural filter(s) (singular would be correct as in 2d/3s case since function accepts only single filter if I understood documentation correctly.)",0,,1,2016-12-17T19:14:25Z,CONTRIBUTOR
6360,Locking mechanisms,type:feature,"Especially when integrating TensorFlow into an exiting multi-threaded application, it's not always easy to use queues for synchronization. Currently, we must use Python locks to lock the `sess.run(...)` calls from different threads. Exposing a TensorFlow lock interface could allow to synchronize access only to needed values of the session:

```python
x = tf.placeholder(tf.float32, [None, 784])
y = tf.placeholder(tf.float32, [None, 10])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))

lock = tf.Lock()
with lock:
  pred = tf.nn.softmax(tf.matmul(x, W) + b)
loss = -tf.reduce_mean(tf.reduce_sum(y * tf.log(pred), 1))
with lock:
  train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

def inference_thread():
  while True:
    # Generate data...
    sess.run(pred, data)

def training_thread():
  while True:
    # Generate data...
    sess.run(train_step, data)
```

Or simpler:

```python
with tf.Lock():
  W = tf.Variable(tf.zeros([784, 10]))
# ...
```",1,,45,2016-12-16T13:45:13Z,MEMBER
6308,Bug in error message from dynamic_rnn,stat:awaiting tensorflower,"When using inputs of dimention 2 instead of 3 I get following error

""ValueError: Dimension must be 2 but is 3 for 'transpose' ""

I believe the numbers in the error message are switched.",1,,6,2016-12-14T10:31:35Z,NONE
6269,GPU kernel for tf.random_shuffle,"stat:contributions welcome,type:feature","There doesn't seem to be a `tf.random_shuffle` impl for the GPU. Some of the work I do can utilize a GPU shuffle.

Running:
  - tf0.12RC0
  - CUDA8.0
  - CUDNN5.1
  - Titan X (non-pascal)

```bash
InvalidArgumentError (see above for traceback): Cannot assign a device to node 'RandomShuffle_8': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: RandomShuffle_8 = RandomShuffle[T=DT_FLOAT, seed=87654321, seed2=703433, _device=""/device:GPU:0""](transpose_16)]]
```",0,,11,2016-12-12T22:17:29Z,NONE
6230,Poor colors for embedding projector,"stat:contributions welcome,type:feature","The second and third colors available in ""color by"" are extremely similar when there is overlap: the second color (orangish) appears very similar to third (redish) one.   This prevents any pop-out effect.",0,,4,2016-12-10T00:44:54Z,NONE
6219,Allow using raw values for Projector?,"stat:contributions welcome,type:feature",It would be great if Projector would allow raw values for visualization (e.g. in case the data has PCA or t-SNE applied already ),0,,2,2016-12-09T18:47:15Z,CONTRIBUTOR
6195,Running summary call crashes sporadically,stat:awaiting response,"Every so often when calling session.run on my summary graph, the whole thing crashes. The only error it says is Segmentation fault (core dumped). I don't know exactly what steps to take to reproduce it, but I do know it fails on this line:
``` python
_, summary_str = sess.run([train_op, summary],  
    options=run_options,
    run_metadata=run_metadata)
```
Summary is just defined as `summary = tf.summary.merge_all()`

It never crashes when only running train_op, and only crashes when running the summary every 10,000 or so iterations.

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 8.0, cudnn 5.1.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
ls -l /usr/local/cuda/lib64/libcud* results in 

-rw-r--r-- 1 root root   558720 Nov 17 14:07 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Nov 17 14:07 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Nov 17 14:07 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Nov 17 14:07 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Nov 17 14:07 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 Nov 17 17:24 /usr/local/cuda/lib64/libcudnn.so
lrwxrwxrwx 1 root root       33 Nov 17 17:25 /usr/local/cuda/lib64/libcudnn.so.5 -> /usr/local/cuda/lib64/libcudnn.so
lrwxrwxrwx 1 root root       33 Nov 17 17:25 /usr/local/cuda/lib64/libcudnn.so.5.1 -> /usr/local/cuda/lib64/libcudnn.so
lrwxrwxrwx 1 root root       33 Nov 17 17:25 /usr/local/cuda/lib64/libcudnn.so.5.1.5 -> /usr/local/cuda/lib64/libcudnn.so

1. The commit hash (`git rev-parse HEAD`) 93a91d9b782e01612175bb1f76688aa2580a968f
2. The output of `bazel version`
Extracting Bazel installation...
..........
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254
",0,,12,2016-12-08T20:00:51Z,CONTRIBUTOR
6141,Feature request: directional distributions (like von Mises-Fisher),"stat:contributions welcome,type:feature","Are there plans to implement directional statistical distributions? In particular, I'm looking to get a von Mises-Fisher distribution into `contrib/distributions/python`.

I'm beginning work on a VMF distribution myself, but as a new TF user my progress is likely to be slow.

(Note that `scipy.stats` implements a basic von Mises distribution.)

References:
[Wikipedia: Von Mises–Fisher distribution](https://en.wikipedia.org/wiki/Von_Mises%E2%80%93Fisher_distribution)
[Arxiv: Directional Statistics in Machine Learning: a Brief Review]( https://arxiv.org/pdf/1605.00316.pdf
)",0,,2,2016-12-07T04:55:12Z,NONE
6097,Using classifiers with scikit-learn ensemble methods,"stat:contributions welcome,type:feature","NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?: http://stackoverflow.com/questions/35464652/how-to-create-ensemble-in-tensorflow

### Environment info
Operating System: Ubuntu 16.04.1 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): Using CPU only version of TensorFlow

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 0.12.0-rc0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
It would be useful if the TensorFlow Learn classifiers had a `get_params` method so that they could be used with the `VotingClassifier` in `scikit-learn`. Note that XGBoost does currently work well with `VotingClassifier`

```python
from sklearn.svm import SVC
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn import neighbors
from sklearn.ensemble import VotingClassifier

import tensorflow as tf
from tensorflow.contrib import learn

clf_svm = SVC(C=1000, gamma=1)
clf_dt = tree.DecisionTreeClassifier(max_depth=30)
clf_knn = neighbors.KNeighborsClassifier(7, weights=""distance"")
feature_columns = learn.infer_real_valued_columns_from_input(X_train)
clf_dnn = learn.DNNClassifier(feature_columns=feature_columns, hidden_units=[200, 400, 200], n_classes=10)
clf_rf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)

eclf = VotingClassifier(estimators=[('SVM', clf_svm), 
                                    ('DecisionTree', clf_dt), 
                                    ('KNN', clf_knn), 
                                    ('DNN', clf_dnn), 
                                    ('RandomForest', clf_rf),], 
                        voting='hard')

eclf.fit(X_train, y_train)
predicted_labels = eclf.predict(X_test)
```

### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-117-461ecf12b1de> in <module>()
     17                         voting='hard')
     18 
---> 19 eclf.fit(X_train, y_train)
     20 predicted_labels = eclf.predict(X_test)
     21 

/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/voting_classifier.py in fit(self, X, y, sample_weight)
    163                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,
    164                     sample_weight)
--> 165                     for _, clf in self.estimators)
    166 
    167         return self

/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    756             # was dispatched. In particular this covers the edge
    757             # case of Parallel used with an exhausted iterator.
--> 758             while self.dispatch_one_batch(iterator):
    759                 self._iterating = True
    760             else:

/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    601 
    602         with self._lock:
--> 603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))
    604             if len(tasks) == 0:
    605                 # No more tasks available in the iterator: tell caller to stop.

/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __init__(self, iterator_slice)
    125 
    126     def __init__(self, iterator_slice):
--> 127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 

/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/voting_classifier.py in <genexpr>(.0)
    163                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,
    164                     sample_weight)
--> 165                     for _, clf in self.estimators)
    166 
    167         return self

/usr/local/lib/python3.5/dist-packages/sklearn/base.py in clone(estimator, safe)
     63                             ""it does not seem to be a scikit-learn estimator ""
     64                             ""as it does not implement a 'get_params' methods.""
---> 65                             % (repr(estimator), type(estimator)))
     66     klass = estimator.__class__
     67     new_object_params = estimator.get_params(deep=False)

TypeError: Cannot clone object '<tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x7f1d773f80f0>' (type <class 'tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.
```
",0,,1,2016-12-05T21:15:28Z,NONE
6035,Error message for running tf.nn.max_pool_with_argmax() on CPU,"stat:contributions welcome,type:feature","Running `tf.nn.max_pool_with_argmax()` on CPU gives a very obscure error:

`tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:
`  <no registered kernels>

From this line:

https://github.com/tensorflow/tensorflow/blob/bc64f05d4090262025a95438b42a54bfdc5bcc80/tensorflow/core/kernels/maxpooling_op.cc#L672

I think it's useful to mention `tf.nn.max_pool_with_argmax()` is only implemented for GPU instead.",0,,46,2016-12-02T07:49:37Z,NONE
6034,ctc_beam_search_decoder()'s log_probabilities holds invalid values,stat:awaiting tensorflower,"### Environment info
Operating System: OS X 10.11.6
TF Version: 0.10.0rc0 (No GPU)

### Example
Ran `log_probabilities` op created from
```python
decoded, log_probabilities = ctc_ops.ctc_beam_search_decoder(logits, \
                                                             seq_length, \
                                                             beam_width=beam_width, \
                                                             top_paths=top_paths, \
                                                             merge_repeated=False)
```
The `decoded` result is as expected. However, the `log_probabilities` contains positive values which can not be log probabilities. For example, with batch size 4 and top_paths=10 the `log_probabilities` printout is as follows
```
[[ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]
 [ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]
 [ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]
 [ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]]
```

### Other attempted solutions
None


### Logs or other output that would be helpful
Link to the entire code in context[[1](https://github.com/mozilla/DeepSpeech/blob/issue8++/DeepSpeech.ipynb)]
",1,,18,2016-12-02T06:20:00Z,NONE
5987,"Request for documentation on recommended flow in slim for train, validation, and test sets",stat:awaiting tensorflower,"The examples in the [slim README.md](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) give basic documentation for training and evaluating models when used separately; however, there is guidance missing on how to do the classic cycle of mini-batch gradient descent using shuffled subsets of the training set, periodically evaluating validation set, and then evaluating on the test set post-training. 

Using the [MNIST tutorial](https://www.tensorflow.org/versions/r0.12/tutorials/mnist/tf/index.html) and [this tutorial](https://github.com/mnuke/tf-slim-mnist) for reference, the best I came up with was something like this where I'm effectively monkey-patching the train_step_fn to periodically output accuracies: 

```
from tensorflow.contrib.slim.python.slim.learning import train_step

graph = tf.Graph()
with graph.as_default():
  image, label = input('train', FLAGS.dataset_dir)
  images, labels = tf.train.shuffle_batch([image, label], batch_size=FLAGS.batch_size, capacity=1000 + 3 * FLAGS.batch_size, min_after_dequeue=1000)
  images_validation, labels_validation = inputs('validation', FLAGS.dataset_dir, 5000)
  images_test, labels_test = inputs('test', FLAGS.dataset_dir, 10000)
 
  with tf.variable_scope(""model"") as scope:
    predictions = model(images, FLAGS)
    scope.reuse_variables()
    predictions_validation = model(images_validation, FLAGS)
    predictions_test = model(images_test, FLAGS)
    
  slim.losses.softmax_cross_entropy(predictions, labels)
  optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)
  train_op = slim.learning.create_train_op(slim.losses.get_total_loss(), optimizer)

  accuracy_validation = slim.metrics.accuracy(tf.to_int32(tf.argmax(predictions_validation, 1)), tf.to_int32(tf.argmax(labels_validation, 1)))
  accuracy_test = slim.metrics.accuracy(tf.to_int32(tf.argmax(predictions_test, 1)), tf.to_int32(tf.argmax(labels_test, 1)))
    
def train_step_fn(session, *args, **kwargs):
  total_loss, should_stop = train_step(session, *args, **kwargs)

  if train_step_fn.step % FLAGS.validation_check == 0:
    accuracy = session.run(train_step_fn.accuracy_validation)
    print('Step %s - Loss: %.2f Accuracy: %.2f%%' % (str(train_step_fn.step).rjust(6, '0'), total_loss, accuracy * 100))

  if train_step_fn.step == (FLAGS.max_steps - 1):
    accuracy = session.run(accuracy_test)
    print('%s - Loss: %.2f Accuracy: %.2f%%' % ('FINAL TEST', total_loss, accuracy * 100))
    
  train_step_fn.step += 1
  return [total_loss, should_stop]

train_step_fn.step = 0
train_step_fn.accuracy_validation = accuracy_validation

slim.learning.train(
  train_op,
  FLAGS.logs_dir,
  train_step_fn=train_step_fn,
  graph=graph,
  number_of_steps=FLAGS.max_steps
)
```

**Note**: one problem with this implementation is that the final test set is not guaranteed to be run in the case of early exit.
 
I've posted in the slack channel and Googled around, but haven't been able to find any examples for this basic use case. Accordingly, I would like to propose that an example providing the best practice to periodically evaluate batch trained models using the validate set and the trained model against the test set to be added to the slim README.md.

I think it would really help the community to have a clearer idea on the intentions of the slim team on how the batch training and evaluation paths were designed to be used together during and after training.
",1,,25,2016-11-30T17:19:04Z,NONE
5972,optimize variable with dynamic shape not supported,stat:contributions welcome,"TensorFlow 0.11.0.

I want to use a variable where the shape is unknown in advance and it will change from time to time (although ndim is known and fixed).

I declare it like:

```
initializer = tf.random_uniform_initializer()
shape = (s0, s1, s2)  # these are symbolic vars
foo_var = tf.Variable(initializer(shape=shape), name=""foo"", validate_shape=False)
```
This seems to work when I create the computation graph up to the point where I want to optimize w.r.t. this variable, i.e.:
```
optimizer = tf.train.AdamOptimizer(learning_rate=0.1, epsilon=1e-4)
optim = optimizer.minimize(loss, var_list=[foo_var])
```

That fails in the optimizer in some function `create_zeros_slot` where it seems to depend on the static shape information (it uses `primary.get_shape().as_list()`).

So, using the optimizer works only with variables with static shape? Is that a bug?

My current solution is some hacky monkey patching:
```
def _tf_create_slot_var(primary, val, scope):
  """"""Helper function for creating a slot variable.""""""

  from tensorflow.python.ops import variables
  slot = variables.Variable(val, name=scope, trainable=False, validate_shape=primary.get_shape().is_fully_defined())
  # pylint: disable=protected-access
  if isinstance(primary, variables.Variable) and primary._save_slice_info:
    # Primary is a partitioned variable, so we need to also indicate that
    # the slot is a partitioned variable.  Slots have the same partitioning
    # as their primaries.
    real_slot_name = scope[len(primary.op.name + ""/""):-1]
    slice_info = primary._save_slice_info
    slot._set_save_slice_info(variables.Variable.SaveSliceInfo(
        slice_info.full_name + ""/"" + real_slot_name,
        slice_info.full_shape[:],
        slice_info.var_offset[:],
        slice_info.var_shape[:]))
  # pylint: enable=protected-access
  return slot


def _tf_create_zeros_slot(primary, name, dtype=None, colocate_with_primary=True):
  """"""Create a slot initialized to 0 with same shape as the primary object.

  Args:
    primary: The primary `Variable` or `Tensor`.
    name: Name to use for the slot variable.
    dtype: Type of the slot variable.  Defaults to the type of `primary`.
    colocate_with_primary: Boolean.  If True the slot is located
      on the same device as `primary`.

  Returns:
    A `Variable` object.
  """"""
  if dtype is None:
    dtype = primary.dtype
  from tensorflow.python.ops import array_ops
  val = array_ops.zeros(
      primary.get_shape().as_list() if primary.get_shape().is_fully_defined() else tf.shape(primary),
      dtype=dtype)
  from tensorflow.python.training import slot_creator
  return slot_creator.create_slot(primary, val, name, colocate_with_primary=colocate_with_primary)


def monkey_patch_tf_slot_creator():
    """"""
    The TensorFlow optimizers cannot handle variables with unknown shape.
    We hack this.
    """"""
    from tensorflow.python.training import slot_creator
    slot_creator._create_slot_var = _tf_create_slot_var
    slot_creator.create_zeros_slot = _tf_create_zeros_slot
```

(That was also asked [on StackOverflow](http://stackoverflow.com/questions/40863082/optimize-variable-with-dynamic-shape/).)",0,,3,2016-11-30T07:39:55Z,NONE
5965,Feature request: GPU ops for tf.unique; tf.where; and tf.dynamic_partition ,stat:contributions welcome,"This is a feature request.  As far as I know, all three of them currently do not have GPU ops.

It seems that if we can at least get a GPU implementation of `tf.unique` for integers, then the user can make `tf.where` and `tf.dynamic_partition` manually.  For those of us who are trying to build models that want to mess around with indices rather frequently, this would be incredibly helpful. ",0,,10,2016-11-30T03:10:13Z,CONTRIBUTOR
5938,Saved model by TensorForestEstimator can not be freezed,stat:awaiting tensorflower,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I asked a question in stackoverflow, but I guess it is a bug or inconsistency in tensorflow.

http://stackoverflow.com/questions/40849477/error-in-saving-and-using-model-of-tensorforestestimator-for-android

### Environment info
Operating System:

Mac OSX 10.10.2
Python 2.7.12

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py2-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. Version: 0.12.0-rc0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

import tensorflow as tf
import numpy as np
from freeze_graph import freeze_graph
import os
from tensorflow.contrib.learn.python.learn.estimators.random_forest import TensorForestEstimator

Creating the model and saving:
=========================
hparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(
        num_trees=3, max_nodes=1000, num_classes=3, num_features=4)
classifier = TensorForestEstimator(hparams, model_dir='test/')
iris = tf.contrib.learn.datasets.load_iris()
data = iris.data.astype(np.float32)
target = iris.target.astype(np.float32)
classifier.fit(x=data, y=target, steps=100)

Freezing the model:
=========================
model_name = 'test/'
checkpoint_state_name = ""checkpoint""
input_graph_name = ""graph.pbtxt""
output_graph_name = ""newgraph.pb""
input_graph_path = os.path.join(model_name, input_graph_name)
input_saver_def_path = model_name
input_binary = False
input_checkpoint_path = os.path.join(model_name, checkpoint_state_name)
output_node_names = ""sample""
restore_op_name = ""save/restore_all""
filename_tensor_name = ""save/Const:0""
output_graph_path = os.path.join(model_name, output_graph_name)
clear_devices = True
freeze_graph(input_graph_path, input_saver_def_path,
                          input_binary, input_checkpoint_path,
                          output_node_names, restore_op_name,
                          filename_tensor_name, output_graph_path,
                          clear_devices, """")

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

The code can create and save the model perfectly (I can open the graph by tensorboard), but I get the following error for freezing the graph:

Traceback (most recent call last):
  File ""/XXXXX/model/test.py"", line 41, in <module>
    clear_devices, """")
  File ""/XXXXX/model/freeze_graph.py"", line 99, in freeze_graph
    _ = tf.import_graph_def(input_graph_def, name="""")
  File ""/XXXXX/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 258, in import_graph_def
    op_def = op_dict[node.op]
KeyError: u'TreePredictions'

When I am building the model, I get the following warning:

Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.
WARNING:tensorflow:Consider switching to the more efficient V2 format:
WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`
WARNING:tensorflow:now on by default.
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.
WARNING:tensorflow:Consider switching to the more efficient V2 format:
WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`
WARNING:tensorflow:now on by default.
WARNING:tensorflow:*******************************************************


",1,,13,2016-11-29T15:40:16Z,NONE
5920,Make activation function support sparse tensors,"stat:contributions welcome,type:feature","Usually, the input features need to be normalized, for example, when the feature is *duration of app usage* in *wide and deep* model. Usually you are not clear which normalization function is best for your model when you generate the features. So in the model, an activation function(for example softsign) can be applied to the input first. Currently sparse tensor is not supported. This change can be trivial.
",0,,1,2016-11-29T02:17:26Z,CONTRIBUTOR
5919,strip_unused should remove Switch Node with Constant Input,"stat:contributions welcome,type:feature",`strip_unused` does not appear to remove a `Switch` node with constant input.,0,,7,2016-11-28T23:43:49Z,CONTRIBUTOR
5918,add convert_placeholders_to_constants to tensorflow,"stat:contributions welcome,type:feature","Add `convert_placeholders_to_constants` which permanently injects a constant to fill in the value of a Placeholder.

Repost from [SO](http://stackoverflow.com/questions/40852729/permanently-inject-constant-into-tensorflow-graph-for-inference/40852855). /CC @mrry ",0,,0,2016-11-28T23:28:32Z,CONTRIBUTOR
5869,Model Exporting Does not Use optimize_for_inference_lib,"stat:contributions welcome,type:feature","Looking at the code in master, It looks like neither [`tensorflow.python.training.saver`](https://github.com/tensorflow/tensorflow/blob/eea96fc81bb1ae22eeb1d2141e47e182cecb7608/tensorflow/python/training/saver.py) nor [`tensorflow.contrib.session_bundle.exporter`](https://github.com/tensorflow/tensorflow/blob/eea96fc81bb1ae22eeb1d2141e47e182cecb7608/tensorflow/contrib/session_bundle/exporter.py) use [`optimize_for_inference_lib`](https://github.com/tensorflow/tensorflow/blob/df871edcff2faf643975b9863100ed41b6da9c3f/tensorflow/python/tools/optimize_for_inference_lib.py) which is described as:
>There are several common transformations ... that help reduce the amount of computation needed when the network is used only for inference.

Further these optimizations are not mentioned / suggested in the tensorflow serving docs:
* https://tensorflow.github.io/serving/
* https://github.com/tensorflow/tensorflow/blob/55cb1b37133e6c0409a708a763fccf566580a90a/tensorflow/contrib/session_bundle/README.md

Arguable the serving logic could be changed to [use frozen models](https://github.com/tensorflow/tensorflow/blob/5a5a25ea3ebef623e07fb9a46419a9df377a37a5/tensorflow/g3doc/how_tos/tool_developers/index.md#freezing) (see [`freeze_graph`](https://github.com/tensorflow/tensorflow/blob/df871edcff2faf643975b9863100ed41b6da9c3f/tensorflow/python/tools/freeze_graph.py)) which calls `convert_variables_to_constants`.",0,,0,2016-11-25T23:42:25Z,CONTRIBUTOR
5867,optimize_for_inference.py should remove Dropout operations,"stat:contributions welcome,type:feature","When I first tried using an exported MNIST model with TensorFlow on iOS, I got the following error:

    Invalid argument: No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered devices: [CPU], Registered kernels:
      <no registered kernels>
    
         [[Node: dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](dropout/Shape)]]

Since Dropout operations are no-ops during inference (we pass in a keep probability of 1), it would be nice if they were removed (or turned into no-ops of some kind that can be parsed and ignored by the iOS library).

While I was able to work around this by explicitly exporting a separate graph that does not contain Dropout, it was pretty tedious and it would be nice if the `optimize_for_inference.py` script did this automatically.

### Environment info
Operating System: macOS 10.12

Installed version of CUDA and cuDNN: 
None

Source:
This week's tip-of-tree (around d93d526cb804896004c1c20a41586ce0e2415b9c)
",0,,6,2016-11-25T18:06:04Z,NONE
5786,Gradients and variables was not shared in Adam optimizers when using bucketing,stat:contributions welcome,"All,

I used bucketing-like technology for seq2seq task:

```python
# For different length in encoder and decoder
model_map = {}
for i in encoder_shape:
    for j in decoder_shape:
        with variable_scope.variable_scope(variable_scope.get_variable_scope(),
                                 reuse=True if tt > 0 else None):
            model = Seq2SeqModel()
            model.build(encoder[:i], decoder[:j])
            model_map[i*100+j] = model
```
And get shared model's parameters:

```python
for t in tf.all_variables():
    print t.name, t.get_shape() 
```

```
Print: 
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding:0 (50000, 256)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias:0 (1600,)
```
Model's optimizer is like below:

```python
#every model have an optimizer
params = tf.trainable_variables()
opt = tf.train.AdamOptimizer(1e-3)
gradients = tf.gradients(self.loss, params)
self.optimizer = opt.apply_gradients(zip(gradients, params))
```
But I find that the optimizers don't share gradient:
```
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam:0 (50000, 256)
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam_1:0 (50000, 256)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam_1:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam:0 (1600,)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam_1:0 (1600,)
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam_2:0 (50000, 256)
embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding/Adam_3:0 (50000, 256)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam_2:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix/Adam_3:0 (1056, 1600)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam_2:0 (1600,)
embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias/Adam_3:0 (1600,)
```
With the growth of the number of buckets, the GPU memory will grow too. And meanwhile I get a larger model in tf.train.Saver.save().

So is it possible to share gradient in bucketing?





",0,,11,2016-11-22T14:16:01Z,CONTRIBUTOR
5777,GPU becomes unavailable after computer wakes up ,stat:awaiting tensorflower,"I noticed many have issues with GPU being unavailable with message (e.g., [issue 394](https://github.com/tensorflow/tensorflow/issues/394))

`E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_UNKNOWN
` 
some suggested `sudo apt-get install nvidia-modprobe`  but it does not work for all including me. my GPU works until i put the computer to sleep/suspense, but after waking up the computer i always get the message above and the GPU (gtx 1070) is no longer available in execution of the code (only CPU is used) in nvidia docker.  I also noticed if prior to suspending the computer i exit the docker and then restart it when i wake the computer the GPU is still available in docker. So, the problem happens if i suspend the computer while the ipython-notebook session is up and running. 

I am using nvidia-docker 

`nvidia-docker run -it -p 8888:8888 -v /*..../Data/docker:/docker --name TensorFlow   gcr.io/tensorflow/tensorflow:latest-gpu /bin/bash`

Nvidia-smi and nvidia-debugdump -l both show the GPU is installed and driver is up to date within docker and in the host. 

when i run nvidia-smi in docker the output is 

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 0000:01:00.0      On |                  N/A |
|  0%   41C    P0    39W / 180W |    450MiB /  8105MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+

                                                                               


```
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: ca234sff235
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: ca234sff235
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: 367.57.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.57  Mon Oct  3 20:37:01 PDT 2016
GCC version:  gcc version 4.9.3 (Ubuntu 4.9.3-13ubuntu2) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 367.57.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:293] kernel version seems to match DSO: 367.57.0
```

Software specs:
OS: Ubuntu 16.04 LTS - 64 bit
GPU driver: nvidia 367.57
Cuda : 7.5",0,,20,2016-11-22T07:25:16Z,NONE
5773,extract_image_patches zeros out data for large images,stat:awaiting tensorflower,"I'm reading a large image (7128x5097 pixels) and generating patches with extract_image_patches. Depending on the patch size, some or all of the resulting image is zeroed out. Is there a limit on tensor size that it hits?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
nothing relevant

### Environment info
Operating System: macOS Sierra 10.12.1

Installed version of CUDA and cuDNN: none

A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl
The output from python -c ""import tensorflow; print(tensorflow.__version__)"".
0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

The following code generates a random image, scales it up by a factor of 5, pulls a single pixel out of each patch, and writes an image with the result.

Expected behavior: an image of random pixels.
Observed behavior: for small images it works. But for the 5097x7129 image, N=3 works, N=5 gives a completely blank image, and N=7 is blank after the first 998 rows. (It's kind of strange that 7 works better than 5.)

    from __future__ import absolute_import
    from __future__ import print_function
    import tensorflow as tf
    N = 5 # Can try other numbers
    def main(_):
      img = tf.random_uniform([1, 5097, 7129, 3], minval=0, maxval=255, dtype=tf.int32)
      img = tf.cast(img, tf.uint8)
      patches = tf.extract_image_patches(img, [1, N, N, 1], [1, N, N, 1],
        [1, 1, 1, 1], ""SAME"")
      data = patches[0, :, :, 0:3]
    
      f = open('/tmp/img.png', 'w')
      init_op = tf.initialize_all_variables()
      with tf.Session() as sess:
        sess.run(init_op)
        f.write(tf.image.encode_png(data).eval())
      f.close()
    
    if __name__ == ""__main__"":
      tf.app.run()


### What other attempted solutions have you tried?
This is a simplified version of a larger image learning system, and I've cut it down to the problematic code. I've checked the values to make sure the problem is in extract_image_patches and not image_encode_png. The problem seems to happen if the tensor is big, so there's probably some size limit somewhere.",0,,7,2016-11-22T03:50:19Z,CONTRIBUTOR
5763,The TensorFlow operation concat_offset is undocumented,stat:awaiting tensorflower,"This shows up in some protocol buffers.  A vigorous search through the source code produced a short comment in some C++ code that gives some hints about its behaviour.  In particular, the word 'cumsum"" was used.  There appears to be, at times, a second output argument produced, although I have no idea what that could be except a copy of the first output.

A lot of searching turned up nothing useful.

TensorFlow version .11",0,,9,2016-11-21T21:56:50Z,NONE
5757,CPU slowdown with Quantized Eight bit graphs,,"In attempts to highly optimize my Tensorflow client application (and TF install) for consumer desktop hardware i've noticed (and noticed in other bug reports) that quantized eight bit graphs appear to run very slow.  My goal is to match the realtime 1 batch (1 x 299 x 299 x3 ) iOS performance that the Camera Example gets, yet I can't get a Desktop CPU compile of TF to get lower than roughly 150ms per frame, where in reality close to 16ms per frame is needed for roughly 60hz, or 33ms for 30hz performance. It appears somehow the iOS / ArmV7 build is able to achieve this performance unless I am missing something!

From the discussion group, I was asked by @petewarden to start a bug based on findings

Thread here: https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!msg/discuss/PJwgfoeNIKs/jiegynxLBAAJ

Briefly, I've added Stat Tracing to the Image Label example.  Modified source is here:

https://gist.github.com/vade/18d7e72f633f9479c5080a251661ebd9

Ive downloaded compiled tensor flow with the following bazel build commands, referenced from the makefile for iOS which speeds things up just a bit more than the standard compile:

` bazel build -c opt --copt=-mavx --cxxopt=-fno-exceptions --cxxopt=--std=c++11 --cxxopt=-DNDEBUG --cxxopt=-DNOTFDBG --cxxopt=-O2 --cxxopt=-DUSE_GEMM_FOR_CONV //tensorflow:libtensorflow_cc.so `

I then compiled Image Label via the standard bazel command:

` bazel build tensorflow/examples/label_image/...`

And ran it with 4 graphs:

* Standard InceptionV3
* InceptionV3 run through Inference Optimizer Script
* InceptionV3 run through Inference Optimizer and Quantizer in Weighted Rounding mode
* InceptionV3 run through Inference Optimizer and Quantizer in eight bit mode

The output of the runs are documented here, in order:

* https://gist.github.com/vade/a7d95da155c25dc8134f7cda8168e540
* https://gist.github.com/vade/71af1cbd38864cb176ce64bcafb934de
* https://gist.github.com/vade/e1923d7e7a9abfe1d8c912cc5d36a763
* https://gist.github.com/vade/1d9d5e102878cfb42f9c02a4200b3a50

Note the time for the Quantized Eight bit mode is roughly 2x longer than previous runs.

As a second set of data, my custom C++ app which uses the same lib_tensorfow_cc.so nets similar results to the benchmark : 


* InceptionV3 (no optimizations or quantizations) 
* 222 frames took 32.598143 seconds
* https://gist.github.com/vade/77a9314a5c7a5bda9b4a2c90f691a98e


* InceptionV3 (Inference Optimizations - no quantizations)
* 222 frames took 28.129690 seconds
* https://gist.github.com/vade/1c5dc51015f5a0fa24f4e0a7209cabf9


* InceptionV3 (Inference Optimizations & Quantizations Rounded)
* 222 frames took 25.201791 seconds
* https://gist.github.com/vade/ad8a2c42c5fbcf9be9f074c95d2e95ae


* InceptionV3 (Inference Optimizations & Quantizations Eightbit)
* 222 frames took 63.174700 seconds
* https://gist.github.com/vade/d6dcce06861bf8932446ae5ed33d93bb


Operating System:

`Mac OS X 10.12.1
2.8 GHz Intel Core i7
16GB Ram
Xcode 8.1 / Command Line Tools from 7.3.1 and enabled via xcselect
`
If installed from source, provide 

1. The commit hash

`41285cf7a11fa3a2c2ead6b6e9adcec4232b18ad`

2. The output of

`Build label: 0.4.0-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 19:18:00 2016 (1478114280)
Build timestamp: 1478114280
Build timestamp as int: 1478114280`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)`

See above for source code for minimally modified label image source.

### What other attempted solutions have you tried?

Attempted to run cuda but am targeting consumer desktop systems and would like similar performance to iOS targets for realtime or better than realtime performance for InceptionV3 / pool_3 feature vector determination and possibly labelling / classification.

For my system, cuda compilation netted similar results to CPU, although admittedly I did not enable batch sizes larger than 1. However, I think this is moot because iOS appears to be able to get realtime labelling and desktop cant, (is roughly 10x slower)

### Logs or other output that would be helpful
Logs and links provided in preamble  / description",1,,11,2016-11-21T20:53:19Z,CONTRIBUTOR
5729,Feature request: Please release an official binary for Raspberry Pi,type:build/install,"The Raspberry Pi is an excellent platform for robotics and automation. The native camera also makes a great combo for portable / embedded / robotics computer vision. Having TensorFlow available on this platform would really open up a lot of options in this context.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

none

### Environment info
Operating System:

Raspbian Jessie on Raspberry Pi 3

### What other attempted solutions have you tried?

https://github.com/samjabrahams/tensorflow-on-raspberry-pi

It only provides a binary for TensorFlow 0.10. I've had lots of issues with it running DNNs trained on 0.11. I need to train on 0.11 because the only fast GPU I have is an Nvidia Pascal chip, and 0.10 doesn't work well on Pascal (due to CUDA version issues).

I've tried to compile 0.11 following the guide there, but there were a lot of errors.",2,,38,2016-11-20T06:41:41Z,NONE
5719,[FEATURE REQUEST]Calculate topK on GPU with k-selection algos,"stat:contributions welcome,type:feature","Hi,
I am currently using [tf.nn.top_k](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) in my code. However, I found this operation is calculated on CPU and it is quite slow.
So I am wondering if it is possible to calculate topK on GPU?

Here are the papers and cuda codes about k-selection on GPU:
http://www.math.grin.edu/~blanchaj/Research/ABGS_KSelection.pdf
https://code.google.com/p/ggks/

Hope someday this feature will be added to tensorflow.
",0,,30,2016-11-19T14:33:11Z,NONE
5632,Feature Request: Perspective Transforms,"stat:contributions welcome,type:feature",Currently image processing has some image manipulation functions like brightness adjustment or contrast adjustment.  It would be quite useful to have perspective transforms or other affine transformations to help distort training data.,0,,3,2016-11-15T23:15:57Z,NONE
5592,The performance of fp16  is quite bad.,stat:awaiting tensorflower,"https://github.com/tensorflow/tensorflow/issues/1300

I have got a nvidia p100 GPU which is support fp16, and I run the TF case 'cifar10_train.py'. Without option '--use_fp16', the performance is also 1600 examples/sec, and with the option '--use_fp16', the performance down to 500 examples/sec. Any ideas about this issue?

userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ vi cifar10_train.py 
userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ python cifar10_train.py 
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
>> Downloading cifar-10-binary.tar.gz 100.0%
...
2016-11-14 00:07:57.143739: step 0, loss = 4.67 (12.1 examples/sec; 10.549 sec/batch)
2016-11-14 00:07:58.395209: step 10, loss = 4.57 (1693.6 examples/sec; 0.076 sec/batch)
2016-11-14 00:07:59.177525: step 20, loss = 4.97 (1668.9 examples/sec; 0.077 sec/batch)
2016-11-14 00:07:59.957789: step 30, loss = 4.43 (1588.3 examples/sec; 0.081 sec/batch)
2016-11-14 00:08:00.738431: step 40, loss = 4.52 (1690.5 examples/sec; 0.076 sec/batch)
2016-11-14 00:08:01.501940: step 50, loss = 4.33 (1680.4 examples/sec; 0.076 sec/batch)
2016-11-14 00:08:02.241604: step 60, loss = 4.20 (1733.4 examples/sec; 0.074 sec/batch)
2016-11-14 00:08:03.001845: step 70, loss = 4.27 (1706.0 examples/sec; 0.075 sec/batch)
2016-11-14 00:08:03.765522: step 80, loss = 4.18 (1601.3 examples/sec; 0.080 sec/batch)
2016-11-14 00:08:04.516780: step 90, loss = 4.25 (1646.3 examples/sec; 0.078 sec/batch)


userid@ubuntu-WK-4xP100:~/weike/tensorflow-r0.11/tensorflow/models/image/cifar10$ python cifar10_train.py --use_fp16
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
..
2016-11-14 00:09:09.382854: step 0, loss = 4.67 (12.3 examples/sec; 10.411 sec/batch)
2016-11-14 00:09:11.923842: step 10, loss = 4.58 (659.6 examples/sec; 0.194 sec/batch)
2016-11-14 00:09:13.918448: step 20, loss = 6.62 (460.6 examples/sec; 0.278 sec/batch)
2016-11-14 00:09:16.211809: step 30, loss = 4.37 (583.7 examples/sec; 0.219 sec/batch)
2016-11-14 00:09:18.327690: step 40, loss = 4.30 (618.3 examples/sec; 0.207 sec/batch)
2016-11-14 00:09:20.395409: step 50, loss = 4.37 (643.8 examples/sec; 0.199 sec/batch)
2016-11-14 00:09:22.466230: step 60, loss = 4.32 (574.0 examples/sec; 0.223 sec/batch)
2016-11-14 00:09:24.533225: step 70, loss = 4.17 (646.2 examples/sec; 0.198 sec/batch)
2016-11-14 00:09:26.609277: step 80, loss = 2.59 (601.5 examples/sec; 0.213 sec/batch)
2016-11-14 00:09:28.703648: step 90, loss = 4.15 (625.5 examples/sec; 0.205 sec/batch)
",0,,10,2016-11-14T06:17:58Z,NONE
5587,iOS No OpKernel to support TruncatedNormal,type:docs,"I have a NN similar to this one: http://stackoverflow.com/a/38576462/828184 and my iOS project is based on the simple contrib example.

I write out the graph.pb file like so (and replace it with the original iOS one):
`tf.train.write_graph(sess.graph_def, 'NNModel/', 'graph.pb', as_text=False)`

But XCode crashes on execution with this error:

> RunModelViewController.mm: Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'TruncatedNormal' with these attrs.  Registered kernels:
>   <no registered kernels>
> 	 [[Node: OutputLayer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](OutputLayer/truncated_normal/shape)]]

I guess it's because of the usage of `tf.truncated_normal(...)`. Is there an alternative to that call or am I doing something wrong?

So far I got a minimalistic multiplication graph working on iOS but no trained NN.",1,,11,2016-11-13T22:27:24Z,CONTRIBUTOR
5492,"tf.assign does not update variable shape if tf.Variable(..., validate_shape=True) initially",stat:awaiting tensorflower,"Unless the variable is initially created with tf.Variable(..., validate_shape=False), updating a variable using `tf.assign(..., validate_shape=False)` does not update the variable shape. 

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 8.0 and cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

``` bash
$ ls -l /usr/local/cuda-8.0/lib64/libcud*
-rw-r--r-- 1 root root 558720 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart_static.a
$ ls -l /usr/local/cudnn-5.1-cuda-8.0/lib64/
total 145608
lrwxrwxrwx 1 root root       13 Oct 28 10:07 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Oct 28 10:07 libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Oct 28 10:07 libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 28 10:07 libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#pip-installation

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```bash
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0rc2
```

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

In the following script, if var is created with `validate_shape=True`, subsequent `tf.assign` operations don't update the shape (they remain as [1]), *but they do update the data*.

However, if the var is created with `validate_shape=False`, subsequent `tf.assign` operations do update both data and the shape,  setting the shape to [1], [10], and [20] respectively.

```python
import numpy as np
import tensorflow as tf

dtype = np.float64
shape = (10, )

ph = tf.placeholder(dtype=dtype)
var = tf.Variable(tf.ones(shape=(1,), dtype=dtype), validate_shape=True)
op = tf.assign(var, ph, validate_shape=False)

init_op = tf.initialize_all_variables()

with tf.Session() as S:
    S.run(init_op)
    print S.run(tf.shape(var)) # [1]
    print S.run(var)           # [1.]
    S.run(op, feed_dict={ph: np.ones(shape=(10,), dtype=dtype)})
    print S.run(tf.shape(var)) # [1], should be [10]
    print S.run(var)           # [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]

    S.run(op, feed_dict={ph: np.ones(shape=(20,), dtype=dtype)})
    print S.run(tf.shape(var)) # [1], should be [20]
    print S.run(var)           # [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  1.]
```

### What other attempted solutions have you tried?



### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
",1,,10,2016-11-09T09:02:05Z,CONTRIBUTOR
5477,Deal with _control_flow_context when copying op,"stat:contributions welcome,type:bug/performance","In the current implementation of copying ops (both `tf.contrib.copy_graph` and `tf.contrib.graph_editor`)
The code of copying an op looks like this
```python
# copy inputs
inputs_ = copy_func(op.inputs)
# copy control_inputs
control_inputs_ = copy_func(control_inputs)
# copy _node_def, _op_def
node_def_ = deepcopy(op._node_def)
op_def_ = deepcopy(op._op_def)
output_types_ = op._output_types[:]
input_types_ = op._input_types[:]
# copy name
name_ = copy_func(op.name)
# init the new op with above copies
new_op = tf_ops.Operation(node_def_, ...)
# ... copy shape and add to graph
```
But the `op._control_flow_context` is not copied at all. This causes problems when trying to compute gradients on a copied subgraph with control flow op like `tf.cond`. The error looks like
```python
    grads = optimizer.compute_gradients(-lower_bound)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 253, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 461, in gradients
    out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1310, in ZerosLikeOutsideLoop
    pred = op_ctxt.pred
AttributeError: 'NoneType' object has no attribute 'pred'
```
This is because the function `ZerosLikeOutsideLoop` uses `_control_flow_context` when the op is `tf.switch`
```
def ZerosLikeOutsideLoop(op, index):
  """"""Create zeros_like for the specified output of an op.""""""
  val = op.outputs[index]
  if not IsSwitch(op):
    return array_ops.zeros_like(val, optimize=False)
  else:
    op_ctxt = op._get_control_flow_context()
    pred = op_ctxt.pred
    branch = op_ctxt.branch
    switch_val = switch(op.inputs[0], pred)[1 - branch]
    zeros_shape = array_ops.shape_internal(switch_val, optimize=False)
    return array_ops.zeros(zeros_shape, dtype=val.dtype)
```
I tried setting `new_op. _control_flow_context` as `op._control_flow_context`
Now the error step passed. But I'm not sure whether this is right for dealing with _control_flow_context copy. Do you have some advice?",0,,5,2016-11-08T15:12:30Z,CONTRIBUTOR
5443,"einsum with ellipses ""..."" (indefinite number of axes)","stat:contributions welcome,type:feature","Thank you very much for providing the (numpy) einsum feature in tensorflow, that is really great. The documentation for einsum says to look at the numpy documentation as it provides the same api. It is not exactly the same, one difference is the possibility of using ""..."" in numpy which seems not to be implemented in tensorflow. This would definitely be a nice feature to have in tensorflow also since that way one could build various function/transformations in tensorflow which are not dependent on the number of axis the tensor has (i.e. the specific use case). 

Here is the error I encountered when trying to do that:
`d = tf.einsum(""i...,ij->j..."",c,b)`

> ---------------------------------------------------------------------------
> AssertionError                            Traceback (most recent call last)
> <ipython-input-12-d7c0123ec21a> in <module>()
> ----> 1 d = tf.einsum(""i...,ij->j..."",c,b)
> 
> //anaconda/envs/chaos/lib/python3.5/site-packages/tensorflow/python/ops/special_math_ops.py in einsum(axes, *inputs)
>     100   match = re.match('([a-z,]+)->([a-z]+)', axes)
>     101   assert match, \
> --> 102     ""Indices have incorrect format: %s"" % axes
>     103 
>     104   inputs = list(inputs)
> 
> AssertionError: Indices have incorrect format: i...,ij->j...",0,,5,2016-11-07T09:52:01Z,NONE
5350,Sampled and regular softmax should use the same weight matrix shape,"stat:awaiting tensorflower,type:feature","As it is now, the softmax samplers [sampled_softmax_loss](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#sampled_softmax_loss) and [nce_loss](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#nce_loss) require a `|C|x|H|` weight matrix, while the logits from [softmax](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#softmax) come from a `|H|x|C|`-sized one. This discrepancy is problematic on two levels:
1. it makes for an inconsistent API;
1. it results in a performance hit, because if one uses a sampled method for training and softmax for testing (as is usual when the number of classes is huge), one has to call `tf.transpose` somewhere, which does not work well with sparse input (see #4138).

In my case, I can choose between 21150 / 18300 or 22350 / 11900 train / test wps, depending on whether the `tf.transpose` happens on the sampled softmax loss during training or on regular softmax during testing. In either case, the performance is suboptimal.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

As mentioned above, #4138. The fix there, however, is in the client code, not the API in question.

### Environment info
Operating System: `Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u3 (2016-01-17) x86_64 GNU/Linux`

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44`; I don't have cuDNN at the moment

If installed from binary pip package, provide:

1. A link to the pip package you installed: the official GPU install for Python 3.4
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: `0.11.0rc1`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I cannot do that right now, but one can experiment with e.g. the PTB example.

### What other attempted solutions have you tried?
N/A",0,,13,2016-11-02T09:24:43Z,NONE
5277,Eigen implemented CPU op is 10 times slower than OpenMP,type:bug/performance,"I implemented a phase CPU operator consisting of four loop levels. I couldn't find any Eigen tensor docs at that stage so I use OpenMP to trivially parallelise the outer loops. I recently found the Eigen tensor documentation so I thought I'd take advantage of it and get all the multithreading/AVX/SSE goodies for free!

Unfortunately the Eigen version is about 10 times slower!
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: CUDA 8.0 and cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
$ ls -l /usr/local/cuda-8.0/lib64/libcud*
-rw-r--r-- 1 root root 558720 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 15 01:02 /usr/local/cuda-8.0/lib64/libcudart_static.a
```

```
$ ls -l /usr/local/cudnn-5.1-cuda-8.0/lib64/lib*
lrwxrwxrwx 1 root root       13 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 28 10:07 /usr/local/cudnn-5.1-cuda-8.0/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. A link to the pip package you installed: python 2.7 linux GPU nightly
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so locally
0.11.0rc1
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
- [Source code](https://github.com/ska-sa/montblanc/blob/07fa1dd8860de8f3e95a1ceada7524bdaa5c87a7/montblanc/impl/rime/tensorflow/rime_ops/phase_op_cpu.h).
- [Makefile](https://github.com/ska-sa/montblanc/blob/07fa1dd8860de8f3e95a1ceada7524bdaa5c87a7/montblanc/impl/rime/tensorflow/rime_ops/Makefile). In terms of optimisations I'm using **-O2** and **-fopenmp**
- [Test Case](https://github.com/ska-sa/montblanc/blob/07fa1dd8860de8f3e95a1ceada7524bdaa5c87a7/montblanc/impl/rime/tensorflow/rime_ops/test_phase.py) and timing code.
#### OpenMP
- Timings

```
Tensorflow custom GPU time 0.342187
Tensorflow expression GPU time 0.270267
Tensorflow CPU time 0.417076
Numpy CPU time 2.542890
```
- Code

``` cpp
// Compute the complex phase
#pragma omp parallel for
for(int src=0; src<nsrc; ++src)
{
    FT l = lm(src,0);
    FT m = lm(src,1);
    FT n = std::sqrt(1.0 - l*l - m*m) - 1.0;

    for(int time=0; time<ntime; ++time)
    {
        for(int antenna=0; antenna<na; ++antenna)
        {
            FT u = uvw(time,antenna,0);
            FT v = uvw(time,antenna,1);
            FT w = uvw(time,antenna,2);

            FT real_phase_base = minus_two_pi_over_c*(l*u + m*v + n*w);

            for(int chan=0; chan<nchan; ++chan)
            {
                // Our real phase input to the exponential function is purely imaginary so we can
                // can elide a call to std::exp<complex<FT>> and just compute the cos and sin
                FT real_phase = real_phase_base*frequency(chan);
                complex_phase(src,time,antenna,chan) = { std::cos(real_phase), std::sin(real_phase) };
            }
        }
    }
}
```
#### Eigen
- Timings

```
Tensorflow custom GPU time 0.344653
Tensorflow expression GPU time 0.275525
Tensorflow CPU time 9.616667
Numpy CPU time 2.505482
```
- Code

``` cpp
// Doing it this way might give us SIMD's and threading automatically...
const CPUDevice & device = context->eigen_device<CPUDevice>();

// Shapes for reshaping and broadcasting
Eigen::DSizes<int, 4>   lm_shape(nsrc, 1,     1,  1    );
Eigen::DSizes<int, 4>  uvw_shape(1,    ntime, na, 1    );
Eigen::DSizes<int, 4> freq_shape(1,    1,     1,  nchan);

auto l = lm.slice(
        Eigen::DSizes<int, 2>(0,    0),
        Eigen::DSizes<int, 2>(nsrc, 1))
    .reshape(lm_shape);
auto m = lm.slice(
        Eigen::DSizes<int, 2>(0,    1),
        Eigen::DSizes<int, 2>(nsrc, 1))
    .reshape(lm_shape);

auto u = uvw.slice(
        Eigen::DSizes<int, 3>(0,     0,  0),
        Eigen::DSizes<int, 3>(ntime, na, 1))
    .reshape(uvw_shape);

auto v = uvw.slice(
        Eigen::DSizes<int, 3>(0,     0,  1),
        Eigen::DSizes<int, 3>(ntime, na, 1))
    .reshape(uvw_shape);

auto w = uvw.slice(
        Eigen::DSizes<int, 3>(0,     0,  2),
        Eigen::DSizes<int, 3>(ntime, na, 1))
    .reshape(uvw_shape);

// Compute n
auto n = (l.constant(1.0) - l*l - m*m).sqrt() - l.constant(1.0);

// Compute the real phase
auto real_phase = (
    l.broadcast(uvw_shape)*u.broadcast(lm_shape) +
    m.broadcast(uvw_shape)*v.broadcast(lm_shape) +
    n.broadcast(uvw_shape)*w.broadcast(lm_shape))
        .broadcast(freq_shape);

// Reshape and broadcast frequency to match real_phase
auto f = frequency.reshape(freq_shape).broadcast(
    Eigen::DSizes<int, 4>(nsrc, ntime, na, 1));

// Calculate the phase
auto phase = real_phase*f*real_phase.constant(minus_two_pi_over_c);
auto sinp = phase.unaryExpr(Eigen::internal::scalar_sin_op<FT>());
auto cosp = phase.unaryExpr(Eigen::internal::scalar_cos_op<FT>());

// Now evaluate the complex phase on the device
// by combining the cosine and sine of the phase
// to form a complex number
complex_phase.device(device) = cosp.binaryExpr(
    sinp, make_complex_functor<FT>());
```
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
",2,,11,2016-10-29T17:23:34Z,CONTRIBUTOR
5193,CuSPARSE support,"stat:contributions welcome,type:feature","For some machine learning /algorithm problems, we require to multiply matrices with vectors. In some cases - especially those associated with large graph analytics, the matrices are sparse. Given the major limitation with GPUs is the limited GPU memory, representing the matrix in sparse format is vital.

To this end, the CUSPARSE libraries (http://docs.nvidia.com/cuda/cusparse/) provide a suitable object model and various functions for sparse matrix/vector operations.

I would therefore like to request a basic CUSPARSE implementation. 
e.g. - 
- CSR matrix representation - (see http://docs.nvidia.com/cuda/cusparse/#compressed-sparse-row-format-csr)
- basic matrix-vector multiplication for CSR representations (see http://docs.nvidia.com/cuda/cusparse/#cusparse-lt-t-gt-csrmv)

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
### What other attempted solutions have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).
",0,,15,2016-10-25T12:12:22Z,NONE
5099,lookup_embedding returning 0 on missing index,stat:contributions welcome,"If I create a variable with the first dimension equal to k and I use it for looking up vectors with lookup_embeddings, if I input an invalid index (higher than k or lower than 0) the lookup just returns 0s.
In the code below I create a 10x2 embedding matrix e, so that each embedding is of dimension 2. i then lookup for a number that is the step number. This has no use, it's just for showing the issue. Obviously for the first 10 steps the value I fetch is a random embedding of dimension 2, after the tenth iteration, I start getting all 0s.

I think this should be documented. I'm not sure if it is a good default or not, probably it is, but at least there should be a warning or something similar telling that you are trying to access an index that is not there. It would be really useful for debugging. I would have saved few hours of work if I noticed this before.
### Environment info

Operating System: Ubuntu 16.04 64bit
Installed version of CUDA and cuDNN: cuda 8.0 cudnn 5.1
Tensorflow version: 0.10.0 compiled for cuda 8.0 (but it is not the issue)
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import numpy as np
import tensorflow as tf

num_embedding = 10
embedding_size = 2

x = np.array([[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]])
y = np.array([0, 0, 0, 1, 1, 1, 1, 1, 1])

graph = tf.Graph()
with graph.as_default():
    x_p = tf.placeholder(tf.float32, shape=[None, 2])
    e_p = tf.placeholder(tf.int64, shape=[])

    y_p = tf.placeholder(tf.float32, shape=[None])
    y_pe = tf.expand_dims(y_p, 1)

    w = tf.Variable(tf.random_normal([2, 1]))
    b = tf.Variable(tf.random_normal([1]))
    e = tf.Variable(tf.random_normal([num_embedding, embedding_size]))

    embed = tf.nn.embedding_lookup(e, e_p)

    logits = tf.matmul(x_p, w) + b + tf.reduce_sum(embed)

    xe = tf.nn.sigmoid_cross_entropy_with_logits(logits, y_pe)
    loss = tf.reduce_mean(xe)

    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(tf.nn.sigmoid(logits) > 0.5, tf.float32), y_pe), tf.float32))
    optimizer = tf.train.AdamOptimizer(0.5).minimize(loss)

    #Dangling nodes in the computational graph
    z_p = tf.placeholder(tf.float32, shape=[None, 2])
    u = tf.Variable(tf.random_normal([2, 1]))
    l = tf.matmul(z_p, u)

    saver = tf.train.Saver()

with tf.Session(graph=graph) as session:
    tf.initialize_all_variables().run()
    for step in range(201):
        if step % 100 == 0:
            save_path = saver.save(session, ""lc_{:04d}.ckpt"".format(step))
        _, loss_val, acc_val, embed_val = session.run(
            [optimizer, loss, accuracy, embed],
            feed_dict={x_p: x, e_p: step, y_p: y})
        print(""step {step} - loss: {loss_val:.6f}, acc: {acc_val:.4f}"".format(step=step, loss_val=loss_val, acc_val=acc_val))
        print(""embed_val: {}"".format(embed_val))

```
",0,,13,2016-10-20T20:23:26Z,NONE
5073,export/00000000-tmp/export-?????-of-00001 is not in all_model_checkpoint_paths. Manually adding it.,stat:awaiting tensorflower,"Now that I am using the 11rc, I am seeing a lot of this printed out:

```
INFO in saver: /output/4885/export/00000000-tmp/export-?????-of-00001 is not in all_model_checkpoint_paths. Manually adding it.
```

I believe when I call:

```
# Done once:
saver = tf_saver.Saver(sharded=True)
model_exporter = exporter.Exporter(saver)
model_exporter.init(...)
...
# Done each epoch / step:
model_exporter.export(export_path, tf.constant(i), sess)
```
### Environment info

Operating System:
Using nvidia Docker,

```
uname -a
Linux b2dcea60c730 3.13.0-57-generic #95-Ubuntu SMP Fri Jun 19 09:28:15 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
# ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
```
1. The commit hash (`git rev-parse HEAD`)
   `8915f0f8072c406ae3fe0dff888f51b4cad02d7d`
2. The output of `bazel version`

```
# bazel version
INFO: Reading 'startup' options from /root/.bazelrc: --batch
Extracting Bazel installation...
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392
```
",0,,16,2016-10-19T19:21:01Z,CONTRIBUTOR
5007,Update classify_image.py code to use latest pre-trained model,stat:contributions welcome,"The code in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py references the older pre-trained model at http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz however, a new pre-trained model is available at http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz and is referenced in other parts of the code tree (such as https://github.com/tensorflow/models/tree/master/inception).

Please update the code in classify_image.py to reflect the latest pre-trained  model.
",0,,4,2016-10-17T13:42:13Z,NONE
4965,Feature request: Hamiltonian Monte Carlo ,"stat:contributions welcome,type:feature","Hamiltonian Monte Carlo (HMC), also known as Hybrid Monte Carlo, is an efficient Markov Chain Monte Carlo (MCMC) method that exploits gradient information to improve on the simpler MCMC methods. See this freely available book chapter by Radford Neal:

http://www.mcmchandbook.net/HandbookChapter5.pdf

It has been successfully applied to Bayesian inference in Neural Networks, again  by Neal. See for instance Neal's thesis which later became a book:

http://www.cs.toronto.edu/~radford/ftp/thesis.pdf

HMC is heavily used in modern Bayesian modelling, For instance, HMC and its variants are the primary inference method for Stan, a popular probabilistic programming language:

http://mc-stan.org/

It would be useful to be able to use HMC in TensorFlow much as one is currently able to use Optimizers such as Adam or Momentum optimization. Much of the requisite code would be similar to the optimizer code which can be found here:

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/training

I've raised this feature request as a place to discuss the potential addition of HMC to TensorFlow. 
",0,,38,2016-10-14T10:46:02Z,CONTRIBUTOR
4914,Keeping gradient of sqrt(x) stable for x = 0,"stat:contributions welcome,type:feature","I'm minimizing a function that contains a few `tf.sqrt(c * x)` terms. The `x` is a `tf.Variable` and `c` is a `tf.constant` that is sometimes zero. A `NaN` inevitably presents itself. In my case, the gradient is to `c`, which is `x * 0.5/sqrt(c * x)` and which equals `0 * inf = NaN` when `c` is `0`.

When such a `sqrt` is deeply buried in your function, it can be quite an effort to dig out where the `NaN` is coming from. I can understand and appreciate the fact that there is no check for zero in the `sqrt_grad` operator. However, I feel that debugging could be easier for ops that are known to be unstable in some numerical range.

Two possible fixes would be:
1. Add exceptions to the documentation of these ops. Right now this is not even indicated for `tf.div`, for instance. Since the use-cases of TensorFlow almost always mean that gradients will be involved, the allowed range should also be mentioned for the gradient, if different from that of the op itself.
2. Add debug-mode versions of the ops. These could include `NaN` and `inf` checks.

By the way, I was using the `tf.contrib.opt.ScipyOptimizerInterface` for the minimization, which does not support manually changing the gradients by using `compute_gradients` and `apply_gradients`. That's beside the point, though.

Below some example code for completeness' sake. The differences in outcome only add to the confusion.

``` python
from __future__ import absolute_import, division, print_function
import tensorflow as tf

c = tf.Variable(0.0)

sqrt_grad = tf.gradients(tf.sqrt(c), c)

# another possibility is when another factor in the argument is zero
x = tf.Variable(1.)
sqrt_x_grad = tf.gradients(tf.sqrt(x * c), x)

# try to use select to filter out the NaN
selsqrt_grad = tf.gradients(tf.select(c > 0, tf.sqrt(c), 0), c)

# try clipping of the sqrt
clipsqrt_grad = tf.gradients(tf.clip_by_value(tf.sqrt(c), 1e-10, 1), c)

# clip the argument of the sqrt --> only numerically stable option
clipargsqrt_grad = tf.gradients(tf.sqrt(tf.clip_by_value(c, 1e-10, 1)), c)

init_op = tf.initialize_all_variables()

with tf.Session() as sess:
    sess.run(init_op)

    print(sess.run([sqrt_grad, sqrt_x_grad, selsqrt_grad,
                    clipsqrt_grad, clipargsqrt_grad]))
    # [[inf], [nan], [nan], [nan], [0.0]]
```
",0,,9,2016-10-12T13:57:36Z,NONE
4907,DeepDream tutorial and TFSlim,"stat:contributions welcome,type:feature","What do you think to switch the DeepDream tutorial  notebook to MetaGraph? I see that  fine tuning and new inception models are more oriented on tfslim and slim models use the new meta+check point.
",0,,16,2016-10-12T08:18:41Z,NONE
4887,resnet model in tf slim does not take is_training param,stat:contributions welcome,"Compare the [resnet_v2 model](https://github.com/tensorflow/tensorflow/blob/8e48ec6ea0492e2cb9fd19c0a2ccf41afc7b4dc6/tensorflow/contrib/slim/python/slim/nets/resnet_v2.py) to the [vgg model](https://github.com/tensorflow/tensorflow/blob/8e48ec6ea0492e2cb9fd19c0a2ccf41afc7b4dc6/tensorflow/contrib/slim/python/slim/nets/vgg.py). The vgg model takes `is_training` whereas the resnet model does not. This param should be taken and passed to the `batch_norm` layers.

The docs for the v1 model do reference `is_training`, but I don't see it used.
",0,,11,2016-10-11T03:49:56Z,CONTRIBUTOR
4863,iOS error: No OpKernel was registered to support Op 'Mul' with these attrs [T=DT_INT32],"stat:awaiting tensorflower,type:bug/performance","I have some issues performing a multiplication of int32 data on iOS. Session::Run fails with the error shown below, indicating that this particular multiplication op is not supported. I've already checked tf_op_files.txt, and 'tensorflow/core/kernels/cwise_op_mul.cc' is there, obviously, and it looks to like the int32 version should also get registered there.

Do I need to take any extra steps to enable int32 multiplication on iOS?

This is the exact error message I'm getting:

```
No OpKernel was registered to support Op 'Mul' with these attrs
     [[Node: mul = Mul[T=DT_INT32](Cast, Cast)]]
```

I'm using TensorFlow 0.10. Here is how I create the graph def file in Python:

```
import tensorflow as tf
from tensorflow.python.framework import graph_util

input = tf.placeholder(tf.float32, shape=(1,4), name='input')

v = tf.cast(input, tf.int32)
v = v * v
output = tf.cast(v, tf.float32, name='output')

with tf.Session() as sess:
    output_graph_def = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['output'])

with tf.gfile.GFile('/tmp/test_graph.pb', 'wb') as f:
    f.write(output_graph_def.SerializeToString())
```

Thanks a lot,
Peter
",1,,27,2016-10-09T20:01:28Z,NONE
4821,Request for documentation: quantize_training in python,type:docs,"Poking around, I find https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=quantize_training

However there is no documents that I can find describe how this can be used. Can we add some example and also documentation around it so that people can start to play with it?
",1,,6,2016-10-07T14:00:24Z,NONE
4814,[Feature Request] Make streaming metrics resettable,"stat:contributions welcome,type:feature","Hi! 
Currently, the streaming metrics are (as far as I know) not resettable. I'd like to be able to e.g. reset the counter after each epoch. This way, having e.g. a very bad accuracy in the beginning of training will not still influence the accuracy value ten epochs later. It makes it easier to compare my results to runs obtained outside tensorflow.

The only workaround I found is to do `sess.run(tf.initialize_local_variables())` after each epoch, but of course this can have bad side effects if I have other local variables that I don't want to reset.

Or is there a way to achieve what I want that I didn't think of?
",0,,20,2016-10-07T08:57:48Z,NONE
4809,Getting Send/Recv timings for distributed TF,,"I'm trying to troubleshoot some slowness in our distributed models , and it would be useful to have access to timing of Send/Recv ops across graph partition.

cc @suharshs because maybe StatsPublisherInterface is relevant?

For instance, a toy benchmark [here](https://gist.github.com/yaroslavvb/1124bb02a9fd4abce3d86caf2f950cb2) adds 100MB vectors of 1's in one process to variable in another process on local machine. If I look at timeline/stepstats, I see 120ms of emptiness, followed by 20ms in `AddOp` followed by another 700ms of missing time.

Because it's a toy benchmark, I can figure out that 120ms is spent in transferring 100MB from one TF runtime to another, and 700ms is spent making the result available to Python client. But it's harder to do this on a large model

<img width=""1298"" alt=""screen shot 2016-10-06 at 5 27 51 pm"" src=""https://cloud.githubusercontent.com/assets/23068/19175296/47ddfe64-8bea-11e6-9882-a4a59a9823c8.png"">
",2,,17,2016-10-07T00:26:23Z,CONTRIBUTOR
4790,iOS cannot run the new trained Inception v1 model <no registered kernels>,stat:awaiting tensorflower,"### Environment info

iOS
### steps:

1, i train inception v1 (slim) on a subset of ImageNet dataset (269 of 1000)
2, convert .ckpt into .pb by freeze_graph
3, convert .pb file into 8bit precision
4, load into iOS and run
### Logs

simple/RunModelViewController.mm:222] Running model failed: Invalid argument: **No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered kernels:**

 <**no registered kernels**>

[[Node: InceptionV1/Logits/Dropout_0b/dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _output_shapes=[[128,1,1,1024]], dtype=DT_FLOAT, seed=0, seed2=0](InceptionV1/Logits/Dropout_0b/dropout/Shape)]]

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""ArgMin"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""dimension""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""ArgMin"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""dimension""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""ArgMax"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""dimension""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""ArgMax"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""dimension""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""AvgPoolGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""orig_input_shape""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""BatchNormWithGlobalNormalizationGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""BroadcastGradientArgs"" device_type: ""GPU"" host_memory_arg: ""s0"" host_memory_arg: ""s1"" host_memory_arg: ""r0"" host_memory_arg: ""r1""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""BroadcastGradientArgs"" device_type: ""CPU"" host_memory_arg: ""s0"" host_memory_arg: ""s1"" host_memory_arg: ""r0"" host_memory_arg: ""r1""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""BiasAddGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""BiasAddGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""BiasAddV1"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""BiasAddV1"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""CheckNumerics"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""ConcatOffset"" device_type: ""GPU"" host_memory_arg: ""concat_dim"" host_memory_arg: ""shape"" host_memory_arg: ""offset""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""ConcatOffset"" device_type: ""CPU""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT16 } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT16 } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""concat_dim""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Placeholder"" device_type: ""GPU""')

I tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: ""Placeholder"" device_type: ""CPU""')
",0,,33,2016-10-06T00:02:21Z,NONE
4737,No gradient defined for operation EluGrad,stat:contributions welcome,"tf.nn.elu does not support second derivatives currently. 

This would be awesome, as in variational autoencoder models these activation functions improve performance by a few nats in the objective compared to tanh, sigmoid (which do support second derivatives).

In the meantime I'm using `elu = lambda x: tf.select(x < 0., tf.exp(x) - 1., x)` which seems to work:

```
In [29]: elu = lambda x: tf.select(x < 0., tf.exp(x) - 1., x)

In [30]: sess.run(tf.gradients(elu(z), z), {z: -1.})
Out[30]: [0.36787945]

In [31]: sess.run(tf.gradients(elu(z), z), {z: 1.})
Out[31]: [1.0]
```
",0,,3,2016-10-03T19:32:37Z,NONE
4722,einsum not fully implemented,"stat:contributions welcome,type:feature","I am glad to see the newly added einsum function. The documentation claims that its usage is the same as numpy. However, it can do almost nothing as compared to numpy. For example, it only supports subscripts in the form of '_->_'. Unfortunately, even matrix transpose does not work, i.e., 'ij->ji'. 
Numpy works:

```
>>> A
array([[ 0.3828997 , -0.39114848, -0.09727838, -0.20430113],
       [ 0.48020577, -0.47122706,  0.42830791,  0.25665744],
       [-0.30885863,  0.21669025,  0.31648793,  0.22417514],
       [ 0.32505724,  0.30478035,  0.48655034,  0.20040547]])
>>> einsum('ij->ji',A)
array([[ 0.3828997 ,  0.48020577, -0.30885863,  0.32505724],
       [-0.39114848, -0.47122706,  0.21669025,  0.30478035],
       [-0.09727838,  0.42830791,  0.31648793,  0.48655034],
       [-0.20430113,  0.25665744,  0.22417514,  0.20040547]])
```

Tensorflow does not work:

```
pseudo-code:
M_ = tf.Variable(tf.random_normal([4,4]))
N_ = tf.einsum('ij->ji',M_)              
print [M_, N_]

output:
[array([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],
       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],
       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],
       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32), 
array([[ 0.80474716, -1.38590837, -0.3379252 , -1.24965811],
       [ 2.57852983,  0.05492432,  0.23039417, -0.74263287],
       [-2.42627382,  1.70774114,  1.19503212,  0.43006262],
       [-1.04652011, -0.32753903, -1.26430523,  0.8810069 ]], dtype=float32)]
```

I want to multiply a matrix with every frame vector in every batch. Or similar operations which can be done by a simple tensor product. It seems that I still have to duplicate the matrix so many times and perform a batch_matmul, which is very inconvenient and slow and memory consuming.

I suggest tensorflow to implement either the tensordot or einsum function which can perform tensor product.

It is quite a shame that tensorflow cannot even perform basic tensor product so far :(
",0,,10,2016-10-03T01:21:59Z,NONE
4639,Implement NumPy style boolean indexing,type:feature,"See NumPy's documentation
http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#boolean-array-indexing

We currently support basic indexing http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#basic-slicing-and-indexing.

Broken off of #206.
",1,,4,2016-09-28T21:18:29Z,MEMBER
4638,Implement advanced indexing (and mixed basic/advanced),type:feature,"NumPy style advanced indexing is documented here http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#advanced-indexing

We currently support basic indexing http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#basic-slicing-and-indexing
using StridedSlice.

e.g.

foo = Some tensor
idx1=[1,2,3]
idx2=[3,4,5]
foo[idx1, idx2, 3]
",1,,26,2016-09-28T21:16:49Z,MEMBER
4590,Better shape inference for tf.slice and tf.strided_slice,stat:contributions welcome,"Currently, if any of the values in the `size` argument is not a constant, the output shape is completely unknown (but the correct rank):

``` python
>>> z = tf.zeros((1, 2, 3))
>>> z.get_shape().as_list()
[1, 2, 3]
>>> m = tf.slice(z, [0, 0, 0], [-1, -1, -1])
>>> m.get_shape().as_list()
[1, 2, 3]
>>> m = tf.slice(z, [0, 0, 0], [tf.constant(1) + 0, -1, -1])
>>> m.get_shape().as_list()
[None, None, None]
```

The desired behaviour would instead treat the second and third dimensions correctly:

``` python
>>> m = tf.slice(z, [0, 0, 0], [tf.constant(1) + 0, -1, -1])
>>> m.get_shape().as_list()
[None, 2, 3]
```

Looking briefly at the code, this would requite being a bit more clever in terms of how constant values are computed; right now if anything in a `Pack`-ed array is unknown at graph construction time, the entire array is unknown (see `_ConstantValue`'s `Pack` case).

I guess this request ends up being just a request for a better constant propagation system which supports partially-known tensors. Perhaps you already have other use cases for such a feature, in which case view this as just another request that such a feature would enable.
",0,,7,2016-09-26T20:34:25Z,CONTRIBUTOR
4589,Support for native half-float computation (float16/fp16),type:feature,"https://github.com/tensorflow/tensorflow/issues/1300 added support for fp16 storage, but there is currently no support for native fp16 computation, which is available on some hardware such as Pascal GPUs.

In particular, the conv2d and matmul ops could take a new parameter along the lines of ""compute_dtype"", which would be plumbed through to CUDNN (convolution descriptor) and CUBLAS (Hgemm) in the backend, with the potential for up to a 2x speedup.

Related issues:
https://github.com/tensorflow/tensorflow/issues/1300
https://github.com/tensorflow/tensorflow/issues/4314
https://github.com/tensorflow/tensorflow/issues/851#issuecomment-230923665
",2,,30,2016-09-26T20:09:47Z,CONTRIBUTOR
4434,Why is quantized graph inference takes much more time than using the original graph?,stat:awaiting tensorflower,"I followed this [tutorial](https://www.tensorflow.org/versions/r0.10/how_tos/quantization/index.html) in order to quantize my graph into 8 bit.I can't share the exact graph here but i can say it's a simple convolutional neural network.

When i run the [benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/benchmark) over the original and quantized networks it's clear that the quantized network is much much slower (100 ms vs. 4.5 ms).

Slowest nodes in original network :

```
time average [ms]   [%] [cdf%]  [Op]    [Name]
1.198   26.54%  26.54%  MatMul  fc10/fc10/MatMul
0.337   7.47%   34.02%  Conv2D  conv2/Conv2D
0.332   7.36%   41.37%  Conv2D  conv4/Conv2D
0.323   7.15%   48.53%  Conv2D  conv3/Conv2D
0.322   7.14%   55.66%  Conv2D  conv5/Conv2D
0.310   6.86%   62.53%  Conv2D  conv1/Conv2D
0.118   2.61%   65.13%  Conv2D  conv2_1/Conv2D
0.105   2.32%   67.45%  MaxPool pool1
```

Slowest nodes in quantized network :

```
time average [ms]   [%] [cdf%]  [Op]    [Name]
8.289   47.67%  47.67%  QuantizedMatMul fc10/fc10/MatMul_eightbit_quantized_bias_add
5.398   5.33%   53.00%  QuantizedConv2D conv5/Conv2D_eightbit_quantized_conv
5.248   5.18%   58.18%  QuantizedConv2D conv4/Conv2D_eightbit_quantized_conv
4.981   4.92%   63.10%  QuantizedConv2D conv2/Conv2D_eightbit_quantized_conv
4.908   4.85%   67.95%  QuantizedConv2D conv3/Conv2D_eightbit_quantized_conv
3.167   3.13%   71.07%  QuantizedConv2D conv5_1/Conv2D_eightbit_quantized_conv
3.049   3.01%   74.08%  QuantizedConv2D conv4_1/Conv2D_eightbit_quantized_conv
2.973   2.94%   77.02%  QuantizedMatMul fc11/MatMul_eightbit_quantized_bias_add
```

What is the reason for that ? 
Is it the expected behavior for quantized network ?
### Environment info

Operating System: Ubuntu 16.04
Installed from source, without GPU support :
1. commit hash = 37256f4
2. bazel version = 
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392
",0,,16,2016-09-18T06:45:30Z,NONE
4386,bazel build should warn you if you haven't run ./configure,"stat:contributions welcome,type:feature","The errors when not running configure are not terribly intuitive (see e.g. #4279 ). 
",1,,4,2016-09-14T17:13:20Z,MEMBER
4337,Multi-CPU kernel for sparse_tensor_dense_matmul,stat:awaiting tensorflower,"Are there plans to implement a multi-cpu kernel for tf.sparse_tensor_dense_matmul? The current version seems to be single core only and is not performing well. 

I am working with a very large sparse tensor - about 8GB sparse and 200GB dense that I cannot work with as a dense tensor for memory reasons. Any suggestions for achieving fast matrix multiplication? 
",1,,7,2016-09-12T18:19:24Z,NONE
4290,Aspect Preserving Image Downsample That does not Require Cropping,"stat:contributions welcome,type:feature","Right now it looks like all of the image downsize (ie resize to a smaller size) operations involve either changing aspect ratio (e.g. [resize_images](https://www.tensorflow.org/versions/r0.10/api_docs/python/image.html#resize_images)) or cropping (e.g. [resize_image_with_crop_or_pad](https://www.tensorflow.org/versions/r0.10/api_docs/python/image.html#resize_image_with_crop_or_pad)). Compare this to the [thumbnail operation in Pillow](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) that maintains the aspect ratio but does not crop.

There are some related [questions on SO](http://stackoverflow.com/questions/35208832/tensorflow-resize-image-tensor-to-dynamic-shape).
",0,,3,2016-09-09T03:20:58Z,CONTRIBUTOR
4227,SparseTensor doesn't have get_shape() function,stat:contributions welcome,"I've been trying to add SparseTensor support to Keras (https://github.com/fchollet/keras/pull/3695) and one of the issues I've run into is that because of the lack of get_shape() I need to add SparseTensor-specific code.

Luckily so far I've only needed the rank of SparseTensors, so sparse.shape.get_shape()[0] has worked for me, but if I pass in a shape in the sparse_placeholder constructor (https://github.com/tensorflow/tensorflow/issues/4226) I would like to be able to retrieve it with sparse.get_shape()
",0,,5,2016-09-06T15:31:15Z,NONE
4193,CTC loss is numerically unstable for long sequence lengths,stat:awaiting tensorflower,"Hi All, great work TF team, thanks for implementing CTC loss ops recently!

I've noticed that CTC loss becomes quite numerically unstable for long sequences, in the attached code that reproduces the plot from the CTC paper, sequences longer than 10,000 or so degrade the quality of the gradients quite severely.

I'm not sure what the best fix is, trying to improve the numerical stability of CTC loss calculation could help, but I have no idea how difficult this would be.

In the interim, I suppose it might be worth issuing a warning when the op is used with long sequences, or placing internal consistency checks that warn the user when CTC loss may be producing bogus outputs. Or even just improving the documentation for CTC loss so that users know that this is a pitfall.

This is also sort of a public service announcement so nobody gets burned on long sequences.

Again, great work, thanks for all your effort.

:)
### Environment info

Pip Package Version: 0.10.0rc0
### Minimal Example

``` python
import numpy as np
import tensorflow as tf

%matplotlib inline
import matplotlib.pyplot as plt

# n = 100
n = 20000
k = 4

with tf.Session() as sess:
    inputs = tf.zeros((n, 1, k+1), dtype=tf.float32)
    labels_indices = tf.constant([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4]], dtype=tf.int64)
    labels_values  = tf.constant([0, 1, 2, 3, 4], dtype=tf.int32)
    labels = tf.SparseTensor(indices=labels_indices, values=labels_values, shape=(1, k+1))
    sequence_length = np.array([n])

    loss = tf.nn.ctc_loss(inputs, labels, sequence_length)
    g, = tf.gradients(loss, inputs)

    g_v = sess.run(g)

plt.plot(-g_v[:,0,:])
```
",1,,12,2016-09-04T13:54:11Z,CONTRIBUTOR
4090,Make CUDA library version numbers available from python,stat:contributions welcome,"Hi!

Is it possible to make the versions of the CUDA libraries available as a python variable? Currently, after importing, there is the following output:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.1.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally
```

So apparently the versioning information is loaded, I just couldn't find an API to access it.

I would like to record the CUDA as meta-information along with my checkpoint and event files, to be able to 100% reproduce any runs.
",0,,4,2016-08-29T08:48:15Z,NONE
4003,Print Version of cuDNN Being Used,"stat:contributions welcome,type:feature","Right now what you get is device info for example:

```
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.95GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
```

Theano prints:

```
Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)
```

giving you device info but also info on the version of cuDNN.
",1,,13,2016-08-24T04:08:20Z,CONTRIBUTOR
3945,Feature request: extend tf.select to broadcast a scalar condition,"stat:contributions welcome,type:feature","Consider allowing tensorflow.select to accept scalar conditions.  I.e., `tf.select(condition, t, e, name=None)` with `condition` a scalar, and `t`, `e` having the same shape.
",0,,20,2016-08-21T02:42:02Z,NONE
3862,tf.cumprod's gradient produces nans given zeros,"stat:contributions welcome,type:bug/performance","Example:

```
tf.reset_default_graph()
var = tf.Variable([0.])
cumprod = tf.cumprod(var)
grad = tf.gradients(cumprod, var)
init = tf.initialize_all_variables()
with tf.Session() as sess:
  sess.run(init)
  print(sess.run(grad))

---> [array([ nan], dtype=float32)]
```

@ibab Do you know the right way to fix this?
",0,,5,2016-08-16T22:27:20Z,CONTRIBUTOR
3851,CSV decode error,stat:contributions welcome,"I am using Tensorflow 0.9.0. I have CUDA Driver Version = 7.5 and CUDNN 4 on Ubuntu 14.04
This maybe related to another issue I found [here](https://github.com/tensorflow/tensorflow/issues/633)

I have a simple csv file which has a single line like this

```
""field with
newline"",0
```

where the newline has been added by pressing Enter key in vim on Ubuntu.
I am able to read this file in pandas using the read_csv function where the text field is shown as containing a single \n character.

But when I try to read it in tensorflow, I get the following error:
`tensorflow.python.framework.errors.InvalidArgumentError: Quoted field has to end with quote followed by delim or end`

My tensorflow code to read the csv uses this function to read a single row.

```
def read_single_example(filename_queue, skip_header_lines, record_defaults, feature_index, label_index):
    reader = tf.TextLineReader(skip_header_lines=skip_header_lines)
    key, value = reader.read(filename_queue)
    record = tf.decode_csv(
            value,
            record_defaults=record_defaults)
    features, label = record[feature_index], record[label_index]
    return features, label
```

If I read using pandas and replace all newlines with spaces, the tensorflow code is able to parse the csv successfully.

But it will be really helpful if newlines can be handled within the Tensorflow CSV pipeline itself.
",0,,14,2016-08-16T16:49:42Z,NONE
3840,missing return statement at end of non-void function,stat:contributions welcome,"Since TensorFlow uses C++11 I think it would be good style to fix the errors such as:

```
framework/allocator.h(155): warning: missing return statement at end of non-void function ""tensorflow::Allocator::RequestedSize""
```

The code is not harmful in this instance but the compiler would have to parse and trust comments:

``` cpp
// CHECK dies with a fatal error if condition is not true.  It is *not*
// controlled by NDEBUG, so the check will be executed regardless of
// compilation mode.
```

A simple patch for the problem would be:

``` cpp
  virtual size_t RequestedSize(void* ptr) {
    CHECK(false) << ""allocator doesn't track sizes"";
  }
```

-->

``` cpp
  virtual size_t RequestedSize  [[ noreturn ]] (void* ptr) {
    CHECK(false) << ""allocator doesn't track sizes"";
  }
```

Reference: http://www.stroustrup.com/C++11FAQ.html#attributes
",0,,7,2016-08-16T08:21:58Z,CONTRIBUTOR
3638,tf.gather produces zeros for invalid indices on GPU,"stat:contributions welcome,type:bug/performance,type:docs","### Environment info

Operating System: Ubuntu 16.04 LTS (64 bit)

```
$ dpkg -l | grep cuda | grep ^ii
ii  libcuda1-361                                361.42-0ubuntu2                                             amd64        NVIDIA CUDA runtime library
ii  libcudart7.5:amd64                          7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA Runtime Library
ii  libcudnn5                                   5.0.5-1+cuda7.5                                             amd64        cuDNN runtime libraries
ii  libcudnn5-dev                               5.0.5-1+cuda7.5                                             amd64        cuDNN development libraries and headers
ii  libcudnn5-doc                               5.0.5-1+cuda7.5                                             amd64        cuDNN documents and samples
ii  nvidia-cuda-dev                             7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA development files
ii  nvidia-cuda-doc                             7.5.18-0ubuntu1                                             all          NVIDIA CUDA and OpenCL documentation
ii  nvidia-cuda-gdb                             7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA Debugger (GDB)
ii  nvidia-cuda-toolkit                         7.5.18-0ubuntu1                                             amd64        NVIDIA CUDA development toolkit
```

```
$ find /usr/lib -name libcud\*
/usr/lib/i386-linux-gnu/libcuda.so.1
/usr/lib/i386-linux-gnu/libcuda.so.361.42
/usr/lib/i386-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcudnn_static.a
/usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a
/usr/lib/x86_64-linux-gnu/libcuda.so.1
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18
/usr/lib/x86_64-linux-gnu/libcudnn.so
/usr/lib/x86_64-linux-gnu/libcuda.so.361.42
/usr/lib/x86_64-linux-gnu/libcudnn.so.5.0.5
/usr/lib/x86_64-linux-gnu/libcudart.so
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5
/usr/lib/x86_64-linux-gnu/libcudadevrt.a
/usr/lib/x86_64-linux-gnu/libcudnn.so.5
/usr/lib/x86_64-linux-gnu/stubs/libcuda.so
/usr/lib/x86_64-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcudart_static.a
```

```
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.10.0rc0
```
### Steps to reproduce

```
In [23]: x = tf.constant([1.1,2.2,3.3])

In [24]: a = tf.constant(123,dtype=tf.int32)

In [25]: tf.gather(x,a,validate_indices=True).eval()
Gather_8: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Gather_8: /job:localhost/replica:0/task:0/gpu:0
Const_8: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Const_8: /job:localhost/replica:0/task:0/gpu:0
Const_7: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Const_7: /job:localhost/replica:0/task:0/gpu:0
Out[25]: 0.0

In [26]: 
```
",0,,27,2016-08-04T08:44:14Z,CONTRIBUTOR
3636,Inception retraining / transfer learning can only utilize one CPU core and one GPU,,"The retraining code is example code, but it does seem like there are many people experimenting with retraining and improving performance could make the example code much more useful as a launchpad for others if it can scale across GPUs and multiple CPU cores.

At the moment, running
`bazel-bin/tensorflow/examples/image_retraining/retrain --num_gpus=2 --image_dir /images`
will only result in a single GPU performing computations in `nvidia-smi`, even though both GPUs are running `python` in nvidia-smi.  GPU #2 will see zero memory/power utilization during the computation beyond idle levels.  GPU #1 will utilize all memory TensorFlow and an additional 30 watts or so.

The other related issue is that, during training, a single CPU core will be maxed out at 100% running python; given the capabilities of the card, I'm guessing removing this bottleneck would increase retraining speed by perhaps 200-400%.  `nmon` shows that disk IO is not a bottleneck.

Thanks for your time and for making TensorFlow available to everyone!
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 8.0 and 5 with two GTX 1080 cards

retrain.py: `train_batch_size` is 20000 and `learning_rate` is 0.5
1. The commit hash (`git rev-parse HEAD`): r0.9.0
2. The output of `bazel version`: Build label: 0.2.3
   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
   Build time: Tue May 17 14:21:13 2016 (1463494873)
   Build timestamp: 1463494873
   Build timestamp as int: 1463494873
",1,,9,2016-08-04T05:52:31Z,NONE
3628,Unable to import frozen graph with batchnorm,"stat:awaiting tensorflower,type:bug/performance","Error when loading the frozen graph with [tensorflow.contrib.layers.python.layers.batch_norm](https://github.com/tensorflow/tensorflow/blob/88d9bc16d6a16e5b660cda548b74944f27ddcd1b/tensorflow/contrib/layers/python/layers/layers.py)
`
ValueError: graph_def is invalid at node u'BatchNorm/cond/AssignMovingAvg/Switch': Input tensor 'BatchNorm/moving_mean:0' Cannot convert a tensor of type float32 to an input of type float32_ref
`
[freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py)  doesn't seem to store moving_mean and moving_variance properly
",2,,44,2016-08-03T18:06:26Z,NONE
3519,Suggestions for simplifying directory structure,"stat:contributions welcome,type:feature","(version/machine agnostic)

I just want to say that after using TF for a while, I still have to fire too many brain cells to remember which directory certain files are in.  

The shortest way I can say this is that I suggest placing **all** instructional/non-source files in the same directory, _probably at the top_ of tensorflow so  visitors can easily find them.

Right now there are:
- `tensorflow[org]/models` (separate repo containing pre-trained models)
- `tensorflow[org]/tensorflow/tensorflow/examples/`
  -`tensorflow[org]/tensorflow/tensorflow/models`
- `tensorflow[org]/tensorflow/tensorflow/tutorials` (these are Tensorflow website tutorials)
- `tensorflow[org]/tensorflow/tensorflow/examples/how_tos`

Hopefully I am not the only one that sometimes finds this confusing, probably because of the same words being used repeatedly to describe different things.

Suggestion 1 is to place the tensorflow/[examples & models] directories into the root of `tensorflow[org]/tensorflow` and renaming that directory to examples_tutorials, to make where to look obvious for those not digging through the source (which is probably a majority of visitors).  I think that single, simple change would simplify this directory structure quite a bit.

I have a couple of additional suggestions for renaming the tensorflow/tensorflow/models directory (note not the pre-trained repo).
1. Rename the separate tensorflow/models **repo** (that contains code pertaining to pre-trained models) to `pre-trained-models` or `pre-trained-weights` and rename the `tensorflow/examples/models` **directory** to something that conveys the fact that it contains research paper models and not pre-trained ones.
2. Rename `models/embedding` to `word2vec` or something else more descriptive

Happy to submit a PR or two if the team wants to make these changes.
",0,,2,2016-07-27T00:22:03Z,CONTRIBUTOR
3502,Streaming_mean along specific dimension,"stat:contributions welcome,type:feature","Currently the streaming_mean function computes the mean for all tensor values. It would be interesting to have the possibility to specify the axis along with we want to compute the mean. 
",0,,1,2016-07-26T08:47:09Z,NONE
3392,Remove unnecessary input-size requirement for convolutions with padding='SAME',"stat:contributions welcome,type:feature","Right now there is conflicting behavior when `padding='SAME'`: If inputs have a defined height and width, then convolutions require that filters be no larger than input images (spatially). If inputs do not have a defined height and width, then it's okay for filters to be larger than images.

I think this conflicting behavior should be removed, especially since `padding='SAME'` is used for convenience and with the intention of allowing some border effects, and because this way we can continue to use this convenience even when filter size > input size.

TensorFlow 0.9 example with defined height and width:

```
inputs = tf.placeholder(tf.float32, shape=[None, 2, 2, 3])
weights = tf.get_variable('weights', [3, 3, 3, 10], tf.float32,
                          initializer=tf.random_normal_initializer())
t = tf.nn.conv2d(inputs, weights, [1, 1, 1, 1], 'SAME')

# ValueError: Filter must not be larger than the input: Filter: (3, 3) Input: (2, 2)
```

TensorFlow 0.9 example without defined height and width:

```
inputs = tf.placeholder(tf.float32, shape=[None, None, None, 3])
weights = tf.get_variable('weights', [3, 3, 3, 10], tf.float32,
                          initializer=tf.random_normal_initializer())
t = tf.nn.conv2d(inputs, weights, [1, 1, 1, 1], 'SAME')

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print(sess.run(t, feed_dict={inputs: np.random.rand(1, 2, 2, 3)}).shape)

# Shape is what we expect: (1, 2, 2, 10)
```
",0,,4,2016-07-19T15:50:59Z,CONTRIBUTOR
3350,No GPU implementation of determinant and no gradient of determinant?,"stat:contributions welcome,type:feature","We do not have GPU implementation of determinant calculation and its gradient is not available? It is really nice to have them.

Thanks!
",0,,12,2016-07-17T08:42:07Z,NONE
3334,tf.case doesn't preserve shape information,stat:awaiting tensorflower,"tf.case is a python implementation of a case statement using tf.cond, but unlike cond it doesn't preserve shape information when executing. This is because of this little snippet:

``` python
...
    # preds = [p1, p2, p3]
    # fns = [f1, f2, f3]
    # not_preds = [~p1, ~p2, ~p3]
    # and_not_preds = [True, ~p1, ~p1 & ~p2, ~p1 & ~p2 & ~p3]
    # case_preds = [p1,
    #               p2 & ~p1,
    #               p3 & ~p2 & ~p1,
    #              ~p3 & ~p2 & ~p1]

    case_preds = []
    for i, (p, and_not_p_prev) in enumerate(zip(preds, and_not_preds[:-1])):
      with ops.name_scope(""case_%d"" % i):
        case_preds.append(math_ops.logical_and(p, and_not_p_prev))
    with ops.name_scope(""case_none_are_true""):
      case_preds.append(and_not_preds[-1])

    # Create an empty tensor, or list, with the right type and shape
    with ops.name_scope(""case_create_empty""):
      dummy_value = default()
      def _correct_empty(v):
        if isinstance(v, ops.Operation):
          return no_op()
        elif v.dtype == dtypes.string:
          return array_ops.constant("""")
        else:
          return array_ops.constant(v.dtype.as_numpy_dtype())

      if isinstance(dummy_value, collections.Sequence):
        dummy_type = type(dummy_value)
        empty = lambda: dummy_type(_correct_empty(v) for v in dummy_value)
      else:
        empty = lambda: _correct_empty(dummy_value)

    # case_sequence = [
    #   cond(~p3 & ~p2 & ~p1, default, empty),
    #   cond(p3 & ~p2 & ~p1, f3, lambda: case_sequence[0]),
    #   cond(p2 & ~p1, f2, lambda: case_sequence[1]),
    #   cond(p1, f1, lambda: case_sequence[2])
    # ]
    #
    # And the return value will be case_sequence[-1]
    def _build_case():
      all_fns = [fn for fn in fns]
      all_fns.append(default)
      prev_case = None
      for i, (cp, fn) in enumerate(list(zip(case_preds, all_fns))[::-1]):
        prev_case = cond(
            cp, fn,
            empty if i == 0 else lambda: prev_case,
            name=""If_%d"" % i)
      return prev_case
...
```

The op works by evaluating a series of predicates (including a predicate for the default value) but it starts off with an empty object. The empty object seems to be designed to pass on correct shape and type information but it fails to do so in my use case. I recommend changing this code to read:

``` python
...
    # preds = [p1, p2, p3]
    # fns = [f1, f2, f3]
    # not_preds = [~p1, ~p2, ~p3]
    # and_not_preds = [True, ~p1, ~p1 & ~p2, ~p1 & ~p2 & ~p3]
    # case_preds = [p1,
    #               p2 & ~p1,
    #               p3 & ~p2 & ~p1]

    case_preds = []
    for i, (p, and_not_p_prev) in enumerate(zip(preds, and_not_preds[:-1])):
      with ops.name_scope(""case_%d"" % i):
        case_preds.append(math_ops.logical_and(p, and_not_p_prev))

    # case_sequence = [
    #   cond(p3 & ~p2 & ~p1, f3, default),
    #   cond(p2 & ~p1, f2, lambda: case_sequence[0]),
    #   cond(p1, f1, lambda: case_sequence[1])
    # ]
    #
    # And the return value will be case_sequence[-1]
    def _build_case():
      all_fns = [fn for fn in fns]
      prev_case = None
      for i, (cp, fn) in enumerate(list(zip(case_preds, all_fns))[::-1]):
        prev_case = cond(
            cp, fn,
            default if prev_case is None else lambda: prev_case,
            name=""If_%d"" % i)
      return prev_case
...
```

This removes the need not only for creating a dummy empty op, but also removes the need to create a separate predicate for the default op, simplifying the whole op by about 18 lines of code.
",1,,10,2016-07-15T22:36:01Z,NONE
3332,Feature Request: Support for depthwise convolution by groups,type:feature,"As much as I have managed to follow the API section of tensorflow the depthwise_conv2d doesn't fulfill my thoughts on what I would like to do with the input/filters.

```
shape = (2,5,5,48,128)
initializer = tf.truncated_normal_initializer(stddev=1e-2)
kernel = tf.get_variable(name='weights', shape=shape, initializer=initializer)
```

Considering the input is of shape (batch_size, 55, 55, 96),
the function definition would be:

```
def depthwise_group_conv2d(input, filter, groups, strides, padding, name)
```

which would be able to do

```
conv = tf.nn.depthwise_group_conv2d(input, kernel, [48,48], strides, padding, name)
```

that would split the input depthwise into depths from given 'groups' parameter and perform the convolution with shared parameters (i.e. depths [:48] take weights[0] and depths[48:] take weights[1]) inside a group. Then the outputs of convolutions by groups would be concatenated depthwise.

This would make it easier to define groups such as one used in AlexNet/CaffeNet architectures.

Hopefully I have missed a certain feature already existing for making this easier.

Best regards,
Filip
",1,,31,2016-07-15T17:50:40Z,NONE
3001,Use Basic neural network subroutines (BNNS) on iOS,"stat:contributions welcome,type:feature","Take advantage of the [BNNS library that Apple announced for iOS](https://developer.apple.com/reference/accelerate/1912851-bnns).
",1,,10,2016-06-22T23:09:53Z,CONTRIBUTOR
2916,[Feature] RDMA support for distribued Tensorflow,stat:contributions welcome,"Tensorflow paper (http://arxiv.org/pdf/1605.08695v1.pdf) states that Tensorflow supports multiple communication protocols such as gRPC over TCP, and RDMA over Converged Ethernet. Current repo, on the other hand, only has gRPC implementations. 

Do you have any plan to introduce RDMA support? It should be beneficial especially for GPU-to-GPU communications across servers. 
",0,,59,2016-06-16T23:07:16Z,NONE
2807,Slow quantized graph,,"1. On Ubuntu 15.10 with CUDA 7.5, cuDNN 7.0, tensorflow-0.9.0rc0, ran ""tensorflow/examples/label_image/"" application by taking inception-v3 graph and roughly measure the elapsed time. 
2. Then take ""tensorflow/contrib/quantization/tools:quantize_graph"" to quant inception-v3, rebuilt application by giving 
   
   ```
   ""//tensorflow/contrib/quantization:cc_ops"",
   ""//tensorflow/contrib/quantization/kernels:quantized_ops"",
   ```

into ""tensorflow/examples/label_image/BUILD"" and redo the same classification and measure the time. 

Before/After quantization, elapsed time were 6 seconds vs. 17 seconds, i.e. quantization doubled the inference time? 

The results looks ok as below so I think I was running it correctly. 
Before
- military uniform (866): 0.647299
- suit (794): 0.0477195
- academic gown (896): 0.0232407
- bow tie (817): 0.0157355
- bolo tie (940): 0.0145023

After
- military uniform (866): 0.703474
- suit (794): 0.0248454
- bow tie (817): 0.0171362
- bolo tie (940): 0.0171362
- academic gown (896): 0.0164432

My tensor flow was built as CPU only. Have also tried to enable GPU while the timing didn't change. Do we know what the expected performance would be? 
",1,,37,2016-06-11T16:50:02Z,NONE
2793,Clipping gradient w.r.t. inputs at each time step for RNN/LSTM,stat:contributions welcome,"New feature request:

While training LSTMs, is it often useful to clip the derivates w.r.t the inputs into the LSTM at each time step ([Alex Graves](http://arxiv.org/pdf/1308.0850v5.pdf), Sec 2.1). This is different from clipping the overall gradient. Theano supports this feature with `theano.gradient.grad_clip(tensor_var)`. Can we have a similar feature in tensorflow? 
",1,,7,2016-06-10T21:53:17Z,NONE
2789,DropoutWrapper has unintended mask behavior when random seed is set,stat:contributions welcome,"When using the non-dynamic `rnn`, if the `seed` is set to something other than `None` for `DropoutWrapper`, the dropout masks for the inputs become synchronized across time steps. I.e. the same input dimension is dropped for all time steps for a given entry in a batch. If the maximum number of time steps varies between batches, then the later time steps begin to go out of sync (but all time steps that are earlier than the shortest sequence remain synchronized throughout). This behavior only affects the statically rolled out `rnn`. Dynamically rolled out RNNs using `dynamic_rnn` are always randomized per time step.
",0,,8,2016-06-10T18:17:33Z,NONE
2625,Numerically stable summation methods,"stat:contributions welcome,type:feature","It would be nice to be able to use numerically stable summation methods like
- pairwise summation
- Kahan summation

for applications where numerical accuracy is important.
This could work with an optional `stable` keyword argument to `tf.reduce_sum` or via a `tf.stable_reduce_sum` op.

I think implementing Kahan summation in the Eigen tensor library wouldn't be difficult at all, we would simply have to add a stateful `KahanSumReducer`.
It should also be possible to provide a vectorized version.
Pairwise summation might be more difficult, as the reduction code would have to be touched.
",0,,9,2016-06-02T18:42:58Z,CONTRIBUTOR
2594,add tf.assert for GPU (maybe also host-memory Const[string] for GPU) was: dynamic_rnn GPU support error ,"stat:contributions welcome,type:feature","When attempting to place dynamic_rnn on the gpu, I get the following error:

```
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'RNN/Assert/data_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available
         [[Node: RNN/Assert/data_2 = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values:  but saw shape: >, _device=""/device:GPU:0""]()]]
```

Full traceback:

```
Traceback (most recent call last):
  File ""test_model2_parallel_buffered.py"", line 84, in <module>
    sess.run(init_op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 333, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 573, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 648, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'RNN/Assert/data_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available
         [[Node: RNN/Assert/data_2 = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values:  but saw shape: >, _device=""/device:GPU:0""]()]]
Caused by op u'RNN/Assert/data_2', defined at:
  File ""test_model2_parallel_buffered.py"", line 47, in <module>
    tower_logits_t = model.inference(frames_t, seq_length_t, BATCH_SIZE)
  File ""/home/woodward/ml/football_plays/model2.py"", line 73, in inference
    _, rnn_state_final_t = tf.nn.dynamic_rnn(rnn_cell, rnn_inputs_t, sequence_length=seq_length_t, initial_state=rnn_initial_state_t, swap_memory=True, time_major=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 567, in dynamic_rnn
    [_assert_has_shape(sequence_length, [batch_size])]):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 562, in _assert_has_shape
    packed_shape, "" but saw shape: "", x_shape])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/logging_ops.py"", line 58, in Assert
    return gen_logging_ops._assert(condition, data, summarize, name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_logging_ops.py"", line 37, in _assert
    summarize=summarize, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 410, in apply_op
    as_ref=input_arg.is_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 664, in convert_n_to_tensor
    ret.append(convert_to_tensor(value, dtype=dtype, name=n, as_ref=as_ref))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 166, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1224, in __init__
    self._traceback = _extract_stack()
```

It seems to have some problem with a tensor shape, but I can't deduce why. This error does not occur if I enclose the tf.nn.dynamic_rnn(...) call in a tf.device('/cpu:0') statement. I am on commit 0050a205bc5521a563ee66baa3b73373d4c0e62e from mid last week.

I am doing data parallel processing and am trying to keep as much as possible on each GPU.
",0,,12,2016-05-31T18:21:37Z,NONE
2412,Packaged TensorFlow C++ library for bazel-independent use,"stat:contributions welcome,type:feature","Currently, building a C++ application in tensorflow requires creating a project in the tensorflow source tree and compiling with bazel. In my case I would like to use tensorflow in a (fairly large) existing application with an existing build system that would be difficult to port to bazel. The solution to me seems to be exposing tensorflow as a library that can be linked with.
",0,,62,2016-05-18T02:39:12Z,CONTRIBUTOR
2305,FR: Create/Support an automated hyperparameter selector like TPOT,stat:contributions welcome,"Not sure if you've seen TPOT (http://rhiever.github.io/tpot/, introductory blog post at http://www.randalolson.com/2016/05/08/tpot-a-python-tool-for-automating-data-science/) but it would be awesome if you collaborated with them to add something like this to TensorFlow.
",0,,0,2016-05-10T14:50:21Z,NONE
2291,Add -lm (Was: undefined reference to symbol 'ceil@@GLIBC_2.2.5),stat:contributions welcome,"### Environment info

Operating System:

epel-release-6-8.noarch
redhat-release-server-6Server-6.7.0.3.el6.x86_64

Installed version of CUDA and cuDNN: 

None

If installed from sources, provide the commit hash:

f8eb1d70a7ea7dc2cd5e1eddde389395f88a6be9
### Steps to reproduce
1. bazel clean
2. ./configure
3. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

ERROR: /home/ebice/tensorflow/google/protobuf/BUILD:272:1: Linking of rule '//google/protobuf:protoc' failed: gcc failed: error executing command /opt/rh/devtoolset-2/root/usr/bin/gcc -o bazel-out/host/bin/google/protobuf/protoc -no-canonical-prefixes -B/opt/rh/devtoolset-2/root/usr/bin -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' ... (remaining 11 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/opt/rh/devtoolset-2/root/usr/bin/ld: /opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/libstdc++_nonshared.a(hashtable_c++0x44.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'
/opt/rh/devtoolset-2/root/usr/bin/ld: note: 'ceil@@GLIBC_2.2.5' is defined in DSO /lib64/libm.so.6 so try adding it to the linker command line
/lib64/libm.so.6: could not read symbols: Invalid operation
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
",0,,12,2016-05-09T13:34:03Z,NONE
2217,Wrap cuSOLVER in stream,stat:contributions welcome,"I have started to wrap NVIDIA's cusolver library (LAPACK-like) for my work on #367. Is this something the TF team would consider supporting/helping with? I have so far only wrapped potrf, but adding more functions should be fairly easy now that I have done the long-winded bit.

[Its in my fork](https://github.com/c0g/tensorflow).
",0,,10,2016-05-04T11:46:19Z,CONTRIBUTOR
2169,Unpooling layer in tensorflow,"stat:contributions welcome,type:feature","It would be nice to have in TensorFlow also the unpooling layer as it is described in the paper on deconvolution networks: http://cvlab.postech.ac.kr/research/deconvnet/

I was googling a bit and I found that the added unpooling layer would be handful also for others:
http://stackoverflow.com/questions/36548736/tensorflow-unpooling 
",0,,109,2016-04-29T14:19:23Z,CONTRIBUTOR
2146,CTC GPU support,stat:contributions welcome,"Very happy to see CTC in  #tensorflow! #32
My question is:
Is someone working on CTC GPU implement internal? Or is it 'contribution welcomed'?
Baidu has a CTC GPU implement:

https://github.com/baidu-research/warp-ctc
",1,,26,2016-04-28T09:22:54Z,NONE
2126,Auto device placement for distributed runtime,,"In a distributed TF setting, we need to place variables and ops to different devices. This is annoying to manually assign each variable and op, especially when we have GPU resources in our environment.

TF offer a context named `tf.train.replica_device_setter` which place variables to ps devices in round-robin manner, and this is helpful but not enough. @mrry can you shed some light on the auto distributed devices placement problem?
",2,,32,2016-04-27T08:07:02Z,NONE
2118,Default for tf.nn.conv2d_transpose output_shape,"stat:contributions welcome,type:feature","I am currently working with `tf.nn.conv2d_transpose`. From the past I am used to Caffe deconvolution layer and `tf.nn.conv2d_transpose` is kind of TensorFlow equivalent to it.

My question here is if someone could point me to detailed behaviour/documenatation of `tf.nn.conv2d_transpose`.
Particularly I am confused by `output_shape` parameter. My question is, why there is needed the `output_shape` parameter. Isn't the output shape directly come from the conv2d_transpose operation?
Based on how I understand it from Caffe and from [here](http://cs231n.stanford.edu/slides/winter1516_lecture13.pdf), computed as:

```
h = ((len(value[1]) - 1) * stride_h) + kernel_h - 2 * pad_h
w = ((len(value[2]) - 1) * stride_w) + kernel_w - 2 * pad_w
```

What happens when I set `output_shape` smaller than `h` and `w`? Is the new layer being cropped?

What happens when I set it higher? Is there being created padding with only zeros?
",0,,20,2016-04-26T20:50:52Z,CONTRIBUTOR
1882,Distortions in Retrain.py (Transfer learning w/ inception model) take exceedingly long,stat:contributions welcome,"### Environment info

Operating System:
Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA: 7.5
cuDNN: 6.5 (v2)
Using nVidia Quadro K2200

If installed from sources, provide the commit hash:
fe9dafd1583da5ccc205eab776f86afcb00411d2
### Steps to reproduce

Retrain.py runs fine without any distortions. Not massively faster than CPU, but faster.
NVIDIA-SMI shows that the GPU has 3824mb used during training.

If any distortions are used, training becomes very, very, long. It takes almost ten minutes for ten images to be trained.

Is this very slow speed intended?

Best

Oren
",0,,6,2016-04-12T16:48:36Z,NONE
1843,Implement an efficient AssignMatMul() for general BLAS GEMM pattern,"stat:contributions welcome,type:feature","TensorFlow currently lacks efficient in-place matrix updates such as rank-1 update `A += U V'`. @rmlarsen recommends supporting these in-place updates through a single new `AssignMatMul()` method that wraps the underlying GEMM kernels in Eigen or cuBlas etc.
",0,,1,2016-04-11T00:36:52Z,CONTRIBUTOR
1763,"image processing functions should not convert dtypes unless necessary (e.g. resize/crop/transpose/rotate, ...)","stat:contributions welcome,type:bug/performance,type:feature","### Environment info

Operating System: OSX

If installed from binary pip package, provide:
1. package: tensorflow
2. version: 0.7.1
### Steps to reproduce

Perform a resize action on a decoded jpeg before passing it to convert_image_dtype with a target of float32.  The values will still be in the range 0-255 rather than 0-1.

This line works as expected
tf.image.convert_image_dtype(tf.image.decode_jpeg(value, channels=3), tf.float32)
This line doesn't(values in the tensor are still 0-255 rather than 0-1)
tf.image.convert_image_dtype(tf.resize_images(tf.image.decode_jpeg(value, channels=3), x, y), tf.float32)
### What have you tried?
1. Changing the order as described above works.
",0,,25,2016-04-04T04:35:07Z,NONE
1736,Batch normalization for RNNs,stat:contributions welcome,"I realize that this is hot off the press, but since batch normalization for feed forward layers is being added, any chance we can see it for RNNs? The performance improvements seem substantial.

http://arxiv.org/abs/1603.09025
",0,,12,2016-04-01T01:14:40Z,NONE
1686,Distributed cluster manager support: Slurm,stat:contributions welcome,"Per the comment on [this introduction](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md), i.e. 

> N.B. Manually specifying these cluster specifications can be tedious, especially for large clusters. We are working on tools for launching tasks programmatically, e.g. using a cluster manager like Kubernetes. If there are particular cluster managers for which you'd like to see support, please raise a GitHub issue.

Is there is any possibility of supporting [Slurm](http://slurm.schedmd.com/)? Forgive my ignorance but I've really only played around with TensorFlow and I've only used Slurm for fairly simple MPI projects, but I recently got access to a cluster with some GPU nodes and I'd like to incorporate TF in my research project. It would be great if I was able to use all the resources I could to speed things along.

If it helps, specific info about the setup can be found [here](https://wiki.auckland.ac.nz/display/CER/Centre+for+eResearch+User+Documentation+Start).
",0,,9,2016-03-29T02:02:43Z,NONE
1604,Feature request: Implementing spatially-sparse conv networks in TensorFlow,"stat:contributions welcome,type:feature","I am inspired by Dr. Ben Graham's recent work regarding spatially-sparse convolutional neural networks:

http://arxiv.org/abs/1409.6070 (particularly section 2.3)
http://www2.warwick.ac.uk/fac/sci/statistics/staff/academic-research/graham/sparse3d.pdf

He has graciously open-sourced his neural network library but I'd like to utilize these same ideas in my models, which are implemented in Tensorflow.

Unfortunately, I'm finding his implementation and citations a little hard to follow, but his description of a ""feature matrix"" and a ""pointer matrix"" sounds a little like something that can be implemented using sparse variable updates in Tensorflow (https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#sparse-variable-updates), but I'm afraid that it might not be so simple and would require building custom kernels to support a new-ish type of convolution. But I don't know enough to say for certain which direction to take.

Any thoughts on how we can bring spatially-sparse convolutions to Tensorflow? Anyone interested in collaborating on implementing this?
",0,,12,2016-03-23T20:24:09Z,NONE
1592,Binary ops,"stat:contributions welcome,type:feature","Is there already a plan to add binary ops like bitcount for [XNOR-NET](http://arxiv.org/abs/1603.05279)?
",0,,67,2016-03-23T09:02:04Z,NONE
1539,[clang+CUDA] No ZeroesLike[DT_BOOL] kernel,stat:contributions welcome,"I'm working on getting tensorflow to build its GPU code with clang.

I have a hacked up crosstool, a hacked up clang (for std::complex support), and some minor changes to eigen (which are awaiting review).  The branch is at jlebar/tensorflow@cuda-clang, but checking that out isn't sufficient, because you need to customize some paths to make crosstool happy.  Anyway you don't have my WIP compiler changes, so you won't get very far.  :)

Having said all that, I'm trying to get the tensorflow tests to pass, while I wait for tra@ to hopefully figure out the crosstool business.  I'm looking at this one

```
$ bazel test -c opt --config=cuda_clang //tensorflow/core:ops_array_grad_test 
```

, which fails with

```
E tensorflow/core/common_runtime/executor.cc:332] Executor failed to create kernel. Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n4 = ZerosLike[T=DT_BOOL](n1)
     [[Node: n4 = ZerosLike[T=DT_BOOL](n1)]]
F tensorflow/core/ops/array_grad_test.cc:365] Check failed: ::tensorflow::Status::OK() == (sess->Run({{""x:0"", x}, {""dims:0"", dims}, {""dy:0"", dy}}, {""dx:0"", ""dx:1""}, {}, &out)) (OK vs. Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n4 = ZerosLike[T=DT_BOOL](n1)
     [[Node: n4 = ZerosLike[T=DT_BOOL](n1)]]
     [[Node: dx = SymbolicGradient[Tin=[DT_FLOAT, DT_BOOL, DT_FLOAT], Tout=[DT_FLOAT, DT_BOOL], f=Reverse[T=DT_FLOAT], _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_x_0/_2, _recv_dims_0/_4, _recv_dy_0/_6)]]
     [[Node: dx/_8 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_14_dx"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]])
external/bazel_tools/tools/test/test-setup.sh: line 52: 106730 Aborted                 (core dumped) ""$@""
```

Looking through the code, it seems that there's no zeroing kernel for bools, so I'm not sure how this is supposed to work?  The obvious change to add a kernel, jlebar/tensorflow@286c1647cca9ebcdbce4497995c794d4b0c55633, doesn't work -- we seem to invoke the new kernel, but the whole program just silently dies.

I'm pretty confused by what's going on here, what with the To32Bit functor being applied to an array of doubles (?) and so on.  Any pointers would be very much appreciated.
",0,,20,2016-03-18T02:01:26Z,MEMBER
1374,Document trick with slash in scope names,"stat:contributions welcome,type:docs","The documentation for `tf.name_scope` is rather ambiguous on what happens if the scope name ends with '/', merely stating what happens if it doesn't end with a '/'. The fact that the behavior is different, specifically that ending with a '/' does not result in automatically uniqueifying the scope name, is very important and useful, because sometimes one wants to reenter a previously created scope. This possibility is only alluded to when describing recapturing `scope` variables, but the functionality is more general than that.
",0,,1,2016-03-03T18:44:24Z,NONE
1325,tf.get_variable() cannot recognize existing variables,"stat:awaiting tensorflower,type:support","`with tf.variable_scope(""conv"", reuse=True):
    x = tf.get_variable(""w"",[1])`

The above code cannot recognize an existing variable, but clearly the existing variable was created before as print out of the variable .name shows : `conv/w:0`

I get an error when using tf.get_variable:
`ValueError: Under-sharing: Variable conv/w does not exist, disallowed. Did you mean to set reuse=None in VarScope?`

If set to reuse=None...
`with tf.variable_scope(""conv"", reuse=None):
    x = tf.get_variable(""w"",[1])`

Then it creates another variable with .name  `conv/w_1:0`

It's a bug! Now I have 2 variables, with names `'conv/w'`  and `'conv/w_1'`
",0,,54,2016-02-28T09:16:41Z,NONE
1122,Easy to use batch norm layer.,"stat:contributions welcome,type:docs","Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.

It would be nice to have an official batch norm layer given its importance in training DNNs.
",1,,125,2016-02-16T13:18:56Z,CONTRIBUTOR
971,Expose TensorFlow build details,"stat:contributions welcome,type:feature","Requesting addition of API method(s) to enable programmatic checking of TensorFlow version and other build capabilities (such as if TF was compiled with GPU support, for eg.). I would find this useful in deployment scripts that operate in foreign TensorFlow environments.
",0,,6,2016-02-02T22:29:56Z,NONE
956,Feature request: other types of padding besides zero-padding.,"stat:contributions welcome,type:feature","I would like to have other options of padding for tf.pad and convolution ops.

Some types that come to my mind right now:
- reflect
- constant value (other than zero)
- maybe implement other options of numpy.pad: http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.pad.html
",0,,12,2016-02-02T03:01:18Z,CONTRIBUTOR
823,Give a convenient way to retrieve shadow variables created by ExponentialMovingAverage.,"stat:contributions welcome,type:feature","At first I was under the impression, the variables returned by `tf.moving_average_variables()` would be shadow variables created, but that does not seem to be the case (they didn't save/restore correctly for me). 

Now that I'm reading the code, that seems to be the intention, though? Shouldn't [this line](https://github.com/tensorflow/tensorflow/blame/f2bd0fc399606d14b55f3f7d732d013f32b33dd5/tensorflow/python/training/moving_averages.py#L227) read 

```
ops.add_to_collection(ops.GraphKeys.MOVING_AVERAGE_VARIABLES, avg)
```

? 

If not, it would be great to save the averages under some other key and make them easily retrievable for the saver in a similar way as `tf.moving_average_variables()`, maybe as  `tf.moving_average_shadow_variables()`.
",0,,11,2016-01-20T21:34:04Z,CONTRIBUTOR
781,rotate an image for data augmentation,type:feature," I would like to rotate an image from a random angle, for data augmentation. But I don't find this transformation in the tf.image module.

see: http://stackoverflow.com/questions/34801342/tensorflow-how-to-rotate-an-image-for-data-augmentation
",1,,60,2016-01-15T06:51:12Z,NONE
720,Make tensorflow and tensorflow-devel deb packages,"stat:contributions welcome,type:build/install","Will you make it possible to install and update it by distributions package systems (deb & rpm)? You can make an official repository.
Will you make it possible to install a Tensorflow-devel package, which gives acces to C++ headers to make programs, which link to Tensorflow?
",0,,35,2016-01-07T19:00:38Z,NONE
675,Gradients of non-scalars (higher rank Jacobians),"stat:contributions welcome,type:feature","Currently if you call gradients(ys, xs), it will return the sum of dy/dx over all ys for each x in xs. I believe this doesn't accord with an a priori mathematical notion of the derivative of a vector. I'd like the way to take the derivative of ys wrt xs where both are vectors and have a Jacobian matrix returned. By extension, I'd like to take the derivative of a vector wrt a matrix and get back a 3-tensor. There doesn't seem to be a convenient tensorflow function to compute the Jacobian or higher order derivatives. Am I missing something or is this functionality that we could add? 
",0,,51,2016-01-04T11:16:43Z,CONTRIBUTOR
636,Implementation for GPU depthwise max pooling,"stat:contributions welcome,type:feature","I have this code:

```
    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,
                                        log_device_placement=True))
    with tf.device(""/gpu:0""):
        s, readout, h_fc1 = createNetwork()
    with sess:
            trainNetwork(s, readout, h_fc1, sess)
```

This fails with this error:

```
W tensorflow/core/common_runtime/executor.cc:1076] 0x28d7890 Compute status: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
W tensorflow/core/common_runtime/executor.cc:1076] 0x2a693f0 Compute status: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1039_add_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 428, in _do_run
    target_list)
tensorflow.python.pywrap_tensorflow.StatusNotOK: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1039_add_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bob_learning.py"", line 222, in <module>
    main()
  File ""bob_learning.py"", line 219, in main
    playGame()
  File ""bob_learning.py"", line 216, in playGame
    trainNetwork(s, readout, h_fc1, sess)
  File ""bob_learning.py"", line 141, in trainNetwork
    readout_t = readout.eval(feed_dict = {s : [s_t]})[0]
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 460, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2910, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py"", line 444, in _do_run
    e.code)
tensorflow.python.framework.errors.UnimplementedError: Depthwise max pooling is currently only implemented for CPU devices.
     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=""SAME"", strides=[1, 1, 1, 512], _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_2)]]
     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1039_add_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op 'MaxPool', defined at:
  File ""bob_learning.py"", line 222, in <module>
    main()
  File ""bob_learning.py"", line 219, in main
    playGame()
  File ""bob_learning.py"", line 214, in playGame
    s, readout, h_fc1 = createNetwork()
  File ""bob_learning.py"", line 98, in createNetwork
    h_pool3_flat = tf.reshape(max_pool_featurewise(h_conv3, old_num_filters), [-1, IMSIZE * IMSIZE])
  File ""bob_learning.py"", line 52, in max_pool_featurewise
    return tf.nn.max_pool(x, ksize = [1, 1, 1, num_filters], strides = [1, 1, 1, num_filters], padding = ""SAME"")
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 235, in max_pool
    name=name)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 449, in _max_pool
    strides=strides, padding=padding, name=name)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py"", line 664, in apply_op
    op_def=op_def)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1834, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1043, in __init__
    self._traceback = _extract_stack()
```

As far as I understand, it should just place that single op on the CPU and everything else on the GPU.
",0,,4,2015-12-28T12:37:47Z,NONE
631,Provide sugar for insuring gradient computation of an op is put on the desired device,"stat:contributions welcome,type:feature","Currently, it is somewhat involved to insure that a set of ops are put on the desired device for both the forward and backward (gradient) computations. For example if I have a function that defines its own scope like:

```
def my_op(inputs, name=None):
    with tf.op_scope([inputs], name, 'my_op') as scope:
        ...
```

Simply using the following code would not place its gradient calculations on the specified device:

```
with tf.device('/gpu:0'):
    my_op(...)
```

Instead, the only way I got the above to really work is to define a device function that not only checks the name of the op but also all incoming nodes (because TF adds a lot of additional operations that are not explicitly named under the scope), like this:

```
def _device_function(op):
    if ('my_op' in op.name) or any('my_op' in node.name for node in op.inputs):
        return ""/gpu:0""
    else:
        return None
```

This is unnecessarily involved and may very well be error-prone. Something like a boolean `grad` option for `tf.device` so that the user can simply specify `tf.device(..., grad=True)` would be far cleaner.
",0,,0,2015-12-27T16:07:47Z,NONE
464,RMSProp optimization support for sparse tensors,"stat:contributions welcome,type:feature","It seems that tf.nce_loss is not compatible with the optimizers RMSProp, ADAGRAD and Momentum. (while SGD, ADAM and FTRL works fine).

When using rmsprop, I get this error:

```
    optimizer = tf.train.RMSPropOptimizer(learning_rate = learning_rate, decay = rms_prop_decay).minimize(nce_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 167, in minimize
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 256, in apply_gradients
    update_ops.append(self._apply_sparse(grad, var))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/rmsprop.py"", line 81, in _apply_sparse
    raise NotImplementedError()
NotImplementedError
```

When using adagrad or momentum, I get this error:

```
    optimizer = tf.train.MomentumOptimizer(learning_rate, learning_momentum).minimize(nce_loss)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 167, in minimize
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 256, in apply_gradients
    update_ops.append(self._apply_sparse(grad, var))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/momentum.py"", line 51, in _apply_sparse
    self._momentum_tensor, use_locking=self._use_locking).op
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/gen_training_ops.py"", line 237, in sparse_apply_momentum
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 633, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1712, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1417, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_ops.py"", line 111, in _SparseApplyMomentumShape
    tensor_shape.TensorShape([None]).concatenate(accum_shape[1:]))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 481, in merge_with
    self.assert_same_rank(other)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 524, in assert_same_rank
    ""Shapes %s and %s must have the same rank"" % (self, other))
ValueError: Shapes TensorShape([Dimension(128), Dimension(11), Dimension(192)]) and TensorShape([Dimension(None), Dimension(192)]) must have the same rank
```

Is that expected?
The exact same code works perfectly fine with adam or sgd optimizers, so I do not think I made a mistake when constructing the graph.
",0,,14,2015-12-10T10:33:18Z,NONE
436,Need better error message for error in checkpoint loading,"stat:contributions welcome,type:feature","Hi, I'm loading a previously-built model using the tf.train.Saver and running into an error: `tensorflow.python.pywrap_tensorflow.StatusNotOK: Internal: Unable to get element from the feed.`.

I'm not quite sure what this is referring to as I can load other models just fine. This one also builds and runs as expected. It's only after, when retrieving it again, do I get this error. The ckpt file also points to the correct locations and is reading from the right place.

```
Traceback (most recent call last):
  File ""bridge.py"", line 518, in <module>
    tf.app.run()
  ...
  File ""bridge.py"", line 375, in train
    saver.restore(sess, checkpoint)
  File "".../site-packages/tensorflow/python/training/saver.py"", line 887, in restore
    sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})
  File "".../site-packages/tensorflow/python/client/session.py"", line 368, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File "".../site-packages/tensorflow/python/client/session.py"", line 446, in _do_run
    six.reraise(e_type, e_value, e_traceback)
  File "".../site-packages/tensorflow/python/client/session.py"", line 428, in _do_run
    target_list)
tensorflow.python.pywrap_tensorflow.StatusNotOK: Internal: Unable to get element from the feed.
```

Thoughts?
",0,,15,2015-12-07T23:14:24Z,NONE
378,matmul gradients incorrect with complex64 tensors,"stat:contributions welcome,type:bug/performance","The conjugation step was skipped.
See  https://tensorflow-review.googlesource.com/#/c/1154/ for unit tests and a fix
",0,,7,2015-11-30T18:43:35Z,CONTRIBUTOR
360,Warn when calling session.run() on a very large scatter,"stat:contributions welcome,type:feature","Scatter ops output a ref to the whole tensor for easier chaining. The problem is if one executes the op directly in Session.run() the whole tensor is copied back as a numpy array. This can create very annoying and hard to find performance problems. I think you should consider adding a warning.

For example:
large_table = tf.Variable(... [1000000, 3])
set3_op = tf.scatter_update(large_table, 3, [1,2,3])

session.run([set3_op])

Here run() modifies just 3 elements of the table but returns the whole table as a numpy array that is then 
ignored.
",1,,8,2015-11-26T10:02:45Z,CONTRIBUTOR
252,Make TensorFlow compatible with PyPy,"stat:contributions welcome,type:feature","I know it's not a priority and will be a long way to get there; but making TF compatible with PyPy woud be super cool.

Thoughts?
",0,,16,2015-11-17T08:07:22Z,NONE
216,MatMul Broadcasting / tensordot,"stat:contributions welcome,type:feature","It would really help if `matmul()` and element-wise `mul()` were broadcastable, like in Numpy.  Otherwise you're writing a bunch of boilerplate reshaping code.

For example, suppose I have a `T x n x k` and want to multiply it by a `k x k2`, and then to a max pool over `T` and then a mean pool over `n`.  To do this now, I think you need to reshape, do the `matmul()` and then undo the reshape and then do the pooling.
",0,,12,2015-11-14T05:00:31Z,NONE
152,Segmentation fault when GPUs are already used,stat:contributions welcome,"When I set the nvidia driver in exclusive mode and one of the GPU is already used by another process, I get a segmentation fault:

```
$ python -c ""import tensorflow as tf;tf.InteractiveSession()""
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12
Segmentation fault (core dumped)
```

If I limit the visible GPUs to only GPUs that have nothing running on them, it don't segfault:

```
$CUDA_VISIBLE_DEVICES=1 python -c ""import tensorflow as tf;tf.InteractiveSession()""
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12
I tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:09:00.0
Total memory: 12.00GiB
Free memory: 11.87GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:643] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 12105628263
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 12
```

Here is my output of nvidia-smi:

```
$ nvidia-smi 
Wed Nov 11 16:48:27 2015       
+------------------------------------------------------+                       
| NVIDIA-SMI 352.39     Driver Version: 352.39         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 750     Off  | 0000:05:00.0      On |                  N/A |
| N/A   48C    P8     0W /  38W |     25MiB /  2047MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |
| 42%   82C    P2   127W / 250W |    262MiB / 12287MiB |     39%   E. Process |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |
| 22%   46C    P8    17W / 250W |     23MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |
| 22%   37C    P8    15W / 250W |    361MiB / 12287MiB |      0%   E. Process |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1171    G   /usr/bin/X                                      17MiB |
|    1     32740    C   python                                         209MiB |
|    3      9429    C   python                                         336MiB |
+-----------------------------------------------------------------------------+

```

I suppose that in the code that check the available GPUs, it don't handle correctly a case when one of the GPUs can't be used.
",0,,39,2015-11-11T21:50:05Z,NONE
70,Human Consumable Language Independent DSL,stat:contributions welcome,"Is there a possibility to have a human consumable language independent DSL from which a program in any desired language can be generated.
",0,,21,2015-11-10T03:34:47Z,NONE
37,Node.js (JavaScript) Wrapper API,"languages,stat:contributions welcome","Because JavaScript is Awesome
",0,,231,2015-11-09T20:17:58Z,NONE
22,OpenCL support,"cuda,stat:contributions welcome","I understand TensorFlow only supports CUDA. What would need to be done to add in OpenCL support?
",1,,494,2015-11-09T17:41:26Z,NONE
19,Swift API,"languages,stat:contributions welcome","Swift is a very popular and expressive language with a large community of pro developers.
",0,,59,2015-11-09T17:33:09Z,NONE
18,C# api,"languages,stat:community support","C# is very popular and expressive language with a large community of pro developers.
",0,,76,2015-11-09T17:32:18Z,NONE
